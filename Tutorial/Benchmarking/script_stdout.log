DEBUG: Script execution started
DEBUG: Imported gc
DEBUG: Imported os
DEBUG: Imported numpy
DEBUG: Imported pandas
DEBUG: Imported torch
DEBUG: Imported BatchNorm1d
DEBUG: Imported torch.nn.functional
Error importing huggingface_hub.hf_api: No module named 'yaml'
DEBUG: Imported torch_geometric.data
DEBUG: Imported torch_geometric.loader
DEBUG: Imported torch_geometric.nn
DEBUG: Imported Bio.SeqIO
DEBUG: Imported Bio.AlignIO
DEBUG: Imported Bio.Align.AlignInfo
DEBUG: Imported Bio.PDB.PDBParser
DEBUG: Imported sklearn.preprocessing
DEBUG: Imported sklearn.svm
DEBUG: Imported sklearn.ensemble
DEBUG: Imported sklearn.linear_model
DEBUG: Imported sklearn.model_selection
DEBUG: Imported sklearn.metrics
DEBUG: Imported imblearn.over_sampling
DEBUG: Imported random
DEBUG: Imported subprocess
DEBUG: Imported logging
DEBUG: Imported joblib
DEBUG: Imported warnings
DEBUG: Imported matplotlib
DEBUG: Imported matplotlib.pyplot
DEBUG: Imported seaborn
DEBUG: Imported argparse
DEBUG: Imported json
DEBUG: Imported time
DEBUG: Imported Bio.Seq
DEBUG: Script started - imports completed
DEBUG: Setting matplotlib backend
DEBUG: Matplotlib backend set
DEBUG: Setting up logging
DEBUG: Logging setup complete, warnings ignored
DEBUG: Setting random seeds
DEBUG: CPU seeds set
DEBUG: Checking for CUDA device
DEBUG: Using device: cpu
DEBUG: Defining model class
DEBUG: Defining helper functions
DEBUG: Defining main pipeline function
DEBUG: Starting main script execution (__name__ == '__main__')
DEBUG: Parsing arguments
DEBUG: Arguments parsed: active_file=/home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/GPCR_Active_labeled.csv, inactive_file=/home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/GPCR_Inactive_labeled.csv
DEBUG: Setting up environment based on args
DEBUG: Using device: cpu
DEBUG: Creating output directory: /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking
DEBUG: Progress updated: Initializing...
DEBUG: Progress updated: Starting benchmarking pipeline...
DEBUG: Calling run_benchmarking_pipeline function...
DEBUG: Starting benchmarking pipeline with active_file=/home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/GPCR_Active_labeled.csv, inactive_file=/home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/GPCR_Inactive_labeled.csv
DEBUG: Output paths defined in directory: /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking
DEBUG: Progress updated: Preparing data...
DEBUG: SEED: 42, DEVICE: cpu
DEBUG: Reading active sequences
DEBUG: Reading sequence file /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/GPCR_Active_labeled.csv, is_active=True
DEBUG: Read 98 sequences
DEBUG: Reading inactive sequences
DEBUG: Reading sequence file /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/GPCR_Inactive_labeled.csv, is_active=False
DEBUG: Read 125 sequences
DEBUG: Reading wild type sequence
DEBUG: Reading FASTA file /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/wild_type.fasta
DEBUG: Read 1 sequences from FASTA
DEBUG: Progress updated: Extracting coordinates...
DEBUG: Extracting coordinates for active sequences
DEBUG: Extracted coordinates for 98 active sequences
DEBUG: Extracting coordinates for inactive sequences
DEBUG: Extracted coordinates for 125 inactive sequences
DEBUG: Progress updated: Loading features...
DEBUG: Loading property dictionaries
DEBUG: Loading dictionaries from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/amino_acid_properties.csv
DEBUG: Loaded 4 dictionaries
DEBUG: Writing combined sequences to combined_sequences.fasta
DEBUG: Writing active sequences to active_sequences.fasta
DEBUG: Writing inactive sequences to inactive_sequences.fasta
DEBUG: Progress updated: Calculating conservation scores...
DEBUG: Calculating conservation scores for active sequences
DEBUG: Calculating conservation scores from active_sequences.fasta
DEBUG: Running Clustal Omega: clustalo -i active_sequences.fasta -o aligned_sequences.aln --force --outfmt=clu
DEBUG: Clustal Omega completed successfully
DEBUG: Reading alignment file: aligned_sequences.aln
DEBUG: Alignment file read successfully
DEBUG: Calculated 130 conservation scores
DEBUG: Progress updated: Generating graphs...
DEBUG: Converting active sequences to graphs
DEBUG: Converting active sequence 1/98 to graph
DEBUG: Converting active sequence 2/98 to graph
DEBUG: Converting active sequence 3/98 to graph
DEBUG: Converting active sequence 4/98 to graph
DEBUG: Converting active sequence 5/98 to graph
DEBUG: Converting active sequence 6/98 to graph
DEBUG: Converting active sequence 7/98 to graph
DEBUG: Converting active sequence 8/98 to graph
DEBUG: Converting active sequence 9/98 to graph
DEBUG: Converting active sequence 10/98 to graph
DEBUG: Converting active sequence 11/98 to graph
DEBUG: Converting active sequence 12/98 to graph
DEBUG: Converting active sequence 13/98 to graph
DEBUG: Converting active sequence 14/98 to graph
DEBUG: Converting active sequence 15/98 to graph
DEBUG: Converting active sequence 16/98 to graph
DEBUG: Converting active sequence 17/98 to graph
DEBUG: Converting active sequence 18/98 to graph
DEBUG: Converting active sequence 19/98 to graph
DEBUG: Converting active sequence 20/98 to graph
DEBUG: Converting active sequence 21/98 to graph
DEBUG: Converting active sequence 22/98 to graph
DEBUG: Converting active sequence 23/98 to graph
DEBUG: Converting active sequence 24/98 to graph
DEBUG: Converting active sequence 25/98 to graph
DEBUG: Converting active sequence 26/98 to graph
DEBUG: Converting active sequence 27/98 to graph
DEBUG: Converting active sequence 28/98 to graph
DEBUG: Converting active sequence 29/98 to graph
DEBUG: Converting active sequence 30/98 to graph
DEBUG: Converting active sequence 31/98 to graph
DEBUG: Converting active sequence 32/98 to graph
DEBUG: Converting active sequence 33/98 to graph
DEBUG: Converting active sequence 34/98 to graph
DEBUG: Converting active sequence 35/98 to graph
DEBUG: Converting active sequence 36/98 to graph
DEBUG: Converting active sequence 37/98 to graph
DEBUG: Converting active sequence 38/98 to graph
DEBUG: Converting active sequence 39/98 to graph
DEBUG: Converting active sequence 40/98 to graph
DEBUG: Converting active sequence 41/98 to graph
DEBUG: Converting active sequence 42/98 to graph
DEBUG: Converting active sequence 43/98 to graph
DEBUG: Converting active sequence 44/98 to graph
DEBUG: Converting active sequence 45/98 to graph
DEBUG: Converting active sequence 46/98 to graph
DEBUG: Converting active sequence 47/98 to graph
DEBUG: Converting active sequence 48/98 to graph
DEBUG: Converting active sequence 49/98 to graph
DEBUG: Converting active sequence 50/98 to graph
DEBUG: Converting active sequence 51/98 to graph
DEBUG: Converting active sequence 52/98 to graph
DEBUG: Converting active sequence 53/98 to graph
DEBUG: Converting active sequence 54/98 to graph
DEBUG: Converting active sequence 55/98 to graph
DEBUG: Converting active sequence 56/98 to graph
DEBUG: Converting active sequence 57/98 to graph
DEBUG: Converting active sequence 58/98 to graph
DEBUG: Converting active sequence 59/98 to graph
DEBUG: Converting active sequence 60/98 to graph
DEBUG: Converting active sequence 61/98 to graph
DEBUG: Converting active sequence 62/98 to graph
DEBUG: Converting active sequence 63/98 to graph
DEBUG: Converting active sequence 64/98 to graph
DEBUG: Converting active sequence 65/98 to graph
DEBUG: Converting active sequence 66/98 to graph
DEBUG: Converting active sequence 67/98 to graph
DEBUG: Converting active sequence 68/98 to graph
DEBUG: Converting active sequence 69/98 to graph
DEBUG: Converting active sequence 70/98 to graph
DEBUG: Converting active sequence 71/98 to graph
DEBUG: Converting active sequence 72/98 to graph
DEBUG: Converting active sequence 73/98 to graph
DEBUG: Converting active sequence 74/98 to graph
DEBUG: Converting active sequence 75/98 to graph
DEBUG: Converting active sequence 76/98 to graph
DEBUG: Converting active sequence 77/98 to graph
DEBUG: Converting active sequence 78/98 to graph
DEBUG: Converting active sequence 79/98 to graph
DEBUG: Converting active sequence 80/98 to graph
DEBUG: Converting active sequence 81/98 to graph
DEBUG: Converting active sequence 82/98 to graph
DEBUG: Converting active sequence 83/98 to graph
DEBUG: Converting active sequence 84/98 to graph
DEBUG: Converting active sequence 85/98 to graph
DEBUG: Converting active sequence 86/98 to graph
DEBUG: Converting active sequence 87/98 to graph
DEBUG: Converting active sequence 88/98 to graph
DEBUG: Converting active sequence 89/98 to graph
DEBUG: Converting active sequence 90/98 to graph
DEBUG: Converting active sequence 91/98 to graph
DEBUG: Converting active sequence 92/98 to graph
DEBUG: Converting active sequence 93/98 to graph
DEBUG: Converting active sequence 94/98 to graph
DEBUG: Converting active sequence 95/98 to graph
DEBUG: Converting active sequence 96/98 to graph
DEBUG: Converting active sequence 97/98 to graph
DEBUG: Converting active sequence 98/98 to graph
DEBUG: Converted 98 active sequences to graphs
DEBUG: Calculating conservation scores for inactive sequences
DEBUG: Calculating conservation scores from inactive_sequences.fasta
DEBUG: Running Clustal Omega: clustalo -i inactive_sequences.fasta -o aligned_sequences.aln --force --outfmt=clu
DEBUG: Clustal Omega completed successfully
DEBUG: Reading alignment file: aligned_sequences.aln
DEBUG: Alignment file read successfully
DEBUG: Calculated 130 conservation scores
DEBUG: Converting inactive sequences to graphs
DEBUG: Converting inactive sequence 1/125 to graph
DEBUG: Converting inactive sequence 2/125 to graph
DEBUG: Converting inactive sequence 3/125 to graph
DEBUG: Converting inactive sequence 4/125 to graph
DEBUG: Converting inactive sequence 5/125 to graph
DEBUG: Converting inactive sequence 6/125 to graph
DEBUG: Converting inactive sequence 7/125 to graph
DEBUG: Converting inactive sequence 8/125 to graph
DEBUG: Converting inactive sequence 9/125 to graph
DEBUG: Converting inactive sequence 10/125 to graph
DEBUG: Converting inactive sequence 11/125 to graph
DEBUG: Converting inactive sequence 12/125 to graph
DEBUG: Converting inactive sequence 13/125 to graph
DEBUG: Converting inactive sequence 14/125 to graph
DEBUG: Converting inactive sequence 15/125 to graph
DEBUG: Converting inactive sequence 16/125 to graph
DEBUG: Converting inactive sequence 17/125 to graph
DEBUG: Converting inactive sequence 18/125 to graph
DEBUG: Converting inactive sequence 19/125 to graph
DEBUG: Converting inactive sequence 20/125 to graph
DEBUG: Converting inactive sequence 21/125 to graph
DEBUG: Converting inactive sequence 22/125 to graph
DEBUG: Converting inactive sequence 23/125 to graph
DEBUG: Converting inactive sequence 24/125 to graph
DEBUG: Converting inactive sequence 25/125 to graph
DEBUG: Converting inactive sequence 26/125 to graph
DEBUG: Converting inactive sequence 27/125 to graph
DEBUG: Converting inactive sequence 28/125 to graph
DEBUG: Converting inactive sequence 29/125 to graph
DEBUG: Converting inactive sequence 30/125 to graph
DEBUG: Converting inactive sequence 31/125 to graph
DEBUG: Converting inactive sequence 32/125 to graph
DEBUG: Converting inactive sequence 33/125 to graph
DEBUG: Converting inactive sequence 34/125 to graph
DEBUG: Converting inactive sequence 35/125 to graph
DEBUG: Converting inactive sequence 36/125 to graph
DEBUG: Converting inactive sequence 37/125 to graph
DEBUG: Converting inactive sequence 38/125 to graph
DEBUG: Converting inactive sequence 39/125 to graph
DEBUG: Converting inactive sequence 40/125 to graph
DEBUG: Converting inactive sequence 41/125 to graph
DEBUG: Converting inactive sequence 42/125 to graph
DEBUG: Converting inactive sequence 43/125 to graph
DEBUG: Converting inactive sequence 44/125 to graph
DEBUG: Converting inactive sequence 45/125 to graph
DEBUG: Converting inactive sequence 46/125 to graph
DEBUG: Converting inactive sequence 47/125 to graph
DEBUG: Converting inactive sequence 48/125 to graph
DEBUG: Converting inactive sequence 49/125 to graph
DEBUG: Converting inactive sequence 50/125 to graph
DEBUG: Converting inactive sequence 51/125 to graph
DEBUG: Converting inactive sequence 52/125 to graph
DEBUG: Converting inactive sequence 53/125 to graph
DEBUG: Converting inactive sequence 54/125 to graph
DEBUG: Converting inactive sequence 55/125 to graph
DEBUG: Converting inactive sequence 56/125 to graph
DEBUG: Converting inactive sequence 57/125 to graph
DEBUG: Converting inactive sequence 58/125 to graph
DEBUG: Converting inactive sequence 59/125 to graph
DEBUG: Converting inactive sequence 60/125 to graph
DEBUG: Converting inactive sequence 61/125 to graph
DEBUG: Converting inactive sequence 62/125 to graph
DEBUG: Converting inactive sequence 63/125 to graph
DEBUG: Converting inactive sequence 64/125 to graph
DEBUG: Converting inactive sequence 65/125 to graph
DEBUG: Converting inactive sequence 66/125 to graph
DEBUG: Converting inactive sequence 67/125 to graph
DEBUG: Converting inactive sequence 68/125 to graph
DEBUG: Converting inactive sequence 69/125 to graph
DEBUG: Converting inactive sequence 70/125 to graph
DEBUG: Converting inactive sequence 71/125 to graph
DEBUG: Converting inactive sequence 72/125 to graph
DEBUG: Converting inactive sequence 73/125 to graph
DEBUG: Converting inactive sequence 74/125 to graph
DEBUG: Converting inactive sequence 75/125 to graph
DEBUG: Converting inactive sequence 76/125 to graph
DEBUG: Converting inactive sequence 77/125 to graph
DEBUG: Converting inactive sequence 78/125 to graph
DEBUG: Converting inactive sequence 79/125 to graph
DEBUG: Converting inactive sequence 80/125 to graph
DEBUG: Converting inactive sequence 81/125 to graph
DEBUG: Converting inactive sequence 82/125 to graph
DEBUG: Converting inactive sequence 83/125 to graph
DEBUG: Converting inactive sequence 84/125 to graph
DEBUG: Converting inactive sequence 85/125 to graph
DEBUG: Converting inactive sequence 86/125 to graph
DEBUG: Converting inactive sequence 87/125 to graph
DEBUG: Converting inactive sequence 88/125 to graph
DEBUG: Converting inactive sequence 89/125 to graph
DEBUG: Converting inactive sequence 90/125 to graph
DEBUG: Converting inactive sequence 91/125 to graph
DEBUG: Converting inactive sequence 92/125 to graph
DEBUG: Converting inactive sequence 93/125 to graph
DEBUG: Converting inactive sequence 94/125 to graph
DEBUG: Converting inactive sequence 95/125 to graph
DEBUG: Converting inactive sequence 96/125 to graph
DEBUG: Converting inactive sequence 97/125 to graph
DEBUG: Converting inactive sequence 98/125 to graph
DEBUG: Converting inactive sequence 99/125 to graph
DEBUG: Converting inactive sequence 100/125 to graph
DEBUG: Converting inactive sequence 101/125 to graph
DEBUG: Converting inactive sequence 102/125 to graph
DEBUG: Converting inactive sequence 103/125 to graph
DEBUG: Converting inactive sequence 104/125 to graph
DEBUG: Converting inactive sequence 105/125 to graph
DEBUG: Converting inactive sequence 106/125 to graph
DEBUG: Converting inactive sequence 107/125 to graph
DEBUG: Converting inactive sequence 108/125 to graph
DEBUG: Converting inactive sequence 109/125 to graph
DEBUG: Converting inactive sequence 110/125 to graph
DEBUG: Converting inactive sequence 111/125 to graph
DEBUG: Converting inactive sequence 112/125 to graph
DEBUG: Converting inactive sequence 113/125 to graph
DEBUG: Converting inactive sequence 114/125 to graph
DEBUG: Converting inactive sequence 115/125 to graph
DEBUG: Converting inactive sequence 116/125 to graph
DEBUG: Converting inactive sequence 117/125 to graph
DEBUG: Converting inactive sequence 118/125 to graph
DEBUG: Converting inactive sequence 119/125 to graph
DEBUG: Converting inactive sequence 120/125 to graph
DEBUG: Converting inactive sequence 121/125 to graph
DEBUG: Converting inactive sequence 122/125 to graph
DEBUG: Converting inactive sequence 123/125 to graph
DEBUG: Converting inactive sequence 124/125 to graph
DEBUG: Converting inactive sequence 125/125 to graph
DEBUG: Converted 125 inactive sequences to graphs
DEBUG: Combined 223 features with 223 labels
DEBUG: Progress updated: Splitting data...
DEBUG: Splitting data into train/test sets
DEBUG: Split data: train=178, test=45
DEBUG: Progress updated: Resampling data...
DEBUG: Resampling minority class
DEBUG: Minority class count: 78
DEBUG: Using SMOTE with k_neighbors=10
DEBUG: Fitting resampler
DEBUG: Resampled to 200 samples
DEBUG: Creating resampled training features
DEBUG: Created 200 resampled training features
DEBUG: Creating datasets
DEBUG: Created datasets: train=200, test=45
DEBUG: Using batch_size=64
DEBUG: Initializing DataLoaders...
DEBUG: DataLoaders initialized.
DEBUG: Created DataLoaders: train=4, test=1
DEBUG: Progress updated: Initializing model...
DEBUG: Initializing model
DEBUG: Model parameters: input_dim=5, hidden_dim=128, dropout_rate=0.25, ratio=0.7
DEBUG: Initializing model with in_features=5, hidden_features=128
DEBUG: Model layers initialized
DEBUG: Model initialized and moved to device
DEBUG: Calculating class weights
DEBUG: Class weights: pos_weight=1.2755101919174194
DEBUG: Setting up loss function, optimizer, and scheduler
DEBUG: Using optimizer=AdamW, learning_rate=1e-05
DEBUG: Training parameters: epochs=1000, early_stop_patience=50
DEBUG: Progress updated: Starting training loop...
DEBUG: Setup before training loop completed.
DEBUG: Entering main training loop...

--- Starting Epoch 1/1000 ---
Epoch 1: Starting training phase (4 batches)
  Epoch 1, Batch 1/4: Loading data to device...
  Epoch 1, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 1, Batch 1/4: Zeroing gradients...
  Epoch 1, Batch 1/4: Forward pass...
  Epoch 1, Batch 1/4: Calculating loss...
  Epoch 1, Batch 1/4: Backward pass...
  Epoch 1, Batch 1/4: Clipping gradients...
  Epoch 1, Batch 1/4: Optimizer step...
  Epoch 1, Batch 1/4: Completed in 1.01s
  Epoch 1, Batch 2/4: Loading data to device...
  Epoch 1, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 1, Batch 2/4: Zeroing gradients...
  Epoch 1, Batch 2/4: Forward pass...
  Epoch 1, Batch 2/4: Calculating loss...
  Epoch 1, Batch 2/4: Backward pass...
  Epoch 1, Batch 2/4: Clipping gradients...
  Epoch 1, Batch 2/4: Optimizer step...
  Epoch 1, Batch 2/4: Completed in 0.23s
  Epoch 1, Batch 3/4: Loading data to device...
  Epoch 1, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 1, Batch 3/4: Zeroing gradients...
  Epoch 1, Batch 3/4: Forward pass...
  Epoch 1, Batch 3/4: Calculating loss...
  Epoch 1, Batch 3/4: Backward pass...
  Epoch 1, Batch 3/4: Clipping gradients...
  Epoch 1, Batch 3/4: Optimizer step...
  Epoch 1, Batch 3/4: Completed in 0.23s
  Epoch 1, Batch 4/4: Loading data to device...
  Epoch 1, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 1, Batch 4/4: Zeroing gradients...
  Epoch 1, Batch 4/4: Forward pass...
  Epoch 1, Batch 4/4: Calculating loss...
  Epoch 1, Batch 4/4: Backward pass...
  Epoch 1, Batch 4/4: Clipping gradients...
  Epoch 1, Batch 4/4: Optimizer step...
  Epoch 1, Batch 4/4: Completed in 0.03s
Epoch 1: Training phase completed. Average Train Loss: 0.7567
Epoch 1: Starting validation phase...
  Epoch 1, Val Batch 1/1: Loading data...
  Epoch 1, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 1, Val Batch 1/1: Forward pass...
  Epoch 1, Val Batch 1/1: Calculating loss...
Epoch 1: Validation phase completed. Average Val Loss: 0.7883
Epoch 1 Summary ---> Train Loss: 0.7567 / Validation Loss: 0.7883
Epoch 1: Checking early stopping... (Current Best Loss: inf, Epochs No Improve: 0)
  Epoch 1: Validation loss improved (inf --> 0.7883). Saving model.
Epoch 1: Stepping scheduler...
--- Epoch 1 completed in 1.71 seconds ---

--- Starting Epoch 2/1000 ---
Epoch 2: Starting training phase (4 batches)
  Epoch 2, Batch 1/4: Loading data to device...
  Epoch 2, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 2, Batch 1/4: Zeroing gradients...
  Epoch 2, Batch 1/4: Forward pass...
  Epoch 2, Batch 1/4: Calculating loss...
  Epoch 2, Batch 1/4: Backward pass...
  Epoch 2, Batch 1/4: Clipping gradients...
  Epoch 2, Batch 1/4: Optimizer step...
  Epoch 2, Batch 1/4: Completed in 0.21s
  Epoch 2, Batch 2/4: Loading data to device...
  Epoch 2, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 2, Batch 2/4: Zeroing gradients...
  Epoch 2, Batch 2/4: Forward pass...
  Epoch 2, Batch 2/4: Calculating loss...
  Epoch 2, Batch 2/4: Backward pass...
  Epoch 2, Batch 2/4: Clipping gradients...
  Epoch 2, Batch 2/4: Optimizer step...
  Epoch 2, Batch 2/4: Completed in 0.20s
  Epoch 2, Batch 3/4: Loading data to device...
  Epoch 2, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 2, Batch 3/4: Zeroing gradients...
  Epoch 2, Batch 3/4: Forward pass...
  Epoch 2, Batch 3/4: Calculating loss...
  Epoch 2, Batch 3/4: Backward pass...
  Epoch 2, Batch 3/4: Clipping gradients...
  Epoch 2, Batch 3/4: Optimizer step...
  Epoch 2, Batch 3/4: Completed in 0.20s
  Epoch 2, Batch 4/4: Loading data to device...
  Epoch 2, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 2, Batch 4/4: Zeroing gradients...
  Epoch 2, Batch 4/4: Forward pass...
  Epoch 2, Batch 4/4: Calculating loss...
  Epoch 2, Batch 4/4: Backward pass...
  Epoch 2, Batch 4/4: Clipping gradients...
  Epoch 2, Batch 4/4: Optimizer step...
  Epoch 2, Batch 4/4: Completed in 0.03s
Epoch 2: Training phase completed. Average Train Loss: 0.7685
Epoch 2: Starting validation phase...
  Epoch 2, Val Batch 1/1: Loading data...
  Epoch 2, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 2, Val Batch 1/1: Forward pass...
  Epoch 2, Val Batch 1/1: Calculating loss...
Epoch 2: Validation phase completed. Average Val Loss: 0.7805
Epoch 2 Summary ---> Train Loss: 0.7685 / Validation Loss: 0.7805
Epoch 2: Checking early stopping... (Current Best Loss: 0.7883, Epochs No Improve: 0)
  Epoch 2: Validation loss improved (0.7883 --> 0.7805). Saving model.
Epoch 2: Stepping scheduler...
--- Epoch 2 completed in 0.72 seconds ---

--- Starting Epoch 3/1000 ---
Epoch 3: Starting training phase (4 batches)
  Epoch 3, Batch 1/4: Loading data to device...
  Epoch 3, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 3, Batch 1/4: Zeroing gradients...
  Epoch 3, Batch 1/4: Forward pass...
  Epoch 3, Batch 1/4: Calculating loss...
  Epoch 3, Batch 1/4: Backward pass...
  Epoch 3, Batch 1/4: Clipping gradients...
  Epoch 3, Batch 1/4: Optimizer step...
  Epoch 3, Batch 1/4: Completed in 0.20s
  Epoch 3, Batch 2/4: Loading data to device...
  Epoch 3, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 3, Batch 2/4: Zeroing gradients...
  Epoch 3, Batch 2/4: Forward pass...
  Epoch 3, Batch 2/4: Calculating loss...
  Epoch 3, Batch 2/4: Backward pass...
  Epoch 3, Batch 2/4: Clipping gradients...
  Epoch 3, Batch 2/4: Optimizer step...
  Epoch 3, Batch 2/4: Completed in 0.20s
  Epoch 3, Batch 3/4: Loading data to device...
  Epoch 3, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 3, Batch 3/4: Zeroing gradients...
  Epoch 3, Batch 3/4: Forward pass...
  Epoch 3, Batch 3/4: Calculating loss...
  Epoch 3, Batch 3/4: Backward pass...
  Epoch 3, Batch 3/4: Clipping gradients...
  Epoch 3, Batch 3/4: Optimizer step...
  Epoch 3, Batch 3/4: Completed in 0.20s
  Epoch 3, Batch 4/4: Loading data to device...
  Epoch 3, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 3, Batch 4/4: Zeroing gradients...
  Epoch 3, Batch 4/4: Forward pass...
  Epoch 3, Batch 4/4: Calculating loss...
  Epoch 3, Batch 4/4: Backward pass...
  Epoch 3, Batch 4/4: Clipping gradients...
  Epoch 3, Batch 4/4: Optimizer step...
  Epoch 3, Batch 4/4: Completed in 0.03s
Epoch 3: Training phase completed. Average Train Loss: 0.7474
Epoch 3: Starting validation phase...
  Epoch 3, Val Batch 1/1: Loading data...
  Epoch 3, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 3, Val Batch 1/1: Forward pass...
  Epoch 3, Val Batch 1/1: Calculating loss...
Epoch 3: Validation phase completed. Average Val Loss: 0.7797
Epoch 3 Summary ---> Train Loss: 0.7474 / Validation Loss: 0.7797
Epoch 3: Checking early stopping... (Current Best Loss: 0.7805, Epochs No Improve: 0)
  Epoch 3: Validation loss improved (0.7805 --> 0.7797). Saving model.
Epoch 3: Stepping scheduler...
--- Epoch 3 completed in 0.71 seconds ---

--- Starting Epoch 4/1000 ---
Epoch 4: Starting training phase (4 batches)
  Epoch 4, Batch 1/4: Loading data to device...
  Epoch 4, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 4, Batch 1/4: Zeroing gradients...
  Epoch 4, Batch 1/4: Forward pass...
  Epoch 4, Batch 1/4: Calculating loss...
  Epoch 4, Batch 1/4: Backward pass...
  Epoch 4, Batch 1/4: Clipping gradients...
  Epoch 4, Batch 1/4: Optimizer step...
  Epoch 4, Batch 1/4: Completed in 0.19s
  Epoch 4, Batch 2/4: Loading data to device...
  Epoch 4, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 4, Batch 2/4: Zeroing gradients...
  Epoch 4, Batch 2/4: Forward pass...
  Epoch 4, Batch 2/4: Calculating loss...
  Epoch 4, Batch 2/4: Backward pass...
  Epoch 4, Batch 2/4: Clipping gradients...
  Epoch 4, Batch 2/4: Optimizer step...
  Epoch 4, Batch 2/4: Completed in 0.19s
  Epoch 4, Batch 3/4: Loading data to device...
  Epoch 4, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 4, Batch 3/4: Zeroing gradients...
  Epoch 4, Batch 3/4: Forward pass...
  Epoch 4, Batch 3/4: Calculating loss...
  Epoch 4, Batch 3/4: Backward pass...
  Epoch 4, Batch 3/4: Clipping gradients...
  Epoch 4, Batch 3/4: Optimizer step...
  Epoch 4, Batch 3/4: Completed in 0.20s
  Epoch 4, Batch 4/4: Loading data to device...
  Epoch 4, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 4, Batch 4/4: Zeroing gradients...
  Epoch 4, Batch 4/4: Forward pass...
  Epoch 4, Batch 4/4: Calculating loss...
  Epoch 4, Batch 4/4: Backward pass...
  Epoch 4, Batch 4/4: Clipping gradients...
  Epoch 4, Batch 4/4: Optimizer step...
  Epoch 4, Batch 4/4: Completed in 0.03s
Epoch 4: Training phase completed. Average Train Loss: 0.7324
Epoch 4: Starting validation phase...
  Epoch 4, Val Batch 1/1: Loading data...
  Epoch 4, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 4, Val Batch 1/1: Forward pass...
  Epoch 4, Val Batch 1/1: Calculating loss...
Epoch 4: Validation phase completed. Average Val Loss: 0.7810
Epoch 4 Summary ---> Train Loss: 0.7324 / Validation Loss: 0.7810
Epoch 4: Checking early stopping... (Current Best Loss: 0.7797, Epochs No Improve: 0)
  Epoch 4: Validation loss did not improve. Epochs without improvement: 1
Epoch 4: Stepping scheduler...
--- Epoch 4 completed in 0.68 seconds ---

--- Starting Epoch 5/1000 ---
Epoch 5: Starting training phase (4 batches)
  Epoch 5, Batch 1/4: Loading data to device...
  Epoch 5, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 5, Batch 1/4: Zeroing gradients...
  Epoch 5, Batch 1/4: Forward pass...
  Epoch 5, Batch 1/4: Calculating loss...
  Epoch 5, Batch 1/4: Backward pass...
  Epoch 5, Batch 1/4: Clipping gradients...
  Epoch 5, Batch 1/4: Optimizer step...
  Epoch 5, Batch 1/4: Completed in 0.20s
  Epoch 5, Batch 2/4: Loading data to device...
  Epoch 5, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 5, Batch 2/4: Zeroing gradients...
  Epoch 5, Batch 2/4: Forward pass...
  Epoch 5, Batch 2/4: Calculating loss...
  Epoch 5, Batch 2/4: Backward pass...
  Epoch 5, Batch 2/4: Clipping gradients...
  Epoch 5, Batch 2/4: Optimizer step...
  Epoch 5, Batch 2/4: Completed in 0.19s
  Epoch 5, Batch 3/4: Loading data to device...
  Epoch 5, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 5, Batch 3/4: Zeroing gradients...
  Epoch 5, Batch 3/4: Forward pass...
  Epoch 5, Batch 3/4: Calculating loss...
  Epoch 5, Batch 3/4: Backward pass...
  Epoch 5, Batch 3/4: Clipping gradients...
  Epoch 5, Batch 3/4: Optimizer step...
  Epoch 5, Batch 3/4: Completed in 0.19s
  Epoch 5, Batch 4/4: Loading data to device...
  Epoch 5, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 5, Batch 4/4: Zeroing gradients...
  Epoch 5, Batch 4/4: Forward pass...
  Epoch 5, Batch 4/4: Calculating loss...
  Epoch 5, Batch 4/4: Backward pass...
  Epoch 5, Batch 4/4: Clipping gradients...
  Epoch 5, Batch 4/4: Optimizer step...
  Epoch 5, Batch 4/4: Completed in 0.03s
Epoch 5: Training phase completed. Average Train Loss: 0.7045
Epoch 5: Starting validation phase...
  Epoch 5, Val Batch 1/1: Loading data...
  Epoch 5, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 5, Val Batch 1/1: Forward pass...
  Epoch 5, Val Batch 1/1: Calculating loss...
Epoch 5: Validation phase completed. Average Val Loss: 0.7820
Epoch 5 Summary ---> Train Loss: 0.7045 / Validation Loss: 0.7820
Epoch 5: Checking early stopping... (Current Best Loss: 0.7797, Epochs No Improve: 1)
  Epoch 5: Validation loss did not improve. Epochs without improvement: 2
Epoch 5: Stepping scheduler...
--- Epoch 5 completed in 0.67 seconds ---

--- Starting Epoch 6/1000 ---
Epoch 6: Starting training phase (4 batches)
  Epoch 6, Batch 1/4: Loading data to device...
  Epoch 6, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 6, Batch 1/4: Zeroing gradients...
  Epoch 6, Batch 1/4: Forward pass...
  Epoch 6, Batch 1/4: Calculating loss...
  Epoch 6, Batch 1/4: Backward pass...
  Epoch 6, Batch 1/4: Clipping gradients...
  Epoch 6, Batch 1/4: Optimizer step...
  Epoch 6, Batch 1/4: Completed in 0.19s
  Epoch 6, Batch 2/4: Loading data to device...
  Epoch 6, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 6, Batch 2/4: Zeroing gradients...
  Epoch 6, Batch 2/4: Forward pass...
  Epoch 6, Batch 2/4: Calculating loss...
  Epoch 6, Batch 2/4: Backward pass...
  Epoch 6, Batch 2/4: Clipping gradients...
  Epoch 6, Batch 2/4: Optimizer step...
  Epoch 6, Batch 2/4: Completed in 0.19s
  Epoch 6, Batch 3/4: Loading data to device...
  Epoch 6, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 6, Batch 3/4: Zeroing gradients...
  Epoch 6, Batch 3/4: Forward pass...
  Epoch 6, Batch 3/4: Calculating loss...
  Epoch 6, Batch 3/4: Backward pass...
  Epoch 6, Batch 3/4: Clipping gradients...
  Epoch 6, Batch 3/4: Optimizer step...
  Epoch 6, Batch 3/4: Completed in 0.20s
  Epoch 6, Batch 4/4: Loading data to device...
  Epoch 6, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 6, Batch 4/4: Zeroing gradients...
  Epoch 6, Batch 4/4: Forward pass...
  Epoch 6, Batch 4/4: Calculating loss...
  Epoch 6, Batch 4/4: Backward pass...
  Epoch 6, Batch 4/4: Clipping gradients...
  Epoch 6, Batch 4/4: Optimizer step...
  Epoch 6, Batch 4/4: Completed in 0.03s
Epoch 6: Training phase completed. Average Train Loss: 0.7031
Epoch 6: Starting validation phase...
  Epoch 6, Val Batch 1/1: Loading data...
  Epoch 6, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 6, Val Batch 1/1: Forward pass...
  Epoch 6, Val Batch 1/1: Calculating loss...
Epoch 6: Validation phase completed. Average Val Loss: 0.7805
Epoch 6 Summary ---> Train Loss: 0.7031 / Validation Loss: 0.7805
Epoch 6: Checking early stopping... (Current Best Loss: 0.7797, Epochs No Improve: 2)
  Epoch 6: Validation loss did not improve. Epochs without improvement: 3
Epoch 6: Stepping scheduler...
--- Epoch 6 completed in 0.69 seconds ---

--- Starting Epoch 7/1000 ---
Epoch 7: Starting training phase (4 batches)
  Epoch 7, Batch 1/4: Loading data to device...
  Epoch 7, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 7, Batch 1/4: Zeroing gradients...
  Epoch 7, Batch 1/4: Forward pass...
  Epoch 7, Batch 1/4: Calculating loss...
  Epoch 7, Batch 1/4: Backward pass...
  Epoch 7, Batch 1/4: Clipping gradients...
  Epoch 7, Batch 1/4: Optimizer step...
  Epoch 7, Batch 1/4: Completed in 0.20s
  Epoch 7, Batch 2/4: Loading data to device...
  Epoch 7, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 7, Batch 2/4: Zeroing gradients...
  Epoch 7, Batch 2/4: Forward pass...
  Epoch 7, Batch 2/4: Calculating loss...
  Epoch 7, Batch 2/4: Backward pass...
  Epoch 7, Batch 2/4: Clipping gradients...
  Epoch 7, Batch 2/4: Optimizer step...
  Epoch 7, Batch 2/4: Completed in 0.19s
  Epoch 7, Batch 3/4: Loading data to device...
  Epoch 7, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 7, Batch 3/4: Zeroing gradients...
  Epoch 7, Batch 3/4: Forward pass...
  Epoch 7, Batch 3/4: Calculating loss...
  Epoch 7, Batch 3/4: Backward pass...
  Epoch 7, Batch 3/4: Clipping gradients...
  Epoch 7, Batch 3/4: Optimizer step...
  Epoch 7, Batch 3/4: Completed in 0.19s
  Epoch 7, Batch 4/4: Loading data to device...
  Epoch 7, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 7, Batch 4/4: Zeroing gradients...
  Epoch 7, Batch 4/4: Forward pass...
  Epoch 7, Batch 4/4: Calculating loss...
  Epoch 7, Batch 4/4: Backward pass...
  Epoch 7, Batch 4/4: Clipping gradients...
  Epoch 7, Batch 4/4: Optimizer step...
  Epoch 7, Batch 4/4: Completed in 0.04s
Epoch 7: Training phase completed. Average Train Loss: 0.7094
Epoch 7: Starting validation phase...
  Epoch 7, Val Batch 1/1: Loading data...
  Epoch 7, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 7, Val Batch 1/1: Forward pass...
  Epoch 7, Val Batch 1/1: Calculating loss...
Epoch 7: Validation phase completed. Average Val Loss: 0.7740
Epoch 7 Summary ---> Train Loss: 0.7094 / Validation Loss: 0.7740
Epoch 7: Checking early stopping... (Current Best Loss: 0.7797, Epochs No Improve: 3)
  Epoch 7: Validation loss improved (0.7797 --> 0.7740). Saving model.
Epoch 7: Stepping scheduler...
--- Epoch 7 completed in 0.69 seconds ---

--- Starting Epoch 8/1000 ---
Epoch 8: Starting training phase (4 batches)
  Epoch 8, Batch 1/4: Loading data to device...
  Epoch 8, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 8, Batch 1/4: Zeroing gradients...
  Epoch 8, Batch 1/4: Forward pass...
  Epoch 8, Batch 1/4: Calculating loss...
  Epoch 8, Batch 1/4: Backward pass...
  Epoch 8, Batch 1/4: Clipping gradients...
  Epoch 8, Batch 1/4: Optimizer step...
  Epoch 8, Batch 1/4: Completed in 0.19s
  Epoch 8, Batch 2/4: Loading data to device...
  Epoch 8, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 8, Batch 2/4: Zeroing gradients...
  Epoch 8, Batch 2/4: Forward pass...
  Epoch 8, Batch 2/4: Calculating loss...
  Epoch 8, Batch 2/4: Backward pass...
  Epoch 8, Batch 2/4: Clipping gradients...
  Epoch 8, Batch 2/4: Optimizer step...
  Epoch 8, Batch 2/4: Completed in 0.19s
  Epoch 8, Batch 3/4: Loading data to device...
  Epoch 8, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 8, Batch 3/4: Zeroing gradients...
  Epoch 8, Batch 3/4: Forward pass...
  Epoch 8, Batch 3/4: Calculating loss...
  Epoch 8, Batch 3/4: Backward pass...
  Epoch 8, Batch 3/4: Clipping gradients...
  Epoch 8, Batch 3/4: Optimizer step...
  Epoch 8, Batch 3/4: Completed in 0.19s
  Epoch 8, Batch 4/4: Loading data to device...
  Epoch 8, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 8, Batch 4/4: Zeroing gradients...
  Epoch 8, Batch 4/4: Forward pass...
  Epoch 8, Batch 4/4: Calculating loss...
  Epoch 8, Batch 4/4: Backward pass...
  Epoch 8, Batch 4/4: Clipping gradients...
  Epoch 8, Batch 4/4: Optimizer step...
  Epoch 8, Batch 4/4: Completed in 0.03s
Epoch 8: Training phase completed. Average Train Loss: 0.6456
Epoch 8: Starting validation phase...
  Epoch 8, Val Batch 1/1: Loading data...
  Epoch 8, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 8, Val Batch 1/1: Forward pass...
  Epoch 8, Val Batch 1/1: Calculating loss...
Epoch 8: Validation phase completed. Average Val Loss: 0.7713
Epoch 8 Summary ---> Train Loss: 0.6456 / Validation Loss: 0.7713
Epoch 8: Checking early stopping... (Current Best Loss: 0.7740, Epochs No Improve: 0)
  Epoch 8: Validation loss improved (0.7740 --> 0.7713). Saving model.
Epoch 8: Stepping scheduler...
--- Epoch 8 completed in 0.67 seconds ---

--- Starting Epoch 9/1000 ---
Epoch 9: Starting training phase (4 batches)
  Epoch 9, Batch 1/4: Loading data to device...
  Epoch 9, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 9, Batch 1/4: Zeroing gradients...
  Epoch 9, Batch 1/4: Forward pass...
  Epoch 9, Batch 1/4: Calculating loss...
  Epoch 9, Batch 1/4: Backward pass...
  Epoch 9, Batch 1/4: Clipping gradients...
  Epoch 9, Batch 1/4: Optimizer step...
  Epoch 9, Batch 1/4: Completed in 0.19s
  Epoch 9, Batch 2/4: Loading data to device...
  Epoch 9, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 9, Batch 2/4: Zeroing gradients...
  Epoch 9, Batch 2/4: Forward pass...
  Epoch 9, Batch 2/4: Calculating loss...
  Epoch 9, Batch 2/4: Backward pass...
  Epoch 9, Batch 2/4: Clipping gradients...
  Epoch 9, Batch 2/4: Optimizer step...
  Epoch 9, Batch 2/4: Completed in 0.19s
  Epoch 9, Batch 3/4: Loading data to device...
  Epoch 9, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 9, Batch 3/4: Zeroing gradients...
  Epoch 9, Batch 3/4: Forward pass...
  Epoch 9, Batch 3/4: Calculating loss...
  Epoch 9, Batch 3/4: Backward pass...
  Epoch 9, Batch 3/4: Clipping gradients...
  Epoch 9, Batch 3/4: Optimizer step...
  Epoch 9, Batch 3/4: Completed in 0.20s
  Epoch 9, Batch 4/4: Loading data to device...
  Epoch 9, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 9, Batch 4/4: Zeroing gradients...
  Epoch 9, Batch 4/4: Forward pass...
  Epoch 9, Batch 4/4: Calculating loss...
  Epoch 9, Batch 4/4: Backward pass...
  Epoch 9, Batch 4/4: Clipping gradients...
  Epoch 9, Batch 4/4: Optimizer step...
  Epoch 9, Batch 4/4: Completed in 0.03s
Epoch 9: Training phase completed. Average Train Loss: 0.7092
Epoch 9: Starting validation phase...
  Epoch 9, Val Batch 1/1: Loading data...
  Epoch 9, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 9, Val Batch 1/1: Forward pass...
  Epoch 9, Val Batch 1/1: Calculating loss...
Epoch 9: Validation phase completed. Average Val Loss: 0.7712
Epoch 9 Summary ---> Train Loss: 0.7092 / Validation Loss: 0.7712
Epoch 9: Checking early stopping... (Current Best Loss: 0.7713, Epochs No Improve: 0)
  Epoch 9: Validation loss improved (0.7713 --> 0.7712). Saving model.
Epoch 9: Stepping scheduler...
--- Epoch 9 completed in 0.68 seconds ---

--- Starting Epoch 10/1000 ---
Epoch 10: Starting training phase (4 batches)
  Epoch 10, Batch 1/4: Loading data to device...
  Epoch 10, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 10, Batch 1/4: Zeroing gradients...
  Epoch 10, Batch 1/4: Forward pass...
  Epoch 10, Batch 1/4: Calculating loss...
  Epoch 10, Batch 1/4: Backward pass...
  Epoch 10, Batch 1/4: Clipping gradients...
  Epoch 10, Batch 1/4: Optimizer step...
  Epoch 10, Batch 1/4: Completed in 0.19s
  Epoch 10, Batch 2/4: Loading data to device...
  Epoch 10, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 10, Batch 2/4: Zeroing gradients...
  Epoch 10, Batch 2/4: Forward pass...
  Epoch 10, Batch 2/4: Calculating loss...
  Epoch 10, Batch 2/4: Backward pass...
  Epoch 10, Batch 2/4: Clipping gradients...
  Epoch 10, Batch 2/4: Optimizer step...
  Epoch 10, Batch 2/4: Completed in 0.19s
  Epoch 10, Batch 3/4: Loading data to device...
  Epoch 10, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 10, Batch 3/4: Zeroing gradients...
  Epoch 10, Batch 3/4: Forward pass...
  Epoch 10, Batch 3/4: Calculating loss...
  Epoch 10, Batch 3/4: Backward pass...
  Epoch 10, Batch 3/4: Clipping gradients...
  Epoch 10, Batch 3/4: Optimizer step...
  Epoch 10, Batch 3/4: Completed in 0.20s
  Epoch 10, Batch 4/4: Loading data to device...
  Epoch 10, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 10, Batch 4/4: Zeroing gradients...
  Epoch 10, Batch 4/4: Forward pass...
  Epoch 10, Batch 4/4: Calculating loss...
  Epoch 10, Batch 4/4: Backward pass...
  Epoch 10, Batch 4/4: Clipping gradients...
  Epoch 10, Batch 4/4: Optimizer step...
  Epoch 10, Batch 4/4: Completed in 0.03s
Epoch 10: Training phase completed. Average Train Loss: 0.7424
Epoch 10: Starting validation phase...
  Epoch 10, Val Batch 1/1: Loading data...
  Epoch 10, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 10, Val Batch 1/1: Forward pass...
  Epoch 10, Val Batch 1/1: Calculating loss...
Epoch 10: Validation phase completed. Average Val Loss: 0.7710
Epoch 10 Summary ---> Train Loss: 0.7424 / Validation Loss: 0.7710
Epoch 10: Checking early stopping... (Current Best Loss: 0.7712, Epochs No Improve: 0)
  Epoch 10: Validation loss improved (0.7712 --> 0.7710). Saving model.
Epoch 10: Stepping scheduler...
--- Epoch 10 completed in 0.69 seconds ---

--- Starting Epoch 11/1000 ---
Epoch 11: Starting training phase (4 batches)
  Epoch 11, Batch 1/4: Loading data to device...
  Epoch 11, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 11, Batch 1/4: Zeroing gradients...
  Epoch 11, Batch 1/4: Forward pass...
  Epoch 11, Batch 1/4: Calculating loss...
  Epoch 11, Batch 1/4: Backward pass...
  Epoch 11, Batch 1/4: Clipping gradients...
  Epoch 11, Batch 1/4: Optimizer step...
  Epoch 11, Batch 1/4: Completed in 0.19s
  Epoch 11, Batch 2/4: Loading data to device...
  Epoch 11, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 11, Batch 2/4: Zeroing gradients...
  Epoch 11, Batch 2/4: Forward pass...
  Epoch 11, Batch 2/4: Calculating loss...
  Epoch 11, Batch 2/4: Backward pass...
  Epoch 11, Batch 2/4: Clipping gradients...
  Epoch 11, Batch 2/4: Optimizer step...
  Epoch 11, Batch 2/4: Completed in 0.20s
  Epoch 11, Batch 3/4: Loading data to device...
  Epoch 11, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 11, Batch 3/4: Zeroing gradients...
  Epoch 11, Batch 3/4: Forward pass...
  Epoch 11, Batch 3/4: Calculating loss...
  Epoch 11, Batch 3/4: Backward pass...
  Epoch 11, Batch 3/4: Clipping gradients...
  Epoch 11, Batch 3/4: Optimizer step...
  Epoch 11, Batch 3/4: Completed in 0.20s
  Epoch 11, Batch 4/4: Loading data to device...
  Epoch 11, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 11, Batch 4/4: Zeroing gradients...
  Epoch 11, Batch 4/4: Forward pass...
  Epoch 11, Batch 4/4: Calculating loss...
  Epoch 11, Batch 4/4: Backward pass...
  Epoch 11, Batch 4/4: Clipping gradients...
  Epoch 11, Batch 4/4: Optimizer step...
  Epoch 11, Batch 4/4: Completed in 0.03s
Epoch 11: Training phase completed. Average Train Loss: 0.6861
Epoch 11: Starting validation phase...
  Epoch 11, Val Batch 1/1: Loading data...
  Epoch 11, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 11, Val Batch 1/1: Forward pass...
  Epoch 11, Val Batch 1/1: Calculating loss...
Epoch 11: Validation phase completed. Average Val Loss: 0.8323
Epoch 11 Summary ---> Train Loss: 0.6861 / Validation Loss: 0.8323
Epoch 11: Checking early stopping... (Current Best Loss: 0.7710, Epochs No Improve: 0)
  Epoch 11: Validation loss did not improve. Epochs without improvement: 1
Epoch 11: Stepping scheduler...
--- Epoch 11 completed in 0.68 seconds ---

--- Starting Epoch 12/1000 ---
Epoch 12: Starting training phase (4 batches)
  Epoch 12, Batch 1/4: Loading data to device...
  Epoch 12, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 12, Batch 1/4: Zeroing gradients...
  Epoch 12, Batch 1/4: Forward pass...
  Epoch 12, Batch 1/4: Calculating loss...
  Epoch 12, Batch 1/4: Backward pass...
  Epoch 12, Batch 1/4: Clipping gradients...
  Epoch 12, Batch 1/4: Optimizer step...
  Epoch 12, Batch 1/4: Completed in 0.19s
  Epoch 12, Batch 2/4: Loading data to device...
  Epoch 12, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 12, Batch 2/4: Zeroing gradients...
  Epoch 12, Batch 2/4: Forward pass...
  Epoch 12, Batch 2/4: Calculating loss...
  Epoch 12, Batch 2/4: Backward pass...
  Epoch 12, Batch 2/4: Clipping gradients...
  Epoch 12, Batch 2/4: Optimizer step...
  Epoch 12, Batch 2/4: Completed in 0.19s
  Epoch 12, Batch 3/4: Loading data to device...
  Epoch 12, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 12, Batch 3/4: Zeroing gradients...
  Epoch 12, Batch 3/4: Forward pass...
  Epoch 12, Batch 3/4: Calculating loss...
  Epoch 12, Batch 3/4: Backward pass...
  Epoch 12, Batch 3/4: Clipping gradients...
  Epoch 12, Batch 3/4: Optimizer step...
  Epoch 12, Batch 3/4: Completed in 0.19s
  Epoch 12, Batch 4/4: Loading data to device...
  Epoch 12, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 12, Batch 4/4: Zeroing gradients...
  Epoch 12, Batch 4/4: Forward pass...
  Epoch 12, Batch 4/4: Calculating loss...
  Epoch 12, Batch 4/4: Backward pass...
  Epoch 12, Batch 4/4: Clipping gradients...
  Epoch 12, Batch 4/4: Optimizer step...
  Epoch 12, Batch 4/4: Completed in 0.03s
Epoch 12: Training phase completed. Average Train Loss: 0.6823
Epoch 12: Starting validation phase...
  Epoch 12, Val Batch 1/1: Loading data...
  Epoch 12, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 12, Val Batch 1/1: Forward pass...
  Epoch 12, Val Batch 1/1: Calculating loss...
Epoch 12: Validation phase completed. Average Val Loss: 0.8184
Epoch 12 Summary ---> Train Loss: 0.6823 / Validation Loss: 0.8184
Epoch 12: Checking early stopping... (Current Best Loss: 0.7710, Epochs No Improve: 1)
  Epoch 12: Validation loss did not improve. Epochs without improvement: 2
Epoch 12: Stepping scheduler...
--- Epoch 12 completed in 0.67 seconds ---

--- Starting Epoch 13/1000 ---
Epoch 13: Starting training phase (4 batches)
  Epoch 13, Batch 1/4: Loading data to device...
  Epoch 13, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 13, Batch 1/4: Zeroing gradients...
  Epoch 13, Batch 1/4: Forward pass...
  Epoch 13, Batch 1/4: Calculating loss...
  Epoch 13, Batch 1/4: Backward pass...
  Epoch 13, Batch 1/4: Clipping gradients...
  Epoch 13, Batch 1/4: Optimizer step...
  Epoch 13, Batch 1/4: Completed in 0.19s
  Epoch 13, Batch 2/4: Loading data to device...
  Epoch 13, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 13, Batch 2/4: Zeroing gradients...
  Epoch 13, Batch 2/4: Forward pass...
  Epoch 13, Batch 2/4: Calculating loss...
  Epoch 13, Batch 2/4: Backward pass...
  Epoch 13, Batch 2/4: Clipping gradients...
  Epoch 13, Batch 2/4: Optimizer step...
  Epoch 13, Batch 2/4: Completed in 0.19s
  Epoch 13, Batch 3/4: Loading data to device...
  Epoch 13, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 13, Batch 3/4: Zeroing gradients...
  Epoch 13, Batch 3/4: Forward pass...
  Epoch 13, Batch 3/4: Calculating loss...
  Epoch 13, Batch 3/4: Backward pass...
  Epoch 13, Batch 3/4: Clipping gradients...
  Epoch 13, Batch 3/4: Optimizer step...
  Epoch 13, Batch 3/4: Completed in 0.20s
  Epoch 13, Batch 4/4: Loading data to device...
  Epoch 13, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 13, Batch 4/4: Zeroing gradients...
  Epoch 13, Batch 4/4: Forward pass...
  Epoch 13, Batch 4/4: Calculating loss...
  Epoch 13, Batch 4/4: Backward pass...
  Epoch 13, Batch 4/4: Clipping gradients...
  Epoch 13, Batch 4/4: Optimizer step...
  Epoch 13, Batch 4/4: Completed in 0.03s
Epoch 13: Training phase completed. Average Train Loss: 0.6954
Epoch 13: Starting validation phase...
  Epoch 13, Val Batch 1/1: Loading data...
  Epoch 13, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 13, Val Batch 1/1: Forward pass...
  Epoch 13, Val Batch 1/1: Calculating loss...
Epoch 13: Validation phase completed. Average Val Loss: 0.8010
Epoch 13 Summary ---> Train Loss: 0.6954 / Validation Loss: 0.8010
Epoch 13: Checking early stopping... (Current Best Loss: 0.7710, Epochs No Improve: 2)
  Epoch 13: Validation loss did not improve. Epochs without improvement: 3
Epoch 13: Stepping scheduler...
--- Epoch 13 completed in 0.67 seconds ---

--- Starting Epoch 14/1000 ---
Epoch 14: Starting training phase (4 batches)
  Epoch 14, Batch 1/4: Loading data to device...
  Epoch 14, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 14, Batch 1/4: Zeroing gradients...
  Epoch 14, Batch 1/4: Forward pass...
  Epoch 14, Batch 1/4: Calculating loss...
  Epoch 14, Batch 1/4: Backward pass...
  Epoch 14, Batch 1/4: Clipping gradients...
  Epoch 14, Batch 1/4: Optimizer step...
  Epoch 14, Batch 1/4: Completed in 0.19s
  Epoch 14, Batch 2/4: Loading data to device...
  Epoch 14, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 14, Batch 2/4: Zeroing gradients...
  Epoch 14, Batch 2/4: Forward pass...
  Epoch 14, Batch 2/4: Calculating loss...
  Epoch 14, Batch 2/4: Backward pass...
  Epoch 14, Batch 2/4: Clipping gradients...
  Epoch 14, Batch 2/4: Optimizer step...
  Epoch 14, Batch 2/4: Completed in 0.19s
  Epoch 14, Batch 3/4: Loading data to device...
  Epoch 14, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 14, Batch 3/4: Zeroing gradients...
  Epoch 14, Batch 3/4: Forward pass...
  Epoch 14, Batch 3/4: Calculating loss...
  Epoch 14, Batch 3/4: Backward pass...
  Epoch 14, Batch 3/4: Clipping gradients...
  Epoch 14, Batch 3/4: Optimizer step...
  Epoch 14, Batch 3/4: Completed in 0.19s
  Epoch 14, Batch 4/4: Loading data to device...
  Epoch 14, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 14, Batch 4/4: Zeroing gradients...
  Epoch 14, Batch 4/4: Forward pass...
  Epoch 14, Batch 4/4: Calculating loss...
  Epoch 14, Batch 4/4: Backward pass...
  Epoch 14, Batch 4/4: Clipping gradients...
  Epoch 14, Batch 4/4: Optimizer step...
  Epoch 14, Batch 4/4: Completed in 0.03s
Epoch 14: Training phase completed. Average Train Loss: 0.7016
Epoch 14: Starting validation phase...
  Epoch 14, Val Batch 1/1: Loading data...
  Epoch 14, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 14, Val Batch 1/1: Forward pass...
  Epoch 14, Val Batch 1/1: Calculating loss...
Epoch 14: Validation phase completed. Average Val Loss: 0.7512
Epoch 14 Summary ---> Train Loss: 0.7016 / Validation Loss: 0.7512
Epoch 14: Checking early stopping... (Current Best Loss: 0.7710, Epochs No Improve: 3)
  Epoch 14: Validation loss improved (0.7710 --> 0.7512). Saving model.
Epoch 14: Stepping scheduler...
--- Epoch 14 completed in 0.68 seconds ---

--- Starting Epoch 15/1000 ---
Epoch 15: Starting training phase (4 batches)
  Epoch 15, Batch 1/4: Loading data to device...
  Epoch 15, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 15, Batch 1/4: Zeroing gradients...
  Epoch 15, Batch 1/4: Forward pass...
  Epoch 15, Batch 1/4: Calculating loss...
  Epoch 15, Batch 1/4: Backward pass...
  Epoch 15, Batch 1/4: Clipping gradients...
  Epoch 15, Batch 1/4: Optimizer step...
  Epoch 15, Batch 1/4: Completed in 0.20s
  Epoch 15, Batch 2/4: Loading data to device...
  Epoch 15, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 15, Batch 2/4: Zeroing gradients...
  Epoch 15, Batch 2/4: Forward pass...
  Epoch 15, Batch 2/4: Calculating loss...
  Epoch 15, Batch 2/4: Backward pass...
  Epoch 15, Batch 2/4: Clipping gradients...
  Epoch 15, Batch 2/4: Optimizer step...
  Epoch 15, Batch 2/4: Completed in 0.19s
  Epoch 15, Batch 3/4: Loading data to device...
  Epoch 15, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 15, Batch 3/4: Zeroing gradients...
  Epoch 15, Batch 3/4: Forward pass...
  Epoch 15, Batch 3/4: Calculating loss...
  Epoch 15, Batch 3/4: Backward pass...
  Epoch 15, Batch 3/4: Clipping gradients...
  Epoch 15, Batch 3/4: Optimizer step...
  Epoch 15, Batch 3/4: Completed in 0.19s
  Epoch 15, Batch 4/4: Loading data to device...
  Epoch 15, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 15, Batch 4/4: Zeroing gradients...
  Epoch 15, Batch 4/4: Forward pass...
  Epoch 15, Batch 4/4: Calculating loss...
  Epoch 15, Batch 4/4: Backward pass...
  Epoch 15, Batch 4/4: Clipping gradients...
  Epoch 15, Batch 4/4: Optimizer step...
  Epoch 15, Batch 4/4: Completed in 0.03s
Epoch 15: Training phase completed. Average Train Loss: 0.6975
Epoch 15: Starting validation phase...
  Epoch 15, Val Batch 1/1: Loading data...
  Epoch 15, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 15, Val Batch 1/1: Forward pass...
  Epoch 15, Val Batch 1/1: Calculating loss...
Epoch 15: Validation phase completed. Average Val Loss: 0.7607
Epoch 15 Summary ---> Train Loss: 0.6975 / Validation Loss: 0.7607
Epoch 15: Checking early stopping... (Current Best Loss: 0.7512, Epochs No Improve: 0)
  Epoch 15: Validation loss did not improve. Epochs without improvement: 1
Epoch 15: Stepping scheduler...
--- Epoch 15 completed in 0.68 seconds ---

--- Starting Epoch 16/1000 ---
Epoch 16: Starting training phase (4 batches)
  Epoch 16, Batch 1/4: Loading data to device...
  Epoch 16, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 16, Batch 1/4: Zeroing gradients...
  Epoch 16, Batch 1/4: Forward pass...
  Epoch 16, Batch 1/4: Calculating loss...
  Epoch 16, Batch 1/4: Backward pass...
  Epoch 16, Batch 1/4: Clipping gradients...
  Epoch 16, Batch 1/4: Optimizer step...
  Epoch 16, Batch 1/4: Completed in 0.19s
  Epoch 16, Batch 2/4: Loading data to device...
  Epoch 16, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 16, Batch 2/4: Zeroing gradients...
  Epoch 16, Batch 2/4: Forward pass...
  Epoch 16, Batch 2/4: Calculating loss...
  Epoch 16, Batch 2/4: Backward pass...
  Epoch 16, Batch 2/4: Clipping gradients...
  Epoch 16, Batch 2/4: Optimizer step...
  Epoch 16, Batch 2/4: Completed in 0.20s
  Epoch 16, Batch 3/4: Loading data to device...
  Epoch 16, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 16, Batch 3/4: Zeroing gradients...
  Epoch 16, Batch 3/4: Forward pass...
  Epoch 16, Batch 3/4: Calculating loss...
  Epoch 16, Batch 3/4: Backward pass...
  Epoch 16, Batch 3/4: Clipping gradients...
  Epoch 16, Batch 3/4: Optimizer step...
  Epoch 16, Batch 3/4: Completed in 0.19s
  Epoch 16, Batch 4/4: Loading data to device...
  Epoch 16, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 16, Batch 4/4: Zeroing gradients...
  Epoch 16, Batch 4/4: Forward pass...
  Epoch 16, Batch 4/4: Calculating loss...
  Epoch 16, Batch 4/4: Backward pass...
  Epoch 16, Batch 4/4: Clipping gradients...
  Epoch 16, Batch 4/4: Optimizer step...
  Epoch 16, Batch 4/4: Completed in 0.03s
Epoch 16: Training phase completed. Average Train Loss: 0.7191
Epoch 16: Starting validation phase...
  Epoch 16, Val Batch 1/1: Loading data...
  Epoch 16, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 16, Val Batch 1/1: Forward pass...
  Epoch 16, Val Batch 1/1: Calculating loss...
Epoch 16: Validation phase completed. Average Val Loss: 0.7601
Epoch 16 Summary ---> Train Loss: 0.7191 / Validation Loss: 0.7601
Epoch 16: Checking early stopping... (Current Best Loss: 0.7512, Epochs No Improve: 1)
  Epoch 16: Validation loss did not improve. Epochs without improvement: 2
Epoch 16: Stepping scheduler...
--- Epoch 16 completed in 0.68 seconds ---

--- Starting Epoch 17/1000 ---
Epoch 17: Starting training phase (4 batches)
  Epoch 17, Batch 1/4: Loading data to device...
  Epoch 17, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 17, Batch 1/4: Zeroing gradients...
  Epoch 17, Batch 1/4: Forward pass...
  Epoch 17, Batch 1/4: Calculating loss...
  Epoch 17, Batch 1/4: Backward pass...
  Epoch 17, Batch 1/4: Clipping gradients...
  Epoch 17, Batch 1/4: Optimizer step...
  Epoch 17, Batch 1/4: Completed in 0.19s
  Epoch 17, Batch 2/4: Loading data to device...
  Epoch 17, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 17, Batch 2/4: Zeroing gradients...
  Epoch 17, Batch 2/4: Forward pass...
  Epoch 17, Batch 2/4: Calculating loss...
  Epoch 17, Batch 2/4: Backward pass...
  Epoch 17, Batch 2/4: Clipping gradients...
  Epoch 17, Batch 2/4: Optimizer step...
  Epoch 17, Batch 2/4: Completed in 0.19s
  Epoch 17, Batch 3/4: Loading data to device...
  Epoch 17, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 17, Batch 3/4: Zeroing gradients...
  Epoch 17, Batch 3/4: Forward pass...
  Epoch 17, Batch 3/4: Calculating loss...
  Epoch 17, Batch 3/4: Backward pass...
  Epoch 17, Batch 3/4: Clipping gradients...
  Epoch 17, Batch 3/4: Optimizer step...
  Epoch 17, Batch 3/4: Completed in 0.19s
  Epoch 17, Batch 4/4: Loading data to device...
  Epoch 17, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 17, Batch 4/4: Zeroing gradients...
  Epoch 17, Batch 4/4: Forward pass...
  Epoch 17, Batch 4/4: Calculating loss...
  Epoch 17, Batch 4/4: Backward pass...
  Epoch 17, Batch 4/4: Clipping gradients...
  Epoch 17, Batch 4/4: Optimizer step...
  Epoch 17, Batch 4/4: Completed in 0.03s
Epoch 17: Training phase completed. Average Train Loss: 0.6933
Epoch 17: Starting validation phase...
  Epoch 17, Val Batch 1/1: Loading data...
  Epoch 17, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 17, Val Batch 1/1: Forward pass...
  Epoch 17, Val Batch 1/1: Calculating loss...
Epoch 17: Validation phase completed. Average Val Loss: 0.7690
Epoch 17 Summary ---> Train Loss: 0.6933 / Validation Loss: 0.7690
Epoch 17: Checking early stopping... (Current Best Loss: 0.7512, Epochs No Improve: 2)
  Epoch 17: Validation loss did not improve. Epochs without improvement: 3
Epoch 17: Stepping scheduler...
--- Epoch 17 completed in 0.67 seconds ---

--- Starting Epoch 18/1000 ---
Epoch 18: Starting training phase (4 batches)
  Epoch 18, Batch 1/4: Loading data to device...
  Epoch 18, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 18, Batch 1/4: Zeroing gradients...
  Epoch 18, Batch 1/4: Forward pass...
  Epoch 18, Batch 1/4: Calculating loss...
  Epoch 18, Batch 1/4: Backward pass...
  Epoch 18, Batch 1/4: Clipping gradients...
  Epoch 18, Batch 1/4: Optimizer step...
  Epoch 18, Batch 1/4: Completed in 0.20s
  Epoch 18, Batch 2/4: Loading data to device...
  Epoch 18, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 18, Batch 2/4: Zeroing gradients...
  Epoch 18, Batch 2/4: Forward pass...
  Epoch 18, Batch 2/4: Calculating loss...
  Epoch 18, Batch 2/4: Backward pass...
  Epoch 18, Batch 2/4: Clipping gradients...
  Epoch 18, Batch 2/4: Optimizer step...
  Epoch 18, Batch 2/4: Completed in 0.20s
  Epoch 18, Batch 3/4: Loading data to device...
  Epoch 18, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 18, Batch 3/4: Zeroing gradients...
  Epoch 18, Batch 3/4: Forward pass...
  Epoch 18, Batch 3/4: Calculating loss...
  Epoch 18, Batch 3/4: Backward pass...
  Epoch 18, Batch 3/4: Clipping gradients...
  Epoch 18, Batch 3/4: Optimizer step...
  Epoch 18, Batch 3/4: Completed in 0.19s
  Epoch 18, Batch 4/4: Loading data to device...
  Epoch 18, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 18, Batch 4/4: Zeroing gradients...
  Epoch 18, Batch 4/4: Forward pass...
  Epoch 18, Batch 4/4: Calculating loss...
  Epoch 18, Batch 4/4: Backward pass...
  Epoch 18, Batch 4/4: Clipping gradients...
  Epoch 18, Batch 4/4: Optimizer step...
  Epoch 18, Batch 4/4: Completed in 0.03s
Epoch 18: Training phase completed. Average Train Loss: 0.6620
Epoch 18: Starting validation phase...
  Epoch 18, Val Batch 1/1: Loading data...
  Epoch 18, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 18, Val Batch 1/1: Forward pass...
  Epoch 18, Val Batch 1/1: Calculating loss...
Epoch 18: Validation phase completed. Average Val Loss: 0.7690
Epoch 18 Summary ---> Train Loss: 0.6620 / Validation Loss: 0.7690
Epoch 18: Checking early stopping... (Current Best Loss: 0.7512, Epochs No Improve: 3)
  Epoch 18: Validation loss did not improve. Epochs without improvement: 4
Epoch 18: Stepping scheduler...
--- Epoch 18 completed in 0.69 seconds ---

--- Starting Epoch 19/1000 ---
Epoch 19: Starting training phase (4 batches)
  Epoch 19, Batch 1/4: Loading data to device...
  Epoch 19, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 19, Batch 1/4: Zeroing gradients...
  Epoch 19, Batch 1/4: Forward pass...
  Epoch 19, Batch 1/4: Calculating loss...
  Epoch 19, Batch 1/4: Backward pass...
  Epoch 19, Batch 1/4: Clipping gradients...
  Epoch 19, Batch 1/4: Optimizer step...
  Epoch 19, Batch 1/4: Completed in 0.19s
  Epoch 19, Batch 2/4: Loading data to device...
  Epoch 19, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 19, Batch 2/4: Zeroing gradients...
  Epoch 19, Batch 2/4: Forward pass...
  Epoch 19, Batch 2/4: Calculating loss...
  Epoch 19, Batch 2/4: Backward pass...
  Epoch 19, Batch 2/4: Clipping gradients...
  Epoch 19, Batch 2/4: Optimizer step...
  Epoch 19, Batch 2/4: Completed in 0.19s
  Epoch 19, Batch 3/4: Loading data to device...
  Epoch 19, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 19, Batch 3/4: Zeroing gradients...
  Epoch 19, Batch 3/4: Forward pass...
  Epoch 19, Batch 3/4: Calculating loss...
  Epoch 19, Batch 3/4: Backward pass...
  Epoch 19, Batch 3/4: Clipping gradients...
  Epoch 19, Batch 3/4: Optimizer step...
  Epoch 19, Batch 3/4: Completed in 0.19s
  Epoch 19, Batch 4/4: Loading data to device...
  Epoch 19, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 19, Batch 4/4: Zeroing gradients...
  Epoch 19, Batch 4/4: Forward pass...
  Epoch 19, Batch 4/4: Calculating loss...
  Epoch 19, Batch 4/4: Backward pass...
  Epoch 19, Batch 4/4: Clipping gradients...
  Epoch 19, Batch 4/4: Optimizer step...
  Epoch 19, Batch 4/4: Completed in 0.03s
Epoch 19: Training phase completed. Average Train Loss: 0.6495
Epoch 19: Starting validation phase...
  Epoch 19, Val Batch 1/1: Loading data...
  Epoch 19, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 19, Val Batch 1/1: Forward pass...
  Epoch 19, Val Batch 1/1: Calculating loss...
Epoch 19: Validation phase completed. Average Val Loss: 0.7701
Epoch 19 Summary ---> Train Loss: 0.6495 / Validation Loss: 0.7701
Epoch 19: Checking early stopping... (Current Best Loss: 0.7512, Epochs No Improve: 4)
  Epoch 19: Validation loss did not improve. Epochs without improvement: 5
Epoch 19: Stepping scheduler...
--- Epoch 19 completed in 0.66 seconds ---

--- Starting Epoch 20/1000 ---
Epoch 20: Starting training phase (4 batches)
  Epoch 20, Batch 1/4: Loading data to device...
  Epoch 20, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 20, Batch 1/4: Zeroing gradients...
  Epoch 20, Batch 1/4: Forward pass...
  Epoch 20, Batch 1/4: Calculating loss...
  Epoch 20, Batch 1/4: Backward pass...
  Epoch 20, Batch 1/4: Clipping gradients...
  Epoch 20, Batch 1/4: Optimizer step...
  Epoch 20, Batch 1/4: Completed in 0.19s
  Epoch 20, Batch 2/4: Loading data to device...
  Epoch 20, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 20, Batch 2/4: Zeroing gradients...
  Epoch 20, Batch 2/4: Forward pass...
  Epoch 20, Batch 2/4: Calculating loss...
  Epoch 20, Batch 2/4: Backward pass...
  Epoch 20, Batch 2/4: Clipping gradients...
  Epoch 20, Batch 2/4: Optimizer step...
  Epoch 20, Batch 2/4: Completed in 0.19s
  Epoch 20, Batch 3/4: Loading data to device...
  Epoch 20, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 20, Batch 3/4: Zeroing gradients...
  Epoch 20, Batch 3/4: Forward pass...
  Epoch 20, Batch 3/4: Calculating loss...
  Epoch 20, Batch 3/4: Backward pass...
  Epoch 20, Batch 3/4: Clipping gradients...
  Epoch 20, Batch 3/4: Optimizer step...
  Epoch 20, Batch 3/4: Completed in 0.19s
  Epoch 20, Batch 4/4: Loading data to device...
  Epoch 20, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 20, Batch 4/4: Zeroing gradients...
  Epoch 20, Batch 4/4: Forward pass...
  Epoch 20, Batch 4/4: Calculating loss...
  Epoch 20, Batch 4/4: Backward pass...
  Epoch 20, Batch 4/4: Clipping gradients...
  Epoch 20, Batch 4/4: Optimizer step...
  Epoch 20, Batch 4/4: Completed in 0.03s
Epoch 20: Training phase completed. Average Train Loss: 0.6998
Epoch 20: Starting validation phase...
  Epoch 20, Val Batch 1/1: Loading data...
  Epoch 20, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 20, Val Batch 1/1: Forward pass...
  Epoch 20, Val Batch 1/1: Calculating loss...
Epoch 20: Validation phase completed. Average Val Loss: 0.7660
Epoch 20 Summary ---> Train Loss: 0.6998 / Validation Loss: 0.7660
Epoch 20: Checking early stopping... (Current Best Loss: 0.7512, Epochs No Improve: 5)
  Epoch 20: Validation loss did not improve. Epochs without improvement: 6
Epoch 20: Stepping scheduler...
--- Epoch 20 completed in 0.68 seconds ---

--- Starting Epoch 21/1000 ---
Epoch 21: Starting training phase (4 batches)
  Epoch 21, Batch 1/4: Loading data to device...
  Epoch 21, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 21, Batch 1/4: Zeroing gradients...
  Epoch 21, Batch 1/4: Forward pass...
  Epoch 21, Batch 1/4: Calculating loss...
  Epoch 21, Batch 1/4: Backward pass...
  Epoch 21, Batch 1/4: Clipping gradients...
  Epoch 21, Batch 1/4: Optimizer step...
  Epoch 21, Batch 1/4: Completed in 0.19s
  Epoch 21, Batch 2/4: Loading data to device...
  Epoch 21, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 21, Batch 2/4: Zeroing gradients...
  Epoch 21, Batch 2/4: Forward pass...
  Epoch 21, Batch 2/4: Calculating loss...
  Epoch 21, Batch 2/4: Backward pass...
  Epoch 21, Batch 2/4: Clipping gradients...
  Epoch 21, Batch 2/4: Optimizer step...
  Epoch 21, Batch 2/4: Completed in 0.19s
  Epoch 21, Batch 3/4: Loading data to device...
  Epoch 21, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 21, Batch 3/4: Zeroing gradients...
  Epoch 21, Batch 3/4: Forward pass...
  Epoch 21, Batch 3/4: Calculating loss...
  Epoch 21, Batch 3/4: Backward pass...
  Epoch 21, Batch 3/4: Clipping gradients...
  Epoch 21, Batch 3/4: Optimizer step...
  Epoch 21, Batch 3/4: Completed in 0.19s
  Epoch 21, Batch 4/4: Loading data to device...
  Epoch 21, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 21, Batch 4/4: Zeroing gradients...
  Epoch 21, Batch 4/4: Forward pass...
  Epoch 21, Batch 4/4: Calculating loss...
  Epoch 21, Batch 4/4: Backward pass...
  Epoch 21, Batch 4/4: Clipping gradients...
  Epoch 21, Batch 4/4: Optimizer step...
  Epoch 21, Batch 4/4: Completed in 0.03s
Epoch 21: Training phase completed. Average Train Loss: 0.6483
Epoch 21: Starting validation phase...
  Epoch 21, Val Batch 1/1: Loading data...
  Epoch 21, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 21, Val Batch 1/1: Forward pass...
  Epoch 21, Val Batch 1/1: Calculating loss...
Epoch 21: Validation phase completed. Average Val Loss: 0.7529
Epoch 21 Summary ---> Train Loss: 0.6483 / Validation Loss: 0.7529
Epoch 21: Checking early stopping... (Current Best Loss: 0.7512, Epochs No Improve: 6)
  Epoch 21: Validation loss did not improve. Epochs without improvement: 7
Epoch 21: Stepping scheduler...
--- Epoch 21 completed in 0.67 seconds ---

--- Starting Epoch 22/1000 ---
Epoch 22: Starting training phase (4 batches)
  Epoch 22, Batch 1/4: Loading data to device...
  Epoch 22, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 22, Batch 1/4: Zeroing gradients...
  Epoch 22, Batch 1/4: Forward pass...
  Epoch 22, Batch 1/4: Calculating loss...
  Epoch 22, Batch 1/4: Backward pass...
  Epoch 22, Batch 1/4: Clipping gradients...
  Epoch 22, Batch 1/4: Optimizer step...
  Epoch 22, Batch 1/4: Completed in 0.19s
  Epoch 22, Batch 2/4: Loading data to device...
  Epoch 22, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 22, Batch 2/4: Zeroing gradients...
  Epoch 22, Batch 2/4: Forward pass...
  Epoch 22, Batch 2/4: Calculating loss...
  Epoch 22, Batch 2/4: Backward pass...
  Epoch 22, Batch 2/4: Clipping gradients...
  Epoch 22, Batch 2/4: Optimizer step...
  Epoch 22, Batch 2/4: Completed in 0.19s
  Epoch 22, Batch 3/4: Loading data to device...
  Epoch 22, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 22, Batch 3/4: Zeroing gradients...
  Epoch 22, Batch 3/4: Forward pass...
  Epoch 22, Batch 3/4: Calculating loss...
  Epoch 22, Batch 3/4: Backward pass...
  Epoch 22, Batch 3/4: Clipping gradients...
  Epoch 22, Batch 3/4: Optimizer step...
  Epoch 22, Batch 3/4: Completed in 0.19s
  Epoch 22, Batch 4/4: Loading data to device...
  Epoch 22, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 22, Batch 4/4: Zeroing gradients...
  Epoch 22, Batch 4/4: Forward pass...
  Epoch 22, Batch 4/4: Calculating loss...
  Epoch 22, Batch 4/4: Backward pass...
  Epoch 22, Batch 4/4: Clipping gradients...
  Epoch 22, Batch 4/4: Optimizer step...
  Epoch 22, Batch 4/4: Completed in 0.03s
Epoch 22: Training phase completed. Average Train Loss: 0.6729
Epoch 22: Starting validation phase...
  Epoch 22, Val Batch 1/1: Loading data...
  Epoch 22, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 22, Val Batch 1/1: Forward pass...
  Epoch 22, Val Batch 1/1: Calculating loss...
Epoch 22: Validation phase completed. Average Val Loss: 0.7528
Epoch 22 Summary ---> Train Loss: 0.6729 / Validation Loss: 0.7528
Epoch 22: Checking early stopping... (Current Best Loss: 0.7512, Epochs No Improve: 7)
  Epoch 22: Validation loss did not improve. Epochs without improvement: 8
Epoch 22: Stepping scheduler...
--- Epoch 22 completed in 0.67 seconds ---

--- Starting Epoch 23/1000 ---
Epoch 23: Starting training phase (4 batches)
  Epoch 23, Batch 1/4: Loading data to device...
  Epoch 23, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 23, Batch 1/4: Zeroing gradients...
  Epoch 23, Batch 1/4: Forward pass...
  Epoch 23, Batch 1/4: Calculating loss...
  Epoch 23, Batch 1/4: Backward pass...
  Epoch 23, Batch 1/4: Clipping gradients...
  Epoch 23, Batch 1/4: Optimizer step...
  Epoch 23, Batch 1/4: Completed in 0.19s
  Epoch 23, Batch 2/4: Loading data to device...
  Epoch 23, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 23, Batch 2/4: Zeroing gradients...
  Epoch 23, Batch 2/4: Forward pass...
  Epoch 23, Batch 2/4: Calculating loss...
  Epoch 23, Batch 2/4: Backward pass...
  Epoch 23, Batch 2/4: Clipping gradients...
  Epoch 23, Batch 2/4: Optimizer step...
  Epoch 23, Batch 2/4: Completed in 0.20s
  Epoch 23, Batch 3/4: Loading data to device...
  Epoch 23, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 23, Batch 3/4: Zeroing gradients...
  Epoch 23, Batch 3/4: Forward pass...
  Epoch 23, Batch 3/4: Calculating loss...
  Epoch 23, Batch 3/4: Backward pass...
  Epoch 23, Batch 3/4: Clipping gradients...
  Epoch 23, Batch 3/4: Optimizer step...
  Epoch 23, Batch 3/4: Completed in 0.19s
  Epoch 23, Batch 4/4: Loading data to device...
  Epoch 23, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 23, Batch 4/4: Zeroing gradients...
  Epoch 23, Batch 4/4: Forward pass...
  Epoch 23, Batch 4/4: Calculating loss...
  Epoch 23, Batch 4/4: Backward pass...
  Epoch 23, Batch 4/4: Clipping gradients...
  Epoch 23, Batch 4/4: Optimizer step...
  Epoch 23, Batch 4/4: Completed in 0.03s
Epoch 23: Training phase completed. Average Train Loss: 0.6528
Epoch 23: Starting validation phase...
  Epoch 23, Val Batch 1/1: Loading data...
  Epoch 23, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 23, Val Batch 1/1: Forward pass...
  Epoch 23, Val Batch 1/1: Calculating loss...
Epoch 23: Validation phase completed. Average Val Loss: 0.7437
Epoch 23 Summary ---> Train Loss: 0.6528 / Validation Loss: 0.7437
Epoch 23: Checking early stopping... (Current Best Loss: 0.7512, Epochs No Improve: 8)
  Epoch 23: Validation loss improved (0.7512 --> 0.7437). Saving model.
Epoch 23: Stepping scheduler...
--- Epoch 23 completed in 0.68 seconds ---

--- Starting Epoch 24/1000 ---
Epoch 24: Starting training phase (4 batches)
  Epoch 24, Batch 1/4: Loading data to device...
  Epoch 24, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 24, Batch 1/4: Zeroing gradients...
  Epoch 24, Batch 1/4: Forward pass...
  Epoch 24, Batch 1/4: Calculating loss...
  Epoch 24, Batch 1/4: Backward pass...
  Epoch 24, Batch 1/4: Clipping gradients...
  Epoch 24, Batch 1/4: Optimizer step...
  Epoch 24, Batch 1/4: Completed in 0.19s
  Epoch 24, Batch 2/4: Loading data to device...
  Epoch 24, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 24, Batch 2/4: Zeroing gradients...
  Epoch 24, Batch 2/4: Forward pass...
  Epoch 24, Batch 2/4: Calculating loss...
  Epoch 24, Batch 2/4: Backward pass...
  Epoch 24, Batch 2/4: Clipping gradients...
  Epoch 24, Batch 2/4: Optimizer step...
  Epoch 24, Batch 2/4: Completed in 0.19s
  Epoch 24, Batch 3/4: Loading data to device...
  Epoch 24, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 24, Batch 3/4: Zeroing gradients...
  Epoch 24, Batch 3/4: Forward pass...
  Epoch 24, Batch 3/4: Calculating loss...
  Epoch 24, Batch 3/4: Backward pass...
  Epoch 24, Batch 3/4: Clipping gradients...
  Epoch 24, Batch 3/4: Optimizer step...
  Epoch 24, Batch 3/4: Completed in 0.19s
  Epoch 24, Batch 4/4: Loading data to device...
  Epoch 24, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 24, Batch 4/4: Zeroing gradients...
  Epoch 24, Batch 4/4: Forward pass...
  Epoch 24, Batch 4/4: Calculating loss...
  Epoch 24, Batch 4/4: Backward pass...
  Epoch 24, Batch 4/4: Clipping gradients...
  Epoch 24, Batch 4/4: Optimizer step...
  Epoch 24, Batch 4/4: Completed in 0.03s
Epoch 24: Training phase completed. Average Train Loss: 0.6482
Epoch 24: Starting validation phase...
  Epoch 24, Val Batch 1/1: Loading data...
  Epoch 24, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 24, Val Batch 1/1: Forward pass...
  Epoch 24, Val Batch 1/1: Calculating loss...
Epoch 24: Validation phase completed. Average Val Loss: 0.7425
Epoch 24 Summary ---> Train Loss: 0.6482 / Validation Loss: 0.7425
Epoch 24: Checking early stopping... (Current Best Loss: 0.7437, Epochs No Improve: 0)
  Epoch 24: Validation loss improved (0.7437 --> 0.7425). Saving model.
Epoch 24: Stepping scheduler...
--- Epoch 24 completed in 0.67 seconds ---

--- Starting Epoch 25/1000 ---
Epoch 25: Starting training phase (4 batches)
  Epoch 25, Batch 1/4: Loading data to device...
  Epoch 25, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 25, Batch 1/4: Zeroing gradients...
  Epoch 25, Batch 1/4: Forward pass...
  Epoch 25, Batch 1/4: Calculating loss...
  Epoch 25, Batch 1/4: Backward pass...
  Epoch 25, Batch 1/4: Clipping gradients...
  Epoch 25, Batch 1/4: Optimizer step...
  Epoch 25, Batch 1/4: Completed in 0.19s
  Epoch 25, Batch 2/4: Loading data to device...
  Epoch 25, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 25, Batch 2/4: Zeroing gradients...
  Epoch 25, Batch 2/4: Forward pass...
  Epoch 25, Batch 2/4: Calculating loss...
  Epoch 25, Batch 2/4: Backward pass...
  Epoch 25, Batch 2/4: Clipping gradients...
  Epoch 25, Batch 2/4: Optimizer step...
  Epoch 25, Batch 2/4: Completed in 0.19s
  Epoch 25, Batch 3/4: Loading data to device...
  Epoch 25, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 25, Batch 3/4: Zeroing gradients...
  Epoch 25, Batch 3/4: Forward pass...
  Epoch 25, Batch 3/4: Calculating loss...
  Epoch 25, Batch 3/4: Backward pass...
  Epoch 25, Batch 3/4: Clipping gradients...
  Epoch 25, Batch 3/4: Optimizer step...
  Epoch 25, Batch 3/4: Completed in 0.20s
  Epoch 25, Batch 4/4: Loading data to device...
  Epoch 25, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 25, Batch 4/4: Zeroing gradients...
  Epoch 25, Batch 4/4: Forward pass...
  Epoch 25, Batch 4/4: Calculating loss...
  Epoch 25, Batch 4/4: Backward pass...
  Epoch 25, Batch 4/4: Clipping gradients...
  Epoch 25, Batch 4/4: Optimizer step...
  Epoch 25, Batch 4/4: Completed in 0.03s
Epoch 25: Training phase completed. Average Train Loss: 0.7142
Epoch 25: Starting validation phase...
  Epoch 25, Val Batch 1/1: Loading data...
  Epoch 25, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 25, Val Batch 1/1: Forward pass...
  Epoch 25, Val Batch 1/1: Calculating loss...
Epoch 25: Validation phase completed. Average Val Loss: 0.7237
Epoch 25 Summary ---> Train Loss: 0.7142 / Validation Loss: 0.7237
Epoch 25: Checking early stopping... (Current Best Loss: 0.7425, Epochs No Improve: 0)
  Epoch 25: Validation loss improved (0.7425 --> 0.7237). Saving model.
Epoch 25: Stepping scheduler...
--- Epoch 25 completed in 0.68 seconds ---

--- Starting Epoch 26/1000 ---
Epoch 26: Starting training phase (4 batches)
  Epoch 26, Batch 1/4: Loading data to device...
  Epoch 26, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 26, Batch 1/4: Zeroing gradients...
  Epoch 26, Batch 1/4: Forward pass...
  Epoch 26, Batch 1/4: Calculating loss...
  Epoch 26, Batch 1/4: Backward pass...
  Epoch 26, Batch 1/4: Clipping gradients...
  Epoch 26, Batch 1/4: Optimizer step...
  Epoch 26, Batch 1/4: Completed in 0.19s
  Epoch 26, Batch 2/4: Loading data to device...
  Epoch 26, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 26, Batch 2/4: Zeroing gradients...
  Epoch 26, Batch 2/4: Forward pass...
  Epoch 26, Batch 2/4: Calculating loss...
  Epoch 26, Batch 2/4: Backward pass...
  Epoch 26, Batch 2/4: Clipping gradients...
  Epoch 26, Batch 2/4: Optimizer step...
  Epoch 26, Batch 2/4: Completed in 0.19s
  Epoch 26, Batch 3/4: Loading data to device...
  Epoch 26, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 26, Batch 3/4: Zeroing gradients...
  Epoch 26, Batch 3/4: Forward pass...
  Epoch 26, Batch 3/4: Calculating loss...
  Epoch 26, Batch 3/4: Backward pass...
  Epoch 26, Batch 3/4: Clipping gradients...
  Epoch 26, Batch 3/4: Optimizer step...
  Epoch 26, Batch 3/4: Completed in 0.19s
  Epoch 26, Batch 4/4: Loading data to device...
  Epoch 26, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 26, Batch 4/4: Zeroing gradients...
  Epoch 26, Batch 4/4: Forward pass...
  Epoch 26, Batch 4/4: Calculating loss...
  Epoch 26, Batch 4/4: Backward pass...
  Epoch 26, Batch 4/4: Clipping gradients...
  Epoch 26, Batch 4/4: Optimizer step...
  Epoch 26, Batch 4/4: Completed in 0.03s
Epoch 26: Training phase completed. Average Train Loss: 0.7056
Epoch 26: Starting validation phase...
  Epoch 26, Val Batch 1/1: Loading data...
  Epoch 26, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 26, Val Batch 1/1: Forward pass...
  Epoch 26, Val Batch 1/1: Calculating loss...
Epoch 26: Validation phase completed. Average Val Loss: 0.7004
Epoch 26 Summary ---> Train Loss: 0.7056 / Validation Loss: 0.7004
Epoch 26: Checking early stopping... (Current Best Loss: 0.7237, Epochs No Improve: 0)
  Epoch 26: Validation loss improved (0.7237 --> 0.7004). Saving model.
Epoch 26: Stepping scheduler...
--- Epoch 26 completed in 0.67 seconds ---

--- Starting Epoch 27/1000 ---
Epoch 27: Starting training phase (4 batches)
  Epoch 27, Batch 1/4: Loading data to device...
  Epoch 27, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 27, Batch 1/4: Zeroing gradients...
  Epoch 27, Batch 1/4: Forward pass...
  Epoch 27, Batch 1/4: Calculating loss...
  Epoch 27, Batch 1/4: Backward pass...
  Epoch 27, Batch 1/4: Clipping gradients...
  Epoch 27, Batch 1/4: Optimizer step...
  Epoch 27, Batch 1/4: Completed in 0.19s
  Epoch 27, Batch 2/4: Loading data to device...
  Epoch 27, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 27, Batch 2/4: Zeroing gradients...
  Epoch 27, Batch 2/4: Forward pass...
  Epoch 27, Batch 2/4: Calculating loss...
  Epoch 27, Batch 2/4: Backward pass...
  Epoch 27, Batch 2/4: Clipping gradients...
  Epoch 27, Batch 2/4: Optimizer step...
  Epoch 27, Batch 2/4: Completed in 0.19s
  Epoch 27, Batch 3/4: Loading data to device...
  Epoch 27, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 27, Batch 3/4: Zeroing gradients...
  Epoch 27, Batch 3/4: Forward pass...
  Epoch 27, Batch 3/4: Calculating loss...
  Epoch 27, Batch 3/4: Backward pass...
  Epoch 27, Batch 3/4: Clipping gradients...
  Epoch 27, Batch 3/4: Optimizer step...
  Epoch 27, Batch 3/4: Completed in 0.19s
  Epoch 27, Batch 4/4: Loading data to device...
  Epoch 27, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 27, Batch 4/4: Zeroing gradients...
  Epoch 27, Batch 4/4: Forward pass...
  Epoch 27, Batch 4/4: Calculating loss...
  Epoch 27, Batch 4/4: Backward pass...
  Epoch 27, Batch 4/4: Clipping gradients...
  Epoch 27, Batch 4/4: Optimizer step...
  Epoch 27, Batch 4/4: Completed in 0.03s
Epoch 27: Training phase completed. Average Train Loss: 0.6603
Epoch 27: Starting validation phase...
  Epoch 27, Val Batch 1/1: Loading data...
  Epoch 27, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 27, Val Batch 1/1: Forward pass...
  Epoch 27, Val Batch 1/1: Calculating loss...
Epoch 27: Validation phase completed. Average Val Loss: 0.6797
Epoch 27 Summary ---> Train Loss: 0.6603 / Validation Loss: 0.6797
Epoch 27: Checking early stopping... (Current Best Loss: 0.7004, Epochs No Improve: 0)
  Epoch 27: Validation loss improved (0.7004 --> 0.6797). Saving model.
Epoch 27: Stepping scheduler...
--- Epoch 27 completed in 0.66 seconds ---

--- Starting Epoch 28/1000 ---
Epoch 28: Starting training phase (4 batches)
  Epoch 28, Batch 1/4: Loading data to device...
  Epoch 28, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 28, Batch 1/4: Zeroing gradients...
  Epoch 28, Batch 1/4: Forward pass...
  Epoch 28, Batch 1/4: Calculating loss...
  Epoch 28, Batch 1/4: Backward pass...
  Epoch 28, Batch 1/4: Clipping gradients...
  Epoch 28, Batch 1/4: Optimizer step...
  Epoch 28, Batch 1/4: Completed in 0.19s
  Epoch 28, Batch 2/4: Loading data to device...
  Epoch 28, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 28, Batch 2/4: Zeroing gradients...
  Epoch 28, Batch 2/4: Forward pass...
  Epoch 28, Batch 2/4: Calculating loss...
  Epoch 28, Batch 2/4: Backward pass...
  Epoch 28, Batch 2/4: Clipping gradients...
  Epoch 28, Batch 2/4: Optimizer step...
  Epoch 28, Batch 2/4: Completed in 0.19s
  Epoch 28, Batch 3/4: Loading data to device...
  Epoch 28, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 28, Batch 3/4: Zeroing gradients...
  Epoch 28, Batch 3/4: Forward pass...
  Epoch 28, Batch 3/4: Calculating loss...
  Epoch 28, Batch 3/4: Backward pass...
  Epoch 28, Batch 3/4: Clipping gradients...
  Epoch 28, Batch 3/4: Optimizer step...
  Epoch 28, Batch 3/4: Completed in 0.19s
  Epoch 28, Batch 4/4: Loading data to device...
  Epoch 28, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 28, Batch 4/4: Zeroing gradients...
  Epoch 28, Batch 4/4: Forward pass...
  Epoch 28, Batch 4/4: Calculating loss...
  Epoch 28, Batch 4/4: Backward pass...
  Epoch 28, Batch 4/4: Clipping gradients...
  Epoch 28, Batch 4/4: Optimizer step...
  Epoch 28, Batch 4/4: Completed in 0.04s
Epoch 28: Training phase completed. Average Train Loss: 0.6245
Epoch 28: Starting validation phase...
  Epoch 28, Val Batch 1/1: Loading data...
  Epoch 28, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 28, Val Batch 1/1: Forward pass...
  Epoch 28, Val Batch 1/1: Calculating loss...
Epoch 28: Validation phase completed. Average Val Loss: 0.6763
Epoch 28 Summary ---> Train Loss: 0.6245 / Validation Loss: 0.6763
Epoch 28: Checking early stopping... (Current Best Loss: 0.6797, Epochs No Improve: 0)
  Epoch 28: Validation loss improved (0.6797 --> 0.6763). Saving model.
Epoch 28: Stepping scheduler...
--- Epoch 28 completed in 0.67 seconds ---

--- Starting Epoch 29/1000 ---
Epoch 29: Starting training phase (4 batches)
  Epoch 29, Batch 1/4: Loading data to device...
  Epoch 29, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 29, Batch 1/4: Zeroing gradients...
  Epoch 29, Batch 1/4: Forward pass...
  Epoch 29, Batch 1/4: Calculating loss...
  Epoch 29, Batch 1/4: Backward pass...
  Epoch 29, Batch 1/4: Clipping gradients...
  Epoch 29, Batch 1/4: Optimizer step...
  Epoch 29, Batch 1/4: Completed in 0.19s
  Epoch 29, Batch 2/4: Loading data to device...
  Epoch 29, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 29, Batch 2/4: Zeroing gradients...
  Epoch 29, Batch 2/4: Forward pass...
  Epoch 29, Batch 2/4: Calculating loss...
  Epoch 29, Batch 2/4: Backward pass...
  Epoch 29, Batch 2/4: Clipping gradients...
  Epoch 29, Batch 2/4: Optimizer step...
  Epoch 29, Batch 2/4: Completed in 0.19s
  Epoch 29, Batch 3/4: Loading data to device...
  Epoch 29, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 29, Batch 3/4: Zeroing gradients...
  Epoch 29, Batch 3/4: Forward pass...
  Epoch 29, Batch 3/4: Calculating loss...
  Epoch 29, Batch 3/4: Backward pass...
  Epoch 29, Batch 3/4: Clipping gradients...
  Epoch 29, Batch 3/4: Optimizer step...
  Epoch 29, Batch 3/4: Completed in 0.19s
  Epoch 29, Batch 4/4: Loading data to device...
  Epoch 29, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 29, Batch 4/4: Zeroing gradients...
  Epoch 29, Batch 4/4: Forward pass...
  Epoch 29, Batch 4/4: Calculating loss...
  Epoch 29, Batch 4/4: Backward pass...
  Epoch 29, Batch 4/4: Clipping gradients...
  Epoch 29, Batch 4/4: Optimizer step...
  Epoch 29, Batch 4/4: Completed in 0.03s
Epoch 29: Training phase completed. Average Train Loss: 0.6625
Epoch 29: Starting validation phase...
  Epoch 29, Val Batch 1/1: Loading data...
  Epoch 29, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 29, Val Batch 1/1: Forward pass...
  Epoch 29, Val Batch 1/1: Calculating loss...
Epoch 29: Validation phase completed. Average Val Loss: 0.6576
Epoch 29 Summary ---> Train Loss: 0.6625 / Validation Loss: 0.6576
Epoch 29: Checking early stopping... (Current Best Loss: 0.6763, Epochs No Improve: 0)
  Epoch 29: Validation loss improved (0.6763 --> 0.6576). Saving model.
Epoch 29: Stepping scheduler...
--- Epoch 29 completed in 0.67 seconds ---

--- Starting Epoch 30/1000 ---
Epoch 30: Starting training phase (4 batches)
  Epoch 30, Batch 1/4: Loading data to device...
  Epoch 30, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 30, Batch 1/4: Zeroing gradients...
  Epoch 30, Batch 1/4: Forward pass...
  Epoch 30, Batch 1/4: Calculating loss...
  Epoch 30, Batch 1/4: Backward pass...
  Epoch 30, Batch 1/4: Clipping gradients...
  Epoch 30, Batch 1/4: Optimizer step...
  Epoch 30, Batch 1/4: Completed in 0.19s
  Epoch 30, Batch 2/4: Loading data to device...
  Epoch 30, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 30, Batch 2/4: Zeroing gradients...
  Epoch 30, Batch 2/4: Forward pass...
  Epoch 30, Batch 2/4: Calculating loss...
  Epoch 30, Batch 2/4: Backward pass...
  Epoch 30, Batch 2/4: Clipping gradients...
  Epoch 30, Batch 2/4: Optimizer step...
  Epoch 30, Batch 2/4: Completed in 0.19s
  Epoch 30, Batch 3/4: Loading data to device...
  Epoch 30, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 30, Batch 3/4: Zeroing gradients...
  Epoch 30, Batch 3/4: Forward pass...
  Epoch 30, Batch 3/4: Calculating loss...
  Epoch 30, Batch 3/4: Backward pass...
  Epoch 30, Batch 3/4: Clipping gradients...
  Epoch 30, Batch 3/4: Optimizer step...
  Epoch 30, Batch 3/4: Completed in 0.19s
  Epoch 30, Batch 4/4: Loading data to device...
  Epoch 30, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 30, Batch 4/4: Zeroing gradients...
  Epoch 30, Batch 4/4: Forward pass...
  Epoch 30, Batch 4/4: Calculating loss...
  Epoch 30, Batch 4/4: Backward pass...
  Epoch 30, Batch 4/4: Clipping gradients...
  Epoch 30, Batch 4/4: Optimizer step...
  Epoch 30, Batch 4/4: Completed in 0.03s
Epoch 30: Training phase completed. Average Train Loss: 0.6658
Epoch 30: Starting validation phase...
  Epoch 30, Val Batch 1/1: Loading data...
  Epoch 30, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 30, Val Batch 1/1: Forward pass...
  Epoch 30, Val Batch 1/1: Calculating loss...
Epoch 30: Validation phase completed. Average Val Loss: 0.6398
Epoch 30 Summary ---> Train Loss: 0.6658 / Validation Loss: 0.6398
Epoch 30: Checking early stopping... (Current Best Loss: 0.6576, Epochs No Improve: 0)
  Epoch 30: Validation loss improved (0.6576 --> 0.6398). Saving model.
Epoch 30: Stepping scheduler...
--- Epoch 30 completed in 0.68 seconds ---

--- Starting Epoch 31/1000 ---
Epoch 31: Starting training phase (4 batches)
  Epoch 31, Batch 1/4: Loading data to device...
  Epoch 31, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 31, Batch 1/4: Zeroing gradients...
  Epoch 31, Batch 1/4: Forward pass...
  Epoch 31, Batch 1/4: Calculating loss...
  Epoch 31, Batch 1/4: Backward pass...
  Epoch 31, Batch 1/4: Clipping gradients...
  Epoch 31, Batch 1/4: Optimizer step...
  Epoch 31, Batch 1/4: Completed in 0.20s
  Epoch 31, Batch 2/4: Loading data to device...
  Epoch 31, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 31, Batch 2/4: Zeroing gradients...
  Epoch 31, Batch 2/4: Forward pass...
  Epoch 31, Batch 2/4: Calculating loss...
  Epoch 31, Batch 2/4: Backward pass...
  Epoch 31, Batch 2/4: Clipping gradients...
  Epoch 31, Batch 2/4: Optimizer step...
  Epoch 31, Batch 2/4: Completed in 0.21s
  Epoch 31, Batch 3/4: Loading data to device...
  Epoch 31, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 31, Batch 3/4: Zeroing gradients...
  Epoch 31, Batch 3/4: Forward pass...
  Epoch 31, Batch 3/4: Calculating loss...
  Epoch 31, Batch 3/4: Backward pass...
  Epoch 31, Batch 3/4: Clipping gradients...
  Epoch 31, Batch 3/4: Optimizer step...
  Epoch 31, Batch 3/4: Completed in 0.20s
  Epoch 31, Batch 4/4: Loading data to device...
  Epoch 31, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 31, Batch 4/4: Zeroing gradients...
  Epoch 31, Batch 4/4: Forward pass...
  Epoch 31, Batch 4/4: Calculating loss...
  Epoch 31, Batch 4/4: Backward pass...
  Epoch 31, Batch 4/4: Clipping gradients...
  Epoch 31, Batch 4/4: Optimizer step...
  Epoch 31, Batch 4/4: Completed in 0.03s
Epoch 31: Training phase completed. Average Train Loss: 0.6336
Epoch 31: Starting validation phase...
  Epoch 31, Val Batch 1/1: Loading data...
  Epoch 31, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 31, Val Batch 1/1: Forward pass...
  Epoch 31, Val Batch 1/1: Calculating loss...
Epoch 31: Validation phase completed. Average Val Loss: 0.6265
Epoch 31 Summary ---> Train Loss: 0.6336 / Validation Loss: 0.6265
Epoch 31: Checking early stopping... (Current Best Loss: 0.6398, Epochs No Improve: 0)
  Epoch 31: Validation loss improved (0.6398 --> 0.6265). Saving model.
Epoch 31: Stepping scheduler...
--- Epoch 31 completed in 0.70 seconds ---

--- Starting Epoch 32/1000 ---
Epoch 32: Starting training phase (4 batches)
  Epoch 32, Batch 1/4: Loading data to device...
  Epoch 32, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 32, Batch 1/4: Zeroing gradients...
  Epoch 32, Batch 1/4: Forward pass...
  Epoch 32, Batch 1/4: Calculating loss...
  Epoch 32, Batch 1/4: Backward pass...
  Epoch 32, Batch 1/4: Clipping gradients...
  Epoch 32, Batch 1/4: Optimizer step...
  Epoch 32, Batch 1/4: Completed in 0.19s
  Epoch 32, Batch 2/4: Loading data to device...
  Epoch 32, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 32, Batch 2/4: Zeroing gradients...
  Epoch 32, Batch 2/4: Forward pass...
  Epoch 32, Batch 2/4: Calculating loss...
  Epoch 32, Batch 2/4: Backward pass...
  Epoch 32, Batch 2/4: Clipping gradients...
  Epoch 32, Batch 2/4: Optimizer step...
  Epoch 32, Batch 2/4: Completed in 0.19s
  Epoch 32, Batch 3/4: Loading data to device...
  Epoch 32, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 32, Batch 3/4: Zeroing gradients...
  Epoch 32, Batch 3/4: Forward pass...
  Epoch 32, Batch 3/4: Calculating loss...
  Epoch 32, Batch 3/4: Backward pass...
  Epoch 32, Batch 3/4: Clipping gradients...
  Epoch 32, Batch 3/4: Optimizer step...
  Epoch 32, Batch 3/4: Completed in 0.20s
  Epoch 32, Batch 4/4: Loading data to device...
  Epoch 32, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 32, Batch 4/4: Zeroing gradients...
  Epoch 32, Batch 4/4: Forward pass...
  Epoch 32, Batch 4/4: Calculating loss...
  Epoch 32, Batch 4/4: Backward pass...
  Epoch 32, Batch 4/4: Clipping gradients...
  Epoch 32, Batch 4/4: Optimizer step...
  Epoch 32, Batch 4/4: Completed in 0.03s
Epoch 32: Training phase completed. Average Train Loss: 0.6707
Epoch 32: Starting validation phase...
  Epoch 32, Val Batch 1/1: Loading data...
  Epoch 32, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 32, Val Batch 1/1: Forward pass...
  Epoch 32, Val Batch 1/1: Calculating loss...
Epoch 32: Validation phase completed. Average Val Loss: 0.6215
Epoch 32 Summary ---> Train Loss: 0.6707 / Validation Loss: 0.6215
Epoch 32: Checking early stopping... (Current Best Loss: 0.6265, Epochs No Improve: 0)
  Epoch 32: Validation loss improved (0.6265 --> 0.6215). Saving model.
Epoch 32: Stepping scheduler...
--- Epoch 32 completed in 0.68 seconds ---

--- Starting Epoch 33/1000 ---
Epoch 33: Starting training phase (4 batches)
  Epoch 33, Batch 1/4: Loading data to device...
  Epoch 33, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 33, Batch 1/4: Zeroing gradients...
  Epoch 33, Batch 1/4: Forward pass...
  Epoch 33, Batch 1/4: Calculating loss...
  Epoch 33, Batch 1/4: Backward pass...
  Epoch 33, Batch 1/4: Clipping gradients...
  Epoch 33, Batch 1/4: Optimizer step...
  Epoch 33, Batch 1/4: Completed in 0.19s
  Epoch 33, Batch 2/4: Loading data to device...
  Epoch 33, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 33, Batch 2/4: Zeroing gradients...
  Epoch 33, Batch 2/4: Forward pass...
  Epoch 33, Batch 2/4: Calculating loss...
  Epoch 33, Batch 2/4: Backward pass...
  Epoch 33, Batch 2/4: Clipping gradients...
  Epoch 33, Batch 2/4: Optimizer step...
  Epoch 33, Batch 2/4: Completed in 0.19s
  Epoch 33, Batch 3/4: Loading data to device...
  Epoch 33, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 33, Batch 3/4: Zeroing gradients...
  Epoch 33, Batch 3/4: Forward pass...
  Epoch 33, Batch 3/4: Calculating loss...
  Epoch 33, Batch 3/4: Backward pass...
  Epoch 33, Batch 3/4: Clipping gradients...
  Epoch 33, Batch 3/4: Optimizer step...
  Epoch 33, Batch 3/4: Completed in 0.19s
  Epoch 33, Batch 4/4: Loading data to device...
  Epoch 33, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 33, Batch 4/4: Zeroing gradients...
  Epoch 33, Batch 4/4: Forward pass...
  Epoch 33, Batch 4/4: Calculating loss...
  Epoch 33, Batch 4/4: Backward pass...
  Epoch 33, Batch 4/4: Clipping gradients...
  Epoch 33, Batch 4/4: Optimizer step...
  Epoch 33, Batch 4/4: Completed in 0.03s
Epoch 33: Training phase completed. Average Train Loss: 0.6253
Epoch 33: Starting validation phase...
  Epoch 33, Val Batch 1/1: Loading data...
  Epoch 33, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 33, Val Batch 1/1: Forward pass...
  Epoch 33, Val Batch 1/1: Calculating loss...
Epoch 33: Validation phase completed. Average Val Loss: 0.6081
Epoch 33 Summary ---> Train Loss: 0.6253 / Validation Loss: 0.6081
Epoch 33: Checking early stopping... (Current Best Loss: 0.6215, Epochs No Improve: 0)
  Epoch 33: Validation loss improved (0.6215 --> 0.6081). Saving model.
Epoch 33: Stepping scheduler...
--- Epoch 33 completed in 0.67 seconds ---

--- Starting Epoch 34/1000 ---
Epoch 34: Starting training phase (4 batches)
  Epoch 34, Batch 1/4: Loading data to device...
  Epoch 34, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 34, Batch 1/4: Zeroing gradients...
  Epoch 34, Batch 1/4: Forward pass...
  Epoch 34, Batch 1/4: Calculating loss...
  Epoch 34, Batch 1/4: Backward pass...
  Epoch 34, Batch 1/4: Clipping gradients...
  Epoch 34, Batch 1/4: Optimizer step...
  Epoch 34, Batch 1/4: Completed in 0.20s
  Epoch 34, Batch 2/4: Loading data to device...
  Epoch 34, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 34, Batch 2/4: Zeroing gradients...
  Epoch 34, Batch 2/4: Forward pass...
  Epoch 34, Batch 2/4: Calculating loss...
  Epoch 34, Batch 2/4: Backward pass...
  Epoch 34, Batch 2/4: Clipping gradients...
  Epoch 34, Batch 2/4: Optimizer step...
  Epoch 34, Batch 2/4: Completed in 0.20s
  Epoch 34, Batch 3/4: Loading data to device...
  Epoch 34, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 34, Batch 3/4: Zeroing gradients...
  Epoch 34, Batch 3/4: Forward pass...
  Epoch 34, Batch 3/4: Calculating loss...
  Epoch 34, Batch 3/4: Backward pass...
  Epoch 34, Batch 3/4: Clipping gradients...
  Epoch 34, Batch 3/4: Optimizer step...
  Epoch 34, Batch 3/4: Completed in 0.20s
  Epoch 34, Batch 4/4: Loading data to device...
  Epoch 34, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 34, Batch 4/4: Zeroing gradients...
  Epoch 34, Batch 4/4: Forward pass...
  Epoch 34, Batch 4/4: Calculating loss...
  Epoch 34, Batch 4/4: Backward pass...
  Epoch 34, Batch 4/4: Clipping gradients...
  Epoch 34, Batch 4/4: Optimizer step...
  Epoch 34, Batch 4/4: Completed in 0.03s
Epoch 34: Training phase completed. Average Train Loss: 0.6038
Epoch 34: Starting validation phase...
  Epoch 34, Val Batch 1/1: Loading data...
  Epoch 34, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 34, Val Batch 1/1: Forward pass...
  Epoch 34, Val Batch 1/1: Calculating loss...
Epoch 34: Validation phase completed. Average Val Loss: 0.6002
Epoch 34 Summary ---> Train Loss: 0.6038 / Validation Loss: 0.6002
Epoch 34: Checking early stopping... (Current Best Loss: 0.6081, Epochs No Improve: 0)
  Epoch 34: Validation loss improved (0.6081 --> 0.6002). Saving model.
Epoch 34: Stepping scheduler...
--- Epoch 34 completed in 0.69 seconds ---

--- Starting Epoch 35/1000 ---
Epoch 35: Starting training phase (4 batches)
  Epoch 35, Batch 1/4: Loading data to device...
  Epoch 35, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 35, Batch 1/4: Zeroing gradients...
  Epoch 35, Batch 1/4: Forward pass...
  Epoch 35, Batch 1/4: Calculating loss...
  Epoch 35, Batch 1/4: Backward pass...
  Epoch 35, Batch 1/4: Clipping gradients...
  Epoch 35, Batch 1/4: Optimizer step...
  Epoch 35, Batch 1/4: Completed in 0.19s
  Epoch 35, Batch 2/4: Loading data to device...
  Epoch 35, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 35, Batch 2/4: Zeroing gradients...
  Epoch 35, Batch 2/4: Forward pass...
  Epoch 35, Batch 2/4: Calculating loss...
  Epoch 35, Batch 2/4: Backward pass...
  Epoch 35, Batch 2/4: Clipping gradients...
  Epoch 35, Batch 2/4: Optimizer step...
  Epoch 35, Batch 2/4: Completed in 0.19s
  Epoch 35, Batch 3/4: Loading data to device...
  Epoch 35, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 35, Batch 3/4: Zeroing gradients...
  Epoch 35, Batch 3/4: Forward pass...
  Epoch 35, Batch 3/4: Calculating loss...
  Epoch 35, Batch 3/4: Backward pass...
  Epoch 35, Batch 3/4: Clipping gradients...
  Epoch 35, Batch 3/4: Optimizer step...
  Epoch 35, Batch 3/4: Completed in 0.20s
  Epoch 35, Batch 4/4: Loading data to device...
  Epoch 35, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 35, Batch 4/4: Zeroing gradients...
  Epoch 35, Batch 4/4: Forward pass...
  Epoch 35, Batch 4/4: Calculating loss...
  Epoch 35, Batch 4/4: Backward pass...
  Epoch 35, Batch 4/4: Clipping gradients...
  Epoch 35, Batch 4/4: Optimizer step...
  Epoch 35, Batch 4/4: Completed in 0.03s
Epoch 35: Training phase completed. Average Train Loss: 0.6216
Epoch 35: Starting validation phase...
  Epoch 35, Val Batch 1/1: Loading data...
  Epoch 35, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 35, Val Batch 1/1: Forward pass...
  Epoch 35, Val Batch 1/1: Calculating loss...
Epoch 35: Validation phase completed. Average Val Loss: 0.5910
Epoch 35 Summary ---> Train Loss: 0.6216 / Validation Loss: 0.5910
Epoch 35: Checking early stopping... (Current Best Loss: 0.6002, Epochs No Improve: 0)
  Epoch 35: Validation loss improved (0.6002 --> 0.5910). Saving model.
Epoch 35: Stepping scheduler...
--- Epoch 35 completed in 0.68 seconds ---

--- Starting Epoch 36/1000 ---
Epoch 36: Starting training phase (4 batches)
  Epoch 36, Batch 1/4: Loading data to device...
  Epoch 36, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 36, Batch 1/4: Zeroing gradients...
  Epoch 36, Batch 1/4: Forward pass...
  Epoch 36, Batch 1/4: Calculating loss...
  Epoch 36, Batch 1/4: Backward pass...
  Epoch 36, Batch 1/4: Clipping gradients...
  Epoch 36, Batch 1/4: Optimizer step...
  Epoch 36, Batch 1/4: Completed in 0.20s
  Epoch 36, Batch 2/4: Loading data to device...
  Epoch 36, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 36, Batch 2/4: Zeroing gradients...
  Epoch 36, Batch 2/4: Forward pass...
  Epoch 36, Batch 2/4: Calculating loss...
  Epoch 36, Batch 2/4: Backward pass...
  Epoch 36, Batch 2/4: Clipping gradients...
  Epoch 36, Batch 2/4: Optimizer step...
  Epoch 36, Batch 2/4: Completed in 0.19s
  Epoch 36, Batch 3/4: Loading data to device...
  Epoch 36, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 36, Batch 3/4: Zeroing gradients...
  Epoch 36, Batch 3/4: Forward pass...
  Epoch 36, Batch 3/4: Calculating loss...
  Epoch 36, Batch 3/4: Backward pass...
  Epoch 36, Batch 3/4: Clipping gradients...
  Epoch 36, Batch 3/4: Optimizer step...
  Epoch 36, Batch 3/4: Completed in 0.19s
  Epoch 36, Batch 4/4: Loading data to device...
  Epoch 36, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 36, Batch 4/4: Zeroing gradients...
  Epoch 36, Batch 4/4: Forward pass...
  Epoch 36, Batch 4/4: Calculating loss...
  Epoch 36, Batch 4/4: Backward pass...
  Epoch 36, Batch 4/4: Clipping gradients...
  Epoch 36, Batch 4/4: Optimizer step...
  Epoch 36, Batch 4/4: Completed in 0.03s
Epoch 36: Training phase completed. Average Train Loss: 0.7102
Epoch 36: Starting validation phase...
  Epoch 36, Val Batch 1/1: Loading data...
  Epoch 36, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 36, Val Batch 1/1: Forward pass...
  Epoch 36, Val Batch 1/1: Calculating loss...
Epoch 36: Validation phase completed. Average Val Loss: 0.5941
Epoch 36 Summary ---> Train Loss: 0.7102 / Validation Loss: 0.5941
Epoch 36: Checking early stopping... (Current Best Loss: 0.5910, Epochs No Improve: 0)
  Epoch 36: Validation loss did not improve. Epochs without improvement: 1
Epoch 36: Stepping scheduler...
--- Epoch 36 completed in 0.68 seconds ---

--- Starting Epoch 37/1000 ---
Epoch 37: Starting training phase (4 batches)
  Epoch 37, Batch 1/4: Loading data to device...
  Epoch 37, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 37, Batch 1/4: Zeroing gradients...
  Epoch 37, Batch 1/4: Forward pass...
  Epoch 37, Batch 1/4: Calculating loss...
  Epoch 37, Batch 1/4: Backward pass...
  Epoch 37, Batch 1/4: Clipping gradients...
  Epoch 37, Batch 1/4: Optimizer step...
  Epoch 37, Batch 1/4: Completed in 0.19s
  Epoch 37, Batch 2/4: Loading data to device...
  Epoch 37, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 37, Batch 2/4: Zeroing gradients...
  Epoch 37, Batch 2/4: Forward pass...
  Epoch 37, Batch 2/4: Calculating loss...
  Epoch 37, Batch 2/4: Backward pass...
  Epoch 37, Batch 2/4: Clipping gradients...
  Epoch 37, Batch 2/4: Optimizer step...
  Epoch 37, Batch 2/4: Completed in 0.19s
  Epoch 37, Batch 3/4: Loading data to device...
  Epoch 37, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 37, Batch 3/4: Zeroing gradients...
  Epoch 37, Batch 3/4: Forward pass...
  Epoch 37, Batch 3/4: Calculating loss...
  Epoch 37, Batch 3/4: Backward pass...
  Epoch 37, Batch 3/4: Clipping gradients...
  Epoch 37, Batch 3/4: Optimizer step...
  Epoch 37, Batch 3/4: Completed in 0.19s
  Epoch 37, Batch 4/4: Loading data to device...
  Epoch 37, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 37, Batch 4/4: Zeroing gradients...
  Epoch 37, Batch 4/4: Forward pass...
  Epoch 37, Batch 4/4: Calculating loss...
  Epoch 37, Batch 4/4: Backward pass...
  Epoch 37, Batch 4/4: Clipping gradients...
  Epoch 37, Batch 4/4: Optimizer step...
  Epoch 37, Batch 4/4: Completed in 0.04s
Epoch 37: Training phase completed. Average Train Loss: 0.6146
Epoch 37: Starting validation phase...
  Epoch 37, Val Batch 1/1: Loading data...
  Epoch 37, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 37, Val Batch 1/1: Forward pass...
  Epoch 37, Val Batch 1/1: Calculating loss...
Epoch 37: Validation phase completed. Average Val Loss: 0.5748
Epoch 37 Summary ---> Train Loss: 0.6146 / Validation Loss: 0.5748
Epoch 37: Checking early stopping... (Current Best Loss: 0.5910, Epochs No Improve: 1)
  Epoch 37: Validation loss improved (0.5910 --> 0.5748). Saving model.
Epoch 37: Stepping scheduler...
--- Epoch 37 completed in 0.67 seconds ---

--- Starting Epoch 38/1000 ---
Epoch 38: Starting training phase (4 batches)
  Epoch 38, Batch 1/4: Loading data to device...
  Epoch 38, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 38, Batch 1/4: Zeroing gradients...
  Epoch 38, Batch 1/4: Forward pass...
  Epoch 38, Batch 1/4: Calculating loss...
  Epoch 38, Batch 1/4: Backward pass...
  Epoch 38, Batch 1/4: Clipping gradients...
  Epoch 38, Batch 1/4: Optimizer step...
  Epoch 38, Batch 1/4: Completed in 0.19s
  Epoch 38, Batch 2/4: Loading data to device...
  Epoch 38, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 38, Batch 2/4: Zeroing gradients...
  Epoch 38, Batch 2/4: Forward pass...
  Epoch 38, Batch 2/4: Calculating loss...
  Epoch 38, Batch 2/4: Backward pass...
  Epoch 38, Batch 2/4: Clipping gradients...
  Epoch 38, Batch 2/4: Optimizer step...
  Epoch 38, Batch 2/4: Completed in 0.20s
  Epoch 38, Batch 3/4: Loading data to device...
  Epoch 38, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 38, Batch 3/4: Zeroing gradients...
  Epoch 38, Batch 3/4: Forward pass...
  Epoch 38, Batch 3/4: Calculating loss...
  Epoch 38, Batch 3/4: Backward pass...
  Epoch 38, Batch 3/4: Clipping gradients...
  Epoch 38, Batch 3/4: Optimizer step...
  Epoch 38, Batch 3/4: Completed in 0.20s
  Epoch 38, Batch 4/4: Loading data to device...
  Epoch 38, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 38, Batch 4/4: Zeroing gradients...
  Epoch 38, Batch 4/4: Forward pass...
  Epoch 38, Batch 4/4: Calculating loss...
  Epoch 38, Batch 4/4: Backward pass...
  Epoch 38, Batch 4/4: Clipping gradients...
  Epoch 38, Batch 4/4: Optimizer step...
  Epoch 38, Batch 4/4: Completed in 0.03s
Epoch 38: Training phase completed. Average Train Loss: 0.6114
Epoch 38: Starting validation phase...
  Epoch 38, Val Batch 1/1: Loading data...
  Epoch 38, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 38, Val Batch 1/1: Forward pass...
  Epoch 38, Val Batch 1/1: Calculating loss...
Epoch 38: Validation phase completed. Average Val Loss: 0.5727
Epoch 38 Summary ---> Train Loss: 0.6114 / Validation Loss: 0.5727
Epoch 38: Checking early stopping... (Current Best Loss: 0.5748, Epochs No Improve: 0)
  Epoch 38: Validation loss improved (0.5748 --> 0.5727). Saving model.
Epoch 38: Stepping scheduler...
--- Epoch 38 completed in 0.68 seconds ---

--- Starting Epoch 39/1000 ---
Epoch 39: Starting training phase (4 batches)
  Epoch 39, Batch 1/4: Loading data to device...
  Epoch 39, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 39, Batch 1/4: Zeroing gradients...
  Epoch 39, Batch 1/4: Forward pass...
  Epoch 39, Batch 1/4: Calculating loss...
  Epoch 39, Batch 1/4: Backward pass...
  Epoch 39, Batch 1/4: Clipping gradients...
  Epoch 39, Batch 1/4: Optimizer step...
  Epoch 39, Batch 1/4: Completed in 0.20s
  Epoch 39, Batch 2/4: Loading data to device...
  Epoch 39, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 39, Batch 2/4: Zeroing gradients...
  Epoch 39, Batch 2/4: Forward pass...
  Epoch 39, Batch 2/4: Calculating loss...
  Epoch 39, Batch 2/4: Backward pass...
  Epoch 39, Batch 2/4: Clipping gradients...
  Epoch 39, Batch 2/4: Optimizer step...
  Epoch 39, Batch 2/4: Completed in 0.20s
  Epoch 39, Batch 3/4: Loading data to device...
  Epoch 39, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 39, Batch 3/4: Zeroing gradients...
  Epoch 39, Batch 3/4: Forward pass...
  Epoch 39, Batch 3/4: Calculating loss...
  Epoch 39, Batch 3/4: Backward pass...
  Epoch 39, Batch 3/4: Clipping gradients...
  Epoch 39, Batch 3/4: Optimizer step...
  Epoch 39, Batch 3/4: Completed in 0.19s
  Epoch 39, Batch 4/4: Loading data to device...
  Epoch 39, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 39, Batch 4/4: Zeroing gradients...
  Epoch 39, Batch 4/4: Forward pass...
  Epoch 39, Batch 4/4: Calculating loss...
  Epoch 39, Batch 4/4: Backward pass...
  Epoch 39, Batch 4/4: Clipping gradients...
  Epoch 39, Batch 4/4: Optimizer step...
  Epoch 39, Batch 4/4: Completed in 0.03s
Epoch 39: Training phase completed. Average Train Loss: 0.6463
Epoch 39: Starting validation phase...
  Epoch 39, Val Batch 1/1: Loading data...
  Epoch 39, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 39, Val Batch 1/1: Forward pass...
  Epoch 39, Val Batch 1/1: Calculating loss...
Epoch 39: Validation phase completed. Average Val Loss: 0.5644
Epoch 39 Summary ---> Train Loss: 0.6463 / Validation Loss: 0.5644
Epoch 39: Checking early stopping... (Current Best Loss: 0.5727, Epochs No Improve: 0)
  Epoch 39: Validation loss improved (0.5727 --> 0.5644). Saving model.
Epoch 39: Stepping scheduler...
--- Epoch 39 completed in 0.69 seconds ---

--- Starting Epoch 40/1000 ---
Epoch 40: Starting training phase (4 batches)
  Epoch 40, Batch 1/4: Loading data to device...
  Epoch 40, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 40, Batch 1/4: Zeroing gradients...
  Epoch 40, Batch 1/4: Forward pass...
  Epoch 40, Batch 1/4: Calculating loss...
  Epoch 40, Batch 1/4: Backward pass...
  Epoch 40, Batch 1/4: Clipping gradients...
  Epoch 40, Batch 1/4: Optimizer step...
  Epoch 40, Batch 1/4: Completed in 0.19s
  Epoch 40, Batch 2/4: Loading data to device...
  Epoch 40, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 40, Batch 2/4: Zeroing gradients...
  Epoch 40, Batch 2/4: Forward pass...
  Epoch 40, Batch 2/4: Calculating loss...
  Epoch 40, Batch 2/4: Backward pass...
  Epoch 40, Batch 2/4: Clipping gradients...
  Epoch 40, Batch 2/4: Optimizer step...
  Epoch 40, Batch 2/4: Completed in 0.20s
  Epoch 40, Batch 3/4: Loading data to device...
  Epoch 40, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 40, Batch 3/4: Zeroing gradients...
  Epoch 40, Batch 3/4: Forward pass...
  Epoch 40, Batch 3/4: Calculating loss...
  Epoch 40, Batch 3/4: Backward pass...
  Epoch 40, Batch 3/4: Clipping gradients...
  Epoch 40, Batch 3/4: Optimizer step...
  Epoch 40, Batch 3/4: Completed in 0.20s
  Epoch 40, Batch 4/4: Loading data to device...
  Epoch 40, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 40, Batch 4/4: Zeroing gradients...
  Epoch 40, Batch 4/4: Forward pass...
  Epoch 40, Batch 4/4: Calculating loss...
  Epoch 40, Batch 4/4: Backward pass...
  Epoch 40, Batch 4/4: Clipping gradients...
  Epoch 40, Batch 4/4: Optimizer step...
  Epoch 40, Batch 4/4: Completed in 0.03s
Epoch 40: Training phase completed. Average Train Loss: 0.6454
Epoch 40: Starting validation phase...
  Epoch 40, Val Batch 1/1: Loading data...
  Epoch 40, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 40, Val Batch 1/1: Forward pass...
  Epoch 40, Val Batch 1/1: Calculating loss...
Epoch 40: Validation phase completed. Average Val Loss: 0.5677
Epoch 40 Summary ---> Train Loss: 0.6454 / Validation Loss: 0.5677
Epoch 40: Checking early stopping... (Current Best Loss: 0.5644, Epochs No Improve: 0)
  Epoch 40: Validation loss did not improve. Epochs without improvement: 1
Epoch 40: Stepping scheduler...
--- Epoch 40 completed in 0.69 seconds ---

--- Starting Epoch 41/1000 ---
Epoch 41: Starting training phase (4 batches)
  Epoch 41, Batch 1/4: Loading data to device...
  Epoch 41, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 41, Batch 1/4: Zeroing gradients...
  Epoch 41, Batch 1/4: Forward pass...
  Epoch 41, Batch 1/4: Calculating loss...
  Epoch 41, Batch 1/4: Backward pass...
  Epoch 41, Batch 1/4: Clipping gradients...
  Epoch 41, Batch 1/4: Optimizer step...
  Epoch 41, Batch 1/4: Completed in 0.20s
  Epoch 41, Batch 2/4: Loading data to device...
  Epoch 41, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 41, Batch 2/4: Zeroing gradients...
  Epoch 41, Batch 2/4: Forward pass...
  Epoch 41, Batch 2/4: Calculating loss...
  Epoch 41, Batch 2/4: Backward pass...
  Epoch 41, Batch 2/4: Clipping gradients...
  Epoch 41, Batch 2/4: Optimizer step...
  Epoch 41, Batch 2/4: Completed in 0.19s
  Epoch 41, Batch 3/4: Loading data to device...
  Epoch 41, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 41, Batch 3/4: Zeroing gradients...
  Epoch 41, Batch 3/4: Forward pass...
  Epoch 41, Batch 3/4: Calculating loss...
  Epoch 41, Batch 3/4: Backward pass...
  Epoch 41, Batch 3/4: Clipping gradients...
  Epoch 41, Batch 3/4: Optimizer step...
  Epoch 41, Batch 3/4: Completed in 0.19s
  Epoch 41, Batch 4/4: Loading data to device...
  Epoch 41, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 41, Batch 4/4: Zeroing gradients...
  Epoch 41, Batch 4/4: Forward pass...
  Epoch 41, Batch 4/4: Calculating loss...
  Epoch 41, Batch 4/4: Backward pass...
  Epoch 41, Batch 4/4: Clipping gradients...
  Epoch 41, Batch 4/4: Optimizer step...
  Epoch 41, Batch 4/4: Completed in 0.04s
Epoch 41: Training phase completed. Average Train Loss: 0.6224
Epoch 41: Starting validation phase...
  Epoch 41, Val Batch 1/1: Loading data...
  Epoch 41, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 41, Val Batch 1/1: Forward pass...
  Epoch 41, Val Batch 1/1: Calculating loss...
Epoch 41: Validation phase completed. Average Val Loss: 0.5700
Epoch 41 Summary ---> Train Loss: 0.6224 / Validation Loss: 0.5700
Epoch 41: Checking early stopping... (Current Best Loss: 0.5644, Epochs No Improve: 1)
  Epoch 41: Validation loss did not improve. Epochs without improvement: 2
Epoch 41: Stepping scheduler...
--- Epoch 41 completed in 0.69 seconds ---

--- Starting Epoch 42/1000 ---
Epoch 42: Starting training phase (4 batches)
  Epoch 42, Batch 1/4: Loading data to device...
  Epoch 42, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 42, Batch 1/4: Zeroing gradients...
  Epoch 42, Batch 1/4: Forward pass...
  Epoch 42, Batch 1/4: Calculating loss...
  Epoch 42, Batch 1/4: Backward pass...
  Epoch 42, Batch 1/4: Clipping gradients...
  Epoch 42, Batch 1/4: Optimizer step...
  Epoch 42, Batch 1/4: Completed in 0.20s
  Epoch 42, Batch 2/4: Loading data to device...
  Epoch 42, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 42, Batch 2/4: Zeroing gradients...
  Epoch 42, Batch 2/4: Forward pass...
  Epoch 42, Batch 2/4: Calculating loss...
  Epoch 42, Batch 2/4: Backward pass...
  Epoch 42, Batch 2/4: Clipping gradients...
  Epoch 42, Batch 2/4: Optimizer step...
  Epoch 42, Batch 2/4: Completed in 0.19s
  Epoch 42, Batch 3/4: Loading data to device...
  Epoch 42, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 42, Batch 3/4: Zeroing gradients...
  Epoch 42, Batch 3/4: Forward pass...
  Epoch 42, Batch 3/4: Calculating loss...
  Epoch 42, Batch 3/4: Backward pass...
  Epoch 42, Batch 3/4: Clipping gradients...
  Epoch 42, Batch 3/4: Optimizer step...
  Epoch 42, Batch 3/4: Completed in 0.19s
  Epoch 42, Batch 4/4: Loading data to device...
  Epoch 42, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 42, Batch 4/4: Zeroing gradients...
  Epoch 42, Batch 4/4: Forward pass...
  Epoch 42, Batch 4/4: Calculating loss...
  Epoch 42, Batch 4/4: Backward pass...
  Epoch 42, Batch 4/4: Clipping gradients...
  Epoch 42, Batch 4/4: Optimizer step...
  Epoch 42, Batch 4/4: Completed in 0.03s
Epoch 42: Training phase completed. Average Train Loss: 0.6197
Epoch 42: Starting validation phase...
  Epoch 42, Val Batch 1/1: Loading data...
  Epoch 42, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 42, Val Batch 1/1: Forward pass...
  Epoch 42, Val Batch 1/1: Calculating loss...
Epoch 42: Validation phase completed. Average Val Loss: 0.5631
Epoch 42 Summary ---> Train Loss: 0.6197 / Validation Loss: 0.5631
Epoch 42: Checking early stopping... (Current Best Loss: 0.5644, Epochs No Improve: 2)
  Epoch 42: Validation loss improved (0.5644 --> 0.5631). Saving model.
Epoch 42: Stepping scheduler...
--- Epoch 42 completed in 0.68 seconds ---

--- Starting Epoch 43/1000 ---
Epoch 43: Starting training phase (4 batches)
  Epoch 43, Batch 1/4: Loading data to device...
  Epoch 43, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 43, Batch 1/4: Zeroing gradients...
  Epoch 43, Batch 1/4: Forward pass...
  Epoch 43, Batch 1/4: Calculating loss...
  Epoch 43, Batch 1/4: Backward pass...
  Epoch 43, Batch 1/4: Clipping gradients...
  Epoch 43, Batch 1/4: Optimizer step...
  Epoch 43, Batch 1/4: Completed in 0.19s
  Epoch 43, Batch 2/4: Loading data to device...
  Epoch 43, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 43, Batch 2/4: Zeroing gradients...
  Epoch 43, Batch 2/4: Forward pass...
  Epoch 43, Batch 2/4: Calculating loss...
  Epoch 43, Batch 2/4: Backward pass...
  Epoch 43, Batch 2/4: Clipping gradients...
  Epoch 43, Batch 2/4: Optimizer step...
  Epoch 43, Batch 2/4: Completed in 0.19s
  Epoch 43, Batch 3/4: Loading data to device...
  Epoch 43, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 43, Batch 3/4: Zeroing gradients...
  Epoch 43, Batch 3/4: Forward pass...
  Epoch 43, Batch 3/4: Calculating loss...
  Epoch 43, Batch 3/4: Backward pass...
  Epoch 43, Batch 3/4: Clipping gradients...
  Epoch 43, Batch 3/4: Optimizer step...
  Epoch 43, Batch 3/4: Completed in 0.19s
  Epoch 43, Batch 4/4: Loading data to device...
  Epoch 43, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 43, Batch 4/4: Zeroing gradients...
  Epoch 43, Batch 4/4: Forward pass...
  Epoch 43, Batch 4/4: Calculating loss...
  Epoch 43, Batch 4/4: Backward pass...
  Epoch 43, Batch 4/4: Clipping gradients...
  Epoch 43, Batch 4/4: Optimizer step...
  Epoch 43, Batch 4/4: Completed in 0.03s
Epoch 43: Training phase completed. Average Train Loss: 0.5939
Epoch 43: Starting validation phase...
  Epoch 43, Val Batch 1/1: Loading data...
  Epoch 43, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 43, Val Batch 1/1: Forward pass...
  Epoch 43, Val Batch 1/1: Calculating loss...
Epoch 43: Validation phase completed. Average Val Loss: 0.5598
Epoch 43 Summary ---> Train Loss: 0.5939 / Validation Loss: 0.5598
Epoch 43: Checking early stopping... (Current Best Loss: 0.5631, Epochs No Improve: 0)
  Epoch 43: Validation loss improved (0.5631 --> 0.5598). Saving model.
Epoch 43: Stepping scheduler...
--- Epoch 43 completed in 0.67 seconds ---

--- Starting Epoch 44/1000 ---
Epoch 44: Starting training phase (4 batches)
  Epoch 44, Batch 1/4: Loading data to device...
  Epoch 44, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 44, Batch 1/4: Zeroing gradients...
  Epoch 44, Batch 1/4: Forward pass...
  Epoch 44, Batch 1/4: Calculating loss...
  Epoch 44, Batch 1/4: Backward pass...
  Epoch 44, Batch 1/4: Clipping gradients...
  Epoch 44, Batch 1/4: Optimizer step...
  Epoch 44, Batch 1/4: Completed in 0.19s
  Epoch 44, Batch 2/4: Loading data to device...
  Epoch 44, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 44, Batch 2/4: Zeroing gradients...
  Epoch 44, Batch 2/4: Forward pass...
  Epoch 44, Batch 2/4: Calculating loss...
  Epoch 44, Batch 2/4: Backward pass...
  Epoch 44, Batch 2/4: Clipping gradients...
  Epoch 44, Batch 2/4: Optimizer step...
  Epoch 44, Batch 2/4: Completed in 0.19s
  Epoch 44, Batch 3/4: Loading data to device...
  Epoch 44, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 44, Batch 3/4: Zeroing gradients...
  Epoch 44, Batch 3/4: Forward pass...
  Epoch 44, Batch 3/4: Calculating loss...
  Epoch 44, Batch 3/4: Backward pass...
  Epoch 44, Batch 3/4: Clipping gradients...
  Epoch 44, Batch 3/4: Optimizer step...
  Epoch 44, Batch 3/4: Completed in 0.20s
  Epoch 44, Batch 4/4: Loading data to device...
  Epoch 44, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 44, Batch 4/4: Zeroing gradients...
  Epoch 44, Batch 4/4: Forward pass...
  Epoch 44, Batch 4/4: Calculating loss...
  Epoch 44, Batch 4/4: Backward pass...
  Epoch 44, Batch 4/4: Clipping gradients...
  Epoch 44, Batch 4/4: Optimizer step...
  Epoch 44, Batch 4/4: Completed in 0.03s
Epoch 44: Training phase completed. Average Train Loss: 0.6841
Epoch 44: Starting validation phase...
  Epoch 44, Val Batch 1/1: Loading data...
  Epoch 44, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 44, Val Batch 1/1: Forward pass...
  Epoch 44, Val Batch 1/1: Calculating loss...
Epoch 44: Validation phase completed. Average Val Loss: 0.5526
Epoch 44 Summary ---> Train Loss: 0.6841 / Validation Loss: 0.5526
Epoch 44: Checking early stopping... (Current Best Loss: 0.5598, Epochs No Improve: 0)
  Epoch 44: Validation loss improved (0.5598 --> 0.5526). Saving model.
Epoch 44: Stepping scheduler...
--- Epoch 44 completed in 0.68 seconds ---

--- Starting Epoch 45/1000 ---
Epoch 45: Starting training phase (4 batches)
  Epoch 45, Batch 1/4: Loading data to device...
  Epoch 45, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 45, Batch 1/4: Zeroing gradients...
  Epoch 45, Batch 1/4: Forward pass...
  Epoch 45, Batch 1/4: Calculating loss...
  Epoch 45, Batch 1/4: Backward pass...
  Epoch 45, Batch 1/4: Clipping gradients...
  Epoch 45, Batch 1/4: Optimizer step...
  Epoch 45, Batch 1/4: Completed in 0.20s
  Epoch 45, Batch 2/4: Loading data to device...
  Epoch 45, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 45, Batch 2/4: Zeroing gradients...
  Epoch 45, Batch 2/4: Forward pass...
  Epoch 45, Batch 2/4: Calculating loss...
  Epoch 45, Batch 2/4: Backward pass...
  Epoch 45, Batch 2/4: Clipping gradients...
  Epoch 45, Batch 2/4: Optimizer step...
  Epoch 45, Batch 2/4: Completed in 0.19s
  Epoch 45, Batch 3/4: Loading data to device...
  Epoch 45, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 45, Batch 3/4: Zeroing gradients...
  Epoch 45, Batch 3/4: Forward pass...
  Epoch 45, Batch 3/4: Calculating loss...
  Epoch 45, Batch 3/4: Backward pass...
  Epoch 45, Batch 3/4: Clipping gradients...
  Epoch 45, Batch 3/4: Optimizer step...
  Epoch 45, Batch 3/4: Completed in 0.19s
  Epoch 45, Batch 4/4: Loading data to device...
  Epoch 45, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 45, Batch 4/4: Zeroing gradients...
  Epoch 45, Batch 4/4: Forward pass...
  Epoch 45, Batch 4/4: Calculating loss...
  Epoch 45, Batch 4/4: Backward pass...
  Epoch 45, Batch 4/4: Clipping gradients...
  Epoch 45, Batch 4/4: Optimizer step...
  Epoch 45, Batch 4/4: Completed in 0.03s
Epoch 45: Training phase completed. Average Train Loss: 0.6248
Epoch 45: Starting validation phase...
  Epoch 45, Val Batch 1/1: Loading data...
  Epoch 45, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 45, Val Batch 1/1: Forward pass...
  Epoch 45, Val Batch 1/1: Calculating loss...
Epoch 45: Validation phase completed. Average Val Loss: 0.5505
Epoch 45 Summary ---> Train Loss: 0.6248 / Validation Loss: 0.5505
Epoch 45: Checking early stopping... (Current Best Loss: 0.5526, Epochs No Improve: 0)
  Epoch 45: Validation loss improved (0.5526 --> 0.5505). Saving model.
Epoch 45: Stepping scheduler...
--- Epoch 45 completed in 0.67 seconds ---

--- Starting Epoch 46/1000 ---
Epoch 46: Starting training phase (4 batches)
  Epoch 46, Batch 1/4: Loading data to device...
  Epoch 46, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 46, Batch 1/4: Zeroing gradients...
  Epoch 46, Batch 1/4: Forward pass...
  Epoch 46, Batch 1/4: Calculating loss...
  Epoch 46, Batch 1/4: Backward pass...
  Epoch 46, Batch 1/4: Clipping gradients...
  Epoch 46, Batch 1/4: Optimizer step...
  Epoch 46, Batch 1/4: Completed in 0.19s
  Epoch 46, Batch 2/4: Loading data to device...
  Epoch 46, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 46, Batch 2/4: Zeroing gradients...
  Epoch 46, Batch 2/4: Forward pass...
  Epoch 46, Batch 2/4: Calculating loss...
  Epoch 46, Batch 2/4: Backward pass...
  Epoch 46, Batch 2/4: Clipping gradients...
  Epoch 46, Batch 2/4: Optimizer step...
  Epoch 46, Batch 2/4: Completed in 0.19s
  Epoch 46, Batch 3/4: Loading data to device...
  Epoch 46, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 46, Batch 3/4: Zeroing gradients...
  Epoch 46, Batch 3/4: Forward pass...
  Epoch 46, Batch 3/4: Calculating loss...
  Epoch 46, Batch 3/4: Backward pass...
  Epoch 46, Batch 3/4: Clipping gradients...
  Epoch 46, Batch 3/4: Optimizer step...
  Epoch 46, Batch 3/4: Completed in 0.19s
  Epoch 46, Batch 4/4: Loading data to device...
  Epoch 46, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 46, Batch 4/4: Zeroing gradients...
  Epoch 46, Batch 4/4: Forward pass...
  Epoch 46, Batch 4/4: Calculating loss...
  Epoch 46, Batch 4/4: Backward pass...
  Epoch 46, Batch 4/4: Clipping gradients...
  Epoch 46, Batch 4/4: Optimizer step...
  Epoch 46, Batch 4/4: Completed in 0.03s
Epoch 46: Training phase completed. Average Train Loss: 0.6369
Epoch 46: Starting validation phase...
  Epoch 46, Val Batch 1/1: Loading data...
  Epoch 46, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 46, Val Batch 1/1: Forward pass...
  Epoch 46, Val Batch 1/1: Calculating loss...
Epoch 46: Validation phase completed. Average Val Loss: 0.5494
Epoch 46 Summary ---> Train Loss: 0.6369 / Validation Loss: 0.5494
Epoch 46: Checking early stopping... (Current Best Loss: 0.5505, Epochs No Improve: 0)
  Epoch 46: Validation loss improved (0.5505 --> 0.5494). Saving model.
Epoch 46: Stepping scheduler...
--- Epoch 46 completed in 0.67 seconds ---

--- Starting Epoch 47/1000 ---
Epoch 47: Starting training phase (4 batches)
  Epoch 47, Batch 1/4: Loading data to device...
  Epoch 47, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 47, Batch 1/4: Zeroing gradients...
  Epoch 47, Batch 1/4: Forward pass...
  Epoch 47, Batch 1/4: Calculating loss...
  Epoch 47, Batch 1/4: Backward pass...
  Epoch 47, Batch 1/4: Clipping gradients...
  Epoch 47, Batch 1/4: Optimizer step...
  Epoch 47, Batch 1/4: Completed in 0.19s
  Epoch 47, Batch 2/4: Loading data to device...
  Epoch 47, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 47, Batch 2/4: Zeroing gradients...
  Epoch 47, Batch 2/4: Forward pass...
  Epoch 47, Batch 2/4: Calculating loss...
  Epoch 47, Batch 2/4: Backward pass...
  Epoch 47, Batch 2/4: Clipping gradients...
  Epoch 47, Batch 2/4: Optimizer step...
  Epoch 47, Batch 2/4: Completed in 0.19s
  Epoch 47, Batch 3/4: Loading data to device...
  Epoch 47, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 47, Batch 3/4: Zeroing gradients...
  Epoch 47, Batch 3/4: Forward pass...
  Epoch 47, Batch 3/4: Calculating loss...
  Epoch 47, Batch 3/4: Backward pass...
  Epoch 47, Batch 3/4: Clipping gradients...
  Epoch 47, Batch 3/4: Optimizer step...
  Epoch 47, Batch 3/4: Completed in 0.18s
  Epoch 47, Batch 4/4: Loading data to device...
  Epoch 47, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 47, Batch 4/4: Zeroing gradients...
  Epoch 47, Batch 4/4: Forward pass...
  Epoch 47, Batch 4/4: Calculating loss...
  Epoch 47, Batch 4/4: Backward pass...
  Epoch 47, Batch 4/4: Clipping gradients...
  Epoch 47, Batch 4/4: Optimizer step...
  Epoch 47, Batch 4/4: Completed in 0.04s
Epoch 47: Training phase completed. Average Train Loss: 0.6234
Epoch 47: Starting validation phase...
  Epoch 47, Val Batch 1/1: Loading data...
  Epoch 47, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 47, Val Batch 1/1: Forward pass...
  Epoch 47, Val Batch 1/1: Calculating loss...
Epoch 47: Validation phase completed. Average Val Loss: 0.5512
Epoch 47 Summary ---> Train Loss: 0.6234 / Validation Loss: 0.5512
Epoch 47: Checking early stopping... (Current Best Loss: 0.5494, Epochs No Improve: 0)
  Epoch 47: Validation loss did not improve. Epochs without improvement: 1
Epoch 47: Stepping scheduler...
--- Epoch 47 completed in 0.66 seconds ---

--- Starting Epoch 48/1000 ---
Epoch 48: Starting training phase (4 batches)
  Epoch 48, Batch 1/4: Loading data to device...
  Epoch 48, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 48, Batch 1/4: Zeroing gradients...
  Epoch 48, Batch 1/4: Forward pass...
  Epoch 48, Batch 1/4: Calculating loss...
  Epoch 48, Batch 1/4: Backward pass...
  Epoch 48, Batch 1/4: Clipping gradients...
  Epoch 48, Batch 1/4: Optimizer step...
  Epoch 48, Batch 1/4: Completed in 0.19s
  Epoch 48, Batch 2/4: Loading data to device...
  Epoch 48, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 48, Batch 2/4: Zeroing gradients...
  Epoch 48, Batch 2/4: Forward pass...
  Epoch 48, Batch 2/4: Calculating loss...
  Epoch 48, Batch 2/4: Backward pass...
  Epoch 48, Batch 2/4: Clipping gradients...
  Epoch 48, Batch 2/4: Optimizer step...
  Epoch 48, Batch 2/4: Completed in 0.19s
  Epoch 48, Batch 3/4: Loading data to device...
  Epoch 48, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 48, Batch 3/4: Zeroing gradients...
  Epoch 48, Batch 3/4: Forward pass...
  Epoch 48, Batch 3/4: Calculating loss...
  Epoch 48, Batch 3/4: Backward pass...
  Epoch 48, Batch 3/4: Clipping gradients...
  Epoch 48, Batch 3/4: Optimizer step...
  Epoch 48, Batch 3/4: Completed in 0.20s
  Epoch 48, Batch 4/4: Loading data to device...
  Epoch 48, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 48, Batch 4/4: Zeroing gradients...
  Epoch 48, Batch 4/4: Forward pass...
  Epoch 48, Batch 4/4: Calculating loss...
  Epoch 48, Batch 4/4: Backward pass...
  Epoch 48, Batch 4/4: Clipping gradients...
  Epoch 48, Batch 4/4: Optimizer step...
  Epoch 48, Batch 4/4: Completed in 0.03s
Epoch 48: Training phase completed. Average Train Loss: 0.6035
Epoch 48: Starting validation phase...
  Epoch 48, Val Batch 1/1: Loading data...
  Epoch 48, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 48, Val Batch 1/1: Forward pass...
  Epoch 48, Val Batch 1/1: Calculating loss...
Epoch 48: Validation phase completed. Average Val Loss: 0.5554
Epoch 48 Summary ---> Train Loss: 0.6035 / Validation Loss: 0.5554
Epoch 48: Checking early stopping... (Current Best Loss: 0.5494, Epochs No Improve: 1)
  Epoch 48: Validation loss did not improve. Epochs without improvement: 2
Epoch 48: Stepping scheduler...
--- Epoch 48 completed in 0.68 seconds ---

--- Starting Epoch 49/1000 ---
Epoch 49: Starting training phase (4 batches)
  Epoch 49, Batch 1/4: Loading data to device...
  Epoch 49, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 49, Batch 1/4: Zeroing gradients...
  Epoch 49, Batch 1/4: Forward pass...
  Epoch 49, Batch 1/4: Calculating loss...
  Epoch 49, Batch 1/4: Backward pass...
  Epoch 49, Batch 1/4: Clipping gradients...
  Epoch 49, Batch 1/4: Optimizer step...
  Epoch 49, Batch 1/4: Completed in 0.19s
  Epoch 49, Batch 2/4: Loading data to device...
  Epoch 49, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 49, Batch 2/4: Zeroing gradients...
  Epoch 49, Batch 2/4: Forward pass...
  Epoch 49, Batch 2/4: Calculating loss...
  Epoch 49, Batch 2/4: Backward pass...
  Epoch 49, Batch 2/4: Clipping gradients...
  Epoch 49, Batch 2/4: Optimizer step...
  Epoch 49, Batch 2/4: Completed in 0.19s
  Epoch 49, Batch 3/4: Loading data to device...
  Epoch 49, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 49, Batch 3/4: Zeroing gradients...
  Epoch 49, Batch 3/4: Forward pass...
  Epoch 49, Batch 3/4: Calculating loss...
  Epoch 49, Batch 3/4: Backward pass...
  Epoch 49, Batch 3/4: Clipping gradients...
  Epoch 49, Batch 3/4: Optimizer step...
  Epoch 49, Batch 3/4: Completed in 0.19s
  Epoch 49, Batch 4/4: Loading data to device...
  Epoch 49, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 49, Batch 4/4: Zeroing gradients...
  Epoch 49, Batch 4/4: Forward pass...
  Epoch 49, Batch 4/4: Calculating loss...
  Epoch 49, Batch 4/4: Backward pass...
  Epoch 49, Batch 4/4: Clipping gradients...
  Epoch 49, Batch 4/4: Optimizer step...
  Epoch 49, Batch 4/4: Completed in 0.03s
Epoch 49: Training phase completed. Average Train Loss: 0.6317
Epoch 49: Starting validation phase...
  Epoch 49, Val Batch 1/1: Loading data...
  Epoch 49, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 49, Val Batch 1/1: Forward pass...
  Epoch 49, Val Batch 1/1: Calculating loss...
Epoch 49: Validation phase completed. Average Val Loss: 0.5554
Epoch 49 Summary ---> Train Loss: 0.6317 / Validation Loss: 0.5554
Epoch 49: Checking early stopping... (Current Best Loss: 0.5494, Epochs No Improve: 2)
  Epoch 49: Validation loss did not improve. Epochs without improvement: 3
Epoch 49: Stepping scheduler...
--- Epoch 49 completed in 0.67 seconds ---

--- Starting Epoch 50/1000 ---
Epoch 50: Starting training phase (4 batches)
  Epoch 50, Batch 1/4: Loading data to device...
  Epoch 50, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 50, Batch 1/4: Zeroing gradients...
  Epoch 50, Batch 1/4: Forward pass...
  Epoch 50, Batch 1/4: Calculating loss...
  Epoch 50, Batch 1/4: Backward pass...
  Epoch 50, Batch 1/4: Clipping gradients...
  Epoch 50, Batch 1/4: Optimizer step...
  Epoch 50, Batch 1/4: Completed in 0.18s
  Epoch 50, Batch 2/4: Loading data to device...
  Epoch 50, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 50, Batch 2/4: Zeroing gradients...
  Epoch 50, Batch 2/4: Forward pass...
  Epoch 50, Batch 2/4: Calculating loss...
  Epoch 50, Batch 2/4: Backward pass...
  Epoch 50, Batch 2/4: Clipping gradients...
  Epoch 50, Batch 2/4: Optimizer step...
  Epoch 50, Batch 2/4: Completed in 0.19s
  Epoch 50, Batch 3/4: Loading data to device...
  Epoch 50, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 50, Batch 3/4: Zeroing gradients...
  Epoch 50, Batch 3/4: Forward pass...
  Epoch 50, Batch 3/4: Calculating loss...
  Epoch 50, Batch 3/4: Backward pass...
  Epoch 50, Batch 3/4: Clipping gradients...
  Epoch 50, Batch 3/4: Optimizer step...
  Epoch 50, Batch 3/4: Completed in 0.19s
  Epoch 50, Batch 4/4: Loading data to device...
  Epoch 50, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 50, Batch 4/4: Zeroing gradients...
  Epoch 50, Batch 4/4: Forward pass...
  Epoch 50, Batch 4/4: Calculating loss...
  Epoch 50, Batch 4/4: Backward pass...
  Epoch 50, Batch 4/4: Clipping gradients...
  Epoch 50, Batch 4/4: Optimizer step...
  Epoch 50, Batch 4/4: Completed in 0.04s
Epoch 50: Training phase completed. Average Train Loss: 0.5807
Epoch 50: Starting validation phase...
  Epoch 50, Val Batch 1/1: Loading data...
  Epoch 50, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 50, Val Batch 1/1: Forward pass...
  Epoch 50, Val Batch 1/1: Calculating loss...
Epoch 50: Validation phase completed. Average Val Loss: 0.5555
Epoch 50 Summary ---> Train Loss: 0.5807 / Validation Loss: 0.5555
Epoch 50: Checking early stopping... (Current Best Loss: 0.5494, Epochs No Improve: 3)
  Epoch 50: Validation loss did not improve. Epochs without improvement: 4
Epoch 50: Stepping scheduler...
--- Epoch 50 completed in 0.67 seconds ---

--- Starting Epoch 51/1000 ---
Epoch 51: Starting training phase (4 batches)
  Epoch 51, Batch 1/4: Loading data to device...
  Epoch 51, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 51, Batch 1/4: Zeroing gradients...
  Epoch 51, Batch 1/4: Forward pass...
  Epoch 51, Batch 1/4: Calculating loss...
  Epoch 51, Batch 1/4: Backward pass...
  Epoch 51, Batch 1/4: Clipping gradients...
  Epoch 51, Batch 1/4: Optimizer step...
  Epoch 51, Batch 1/4: Completed in 0.19s
  Epoch 51, Batch 2/4: Loading data to device...
  Epoch 51, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 51, Batch 2/4: Zeroing gradients...
  Epoch 51, Batch 2/4: Forward pass...
  Epoch 51, Batch 2/4: Calculating loss...
  Epoch 51, Batch 2/4: Backward pass...
  Epoch 51, Batch 2/4: Clipping gradients...
  Epoch 51, Batch 2/4: Optimizer step...
  Epoch 51, Batch 2/4: Completed in 0.19s
  Epoch 51, Batch 3/4: Loading data to device...
  Epoch 51, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 51, Batch 3/4: Zeroing gradients...
  Epoch 51, Batch 3/4: Forward pass...
  Epoch 51, Batch 3/4: Calculating loss...
  Epoch 51, Batch 3/4: Backward pass...
  Epoch 51, Batch 3/4: Clipping gradients...
  Epoch 51, Batch 3/4: Optimizer step...
  Epoch 51, Batch 3/4: Completed in 0.19s
  Epoch 51, Batch 4/4: Loading data to device...
  Epoch 51, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 51, Batch 4/4: Zeroing gradients...
  Epoch 51, Batch 4/4: Forward pass...
  Epoch 51, Batch 4/4: Calculating loss...
  Epoch 51, Batch 4/4: Backward pass...
  Epoch 51, Batch 4/4: Clipping gradients...
  Epoch 51, Batch 4/4: Optimizer step...
  Epoch 51, Batch 4/4: Completed in 0.03s
Epoch 51: Training phase completed. Average Train Loss: 0.6124
Epoch 51: Starting validation phase...
  Epoch 51, Val Batch 1/1: Loading data...
  Epoch 51, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 51, Val Batch 1/1: Forward pass...
  Epoch 51, Val Batch 1/1: Calculating loss...
Epoch 51: Validation phase completed. Average Val Loss: 0.5572
Epoch 51 Summary ---> Train Loss: 0.6124 / Validation Loss: 0.5572
Epoch 51: Checking early stopping... (Current Best Loss: 0.5494, Epochs No Improve: 4)
  Epoch 51: Validation loss did not improve. Epochs without improvement: 5
Epoch 51: Stepping scheduler...
--- Epoch 51 completed in 0.68 seconds ---

--- Starting Epoch 52/1000 ---
Epoch 52: Starting training phase (4 batches)
  Epoch 52, Batch 1/4: Loading data to device...
  Epoch 52, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 52, Batch 1/4: Zeroing gradients...
  Epoch 52, Batch 1/4: Forward pass...
  Epoch 52, Batch 1/4: Calculating loss...
  Epoch 52, Batch 1/4: Backward pass...
  Epoch 52, Batch 1/4: Clipping gradients...
  Epoch 52, Batch 1/4: Optimizer step...
  Epoch 52, Batch 1/4: Completed in 0.20s
  Epoch 52, Batch 2/4: Loading data to device...
  Epoch 52, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 52, Batch 2/4: Zeroing gradients...
  Epoch 52, Batch 2/4: Forward pass...
  Epoch 52, Batch 2/4: Calculating loss...
  Epoch 52, Batch 2/4: Backward pass...
  Epoch 52, Batch 2/4: Clipping gradients...
  Epoch 52, Batch 2/4: Optimizer step...
  Epoch 52, Batch 2/4: Completed in 0.19s
  Epoch 52, Batch 3/4: Loading data to device...
  Epoch 52, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 52, Batch 3/4: Zeroing gradients...
  Epoch 52, Batch 3/4: Forward pass...
  Epoch 52, Batch 3/4: Calculating loss...
  Epoch 52, Batch 3/4: Backward pass...
  Epoch 52, Batch 3/4: Clipping gradients...
  Epoch 52, Batch 3/4: Optimizer step...
  Epoch 52, Batch 3/4: Completed in 0.19s
  Epoch 52, Batch 4/4: Loading data to device...
  Epoch 52, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 52, Batch 4/4: Zeroing gradients...
  Epoch 52, Batch 4/4: Forward pass...
  Epoch 52, Batch 4/4: Calculating loss...
  Epoch 52, Batch 4/4: Backward pass...
  Epoch 52, Batch 4/4: Clipping gradients...
  Epoch 52, Batch 4/4: Optimizer step...
  Epoch 52, Batch 4/4: Completed in 0.03s
Epoch 52: Training phase completed. Average Train Loss: 0.6192
Epoch 52: Starting validation phase...
  Epoch 52, Val Batch 1/1: Loading data...
  Epoch 52, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 52, Val Batch 1/1: Forward pass...
  Epoch 52, Val Batch 1/1: Calculating loss...
Epoch 52: Validation phase completed. Average Val Loss: 0.5439
Epoch 52 Summary ---> Train Loss: 0.6192 / Validation Loss: 0.5439
Epoch 52: Checking early stopping... (Current Best Loss: 0.5494, Epochs No Improve: 5)
  Epoch 52: Validation loss improved (0.5494 --> 0.5439). Saving model.
Epoch 52: Stepping scheduler...
--- Epoch 52 completed in 0.69 seconds ---

--- Starting Epoch 53/1000 ---
Epoch 53: Starting training phase (4 batches)
  Epoch 53, Batch 1/4: Loading data to device...
  Epoch 53, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 53, Batch 1/4: Zeroing gradients...
  Epoch 53, Batch 1/4: Forward pass...
  Epoch 53, Batch 1/4: Calculating loss...
  Epoch 53, Batch 1/4: Backward pass...
  Epoch 53, Batch 1/4: Clipping gradients...
  Epoch 53, Batch 1/4: Optimizer step...
  Epoch 53, Batch 1/4: Completed in 0.19s
  Epoch 53, Batch 2/4: Loading data to device...
  Epoch 53, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 53, Batch 2/4: Zeroing gradients...
  Epoch 53, Batch 2/4: Forward pass...
  Epoch 53, Batch 2/4: Calculating loss...
  Epoch 53, Batch 2/4: Backward pass...
  Epoch 53, Batch 2/4: Clipping gradients...
  Epoch 53, Batch 2/4: Optimizer step...
  Epoch 53, Batch 2/4: Completed in 0.19s
  Epoch 53, Batch 3/4: Loading data to device...
  Epoch 53, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 53, Batch 3/4: Zeroing gradients...
  Epoch 53, Batch 3/4: Forward pass...
  Epoch 53, Batch 3/4: Calculating loss...
  Epoch 53, Batch 3/4: Backward pass...
  Epoch 53, Batch 3/4: Clipping gradients...
  Epoch 53, Batch 3/4: Optimizer step...
  Epoch 53, Batch 3/4: Completed in 0.19s
  Epoch 53, Batch 4/4: Loading data to device...
  Epoch 53, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 53, Batch 4/4: Zeroing gradients...
  Epoch 53, Batch 4/4: Forward pass...
  Epoch 53, Batch 4/4: Calculating loss...
  Epoch 53, Batch 4/4: Backward pass...
  Epoch 53, Batch 4/4: Clipping gradients...
  Epoch 53, Batch 4/4: Optimizer step...
  Epoch 53, Batch 4/4: Completed in 0.03s
Epoch 53: Training phase completed. Average Train Loss: 0.5865
Epoch 53: Starting validation phase...
  Epoch 53, Val Batch 1/1: Loading data...
  Epoch 53, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 53, Val Batch 1/1: Forward pass...
  Epoch 53, Val Batch 1/1: Calculating loss...
Epoch 53: Validation phase completed. Average Val Loss: 0.5407
Epoch 53 Summary ---> Train Loss: 0.5865 / Validation Loss: 0.5407
Epoch 53: Checking early stopping... (Current Best Loss: 0.5439, Epochs No Improve: 0)
  Epoch 53: Validation loss improved (0.5439 --> 0.5407). Saving model.
Epoch 53: Stepping scheduler...
--- Epoch 53 completed in 0.67 seconds ---

--- Starting Epoch 54/1000 ---
Epoch 54: Starting training phase (4 batches)
  Epoch 54, Batch 1/4: Loading data to device...
  Epoch 54, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 54, Batch 1/4: Zeroing gradients...
  Epoch 54, Batch 1/4: Forward pass...
  Epoch 54, Batch 1/4: Calculating loss...
  Epoch 54, Batch 1/4: Backward pass...
  Epoch 54, Batch 1/4: Clipping gradients...
  Epoch 54, Batch 1/4: Optimizer step...
  Epoch 54, Batch 1/4: Completed in 0.19s
  Epoch 54, Batch 2/4: Loading data to device...
  Epoch 54, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 54, Batch 2/4: Zeroing gradients...
  Epoch 54, Batch 2/4: Forward pass...
  Epoch 54, Batch 2/4: Calculating loss...
  Epoch 54, Batch 2/4: Backward pass...
  Epoch 54, Batch 2/4: Clipping gradients...
  Epoch 54, Batch 2/4: Optimizer step...
  Epoch 54, Batch 2/4: Completed in 0.18s
  Epoch 54, Batch 3/4: Loading data to device...
  Epoch 54, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 54, Batch 3/4: Zeroing gradients...
  Epoch 54, Batch 3/4: Forward pass...
  Epoch 54, Batch 3/4: Calculating loss...
  Epoch 54, Batch 3/4: Backward pass...
  Epoch 54, Batch 3/4: Clipping gradients...
  Epoch 54, Batch 3/4: Optimizer step...
  Epoch 54, Batch 3/4: Completed in 0.19s
  Epoch 54, Batch 4/4: Loading data to device...
  Epoch 54, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 54, Batch 4/4: Zeroing gradients...
  Epoch 54, Batch 4/4: Forward pass...
  Epoch 54, Batch 4/4: Calculating loss...
  Epoch 54, Batch 4/4: Backward pass...
  Epoch 54, Batch 4/4: Clipping gradients...
  Epoch 54, Batch 4/4: Optimizer step...
  Epoch 54, Batch 4/4: Completed in 0.03s
Epoch 54: Training phase completed. Average Train Loss: 0.6358
Epoch 54: Starting validation phase...
  Epoch 54, Val Batch 1/1: Loading data...
  Epoch 54, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 54, Val Batch 1/1: Forward pass...
  Epoch 54, Val Batch 1/1: Calculating loss...
Epoch 54: Validation phase completed. Average Val Loss: 0.5337
Epoch 54 Summary ---> Train Loss: 0.6358 / Validation Loss: 0.5337
Epoch 54: Checking early stopping... (Current Best Loss: 0.5407, Epochs No Improve: 0)
  Epoch 54: Validation loss improved (0.5407 --> 0.5337). Saving model.
Epoch 54: Stepping scheduler...
--- Epoch 54 completed in 0.66 seconds ---

--- Starting Epoch 55/1000 ---
Epoch 55: Starting training phase (4 batches)
  Epoch 55, Batch 1/4: Loading data to device...
  Epoch 55, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 55, Batch 1/4: Zeroing gradients...
  Epoch 55, Batch 1/4: Forward pass...
  Epoch 55, Batch 1/4: Calculating loss...
  Epoch 55, Batch 1/4: Backward pass...
  Epoch 55, Batch 1/4: Clipping gradients...
  Epoch 55, Batch 1/4: Optimizer step...
  Epoch 55, Batch 1/4: Completed in 0.20s
  Epoch 55, Batch 2/4: Loading data to device...
  Epoch 55, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 55, Batch 2/4: Zeroing gradients...
  Epoch 55, Batch 2/4: Forward pass...
  Epoch 55, Batch 2/4: Calculating loss...
  Epoch 55, Batch 2/4: Backward pass...
  Epoch 55, Batch 2/4: Clipping gradients...
  Epoch 55, Batch 2/4: Optimizer step...
  Epoch 55, Batch 2/4: Completed in 0.19s
  Epoch 55, Batch 3/4: Loading data to device...
  Epoch 55, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 55, Batch 3/4: Zeroing gradients...
  Epoch 55, Batch 3/4: Forward pass...
  Epoch 55, Batch 3/4: Calculating loss...
  Epoch 55, Batch 3/4: Backward pass...
  Epoch 55, Batch 3/4: Clipping gradients...
  Epoch 55, Batch 3/4: Optimizer step...
  Epoch 55, Batch 3/4: Completed in 0.19s
  Epoch 55, Batch 4/4: Loading data to device...
  Epoch 55, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 55, Batch 4/4: Zeroing gradients...
  Epoch 55, Batch 4/4: Forward pass...
  Epoch 55, Batch 4/4: Calculating loss...
  Epoch 55, Batch 4/4: Backward pass...
  Epoch 55, Batch 4/4: Clipping gradients...
  Epoch 55, Batch 4/4: Optimizer step...
  Epoch 55, Batch 4/4: Completed in 0.03s
Epoch 55: Training phase completed. Average Train Loss: 0.5415
Epoch 55: Starting validation phase...
  Epoch 55, Val Batch 1/1: Loading data...
  Epoch 55, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 55, Val Batch 1/1: Forward pass...
  Epoch 55, Val Batch 1/1: Calculating loss...
Epoch 55: Validation phase completed. Average Val Loss: 0.5180
Epoch 55 Summary ---> Train Loss: 0.5415 / Validation Loss: 0.5180
Epoch 55: Checking early stopping... (Current Best Loss: 0.5337, Epochs No Improve: 0)
  Epoch 55: Validation loss improved (0.5337 --> 0.5180). Saving model.
Epoch 55: Stepping scheduler...
--- Epoch 55 completed in 0.67 seconds ---

--- Starting Epoch 56/1000 ---
Epoch 56: Starting training phase (4 batches)
  Epoch 56, Batch 1/4: Loading data to device...
  Epoch 56, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 56, Batch 1/4: Zeroing gradients...
  Epoch 56, Batch 1/4: Forward pass...
  Epoch 56, Batch 1/4: Calculating loss...
  Epoch 56, Batch 1/4: Backward pass...
  Epoch 56, Batch 1/4: Clipping gradients...
  Epoch 56, Batch 1/4: Optimizer step...
  Epoch 56, Batch 1/4: Completed in 0.19s
  Epoch 56, Batch 2/4: Loading data to device...
  Epoch 56, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 56, Batch 2/4: Zeroing gradients...
  Epoch 56, Batch 2/4: Forward pass...
  Epoch 56, Batch 2/4: Calculating loss...
  Epoch 56, Batch 2/4: Backward pass...
  Epoch 56, Batch 2/4: Clipping gradients...
  Epoch 56, Batch 2/4: Optimizer step...
  Epoch 56, Batch 2/4: Completed in 0.19s
  Epoch 56, Batch 3/4: Loading data to device...
  Epoch 56, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 56, Batch 3/4: Zeroing gradients...
  Epoch 56, Batch 3/4: Forward pass...
  Epoch 56, Batch 3/4: Calculating loss...
  Epoch 56, Batch 3/4: Backward pass...
  Epoch 56, Batch 3/4: Clipping gradients...
  Epoch 56, Batch 3/4: Optimizer step...
  Epoch 56, Batch 3/4: Completed in 0.20s
  Epoch 56, Batch 4/4: Loading data to device...
  Epoch 56, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 56, Batch 4/4: Zeroing gradients...
  Epoch 56, Batch 4/4: Forward pass...
  Epoch 56, Batch 4/4: Calculating loss...
  Epoch 56, Batch 4/4: Backward pass...
  Epoch 56, Batch 4/4: Clipping gradients...
  Epoch 56, Batch 4/4: Optimizer step...
  Epoch 56, Batch 4/4: Completed in 0.03s
Epoch 56: Training phase completed. Average Train Loss: 0.5725
Epoch 56: Starting validation phase...
  Epoch 56, Val Batch 1/1: Loading data...
  Epoch 56, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 56, Val Batch 1/1: Forward pass...
  Epoch 56, Val Batch 1/1: Calculating loss...
Epoch 56: Validation phase completed. Average Val Loss: 0.5196
Epoch 56 Summary ---> Train Loss: 0.5725 / Validation Loss: 0.5196
Epoch 56: Checking early stopping... (Current Best Loss: 0.5180, Epochs No Improve: 0)
  Epoch 56: Validation loss did not improve. Epochs without improvement: 1
Epoch 56: Stepping scheduler...
--- Epoch 56 completed in 0.67 seconds ---

--- Starting Epoch 57/1000 ---
Epoch 57: Starting training phase (4 batches)
  Epoch 57, Batch 1/4: Loading data to device...
  Epoch 57, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 57, Batch 1/4: Zeroing gradients...
  Epoch 57, Batch 1/4: Forward pass...
  Epoch 57, Batch 1/4: Calculating loss...
  Epoch 57, Batch 1/4: Backward pass...
  Epoch 57, Batch 1/4: Clipping gradients...
  Epoch 57, Batch 1/4: Optimizer step...
  Epoch 57, Batch 1/4: Completed in 0.19s
  Epoch 57, Batch 2/4: Loading data to device...
  Epoch 57, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 57, Batch 2/4: Zeroing gradients...
  Epoch 57, Batch 2/4: Forward pass...
  Epoch 57, Batch 2/4: Calculating loss...
  Epoch 57, Batch 2/4: Backward pass...
  Epoch 57, Batch 2/4: Clipping gradients...
  Epoch 57, Batch 2/4: Optimizer step...
  Epoch 57, Batch 2/4: Completed in 0.19s
  Epoch 57, Batch 3/4: Loading data to device...
  Epoch 57, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 57, Batch 3/4: Zeroing gradients...
  Epoch 57, Batch 3/4: Forward pass...
  Epoch 57, Batch 3/4: Calculating loss...
  Epoch 57, Batch 3/4: Backward pass...
  Epoch 57, Batch 3/4: Clipping gradients...
  Epoch 57, Batch 3/4: Optimizer step...
  Epoch 57, Batch 3/4: Completed in 0.18s
  Epoch 57, Batch 4/4: Loading data to device...
  Epoch 57, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 57, Batch 4/4: Zeroing gradients...
  Epoch 57, Batch 4/4: Forward pass...
  Epoch 57, Batch 4/4: Calculating loss...
  Epoch 57, Batch 4/4: Backward pass...
  Epoch 57, Batch 4/4: Clipping gradients...
  Epoch 57, Batch 4/4: Optimizer step...
  Epoch 57, Batch 4/4: Completed in 0.03s
Epoch 57: Training phase completed. Average Train Loss: 0.5888
Epoch 57: Starting validation phase...
  Epoch 57, Val Batch 1/1: Loading data...
  Epoch 57, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 57, Val Batch 1/1: Forward pass...
  Epoch 57, Val Batch 1/1: Calculating loss...
Epoch 57: Validation phase completed. Average Val Loss: 0.5149
Epoch 57 Summary ---> Train Loss: 0.5888 / Validation Loss: 0.5149
Epoch 57: Checking early stopping... (Current Best Loss: 0.5180, Epochs No Improve: 1)
  Epoch 57: Validation loss improved (0.5180 --> 0.5149). Saving model.
Epoch 57: Stepping scheduler...
--- Epoch 57 completed in 0.65 seconds ---

--- Starting Epoch 58/1000 ---
Epoch 58: Starting training phase (4 batches)
  Epoch 58, Batch 1/4: Loading data to device...
  Epoch 58, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 58, Batch 1/4: Zeroing gradients...
  Epoch 58, Batch 1/4: Forward pass...
  Epoch 58, Batch 1/4: Calculating loss...
  Epoch 58, Batch 1/4: Backward pass...
  Epoch 58, Batch 1/4: Clipping gradients...
  Epoch 58, Batch 1/4: Optimizer step...
  Epoch 58, Batch 1/4: Completed in 0.18s
  Epoch 58, Batch 2/4: Loading data to device...
  Epoch 58, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 58, Batch 2/4: Zeroing gradients...
  Epoch 58, Batch 2/4: Forward pass...
  Epoch 58, Batch 2/4: Calculating loss...
  Epoch 58, Batch 2/4: Backward pass...
  Epoch 58, Batch 2/4: Clipping gradients...
  Epoch 58, Batch 2/4: Optimizer step...
  Epoch 58, Batch 2/4: Completed in 0.19s
  Epoch 58, Batch 3/4: Loading data to device...
  Epoch 58, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 58, Batch 3/4: Zeroing gradients...
  Epoch 58, Batch 3/4: Forward pass...
  Epoch 58, Batch 3/4: Calculating loss...
  Epoch 58, Batch 3/4: Backward pass...
  Epoch 58, Batch 3/4: Clipping gradients...
  Epoch 58, Batch 3/4: Optimizer step...
  Epoch 58, Batch 3/4: Completed in 0.19s
  Epoch 58, Batch 4/4: Loading data to device...
  Epoch 58, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 58, Batch 4/4: Zeroing gradients...
  Epoch 58, Batch 4/4: Forward pass...
  Epoch 58, Batch 4/4: Calculating loss...
  Epoch 58, Batch 4/4: Backward pass...
  Epoch 58, Batch 4/4: Clipping gradients...
  Epoch 58, Batch 4/4: Optimizer step...
  Epoch 58, Batch 4/4: Completed in 0.03s
Epoch 58: Training phase completed. Average Train Loss: 0.5509
Epoch 58: Starting validation phase...
  Epoch 58, Val Batch 1/1: Loading data...
  Epoch 58, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 58, Val Batch 1/1: Forward pass...
  Epoch 58, Val Batch 1/1: Calculating loss...
Epoch 58: Validation phase completed. Average Val Loss: 0.4968
Epoch 58 Summary ---> Train Loss: 0.5509 / Validation Loss: 0.4968
Epoch 58: Checking early stopping... (Current Best Loss: 0.5149, Epochs No Improve: 0)
  Epoch 58: Validation loss improved (0.5149 --> 0.4968). Saving model.
Epoch 58: Stepping scheduler...
--- Epoch 58 completed in 0.66 seconds ---

--- Starting Epoch 59/1000 ---
Epoch 59: Starting training phase (4 batches)
  Epoch 59, Batch 1/4: Loading data to device...
  Epoch 59, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 59, Batch 1/4: Zeroing gradients...
  Epoch 59, Batch 1/4: Forward pass...
  Epoch 59, Batch 1/4: Calculating loss...
  Epoch 59, Batch 1/4: Backward pass...
  Epoch 59, Batch 1/4: Clipping gradients...
  Epoch 59, Batch 1/4: Optimizer step...
  Epoch 59, Batch 1/4: Completed in 0.19s
  Epoch 59, Batch 2/4: Loading data to device...
  Epoch 59, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 59, Batch 2/4: Zeroing gradients...
  Epoch 59, Batch 2/4: Forward pass...
  Epoch 59, Batch 2/4: Calculating loss...
  Epoch 59, Batch 2/4: Backward pass...
  Epoch 59, Batch 2/4: Clipping gradients...
  Epoch 59, Batch 2/4: Optimizer step...
  Epoch 59, Batch 2/4: Completed in 0.19s
  Epoch 59, Batch 3/4: Loading data to device...
  Epoch 59, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 59, Batch 3/4: Zeroing gradients...
  Epoch 59, Batch 3/4: Forward pass...
  Epoch 59, Batch 3/4: Calculating loss...
  Epoch 59, Batch 3/4: Backward pass...
  Epoch 59, Batch 3/4: Clipping gradients...
  Epoch 59, Batch 3/4: Optimizer step...
  Epoch 59, Batch 3/4: Completed in 0.19s
  Epoch 59, Batch 4/4: Loading data to device...
  Epoch 59, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 59, Batch 4/4: Zeroing gradients...
  Epoch 59, Batch 4/4: Forward pass...
  Epoch 59, Batch 4/4: Calculating loss...
  Epoch 59, Batch 4/4: Backward pass...
  Epoch 59, Batch 4/4: Clipping gradients...
  Epoch 59, Batch 4/4: Optimizer step...
  Epoch 59, Batch 4/4: Completed in 0.03s
Epoch 59: Training phase completed. Average Train Loss: 0.5520
Epoch 59: Starting validation phase...
  Epoch 59, Val Batch 1/1: Loading data...
  Epoch 59, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 59, Val Batch 1/1: Forward pass...
  Epoch 59, Val Batch 1/1: Calculating loss...
Epoch 59: Validation phase completed. Average Val Loss: 0.5017
Epoch 59 Summary ---> Train Loss: 0.5520 / Validation Loss: 0.5017
Epoch 59: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 0)
  Epoch 59: Validation loss did not improve. Epochs without improvement: 1
Epoch 59: Stepping scheduler...
--- Epoch 59 completed in 0.67 seconds ---

--- Starting Epoch 60/1000 ---
Epoch 60: Starting training phase (4 batches)
  Epoch 60, Batch 1/4: Loading data to device...
  Epoch 60, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 60, Batch 1/4: Zeroing gradients...
  Epoch 60, Batch 1/4: Forward pass...
  Epoch 60, Batch 1/4: Calculating loss...
  Epoch 60, Batch 1/4: Backward pass...
  Epoch 60, Batch 1/4: Clipping gradients...
  Epoch 60, Batch 1/4: Optimizer step...
  Epoch 60, Batch 1/4: Completed in 0.19s
  Epoch 60, Batch 2/4: Loading data to device...
  Epoch 60, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 60, Batch 2/4: Zeroing gradients...
  Epoch 60, Batch 2/4: Forward pass...
  Epoch 60, Batch 2/4: Calculating loss...
  Epoch 60, Batch 2/4: Backward pass...
  Epoch 60, Batch 2/4: Clipping gradients...
  Epoch 60, Batch 2/4: Optimizer step...
  Epoch 60, Batch 2/4: Completed in 0.19s
  Epoch 60, Batch 3/4: Loading data to device...
  Epoch 60, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 60, Batch 3/4: Zeroing gradients...
  Epoch 60, Batch 3/4: Forward pass...
  Epoch 60, Batch 3/4: Calculating loss...
  Epoch 60, Batch 3/4: Backward pass...
  Epoch 60, Batch 3/4: Clipping gradients...
  Epoch 60, Batch 3/4: Optimizer step...
  Epoch 60, Batch 3/4: Completed in 0.19s
  Epoch 60, Batch 4/4: Loading data to device...
  Epoch 60, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 60, Batch 4/4: Zeroing gradients...
  Epoch 60, Batch 4/4: Forward pass...
  Epoch 60, Batch 4/4: Calculating loss...
  Epoch 60, Batch 4/4: Backward pass...
  Epoch 60, Batch 4/4: Clipping gradients...
  Epoch 60, Batch 4/4: Optimizer step...
  Epoch 60, Batch 4/4: Completed in 0.03s
Epoch 60: Training phase completed. Average Train Loss: 0.6245
Epoch 60: Starting validation phase...
  Epoch 60, Val Batch 1/1: Loading data...
  Epoch 60, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 60, Val Batch 1/1: Forward pass...
  Epoch 60, Val Batch 1/1: Calculating loss...
Epoch 60: Validation phase completed. Average Val Loss: 0.5111
Epoch 60 Summary ---> Train Loss: 0.6245 / Validation Loss: 0.5111
Epoch 60: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 1)
  Epoch 60: Validation loss did not improve. Epochs without improvement: 2
Epoch 60: Stepping scheduler...
--- Epoch 60 completed in 0.66 seconds ---

--- Starting Epoch 61/1000 ---
Epoch 61: Starting training phase (4 batches)
  Epoch 61, Batch 1/4: Loading data to device...
  Epoch 61, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 61, Batch 1/4: Zeroing gradients...
  Epoch 61, Batch 1/4: Forward pass...
  Epoch 61, Batch 1/4: Calculating loss...
  Epoch 61, Batch 1/4: Backward pass...
  Epoch 61, Batch 1/4: Clipping gradients...
  Epoch 61, Batch 1/4: Optimizer step...
  Epoch 61, Batch 1/4: Completed in 0.19s
  Epoch 61, Batch 2/4: Loading data to device...
  Epoch 61, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 61, Batch 2/4: Zeroing gradients...
  Epoch 61, Batch 2/4: Forward pass...
  Epoch 61, Batch 2/4: Calculating loss...
  Epoch 61, Batch 2/4: Backward pass...
  Epoch 61, Batch 2/4: Clipping gradients...
  Epoch 61, Batch 2/4: Optimizer step...
  Epoch 61, Batch 2/4: Completed in 0.19s
  Epoch 61, Batch 3/4: Loading data to device...
  Epoch 61, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 61, Batch 3/4: Zeroing gradients...
  Epoch 61, Batch 3/4: Forward pass...
  Epoch 61, Batch 3/4: Calculating loss...
  Epoch 61, Batch 3/4: Backward pass...
  Epoch 61, Batch 3/4: Clipping gradients...
  Epoch 61, Batch 3/4: Optimizer step...
  Epoch 61, Batch 3/4: Completed in 0.19s
  Epoch 61, Batch 4/4: Loading data to device...
  Epoch 61, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 61, Batch 4/4: Zeroing gradients...
  Epoch 61, Batch 4/4: Forward pass...
  Epoch 61, Batch 4/4: Calculating loss...
  Epoch 61, Batch 4/4: Backward pass...
  Epoch 61, Batch 4/4: Clipping gradients...
  Epoch 61, Batch 4/4: Optimizer step...
  Epoch 61, Batch 4/4: Completed in 0.03s
Epoch 61: Training phase completed. Average Train Loss: 0.5511
Epoch 61: Starting validation phase...
  Epoch 61, Val Batch 1/1: Loading data...
  Epoch 61, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 61, Val Batch 1/1: Forward pass...
  Epoch 61, Val Batch 1/1: Calculating loss...
Epoch 61: Validation phase completed. Average Val Loss: 0.5085
Epoch 61 Summary ---> Train Loss: 0.5511 / Validation Loss: 0.5085
Epoch 61: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 2)
  Epoch 61: Validation loss did not improve. Epochs without improvement: 3
Epoch 61: Stepping scheduler...
--- Epoch 61 completed in 0.68 seconds ---

--- Starting Epoch 62/1000 ---
Epoch 62: Starting training phase (4 batches)
  Epoch 62, Batch 1/4: Loading data to device...
  Epoch 62, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 62, Batch 1/4: Zeroing gradients...
  Epoch 62, Batch 1/4: Forward pass...
  Epoch 62, Batch 1/4: Calculating loss...
  Epoch 62, Batch 1/4: Backward pass...
  Epoch 62, Batch 1/4: Clipping gradients...
  Epoch 62, Batch 1/4: Optimizer step...
  Epoch 62, Batch 1/4: Completed in 0.19s
  Epoch 62, Batch 2/4: Loading data to device...
  Epoch 62, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 62, Batch 2/4: Zeroing gradients...
  Epoch 62, Batch 2/4: Forward pass...
  Epoch 62, Batch 2/4: Calculating loss...
  Epoch 62, Batch 2/4: Backward pass...
  Epoch 62, Batch 2/4: Clipping gradients...
  Epoch 62, Batch 2/4: Optimizer step...
  Epoch 62, Batch 2/4: Completed in 0.18s
  Epoch 62, Batch 3/4: Loading data to device...
  Epoch 62, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 62, Batch 3/4: Zeroing gradients...
  Epoch 62, Batch 3/4: Forward pass...
  Epoch 62, Batch 3/4: Calculating loss...
  Epoch 62, Batch 3/4: Backward pass...
  Epoch 62, Batch 3/4: Clipping gradients...
  Epoch 62, Batch 3/4: Optimizer step...
  Epoch 62, Batch 3/4: Completed in 0.19s
  Epoch 62, Batch 4/4: Loading data to device...
  Epoch 62, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 62, Batch 4/4: Zeroing gradients...
  Epoch 62, Batch 4/4: Forward pass...
  Epoch 62, Batch 4/4: Calculating loss...
  Epoch 62, Batch 4/4: Backward pass...
  Epoch 62, Batch 4/4: Clipping gradients...
  Epoch 62, Batch 4/4: Optimizer step...
  Epoch 62, Batch 4/4: Completed in 0.03s
Epoch 62: Training phase completed. Average Train Loss: 0.5364
Epoch 62: Starting validation phase...
  Epoch 62, Val Batch 1/1: Loading data...
  Epoch 62, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 62, Val Batch 1/1: Forward pass...
  Epoch 62, Val Batch 1/1: Calculating loss...
Epoch 62: Validation phase completed. Average Val Loss: 0.5183
Epoch 62 Summary ---> Train Loss: 0.5364 / Validation Loss: 0.5183
Epoch 62: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 3)
  Epoch 62: Validation loss did not improve. Epochs without improvement: 4
Epoch 62: Stepping scheduler...
--- Epoch 62 completed in 0.66 seconds ---

--- Starting Epoch 63/1000 ---
Epoch 63: Starting training phase (4 batches)
  Epoch 63, Batch 1/4: Loading data to device...
  Epoch 63, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 63, Batch 1/4: Zeroing gradients...
  Epoch 63, Batch 1/4: Forward pass...
  Epoch 63, Batch 1/4: Calculating loss...
  Epoch 63, Batch 1/4: Backward pass...
  Epoch 63, Batch 1/4: Clipping gradients...
  Epoch 63, Batch 1/4: Optimizer step...
  Epoch 63, Batch 1/4: Completed in 0.19s
  Epoch 63, Batch 2/4: Loading data to device...
  Epoch 63, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 63, Batch 2/4: Zeroing gradients...
  Epoch 63, Batch 2/4: Forward pass...
  Epoch 63, Batch 2/4: Calculating loss...
  Epoch 63, Batch 2/4: Backward pass...
  Epoch 63, Batch 2/4: Clipping gradients...
  Epoch 63, Batch 2/4: Optimizer step...
  Epoch 63, Batch 2/4: Completed in 0.19s
  Epoch 63, Batch 3/4: Loading data to device...
  Epoch 63, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 63, Batch 3/4: Zeroing gradients...
  Epoch 63, Batch 3/4: Forward pass...
  Epoch 63, Batch 3/4: Calculating loss...
  Epoch 63, Batch 3/4: Backward pass...
  Epoch 63, Batch 3/4: Clipping gradients...
  Epoch 63, Batch 3/4: Optimizer step...
  Epoch 63, Batch 3/4: Completed in 0.19s
  Epoch 63, Batch 4/4: Loading data to device...
  Epoch 63, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 63, Batch 4/4: Zeroing gradients...
  Epoch 63, Batch 4/4: Forward pass...
  Epoch 63, Batch 4/4: Calculating loss...
  Epoch 63, Batch 4/4: Backward pass...
  Epoch 63, Batch 4/4: Clipping gradients...
  Epoch 63, Batch 4/4: Optimizer step...
  Epoch 63, Batch 4/4: Completed in 0.03s
Epoch 63: Training phase completed. Average Train Loss: 0.5325
Epoch 63: Starting validation phase...
  Epoch 63, Val Batch 1/1: Loading data...
  Epoch 63, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 63, Val Batch 1/1: Forward pass...
  Epoch 63, Val Batch 1/1: Calculating loss...
Epoch 63: Validation phase completed. Average Val Loss: 0.5131
Epoch 63 Summary ---> Train Loss: 0.5325 / Validation Loss: 0.5131
Epoch 63: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 4)
  Epoch 63: Validation loss did not improve. Epochs without improvement: 5
Epoch 63: Stepping scheduler...
--- Epoch 63 completed in 0.67 seconds ---

--- Starting Epoch 64/1000 ---
Epoch 64: Starting training phase (4 batches)
  Epoch 64, Batch 1/4: Loading data to device...
  Epoch 64, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 64, Batch 1/4: Zeroing gradients...
  Epoch 64, Batch 1/4: Forward pass...
  Epoch 64, Batch 1/4: Calculating loss...
  Epoch 64, Batch 1/4: Backward pass...
  Epoch 64, Batch 1/4: Clipping gradients...
  Epoch 64, Batch 1/4: Optimizer step...
  Epoch 64, Batch 1/4: Completed in 0.19s
  Epoch 64, Batch 2/4: Loading data to device...
  Epoch 64, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 64, Batch 2/4: Zeroing gradients...
  Epoch 64, Batch 2/4: Forward pass...
  Epoch 64, Batch 2/4: Calculating loss...
  Epoch 64, Batch 2/4: Backward pass...
  Epoch 64, Batch 2/4: Clipping gradients...
  Epoch 64, Batch 2/4: Optimizer step...
  Epoch 64, Batch 2/4: Completed in 0.19s
  Epoch 64, Batch 3/4: Loading data to device...
  Epoch 64, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 64, Batch 3/4: Zeroing gradients...
  Epoch 64, Batch 3/4: Forward pass...
  Epoch 64, Batch 3/4: Calculating loss...
  Epoch 64, Batch 3/4: Backward pass...
  Epoch 64, Batch 3/4: Clipping gradients...
  Epoch 64, Batch 3/4: Optimizer step...
  Epoch 64, Batch 3/4: Completed in 0.19s
  Epoch 64, Batch 4/4: Loading data to device...
  Epoch 64, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 64, Batch 4/4: Zeroing gradients...
  Epoch 64, Batch 4/4: Forward pass...
  Epoch 64, Batch 4/4: Calculating loss...
  Epoch 64, Batch 4/4: Backward pass...
  Epoch 64, Batch 4/4: Clipping gradients...
  Epoch 64, Batch 4/4: Optimizer step...
  Epoch 64, Batch 4/4: Completed in 0.03s
Epoch 64: Training phase completed. Average Train Loss: 0.5450
Epoch 64: Starting validation phase...
  Epoch 64, Val Batch 1/1: Loading data...
  Epoch 64, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 64, Val Batch 1/1: Forward pass...
  Epoch 64, Val Batch 1/1: Calculating loss...
Epoch 64: Validation phase completed. Average Val Loss: 0.5070
Epoch 64 Summary ---> Train Loss: 0.5450 / Validation Loss: 0.5070
Epoch 64: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 5)
  Epoch 64: Validation loss did not improve. Epochs without improvement: 6
Epoch 64: Stepping scheduler...
--- Epoch 64 completed in 0.68 seconds ---

--- Starting Epoch 65/1000 ---
Epoch 65: Starting training phase (4 batches)
  Epoch 65, Batch 1/4: Loading data to device...
  Epoch 65, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 65, Batch 1/4: Zeroing gradients...
  Epoch 65, Batch 1/4: Forward pass...
  Epoch 65, Batch 1/4: Calculating loss...
  Epoch 65, Batch 1/4: Backward pass...
  Epoch 65, Batch 1/4: Clipping gradients...
  Epoch 65, Batch 1/4: Optimizer step...
  Epoch 65, Batch 1/4: Completed in 0.20s
  Epoch 65, Batch 2/4: Loading data to device...
  Epoch 65, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 65, Batch 2/4: Zeroing gradients...
  Epoch 65, Batch 2/4: Forward pass...
  Epoch 65, Batch 2/4: Calculating loss...
  Epoch 65, Batch 2/4: Backward pass...
  Epoch 65, Batch 2/4: Clipping gradients...
  Epoch 65, Batch 2/4: Optimizer step...
  Epoch 65, Batch 2/4: Completed in 0.19s
  Epoch 65, Batch 3/4: Loading data to device...
  Epoch 65, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 65, Batch 3/4: Zeroing gradients...
  Epoch 65, Batch 3/4: Forward pass...
  Epoch 65, Batch 3/4: Calculating loss...
  Epoch 65, Batch 3/4: Backward pass...
  Epoch 65, Batch 3/4: Clipping gradients...
  Epoch 65, Batch 3/4: Optimizer step...
  Epoch 65, Batch 3/4: Completed in 0.19s
  Epoch 65, Batch 4/4: Loading data to device...
  Epoch 65, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 65, Batch 4/4: Zeroing gradients...
  Epoch 65, Batch 4/4: Forward pass...
  Epoch 65, Batch 4/4: Calculating loss...
  Epoch 65, Batch 4/4: Backward pass...
  Epoch 65, Batch 4/4: Clipping gradients...
  Epoch 65, Batch 4/4: Optimizer step...
  Epoch 65, Batch 4/4: Completed in 0.03s
Epoch 65: Training phase completed. Average Train Loss: 0.5464
Epoch 65: Starting validation phase...
  Epoch 65, Val Batch 1/1: Loading data...
  Epoch 65, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 65, Val Batch 1/1: Forward pass...
  Epoch 65, Val Batch 1/1: Calculating loss...
Epoch 65: Validation phase completed. Average Val Loss: 0.5090
Epoch 65 Summary ---> Train Loss: 0.5464 / Validation Loss: 0.5090
Epoch 65: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 6)
  Epoch 65: Validation loss did not improve. Epochs without improvement: 7
Epoch 65: Stepping scheduler...
--- Epoch 65 completed in 0.69 seconds ---

--- Starting Epoch 66/1000 ---
Epoch 66: Starting training phase (4 batches)
  Epoch 66, Batch 1/4: Loading data to device...
  Epoch 66, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 66, Batch 1/4: Zeroing gradients...
  Epoch 66, Batch 1/4: Forward pass...
  Epoch 66, Batch 1/4: Calculating loss...
  Epoch 66, Batch 1/4: Backward pass...
  Epoch 66, Batch 1/4: Clipping gradients...
  Epoch 66, Batch 1/4: Optimizer step...
  Epoch 66, Batch 1/4: Completed in 0.19s
  Epoch 66, Batch 2/4: Loading data to device...
  Epoch 66, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 66, Batch 2/4: Zeroing gradients...
  Epoch 66, Batch 2/4: Forward pass...
  Epoch 66, Batch 2/4: Calculating loss...
  Epoch 66, Batch 2/4: Backward pass...
  Epoch 66, Batch 2/4: Clipping gradients...
  Epoch 66, Batch 2/4: Optimizer step...
  Epoch 66, Batch 2/4: Completed in 0.19s
  Epoch 66, Batch 3/4: Loading data to device...
  Epoch 66, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 66, Batch 3/4: Zeroing gradients...
  Epoch 66, Batch 3/4: Forward pass...
  Epoch 66, Batch 3/4: Calculating loss...
  Epoch 66, Batch 3/4: Backward pass...
  Epoch 66, Batch 3/4: Clipping gradients...
  Epoch 66, Batch 3/4: Optimizer step...
  Epoch 66, Batch 3/4: Completed in 0.19s
  Epoch 66, Batch 4/4: Loading data to device...
  Epoch 66, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 66, Batch 4/4: Zeroing gradients...
  Epoch 66, Batch 4/4: Forward pass...
  Epoch 66, Batch 4/4: Calculating loss...
  Epoch 66, Batch 4/4: Backward pass...
  Epoch 66, Batch 4/4: Clipping gradients...
  Epoch 66, Batch 4/4: Optimizer step...
  Epoch 66, Batch 4/4: Completed in 0.03s
Epoch 66: Training phase completed. Average Train Loss: 0.5533
Epoch 66: Starting validation phase...
  Epoch 66, Val Batch 1/1: Loading data...
  Epoch 66, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 66, Val Batch 1/1: Forward pass...
  Epoch 66, Val Batch 1/1: Calculating loss...
Epoch 66: Validation phase completed. Average Val Loss: 0.5120
Epoch 66 Summary ---> Train Loss: 0.5533 / Validation Loss: 0.5120
Epoch 66: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 7)
  Epoch 66: Validation loss did not improve. Epochs without improvement: 8
Epoch 66: Stepping scheduler...
--- Epoch 66 completed in 0.68 seconds ---

--- Starting Epoch 67/1000 ---
Epoch 67: Starting training phase (4 batches)
  Epoch 67, Batch 1/4: Loading data to device...
  Epoch 67, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 67, Batch 1/4: Zeroing gradients...
  Epoch 67, Batch 1/4: Forward pass...
  Epoch 67, Batch 1/4: Calculating loss...
  Epoch 67, Batch 1/4: Backward pass...
  Epoch 67, Batch 1/4: Clipping gradients...
  Epoch 67, Batch 1/4: Optimizer step...
  Epoch 67, Batch 1/4: Completed in 0.19s
  Epoch 67, Batch 2/4: Loading data to device...
  Epoch 67, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 67, Batch 2/4: Zeroing gradients...
  Epoch 67, Batch 2/4: Forward pass...
  Epoch 67, Batch 2/4: Calculating loss...
  Epoch 67, Batch 2/4: Backward pass...
  Epoch 67, Batch 2/4: Clipping gradients...
  Epoch 67, Batch 2/4: Optimizer step...
  Epoch 67, Batch 2/4: Completed in 0.19s
  Epoch 67, Batch 3/4: Loading data to device...
  Epoch 67, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 67, Batch 3/4: Zeroing gradients...
  Epoch 67, Batch 3/4: Forward pass...
  Epoch 67, Batch 3/4: Calculating loss...
  Epoch 67, Batch 3/4: Backward pass...
  Epoch 67, Batch 3/4: Clipping gradients...
  Epoch 67, Batch 3/4: Optimizer step...
  Epoch 67, Batch 3/4: Completed in 0.19s
  Epoch 67, Batch 4/4: Loading data to device...
  Epoch 67, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 67, Batch 4/4: Zeroing gradients...
  Epoch 67, Batch 4/4: Forward pass...
  Epoch 67, Batch 4/4: Calculating loss...
  Epoch 67, Batch 4/4: Backward pass...
  Epoch 67, Batch 4/4: Clipping gradients...
  Epoch 67, Batch 4/4: Optimizer step...
  Epoch 67, Batch 4/4: Completed in 0.04s
Epoch 67: Training phase completed. Average Train Loss: 0.5433
Epoch 67: Starting validation phase...
  Epoch 67, Val Batch 1/1: Loading data...
  Epoch 67, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 67, Val Batch 1/1: Forward pass...
  Epoch 67, Val Batch 1/1: Calculating loss...
Epoch 67: Validation phase completed. Average Val Loss: 0.5054
Epoch 67 Summary ---> Train Loss: 0.5433 / Validation Loss: 0.5054
Epoch 67: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 8)
  Epoch 67: Validation loss did not improve. Epochs without improvement: 9
Epoch 67: Stepping scheduler...
--- Epoch 67 completed in 0.67 seconds ---

--- Starting Epoch 68/1000 ---
Epoch 68: Starting training phase (4 batches)
  Epoch 68, Batch 1/4: Loading data to device...
  Epoch 68, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 68, Batch 1/4: Zeroing gradients...
  Epoch 68, Batch 1/4: Forward pass...
  Epoch 68, Batch 1/4: Calculating loss...
  Epoch 68, Batch 1/4: Backward pass...
  Epoch 68, Batch 1/4: Clipping gradients...
  Epoch 68, Batch 1/4: Optimizer step...
  Epoch 68, Batch 1/4: Completed in 0.19s
  Epoch 68, Batch 2/4: Loading data to device...
  Epoch 68, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 68, Batch 2/4: Zeroing gradients...
  Epoch 68, Batch 2/4: Forward pass...
  Epoch 68, Batch 2/4: Calculating loss...
  Epoch 68, Batch 2/4: Backward pass...
  Epoch 68, Batch 2/4: Clipping gradients...
  Epoch 68, Batch 2/4: Optimizer step...
  Epoch 68, Batch 2/4: Completed in 0.19s
  Epoch 68, Batch 3/4: Loading data to device...
  Epoch 68, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 68, Batch 3/4: Zeroing gradients...
  Epoch 68, Batch 3/4: Forward pass...
  Epoch 68, Batch 3/4: Calculating loss...
  Epoch 68, Batch 3/4: Backward pass...
  Epoch 68, Batch 3/4: Clipping gradients...
  Epoch 68, Batch 3/4: Optimizer step...
  Epoch 68, Batch 3/4: Completed in 0.20s
  Epoch 68, Batch 4/4: Loading data to device...
  Epoch 68, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 68, Batch 4/4: Zeroing gradients...
  Epoch 68, Batch 4/4: Forward pass...
  Epoch 68, Batch 4/4: Calculating loss...
  Epoch 68, Batch 4/4: Backward pass...
  Epoch 68, Batch 4/4: Clipping gradients...
  Epoch 68, Batch 4/4: Optimizer step...
  Epoch 68, Batch 4/4: Completed in 0.03s
Epoch 68: Training phase completed. Average Train Loss: 0.5376
Epoch 68: Starting validation phase...
  Epoch 68, Val Batch 1/1: Loading data...
  Epoch 68, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 68, Val Batch 1/1: Forward pass...
  Epoch 68, Val Batch 1/1: Calculating loss...
Epoch 68: Validation phase completed. Average Val Loss: 0.5091
Epoch 68 Summary ---> Train Loss: 0.5376 / Validation Loss: 0.5091
Epoch 68: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 9)
  Epoch 68: Validation loss did not improve. Epochs without improvement: 10
Epoch 68: Stepping scheduler...
--- Epoch 68 completed in 0.68 seconds ---

--- Starting Epoch 69/1000 ---
Epoch 69: Starting training phase (4 batches)
  Epoch 69, Batch 1/4: Loading data to device...
  Epoch 69, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 69, Batch 1/4: Zeroing gradients...
  Epoch 69, Batch 1/4: Forward pass...
  Epoch 69, Batch 1/4: Calculating loss...
  Epoch 69, Batch 1/4: Backward pass...
  Epoch 69, Batch 1/4: Clipping gradients...
  Epoch 69, Batch 1/4: Optimizer step...
  Epoch 69, Batch 1/4: Completed in 0.19s
  Epoch 69, Batch 2/4: Loading data to device...
  Epoch 69, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 69, Batch 2/4: Zeroing gradients...
  Epoch 69, Batch 2/4: Forward pass...
  Epoch 69, Batch 2/4: Calculating loss...
  Epoch 69, Batch 2/4: Backward pass...
  Epoch 69, Batch 2/4: Clipping gradients...
  Epoch 69, Batch 2/4: Optimizer step...
  Epoch 69, Batch 2/4: Completed in 0.18s
  Epoch 69, Batch 3/4: Loading data to device...
  Epoch 69, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 69, Batch 3/4: Zeroing gradients...
  Epoch 69, Batch 3/4: Forward pass...
  Epoch 69, Batch 3/4: Calculating loss...
  Epoch 69, Batch 3/4: Backward pass...
  Epoch 69, Batch 3/4: Clipping gradients...
  Epoch 69, Batch 3/4: Optimizer step...
  Epoch 69, Batch 3/4: Completed in 0.19s
  Epoch 69, Batch 4/4: Loading data to device...
  Epoch 69, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 69, Batch 4/4: Zeroing gradients...
  Epoch 69, Batch 4/4: Forward pass...
  Epoch 69, Batch 4/4: Calculating loss...
  Epoch 69, Batch 4/4: Backward pass...
  Epoch 69, Batch 4/4: Clipping gradients...
  Epoch 69, Batch 4/4: Optimizer step...
  Epoch 69, Batch 4/4: Completed in 0.03s
Epoch 69: Training phase completed. Average Train Loss: 0.5339
Epoch 69: Starting validation phase...
  Epoch 69, Val Batch 1/1: Loading data...
  Epoch 69, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 69, Val Batch 1/1: Forward pass...
  Epoch 69, Val Batch 1/1: Calculating loss...
Epoch 69: Validation phase completed. Average Val Loss: 0.5118
Epoch 69 Summary ---> Train Loss: 0.5339 / Validation Loss: 0.5118
Epoch 69: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 10)
  Epoch 69: Validation loss did not improve. Epochs without improvement: 11
Epoch 69: Stepping scheduler...
--- Epoch 69 completed in 0.67 seconds ---

--- Starting Epoch 70/1000 ---
Epoch 70: Starting training phase (4 batches)
  Epoch 70, Batch 1/4: Loading data to device...
  Epoch 70, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 70, Batch 1/4: Zeroing gradients...
  Epoch 70, Batch 1/4: Forward pass...
  Epoch 70, Batch 1/4: Calculating loss...
  Epoch 70, Batch 1/4: Backward pass...
  Epoch 70, Batch 1/4: Clipping gradients...
  Epoch 70, Batch 1/4: Optimizer step...
  Epoch 70, Batch 1/4: Completed in 0.19s
  Epoch 70, Batch 2/4: Loading data to device...
  Epoch 70, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 70, Batch 2/4: Zeroing gradients...
  Epoch 70, Batch 2/4: Forward pass...
  Epoch 70, Batch 2/4: Calculating loss...
  Epoch 70, Batch 2/4: Backward pass...
  Epoch 70, Batch 2/4: Clipping gradients...
  Epoch 70, Batch 2/4: Optimizer step...
  Epoch 70, Batch 2/4: Completed in 0.19s
  Epoch 70, Batch 3/4: Loading data to device...
  Epoch 70, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 70, Batch 3/4: Zeroing gradients...
  Epoch 70, Batch 3/4: Forward pass...
  Epoch 70, Batch 3/4: Calculating loss...
  Epoch 70, Batch 3/4: Backward pass...
  Epoch 70, Batch 3/4: Clipping gradients...
  Epoch 70, Batch 3/4: Optimizer step...
  Epoch 70, Batch 3/4: Completed in 0.18s
  Epoch 70, Batch 4/4: Loading data to device...
  Epoch 70, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 70, Batch 4/4: Zeroing gradients...
  Epoch 70, Batch 4/4: Forward pass...
  Epoch 70, Batch 4/4: Calculating loss...
  Epoch 70, Batch 4/4: Backward pass...
  Epoch 70, Batch 4/4: Clipping gradients...
  Epoch 70, Batch 4/4: Optimizer step...
  Epoch 70, Batch 4/4: Completed in 0.03s
Epoch 70: Training phase completed. Average Train Loss: 0.5394
Epoch 70: Starting validation phase...
  Epoch 70, Val Batch 1/1: Loading data...
  Epoch 70, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 70, Val Batch 1/1: Forward pass...
  Epoch 70, Val Batch 1/1: Calculating loss...
Epoch 70: Validation phase completed. Average Val Loss: 0.5018
Epoch 70 Summary ---> Train Loss: 0.5394 / Validation Loss: 0.5018
Epoch 70: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 11)
  Epoch 70: Validation loss did not improve. Epochs without improvement: 12
Epoch 70: Stepping scheduler...
--- Epoch 70 completed in 0.66 seconds ---

--- Starting Epoch 71/1000 ---
Epoch 71: Starting training phase (4 batches)
  Epoch 71, Batch 1/4: Loading data to device...
  Epoch 71, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 71, Batch 1/4: Zeroing gradients...
  Epoch 71, Batch 1/4: Forward pass...
  Epoch 71, Batch 1/4: Calculating loss...
  Epoch 71, Batch 1/4: Backward pass...
  Epoch 71, Batch 1/4: Clipping gradients...
  Epoch 71, Batch 1/4: Optimizer step...
  Epoch 71, Batch 1/4: Completed in 0.19s
  Epoch 71, Batch 2/4: Loading data to device...
  Epoch 71, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 71, Batch 2/4: Zeroing gradients...
  Epoch 71, Batch 2/4: Forward pass...
  Epoch 71, Batch 2/4: Calculating loss...
  Epoch 71, Batch 2/4: Backward pass...
  Epoch 71, Batch 2/4: Clipping gradients...
  Epoch 71, Batch 2/4: Optimizer step...
  Epoch 71, Batch 2/4: Completed in 0.19s
  Epoch 71, Batch 3/4: Loading data to device...
  Epoch 71, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 71, Batch 3/4: Zeroing gradients...
  Epoch 71, Batch 3/4: Forward pass...
  Epoch 71, Batch 3/4: Calculating loss...
  Epoch 71, Batch 3/4: Backward pass...
  Epoch 71, Batch 3/4: Clipping gradients...
  Epoch 71, Batch 3/4: Optimizer step...
  Epoch 71, Batch 3/4: Completed in 0.19s
  Epoch 71, Batch 4/4: Loading data to device...
  Epoch 71, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 71, Batch 4/4: Zeroing gradients...
  Epoch 71, Batch 4/4: Forward pass...
  Epoch 71, Batch 4/4: Calculating loss...
  Epoch 71, Batch 4/4: Backward pass...
  Epoch 71, Batch 4/4: Clipping gradients...
  Epoch 71, Batch 4/4: Optimizer step...
  Epoch 71, Batch 4/4: Completed in 0.03s
Epoch 71: Training phase completed. Average Train Loss: 0.5374
Epoch 71: Starting validation phase...
  Epoch 71, Val Batch 1/1: Loading data...
  Epoch 71, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 71, Val Batch 1/1: Forward pass...
  Epoch 71, Val Batch 1/1: Calculating loss...
Epoch 71: Validation phase completed. Average Val Loss: 0.4976
Epoch 71 Summary ---> Train Loss: 0.5374 / Validation Loss: 0.4976
Epoch 71: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 12)
  Epoch 71: Validation loss did not improve. Epochs without improvement: 13
Epoch 71: Stepping scheduler...
--- Epoch 71 completed in 0.68 seconds ---

--- Starting Epoch 72/1000 ---
Epoch 72: Starting training phase (4 batches)
  Epoch 72, Batch 1/4: Loading data to device...
  Epoch 72, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 72, Batch 1/4: Zeroing gradients...
  Epoch 72, Batch 1/4: Forward pass...
  Epoch 72, Batch 1/4: Calculating loss...
  Epoch 72, Batch 1/4: Backward pass...
  Epoch 72, Batch 1/4: Clipping gradients...
  Epoch 72, Batch 1/4: Optimizer step...
  Epoch 72, Batch 1/4: Completed in 0.19s
  Epoch 72, Batch 2/4: Loading data to device...
  Epoch 72, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 72, Batch 2/4: Zeroing gradients...
  Epoch 72, Batch 2/4: Forward pass...
  Epoch 72, Batch 2/4: Calculating loss...
  Epoch 72, Batch 2/4: Backward pass...
  Epoch 72, Batch 2/4: Clipping gradients...
  Epoch 72, Batch 2/4: Optimizer step...
  Epoch 72, Batch 2/4: Completed in 0.19s
  Epoch 72, Batch 3/4: Loading data to device...
  Epoch 72, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 72, Batch 3/4: Zeroing gradients...
  Epoch 72, Batch 3/4: Forward pass...
  Epoch 72, Batch 3/4: Calculating loss...
  Epoch 72, Batch 3/4: Backward pass...
  Epoch 72, Batch 3/4: Clipping gradients...
  Epoch 72, Batch 3/4: Optimizer step...
  Epoch 72, Batch 3/4: Completed in 0.19s
  Epoch 72, Batch 4/4: Loading data to device...
  Epoch 72, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 72, Batch 4/4: Zeroing gradients...
  Epoch 72, Batch 4/4: Forward pass...
  Epoch 72, Batch 4/4: Calculating loss...
  Epoch 72, Batch 4/4: Backward pass...
  Epoch 72, Batch 4/4: Clipping gradients...
  Epoch 72, Batch 4/4: Optimizer step...
  Epoch 72, Batch 4/4: Completed in 0.03s
Epoch 72: Training phase completed. Average Train Loss: 0.5194
Epoch 72: Starting validation phase...
  Epoch 72, Val Batch 1/1: Loading data...
  Epoch 72, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 72, Val Batch 1/1: Forward pass...
  Epoch 72, Val Batch 1/1: Calculating loss...
Epoch 72: Validation phase completed. Average Val Loss: 0.4969
Epoch 72 Summary ---> Train Loss: 0.5194 / Validation Loss: 0.4969
Epoch 72: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 13)
  Epoch 72: Validation loss did not improve. Epochs without improvement: 14
Epoch 72: Stepping scheduler...
--- Epoch 72 completed in 0.67 seconds ---

--- Starting Epoch 73/1000 ---
Epoch 73: Starting training phase (4 batches)
  Epoch 73, Batch 1/4: Loading data to device...
  Epoch 73, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 73, Batch 1/4: Zeroing gradients...
  Epoch 73, Batch 1/4: Forward pass...
  Epoch 73, Batch 1/4: Calculating loss...
  Epoch 73, Batch 1/4: Backward pass...
  Epoch 73, Batch 1/4: Clipping gradients...
  Epoch 73, Batch 1/4: Optimizer step...
  Epoch 73, Batch 1/4: Completed in 0.19s
  Epoch 73, Batch 2/4: Loading data to device...
  Epoch 73, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 73, Batch 2/4: Zeroing gradients...
  Epoch 73, Batch 2/4: Forward pass...
  Epoch 73, Batch 2/4: Calculating loss...
  Epoch 73, Batch 2/4: Backward pass...
  Epoch 73, Batch 2/4: Clipping gradients...
  Epoch 73, Batch 2/4: Optimizer step...
  Epoch 73, Batch 2/4: Completed in 0.19s
  Epoch 73, Batch 3/4: Loading data to device...
  Epoch 73, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 73, Batch 3/4: Zeroing gradients...
  Epoch 73, Batch 3/4: Forward pass...
  Epoch 73, Batch 3/4: Calculating loss...
  Epoch 73, Batch 3/4: Backward pass...
  Epoch 73, Batch 3/4: Clipping gradients...
  Epoch 73, Batch 3/4: Optimizer step...
  Epoch 73, Batch 3/4: Completed in 0.19s
  Epoch 73, Batch 4/4: Loading data to device...
  Epoch 73, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 73, Batch 4/4: Zeroing gradients...
  Epoch 73, Batch 4/4: Forward pass...
  Epoch 73, Batch 4/4: Calculating loss...
  Epoch 73, Batch 4/4: Backward pass...
  Epoch 73, Batch 4/4: Clipping gradients...
  Epoch 73, Batch 4/4: Optimizer step...
  Epoch 73, Batch 4/4: Completed in 0.03s
Epoch 73: Training phase completed. Average Train Loss: 0.5633
Epoch 73: Starting validation phase...
  Epoch 73, Val Batch 1/1: Loading data...
  Epoch 73, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 73, Val Batch 1/1: Forward pass...
  Epoch 73, Val Batch 1/1: Calculating loss...
Epoch 73: Validation phase completed. Average Val Loss: 0.4962
Epoch 73 Summary ---> Train Loss: 0.5633 / Validation Loss: 0.4962
Epoch 73: Checking early stopping... (Current Best Loss: 0.4968, Epochs No Improve: 14)
  Epoch 73: Validation loss improved (0.4968 --> 0.4962). Saving model.
Epoch 73: Stepping scheduler...
--- Epoch 73 completed in 0.67 seconds ---

--- Starting Epoch 74/1000 ---
Epoch 74: Starting training phase (4 batches)
  Epoch 74, Batch 1/4: Loading data to device...
  Epoch 74, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 74, Batch 1/4: Zeroing gradients...
  Epoch 74, Batch 1/4: Forward pass...
  Epoch 74, Batch 1/4: Calculating loss...
  Epoch 74, Batch 1/4: Backward pass...
  Epoch 74, Batch 1/4: Clipping gradients...
  Epoch 74, Batch 1/4: Optimizer step...
  Epoch 74, Batch 1/4: Completed in 0.19s
  Epoch 74, Batch 2/4: Loading data to device...
  Epoch 74, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 74, Batch 2/4: Zeroing gradients...
  Epoch 74, Batch 2/4: Forward pass...
  Epoch 74, Batch 2/4: Calculating loss...
  Epoch 74, Batch 2/4: Backward pass...
  Epoch 74, Batch 2/4: Clipping gradients...
  Epoch 74, Batch 2/4: Optimizer step...
  Epoch 74, Batch 2/4: Completed in 0.19s
  Epoch 74, Batch 3/4: Loading data to device...
  Epoch 74, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 74, Batch 3/4: Zeroing gradients...
  Epoch 74, Batch 3/4: Forward pass...
  Epoch 74, Batch 3/4: Calculating loss...
  Epoch 74, Batch 3/4: Backward pass...
  Epoch 74, Batch 3/4: Clipping gradients...
  Epoch 74, Batch 3/4: Optimizer step...
  Epoch 74, Batch 3/4: Completed in 0.19s
  Epoch 74, Batch 4/4: Loading data to device...
  Epoch 74, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 74, Batch 4/4: Zeroing gradients...
  Epoch 74, Batch 4/4: Forward pass...
  Epoch 74, Batch 4/4: Calculating loss...
  Epoch 74, Batch 4/4: Backward pass...
  Epoch 74, Batch 4/4: Clipping gradients...
  Epoch 74, Batch 4/4: Optimizer step...
  Epoch 74, Batch 4/4: Completed in 0.03s
Epoch 74: Training phase completed. Average Train Loss: 0.5295
Epoch 74: Starting validation phase...
  Epoch 74, Val Batch 1/1: Loading data...
  Epoch 74, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 74, Val Batch 1/1: Forward pass...
  Epoch 74, Val Batch 1/1: Calculating loss...
Epoch 74: Validation phase completed. Average Val Loss: 0.4904
Epoch 74 Summary ---> Train Loss: 0.5295 / Validation Loss: 0.4904
Epoch 74: Checking early stopping... (Current Best Loss: 0.4962, Epochs No Improve: 0)
  Epoch 74: Validation loss improved (0.4962 --> 0.4904). Saving model.
Epoch 74: Stepping scheduler...
--- Epoch 74 completed in 0.68 seconds ---

--- Starting Epoch 75/1000 ---
Epoch 75: Starting training phase (4 batches)
  Epoch 75, Batch 1/4: Loading data to device...
  Epoch 75, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 75, Batch 1/4: Zeroing gradients...
  Epoch 75, Batch 1/4: Forward pass...
  Epoch 75, Batch 1/4: Calculating loss...
  Epoch 75, Batch 1/4: Backward pass...
  Epoch 75, Batch 1/4: Clipping gradients...
  Epoch 75, Batch 1/4: Optimizer step...
  Epoch 75, Batch 1/4: Completed in 0.19s
  Epoch 75, Batch 2/4: Loading data to device...
  Epoch 75, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 75, Batch 2/4: Zeroing gradients...
  Epoch 75, Batch 2/4: Forward pass...
  Epoch 75, Batch 2/4: Calculating loss...
  Epoch 75, Batch 2/4: Backward pass...
  Epoch 75, Batch 2/4: Clipping gradients...
  Epoch 75, Batch 2/4: Optimizer step...
  Epoch 75, Batch 2/4: Completed in 0.19s
  Epoch 75, Batch 3/4: Loading data to device...
  Epoch 75, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 75, Batch 3/4: Zeroing gradients...
  Epoch 75, Batch 3/4: Forward pass...
  Epoch 75, Batch 3/4: Calculating loss...
  Epoch 75, Batch 3/4: Backward pass...
  Epoch 75, Batch 3/4: Clipping gradients...
  Epoch 75, Batch 3/4: Optimizer step...
  Epoch 75, Batch 3/4: Completed in 0.19s
  Epoch 75, Batch 4/4: Loading data to device...
  Epoch 75, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 75, Batch 4/4: Zeroing gradients...
  Epoch 75, Batch 4/4: Forward pass...
  Epoch 75, Batch 4/4: Calculating loss...
  Epoch 75, Batch 4/4: Backward pass...
  Epoch 75, Batch 4/4: Clipping gradients...
  Epoch 75, Batch 4/4: Optimizer step...
  Epoch 75, Batch 4/4: Completed in 0.03s
Epoch 75: Training phase completed. Average Train Loss: 0.5269
Epoch 75: Starting validation phase...
  Epoch 75, Val Batch 1/1: Loading data...
  Epoch 75, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 75, Val Batch 1/1: Forward pass...
  Epoch 75, Val Batch 1/1: Calculating loss...
Epoch 75: Validation phase completed. Average Val Loss: 0.4921
Epoch 75 Summary ---> Train Loss: 0.5269 / Validation Loss: 0.4921
Epoch 75: Checking early stopping... (Current Best Loss: 0.4904, Epochs No Improve: 0)
  Epoch 75: Validation loss did not improve. Epochs without improvement: 1
Epoch 75: Stepping scheduler...
--- Epoch 75 completed in 0.67 seconds ---

--- Starting Epoch 76/1000 ---
Epoch 76: Starting training phase (4 batches)
  Epoch 76, Batch 1/4: Loading data to device...
  Epoch 76, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 76, Batch 1/4: Zeroing gradients...
  Epoch 76, Batch 1/4: Forward pass...
  Epoch 76, Batch 1/4: Calculating loss...
  Epoch 76, Batch 1/4: Backward pass...
  Epoch 76, Batch 1/4: Clipping gradients...
  Epoch 76, Batch 1/4: Optimizer step...
  Epoch 76, Batch 1/4: Completed in 0.19s
  Epoch 76, Batch 2/4: Loading data to device...
  Epoch 76, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 76, Batch 2/4: Zeroing gradients...
  Epoch 76, Batch 2/4: Forward pass...
  Epoch 76, Batch 2/4: Calculating loss...
  Epoch 76, Batch 2/4: Backward pass...
  Epoch 76, Batch 2/4: Clipping gradients...
  Epoch 76, Batch 2/4: Optimizer step...
  Epoch 76, Batch 2/4: Completed in 0.20s
  Epoch 76, Batch 3/4: Loading data to device...
  Epoch 76, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 76, Batch 3/4: Zeroing gradients...
  Epoch 76, Batch 3/4: Forward pass...
  Epoch 76, Batch 3/4: Calculating loss...
  Epoch 76, Batch 3/4: Backward pass...
  Epoch 76, Batch 3/4: Clipping gradients...
  Epoch 76, Batch 3/4: Optimizer step...
  Epoch 76, Batch 3/4: Completed in 0.20s
  Epoch 76, Batch 4/4: Loading data to device...
  Epoch 76, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 76, Batch 4/4: Zeroing gradients...
  Epoch 76, Batch 4/4: Forward pass...
  Epoch 76, Batch 4/4: Calculating loss...
  Epoch 76, Batch 4/4: Backward pass...
  Epoch 76, Batch 4/4: Clipping gradients...
  Epoch 76, Batch 4/4: Optimizer step...
  Epoch 76, Batch 4/4: Completed in 0.03s
Epoch 76: Training phase completed. Average Train Loss: 0.5710
Epoch 76: Starting validation phase...
  Epoch 76, Val Batch 1/1: Loading data...
  Epoch 76, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 76, Val Batch 1/1: Forward pass...
  Epoch 76, Val Batch 1/1: Calculating loss...
Epoch 76: Validation phase completed. Average Val Loss: 0.4836
Epoch 76 Summary ---> Train Loss: 0.5710 / Validation Loss: 0.4836
Epoch 76: Checking early stopping... (Current Best Loss: 0.4904, Epochs No Improve: 1)
  Epoch 76: Validation loss improved (0.4904 --> 0.4836). Saving model.
Epoch 76: Stepping scheduler...
--- Epoch 76 completed in 0.69 seconds ---

--- Starting Epoch 77/1000 ---
Epoch 77: Starting training phase (4 batches)
  Epoch 77, Batch 1/4: Loading data to device...
  Epoch 77, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 77, Batch 1/4: Zeroing gradients...
  Epoch 77, Batch 1/4: Forward pass...
  Epoch 77, Batch 1/4: Calculating loss...
  Epoch 77, Batch 1/4: Backward pass...
  Epoch 77, Batch 1/4: Clipping gradients...
  Epoch 77, Batch 1/4: Optimizer step...
  Epoch 77, Batch 1/4: Completed in 0.20s
  Epoch 77, Batch 2/4: Loading data to device...
  Epoch 77, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 77, Batch 2/4: Zeroing gradients...
  Epoch 77, Batch 2/4: Forward pass...
  Epoch 77, Batch 2/4: Calculating loss...
  Epoch 77, Batch 2/4: Backward pass...
  Epoch 77, Batch 2/4: Clipping gradients...
  Epoch 77, Batch 2/4: Optimizer step...
  Epoch 77, Batch 2/4: Completed in 0.19s
  Epoch 77, Batch 3/4: Loading data to device...
  Epoch 77, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 77, Batch 3/4: Zeroing gradients...
  Epoch 77, Batch 3/4: Forward pass...
  Epoch 77, Batch 3/4: Calculating loss...
  Epoch 77, Batch 3/4: Backward pass...
  Epoch 77, Batch 3/4: Clipping gradients...
  Epoch 77, Batch 3/4: Optimizer step...
  Epoch 77, Batch 3/4: Completed in 0.19s
  Epoch 77, Batch 4/4: Loading data to device...
  Epoch 77, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 77, Batch 4/4: Zeroing gradients...
  Epoch 77, Batch 4/4: Forward pass...
  Epoch 77, Batch 4/4: Calculating loss...
  Epoch 77, Batch 4/4: Backward pass...
  Epoch 77, Batch 4/4: Clipping gradients...
  Epoch 77, Batch 4/4: Optimizer step...
  Epoch 77, Batch 4/4: Completed in 0.03s
Epoch 77: Training phase completed. Average Train Loss: 0.5008
Epoch 77: Starting validation phase...
  Epoch 77, Val Batch 1/1: Loading data...
  Epoch 77, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 77, Val Batch 1/1: Forward pass...
  Epoch 77, Val Batch 1/1: Calculating loss...
Epoch 77: Validation phase completed. Average Val Loss: 0.4834
Epoch 77 Summary ---> Train Loss: 0.5008 / Validation Loss: 0.4834
Epoch 77: Checking early stopping... (Current Best Loss: 0.4836, Epochs No Improve: 0)
  Epoch 77: Validation loss improved (0.4836 --> 0.4834). Saving model.
Epoch 77: Stepping scheduler...
--- Epoch 77 completed in 0.69 seconds ---

--- Starting Epoch 78/1000 ---
Epoch 78: Starting training phase (4 batches)
  Epoch 78, Batch 1/4: Loading data to device...
  Epoch 78, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 78, Batch 1/4: Zeroing gradients...
  Epoch 78, Batch 1/4: Forward pass...
  Epoch 78, Batch 1/4: Calculating loss...
  Epoch 78, Batch 1/4: Backward pass...
  Epoch 78, Batch 1/4: Clipping gradients...
  Epoch 78, Batch 1/4: Optimizer step...
  Epoch 78, Batch 1/4: Completed in 0.19s
  Epoch 78, Batch 2/4: Loading data to device...
  Epoch 78, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 78, Batch 2/4: Zeroing gradients...
  Epoch 78, Batch 2/4: Forward pass...
  Epoch 78, Batch 2/4: Calculating loss...
  Epoch 78, Batch 2/4: Backward pass...
  Epoch 78, Batch 2/4: Clipping gradients...
  Epoch 78, Batch 2/4: Optimizer step...
  Epoch 78, Batch 2/4: Completed in 0.19s
  Epoch 78, Batch 3/4: Loading data to device...
  Epoch 78, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 78, Batch 3/4: Zeroing gradients...
  Epoch 78, Batch 3/4: Forward pass...
  Epoch 78, Batch 3/4: Calculating loss...
  Epoch 78, Batch 3/4: Backward pass...
  Epoch 78, Batch 3/4: Clipping gradients...
  Epoch 78, Batch 3/4: Optimizer step...
  Epoch 78, Batch 3/4: Completed in 0.20s
  Epoch 78, Batch 4/4: Loading data to device...
  Epoch 78, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 78, Batch 4/4: Zeroing gradients...
  Epoch 78, Batch 4/4: Forward pass...
  Epoch 78, Batch 4/4: Calculating loss...
  Epoch 78, Batch 4/4: Backward pass...
  Epoch 78, Batch 4/4: Clipping gradients...
  Epoch 78, Batch 4/4: Optimizer step...
  Epoch 78, Batch 4/4: Completed in 0.03s
Epoch 78: Training phase completed. Average Train Loss: 0.5273
Epoch 78: Starting validation phase...
  Epoch 78, Val Batch 1/1: Loading data...
  Epoch 78, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 78, Val Batch 1/1: Forward pass...
  Epoch 78, Val Batch 1/1: Calculating loss...
Epoch 78: Validation phase completed. Average Val Loss: 0.4869
Epoch 78 Summary ---> Train Loss: 0.5273 / Validation Loss: 0.4869
Epoch 78: Checking early stopping... (Current Best Loss: 0.4834, Epochs No Improve: 0)
  Epoch 78: Validation loss did not improve. Epochs without improvement: 1
Epoch 78: Stepping scheduler...
--- Epoch 78 completed in 0.69 seconds ---

--- Starting Epoch 79/1000 ---
Epoch 79: Starting training phase (4 batches)
  Epoch 79, Batch 1/4: Loading data to device...
  Epoch 79, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 79, Batch 1/4: Zeroing gradients...
  Epoch 79, Batch 1/4: Forward pass...
  Epoch 79, Batch 1/4: Calculating loss...
  Epoch 79, Batch 1/4: Backward pass...
  Epoch 79, Batch 1/4: Clipping gradients...
  Epoch 79, Batch 1/4: Optimizer step...
  Epoch 79, Batch 1/4: Completed in 0.20s
  Epoch 79, Batch 2/4: Loading data to device...
  Epoch 79, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 79, Batch 2/4: Zeroing gradients...
  Epoch 79, Batch 2/4: Forward pass...
  Epoch 79, Batch 2/4: Calculating loss...
  Epoch 79, Batch 2/4: Backward pass...
  Epoch 79, Batch 2/4: Clipping gradients...
  Epoch 79, Batch 2/4: Optimizer step...
  Epoch 79, Batch 2/4: Completed in 0.20s
  Epoch 79, Batch 3/4: Loading data to device...
  Epoch 79, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 79, Batch 3/4: Zeroing gradients...
  Epoch 79, Batch 3/4: Forward pass...
  Epoch 79, Batch 3/4: Calculating loss...
  Epoch 79, Batch 3/4: Backward pass...
  Epoch 79, Batch 3/4: Clipping gradients...
  Epoch 79, Batch 3/4: Optimizer step...
  Epoch 79, Batch 3/4: Completed in 0.20s
  Epoch 79, Batch 4/4: Loading data to device...
  Epoch 79, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 79, Batch 4/4: Zeroing gradients...
  Epoch 79, Batch 4/4: Forward pass...
  Epoch 79, Batch 4/4: Calculating loss...
  Epoch 79, Batch 4/4: Backward pass...
  Epoch 79, Batch 4/4: Clipping gradients...
  Epoch 79, Batch 4/4: Optimizer step...
  Epoch 79, Batch 4/4: Completed in 0.03s
Epoch 79: Training phase completed. Average Train Loss: 0.4892
Epoch 79: Starting validation phase...
  Epoch 79, Val Batch 1/1: Loading data...
  Epoch 79, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 79, Val Batch 1/1: Forward pass...
  Epoch 79, Val Batch 1/1: Calculating loss...
Epoch 79: Validation phase completed. Average Val Loss: 0.4849
Epoch 79 Summary ---> Train Loss: 0.4892 / Validation Loss: 0.4849
Epoch 79: Checking early stopping... (Current Best Loss: 0.4834, Epochs No Improve: 1)
  Epoch 79: Validation loss did not improve. Epochs without improvement: 2
Epoch 79: Stepping scheduler...
--- Epoch 79 completed in 0.70 seconds ---

--- Starting Epoch 80/1000 ---
Epoch 80: Starting training phase (4 batches)
  Epoch 80, Batch 1/4: Loading data to device...
  Epoch 80, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 80, Batch 1/4: Zeroing gradients...
  Epoch 80, Batch 1/4: Forward pass...
  Epoch 80, Batch 1/4: Calculating loss...
  Epoch 80, Batch 1/4: Backward pass...
  Epoch 80, Batch 1/4: Clipping gradients...
  Epoch 80, Batch 1/4: Optimizer step...
  Epoch 80, Batch 1/4: Completed in 0.19s
  Epoch 80, Batch 2/4: Loading data to device...
  Epoch 80, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 80, Batch 2/4: Zeroing gradients...
  Epoch 80, Batch 2/4: Forward pass...
  Epoch 80, Batch 2/4: Calculating loss...
  Epoch 80, Batch 2/4: Backward pass...
  Epoch 80, Batch 2/4: Clipping gradients...
  Epoch 80, Batch 2/4: Optimizer step...
  Epoch 80, Batch 2/4: Completed in 0.20s
  Epoch 80, Batch 3/4: Loading data to device...
  Epoch 80, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 80, Batch 3/4: Zeroing gradients...
  Epoch 80, Batch 3/4: Forward pass...
  Epoch 80, Batch 3/4: Calculating loss...
  Epoch 80, Batch 3/4: Backward pass...
  Epoch 80, Batch 3/4: Clipping gradients...
  Epoch 80, Batch 3/4: Optimizer step...
  Epoch 80, Batch 3/4: Completed in 0.19s
  Epoch 80, Batch 4/4: Loading data to device...
  Epoch 80, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 80, Batch 4/4: Zeroing gradients...
  Epoch 80, Batch 4/4: Forward pass...
  Epoch 80, Batch 4/4: Calculating loss...
  Epoch 80, Batch 4/4: Backward pass...
  Epoch 80, Batch 4/4: Clipping gradients...
  Epoch 80, Batch 4/4: Optimizer step...
  Epoch 80, Batch 4/4: Completed in 0.03s
Epoch 80: Training phase completed. Average Train Loss: 0.5631
Epoch 80: Starting validation phase...
  Epoch 80, Val Batch 1/1: Loading data...
  Epoch 80, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 80, Val Batch 1/1: Forward pass...
  Epoch 80, Val Batch 1/1: Calculating loss...
Epoch 80: Validation phase completed. Average Val Loss: 0.4776
Epoch 80 Summary ---> Train Loss: 0.5631 / Validation Loss: 0.4776
Epoch 80: Checking early stopping... (Current Best Loss: 0.4834, Epochs No Improve: 2)
  Epoch 80: Validation loss improved (0.4834 --> 0.4776). Saving model.
Epoch 80: Stepping scheduler...
--- Epoch 80 completed in 0.70 seconds ---

--- Starting Epoch 81/1000 ---
Epoch 81: Starting training phase (4 batches)
  Epoch 81, Batch 1/4: Loading data to device...
  Epoch 81, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 81, Batch 1/4: Zeroing gradients...
  Epoch 81, Batch 1/4: Forward pass...
  Epoch 81, Batch 1/4: Calculating loss...
  Epoch 81, Batch 1/4: Backward pass...
  Epoch 81, Batch 1/4: Clipping gradients...
  Epoch 81, Batch 1/4: Optimizer step...
  Epoch 81, Batch 1/4: Completed in 0.19s
  Epoch 81, Batch 2/4: Loading data to device...
  Epoch 81, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 81, Batch 2/4: Zeroing gradients...
  Epoch 81, Batch 2/4: Forward pass...
  Epoch 81, Batch 2/4: Calculating loss...
  Epoch 81, Batch 2/4: Backward pass...
  Epoch 81, Batch 2/4: Clipping gradients...
  Epoch 81, Batch 2/4: Optimizer step...
  Epoch 81, Batch 2/4: Completed in 0.19s
  Epoch 81, Batch 3/4: Loading data to device...
  Epoch 81, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 81, Batch 3/4: Zeroing gradients...
  Epoch 81, Batch 3/4: Forward pass...
  Epoch 81, Batch 3/4: Calculating loss...
  Epoch 81, Batch 3/4: Backward pass...
  Epoch 81, Batch 3/4: Clipping gradients...
  Epoch 81, Batch 3/4: Optimizer step...
  Epoch 81, Batch 3/4: Completed in 0.19s
  Epoch 81, Batch 4/4: Loading data to device...
  Epoch 81, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 81, Batch 4/4: Zeroing gradients...
  Epoch 81, Batch 4/4: Forward pass...
  Epoch 81, Batch 4/4: Calculating loss...
  Epoch 81, Batch 4/4: Backward pass...
  Epoch 81, Batch 4/4: Clipping gradients...
  Epoch 81, Batch 4/4: Optimizer step...
  Epoch 81, Batch 4/4: Completed in 0.03s
Epoch 81: Training phase completed. Average Train Loss: 0.5415
Epoch 81: Starting validation phase...
  Epoch 81, Val Batch 1/1: Loading data...
  Epoch 81, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 81, Val Batch 1/1: Forward pass...
  Epoch 81, Val Batch 1/1: Calculating loss...
Epoch 81: Validation phase completed. Average Val Loss: 0.4717
Epoch 81 Summary ---> Train Loss: 0.5415 / Validation Loss: 0.4717
Epoch 81: Checking early stopping... (Current Best Loss: 0.4776, Epochs No Improve: 0)
  Epoch 81: Validation loss improved (0.4776 --> 0.4717). Saving model.
Epoch 81: Stepping scheduler...
--- Epoch 81 completed in 0.69 seconds ---

--- Starting Epoch 82/1000 ---
Epoch 82: Starting training phase (4 batches)
  Epoch 82, Batch 1/4: Loading data to device...
  Epoch 82, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 82, Batch 1/4: Zeroing gradients...
  Epoch 82, Batch 1/4: Forward pass...
  Epoch 82, Batch 1/4: Calculating loss...
  Epoch 82, Batch 1/4: Backward pass...
  Epoch 82, Batch 1/4: Clipping gradients...
  Epoch 82, Batch 1/4: Optimizer step...
  Epoch 82, Batch 1/4: Completed in 0.19s
  Epoch 82, Batch 2/4: Loading data to device...
  Epoch 82, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 82, Batch 2/4: Zeroing gradients...
  Epoch 82, Batch 2/4: Forward pass...
  Epoch 82, Batch 2/4: Calculating loss...
  Epoch 82, Batch 2/4: Backward pass...
  Epoch 82, Batch 2/4: Clipping gradients...
  Epoch 82, Batch 2/4: Optimizer step...
  Epoch 82, Batch 2/4: Completed in 0.19s
  Epoch 82, Batch 3/4: Loading data to device...
  Epoch 82, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 82, Batch 3/4: Zeroing gradients...
  Epoch 82, Batch 3/4: Forward pass...
  Epoch 82, Batch 3/4: Calculating loss...
  Epoch 82, Batch 3/4: Backward pass...
  Epoch 82, Batch 3/4: Clipping gradients...
  Epoch 82, Batch 3/4: Optimizer step...
  Epoch 82, Batch 3/4: Completed in 0.19s
  Epoch 82, Batch 4/4: Loading data to device...
  Epoch 82, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 82, Batch 4/4: Zeroing gradients...
  Epoch 82, Batch 4/4: Forward pass...
  Epoch 82, Batch 4/4: Calculating loss...
  Epoch 82, Batch 4/4: Backward pass...
  Epoch 82, Batch 4/4: Clipping gradients...
  Epoch 82, Batch 4/4: Optimizer step...
  Epoch 82, Batch 4/4: Completed in 0.03s
Epoch 82: Training phase completed. Average Train Loss: 0.5331
Epoch 82: Starting validation phase...
  Epoch 82, Val Batch 1/1: Loading data...
  Epoch 82, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 82, Val Batch 1/1: Forward pass...
  Epoch 82, Val Batch 1/1: Calculating loss...
Epoch 82: Validation phase completed. Average Val Loss: 0.4758
Epoch 82 Summary ---> Train Loss: 0.5331 / Validation Loss: 0.4758
Epoch 82: Checking early stopping... (Current Best Loss: 0.4717, Epochs No Improve: 0)
  Epoch 82: Validation loss did not improve. Epochs without improvement: 1
Epoch 82: Stepping scheduler...
--- Epoch 82 completed in 0.68 seconds ---

--- Starting Epoch 83/1000 ---
Epoch 83: Starting training phase (4 batches)
  Epoch 83, Batch 1/4: Loading data to device...
  Epoch 83, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 83, Batch 1/4: Zeroing gradients...
  Epoch 83, Batch 1/4: Forward pass...
  Epoch 83, Batch 1/4: Calculating loss...
  Epoch 83, Batch 1/4: Backward pass...
  Epoch 83, Batch 1/4: Clipping gradients...
  Epoch 83, Batch 1/4: Optimizer step...
  Epoch 83, Batch 1/4: Completed in 0.19s
  Epoch 83, Batch 2/4: Loading data to device...
  Epoch 83, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 83, Batch 2/4: Zeroing gradients...
  Epoch 83, Batch 2/4: Forward pass...
  Epoch 83, Batch 2/4: Calculating loss...
  Epoch 83, Batch 2/4: Backward pass...
  Epoch 83, Batch 2/4: Clipping gradients...
  Epoch 83, Batch 2/4: Optimizer step...
  Epoch 83, Batch 2/4: Completed in 0.19s
  Epoch 83, Batch 3/4: Loading data to device...
  Epoch 83, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 83, Batch 3/4: Zeroing gradients...
  Epoch 83, Batch 3/4: Forward pass...
  Epoch 83, Batch 3/4: Calculating loss...
  Epoch 83, Batch 3/4: Backward pass...
  Epoch 83, Batch 3/4: Clipping gradients...
  Epoch 83, Batch 3/4: Optimizer step...
  Epoch 83, Batch 3/4: Completed in 0.21s
  Epoch 83, Batch 4/4: Loading data to device...
  Epoch 83, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 83, Batch 4/4: Zeroing gradients...
  Epoch 83, Batch 4/4: Forward pass...
  Epoch 83, Batch 4/4: Calculating loss...
  Epoch 83, Batch 4/4: Backward pass...
  Epoch 83, Batch 4/4: Clipping gradients...
  Epoch 83, Batch 4/4: Optimizer step...
  Epoch 83, Batch 4/4: Completed in 0.03s
Epoch 83: Training phase completed. Average Train Loss: 0.5530
Epoch 83: Starting validation phase...
  Epoch 83, Val Batch 1/1: Loading data...
  Epoch 83, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 83, Val Batch 1/1: Forward pass...
  Epoch 83, Val Batch 1/1: Calculating loss...
Epoch 83: Validation phase completed. Average Val Loss: 0.4702
Epoch 83 Summary ---> Train Loss: 0.5530 / Validation Loss: 0.4702
Epoch 83: Checking early stopping... (Current Best Loss: 0.4717, Epochs No Improve: 1)
  Epoch 83: Validation loss improved (0.4717 --> 0.4702). Saving model.
Epoch 83: Stepping scheduler...
--- Epoch 83 completed in 0.69 seconds ---

--- Starting Epoch 84/1000 ---
Epoch 84: Starting training phase (4 batches)
  Epoch 84, Batch 1/4: Loading data to device...
  Epoch 84, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 84, Batch 1/4: Zeroing gradients...
  Epoch 84, Batch 1/4: Forward pass...
  Epoch 84, Batch 1/4: Calculating loss...
  Epoch 84, Batch 1/4: Backward pass...
  Epoch 84, Batch 1/4: Clipping gradients...
  Epoch 84, Batch 1/4: Optimizer step...
  Epoch 84, Batch 1/4: Completed in 0.19s
  Epoch 84, Batch 2/4: Loading data to device...
  Epoch 84, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 84, Batch 2/4: Zeroing gradients...
  Epoch 84, Batch 2/4: Forward pass...
  Epoch 84, Batch 2/4: Calculating loss...
  Epoch 84, Batch 2/4: Backward pass...
  Epoch 84, Batch 2/4: Clipping gradients...
  Epoch 84, Batch 2/4: Optimizer step...
  Epoch 84, Batch 2/4: Completed in 0.20s
  Epoch 84, Batch 3/4: Loading data to device...
  Epoch 84, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 84, Batch 3/4: Zeroing gradients...
  Epoch 84, Batch 3/4: Forward pass...
  Epoch 84, Batch 3/4: Calculating loss...
  Epoch 84, Batch 3/4: Backward pass...
  Epoch 84, Batch 3/4: Clipping gradients...
  Epoch 84, Batch 3/4: Optimizer step...
  Epoch 84, Batch 3/4: Completed in 0.20s
  Epoch 84, Batch 4/4: Loading data to device...
  Epoch 84, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 84, Batch 4/4: Zeroing gradients...
  Epoch 84, Batch 4/4: Forward pass...
  Epoch 84, Batch 4/4: Calculating loss...
  Epoch 84, Batch 4/4: Backward pass...
  Epoch 84, Batch 4/4: Clipping gradients...
  Epoch 84, Batch 4/4: Optimizer step...
  Epoch 84, Batch 4/4: Completed in 0.03s
Epoch 84: Training phase completed. Average Train Loss: 0.5069
Epoch 84: Starting validation phase...
  Epoch 84, Val Batch 1/1: Loading data...
  Epoch 84, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 84, Val Batch 1/1: Forward pass...
  Epoch 84, Val Batch 1/1: Calculating loss...
Epoch 84: Validation phase completed. Average Val Loss: 0.4686
Epoch 84 Summary ---> Train Loss: 0.5069 / Validation Loss: 0.4686
Epoch 84: Checking early stopping... (Current Best Loss: 0.4702, Epochs No Improve: 0)
  Epoch 84: Validation loss improved (0.4702 --> 0.4686). Saving model.
Epoch 84: Stepping scheduler...
--- Epoch 84 completed in 0.70 seconds ---

--- Starting Epoch 85/1000 ---
Epoch 85: Starting training phase (4 batches)
  Epoch 85, Batch 1/4: Loading data to device...
  Epoch 85, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 85, Batch 1/4: Zeroing gradients...
  Epoch 85, Batch 1/4: Forward pass...
  Epoch 85, Batch 1/4: Calculating loss...
  Epoch 85, Batch 1/4: Backward pass...
  Epoch 85, Batch 1/4: Clipping gradients...
  Epoch 85, Batch 1/4: Optimizer step...
  Epoch 85, Batch 1/4: Completed in 0.20s
  Epoch 85, Batch 2/4: Loading data to device...
  Epoch 85, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 85, Batch 2/4: Zeroing gradients...
  Epoch 85, Batch 2/4: Forward pass...
  Epoch 85, Batch 2/4: Calculating loss...
  Epoch 85, Batch 2/4: Backward pass...
  Epoch 85, Batch 2/4: Clipping gradients...
  Epoch 85, Batch 2/4: Optimizer step...
  Epoch 85, Batch 2/4: Completed in 0.20s
  Epoch 85, Batch 3/4: Loading data to device...
  Epoch 85, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 85, Batch 3/4: Zeroing gradients...
  Epoch 85, Batch 3/4: Forward pass...
  Epoch 85, Batch 3/4: Calculating loss...
  Epoch 85, Batch 3/4: Backward pass...
  Epoch 85, Batch 3/4: Clipping gradients...
  Epoch 85, Batch 3/4: Optimizer step...
  Epoch 85, Batch 3/4: Completed in 0.19s
  Epoch 85, Batch 4/4: Loading data to device...
  Epoch 85, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 85, Batch 4/4: Zeroing gradients...
  Epoch 85, Batch 4/4: Forward pass...
  Epoch 85, Batch 4/4: Calculating loss...
  Epoch 85, Batch 4/4: Backward pass...
  Epoch 85, Batch 4/4: Clipping gradients...
  Epoch 85, Batch 4/4: Optimizer step...
  Epoch 85, Batch 4/4: Completed in 0.03s
Epoch 85: Training phase completed. Average Train Loss: 0.5183
Epoch 85: Starting validation phase...
  Epoch 85, Val Batch 1/1: Loading data...
  Epoch 85, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 85, Val Batch 1/1: Forward pass...
  Epoch 85, Val Batch 1/1: Calculating loss...
Epoch 85: Validation phase completed. Average Val Loss: 0.4679
Epoch 85 Summary ---> Train Loss: 0.5183 / Validation Loss: 0.4679
Epoch 85: Checking early stopping... (Current Best Loss: 0.4686, Epochs No Improve: 0)
  Epoch 85: Validation loss improved (0.4686 --> 0.4679). Saving model.
Epoch 85: Stepping scheduler...
--- Epoch 85 completed in 0.69 seconds ---

--- Starting Epoch 86/1000 ---
Epoch 86: Starting training phase (4 batches)
  Epoch 86, Batch 1/4: Loading data to device...
  Epoch 86, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 86, Batch 1/4: Zeroing gradients...
  Epoch 86, Batch 1/4: Forward pass...
  Epoch 86, Batch 1/4: Calculating loss...
  Epoch 86, Batch 1/4: Backward pass...
  Epoch 86, Batch 1/4: Clipping gradients...
  Epoch 86, Batch 1/4: Optimizer step...
  Epoch 86, Batch 1/4: Completed in 0.19s
  Epoch 86, Batch 2/4: Loading data to device...
  Epoch 86, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 86, Batch 2/4: Zeroing gradients...
  Epoch 86, Batch 2/4: Forward pass...
  Epoch 86, Batch 2/4: Calculating loss...
  Epoch 86, Batch 2/4: Backward pass...
  Epoch 86, Batch 2/4: Clipping gradients...
  Epoch 86, Batch 2/4: Optimizer step...
  Epoch 86, Batch 2/4: Completed in 0.20s
  Epoch 86, Batch 3/4: Loading data to device...
  Epoch 86, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 86, Batch 3/4: Zeroing gradients...
  Epoch 86, Batch 3/4: Forward pass...
  Epoch 86, Batch 3/4: Calculating loss...
  Epoch 86, Batch 3/4: Backward pass...
  Epoch 86, Batch 3/4: Clipping gradients...
  Epoch 86, Batch 3/4: Optimizer step...
  Epoch 86, Batch 3/4: Completed in 0.20s
  Epoch 86, Batch 4/4: Loading data to device...
  Epoch 86, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 86, Batch 4/4: Zeroing gradients...
  Epoch 86, Batch 4/4: Forward pass...
  Epoch 86, Batch 4/4: Calculating loss...
  Epoch 86, Batch 4/4: Backward pass...
  Epoch 86, Batch 4/4: Clipping gradients...
  Epoch 86, Batch 4/4: Optimizer step...
  Epoch 86, Batch 4/4: Completed in 0.03s
Epoch 86: Training phase completed. Average Train Loss: 0.5038
Epoch 86: Starting validation phase...
  Epoch 86, Val Batch 1/1: Loading data...
  Epoch 86, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 86, Val Batch 1/1: Forward pass...
  Epoch 86, Val Batch 1/1: Calculating loss...
Epoch 86: Validation phase completed. Average Val Loss: 0.4652
Epoch 86 Summary ---> Train Loss: 0.5038 / Validation Loss: 0.4652
Epoch 86: Checking early stopping... (Current Best Loss: 0.4679, Epochs No Improve: 0)
  Epoch 86: Validation loss improved (0.4679 --> 0.4652). Saving model.
Epoch 86: Stepping scheduler...
--- Epoch 86 completed in 0.70 seconds ---

--- Starting Epoch 87/1000 ---
Epoch 87: Starting training phase (4 batches)
  Epoch 87, Batch 1/4: Loading data to device...
  Epoch 87, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 87, Batch 1/4: Zeroing gradients...
  Epoch 87, Batch 1/4: Forward pass...
  Epoch 87, Batch 1/4: Calculating loss...
  Epoch 87, Batch 1/4: Backward pass...
  Epoch 87, Batch 1/4: Clipping gradients...
  Epoch 87, Batch 1/4: Optimizer step...
  Epoch 87, Batch 1/4: Completed in 0.20s
  Epoch 87, Batch 2/4: Loading data to device...
  Epoch 87, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 87, Batch 2/4: Zeroing gradients...
  Epoch 87, Batch 2/4: Forward pass...
  Epoch 87, Batch 2/4: Calculating loss...
  Epoch 87, Batch 2/4: Backward pass...
  Epoch 87, Batch 2/4: Clipping gradients...
  Epoch 87, Batch 2/4: Optimizer step...
  Epoch 87, Batch 2/4: Completed in 0.20s
  Epoch 87, Batch 3/4: Loading data to device...
  Epoch 87, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 87, Batch 3/4: Zeroing gradients...
  Epoch 87, Batch 3/4: Forward pass...
  Epoch 87, Batch 3/4: Calculating loss...
  Epoch 87, Batch 3/4: Backward pass...
  Epoch 87, Batch 3/4: Clipping gradients...
  Epoch 87, Batch 3/4: Optimizer step...
  Epoch 87, Batch 3/4: Completed in 0.20s
  Epoch 87, Batch 4/4: Loading data to device...
  Epoch 87, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 87, Batch 4/4: Zeroing gradients...
  Epoch 87, Batch 4/4: Forward pass...
  Epoch 87, Batch 4/4: Calculating loss...
  Epoch 87, Batch 4/4: Backward pass...
  Epoch 87, Batch 4/4: Clipping gradients...
  Epoch 87, Batch 4/4: Optimizer step...
  Epoch 87, Batch 4/4: Completed in 0.03s
Epoch 87: Training phase completed. Average Train Loss: 0.5525
Epoch 87: Starting validation phase...
  Epoch 87, Val Batch 1/1: Loading data...
  Epoch 87, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 87, Val Batch 1/1: Forward pass...
  Epoch 87, Val Batch 1/1: Calculating loss...
Epoch 87: Validation phase completed. Average Val Loss: 0.4745
Epoch 87 Summary ---> Train Loss: 0.5525 / Validation Loss: 0.4745
Epoch 87: Checking early stopping... (Current Best Loss: 0.4652, Epochs No Improve: 0)
  Epoch 87: Validation loss did not improve. Epochs without improvement: 1
Epoch 87: Stepping scheduler...
--- Epoch 87 completed in 0.71 seconds ---

--- Starting Epoch 88/1000 ---
Epoch 88: Starting training phase (4 batches)
  Epoch 88, Batch 1/4: Loading data to device...
  Epoch 88, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 88, Batch 1/4: Zeroing gradients...
  Epoch 88, Batch 1/4: Forward pass...
  Epoch 88, Batch 1/4: Calculating loss...
  Epoch 88, Batch 1/4: Backward pass...
  Epoch 88, Batch 1/4: Clipping gradients...
  Epoch 88, Batch 1/4: Optimizer step...
  Epoch 88, Batch 1/4: Completed in 0.20s
  Epoch 88, Batch 2/4: Loading data to device...
  Epoch 88, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 88, Batch 2/4: Zeroing gradients...
  Epoch 88, Batch 2/4: Forward pass...
  Epoch 88, Batch 2/4: Calculating loss...
  Epoch 88, Batch 2/4: Backward pass...
  Epoch 88, Batch 2/4: Clipping gradients...
  Epoch 88, Batch 2/4: Optimizer step...
  Epoch 88, Batch 2/4: Completed in 0.20s
  Epoch 88, Batch 3/4: Loading data to device...
  Epoch 88, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 88, Batch 3/4: Zeroing gradients...
  Epoch 88, Batch 3/4: Forward pass...
  Epoch 88, Batch 3/4: Calculating loss...
  Epoch 88, Batch 3/4: Backward pass...
  Epoch 88, Batch 3/4: Clipping gradients...
  Epoch 88, Batch 3/4: Optimizer step...
  Epoch 88, Batch 3/4: Completed in 0.20s
  Epoch 88, Batch 4/4: Loading data to device...
  Epoch 88, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 88, Batch 4/4: Zeroing gradients...
  Epoch 88, Batch 4/4: Forward pass...
  Epoch 88, Batch 4/4: Calculating loss...
  Epoch 88, Batch 4/4: Backward pass...
  Epoch 88, Batch 4/4: Clipping gradients...
  Epoch 88, Batch 4/4: Optimizer step...
  Epoch 88, Batch 4/4: Completed in 0.03s
Epoch 88: Training phase completed. Average Train Loss: 0.5180
Epoch 88: Starting validation phase...
  Epoch 88, Val Batch 1/1: Loading data...
  Epoch 88, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 88, Val Batch 1/1: Forward pass...
  Epoch 88, Val Batch 1/1: Calculating loss...
Epoch 88: Validation phase completed. Average Val Loss: 0.4809
Epoch 88 Summary ---> Train Loss: 0.5180 / Validation Loss: 0.4809
Epoch 88: Checking early stopping... (Current Best Loss: 0.4652, Epochs No Improve: 1)
  Epoch 88: Validation loss did not improve. Epochs without improvement: 2
Epoch 88: Stepping scheduler...
--- Epoch 88 completed in 0.71 seconds ---

--- Starting Epoch 89/1000 ---
Epoch 89: Starting training phase (4 batches)
  Epoch 89, Batch 1/4: Loading data to device...
  Epoch 89, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 89, Batch 1/4: Zeroing gradients...
  Epoch 89, Batch 1/4: Forward pass...
  Epoch 89, Batch 1/4: Calculating loss...
  Epoch 89, Batch 1/4: Backward pass...
  Epoch 89, Batch 1/4: Clipping gradients...
  Epoch 89, Batch 1/4: Optimizer step...
  Epoch 89, Batch 1/4: Completed in 0.19s
  Epoch 89, Batch 2/4: Loading data to device...
  Epoch 89, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 89, Batch 2/4: Zeroing gradients...
  Epoch 89, Batch 2/4: Forward pass...
  Epoch 89, Batch 2/4: Calculating loss...
  Epoch 89, Batch 2/4: Backward pass...
  Epoch 89, Batch 2/4: Clipping gradients...
  Epoch 89, Batch 2/4: Optimizer step...
  Epoch 89, Batch 2/4: Completed in 0.19s
  Epoch 89, Batch 3/4: Loading data to device...
  Epoch 89, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 89, Batch 3/4: Zeroing gradients...
  Epoch 89, Batch 3/4: Forward pass...
  Epoch 89, Batch 3/4: Calculating loss...
  Epoch 89, Batch 3/4: Backward pass...
  Epoch 89, Batch 3/4: Clipping gradients...
  Epoch 89, Batch 3/4: Optimizer step...
  Epoch 89, Batch 3/4: Completed in 0.19s
  Epoch 89, Batch 4/4: Loading data to device...
  Epoch 89, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 89, Batch 4/4: Zeroing gradients...
  Epoch 89, Batch 4/4: Forward pass...
  Epoch 89, Batch 4/4: Calculating loss...
  Epoch 89, Batch 4/4: Backward pass...
  Epoch 89, Batch 4/4: Clipping gradients...
  Epoch 89, Batch 4/4: Optimizer step...
  Epoch 89, Batch 4/4: Completed in 0.03s
Epoch 89: Training phase completed. Average Train Loss: 0.5053
Epoch 89: Starting validation phase...
  Epoch 89, Val Batch 1/1: Loading data...
  Epoch 89, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 89, Val Batch 1/1: Forward pass...
  Epoch 89, Val Batch 1/1: Calculating loss...
Epoch 89: Validation phase completed. Average Val Loss: 0.4751
Epoch 89 Summary ---> Train Loss: 0.5053 / Validation Loss: 0.4751
Epoch 89: Checking early stopping... (Current Best Loss: 0.4652, Epochs No Improve: 2)
  Epoch 89: Validation loss did not improve. Epochs without improvement: 3
Epoch 89: Stepping scheduler...
--- Epoch 89 completed in 0.68 seconds ---

--- Starting Epoch 90/1000 ---
Epoch 90: Starting training phase (4 batches)
  Epoch 90, Batch 1/4: Loading data to device...
  Epoch 90, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 90, Batch 1/4: Zeroing gradients...
  Epoch 90, Batch 1/4: Forward pass...
  Epoch 90, Batch 1/4: Calculating loss...
  Epoch 90, Batch 1/4: Backward pass...
  Epoch 90, Batch 1/4: Clipping gradients...
  Epoch 90, Batch 1/4: Optimizer step...
  Epoch 90, Batch 1/4: Completed in 0.19s
  Epoch 90, Batch 2/4: Loading data to device...
  Epoch 90, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 90, Batch 2/4: Zeroing gradients...
  Epoch 90, Batch 2/4: Forward pass...
  Epoch 90, Batch 2/4: Calculating loss...
  Epoch 90, Batch 2/4: Backward pass...
  Epoch 90, Batch 2/4: Clipping gradients...
  Epoch 90, Batch 2/4: Optimizer step...
  Epoch 90, Batch 2/4: Completed in 0.19s
  Epoch 90, Batch 3/4: Loading data to device...
  Epoch 90, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 90, Batch 3/4: Zeroing gradients...
  Epoch 90, Batch 3/4: Forward pass...
  Epoch 90, Batch 3/4: Calculating loss...
  Epoch 90, Batch 3/4: Backward pass...
  Epoch 90, Batch 3/4: Clipping gradients...
  Epoch 90, Batch 3/4: Optimizer step...
  Epoch 90, Batch 3/4: Completed in 0.19s
  Epoch 90, Batch 4/4: Loading data to device...
  Epoch 90, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 90, Batch 4/4: Zeroing gradients...
  Epoch 90, Batch 4/4: Forward pass...
  Epoch 90, Batch 4/4: Calculating loss...
  Epoch 90, Batch 4/4: Backward pass...
  Epoch 90, Batch 4/4: Clipping gradients...
  Epoch 90, Batch 4/4: Optimizer step...
  Epoch 90, Batch 4/4: Completed in 0.03s
Epoch 90: Training phase completed. Average Train Loss: 0.5101
Epoch 90: Starting validation phase...
  Epoch 90, Val Batch 1/1: Loading data...
  Epoch 90, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 90, Val Batch 1/1: Forward pass...
  Epoch 90, Val Batch 1/1: Calculating loss...
Epoch 90: Validation phase completed. Average Val Loss: 0.4729
Epoch 90 Summary ---> Train Loss: 0.5101 / Validation Loss: 0.4729
Epoch 90: Checking early stopping... (Current Best Loss: 0.4652, Epochs No Improve: 3)
  Epoch 90: Validation loss did not improve. Epochs without improvement: 4
Epoch 90: Stepping scheduler...
--- Epoch 90 completed in 0.68 seconds ---

--- Starting Epoch 91/1000 ---
Epoch 91: Starting training phase (4 batches)
  Epoch 91, Batch 1/4: Loading data to device...
  Epoch 91, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 91, Batch 1/4: Zeroing gradients...
  Epoch 91, Batch 1/4: Forward pass...
  Epoch 91, Batch 1/4: Calculating loss...
  Epoch 91, Batch 1/4: Backward pass...
  Epoch 91, Batch 1/4: Clipping gradients...
  Epoch 91, Batch 1/4: Optimizer step...
  Epoch 91, Batch 1/4: Completed in 0.20s
  Epoch 91, Batch 2/4: Loading data to device...
  Epoch 91, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 91, Batch 2/4: Zeroing gradients...
  Epoch 91, Batch 2/4: Forward pass...
  Epoch 91, Batch 2/4: Calculating loss...
  Epoch 91, Batch 2/4: Backward pass...
  Epoch 91, Batch 2/4: Clipping gradients...
  Epoch 91, Batch 2/4: Optimizer step...
  Epoch 91, Batch 2/4: Completed in 0.19s
  Epoch 91, Batch 3/4: Loading data to device...
  Epoch 91, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 91, Batch 3/4: Zeroing gradients...
  Epoch 91, Batch 3/4: Forward pass...
  Epoch 91, Batch 3/4: Calculating loss...
  Epoch 91, Batch 3/4: Backward pass...
  Epoch 91, Batch 3/4: Clipping gradients...
  Epoch 91, Batch 3/4: Optimizer step...
  Epoch 91, Batch 3/4: Completed in 0.20s
  Epoch 91, Batch 4/4: Loading data to device...
  Epoch 91, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 91, Batch 4/4: Zeroing gradients...
  Epoch 91, Batch 4/4: Forward pass...
  Epoch 91, Batch 4/4: Calculating loss...
  Epoch 91, Batch 4/4: Backward pass...
  Epoch 91, Batch 4/4: Clipping gradients...
  Epoch 91, Batch 4/4: Optimizer step...
  Epoch 91, Batch 4/4: Completed in 0.03s
Epoch 91: Training phase completed. Average Train Loss: 0.5224
Epoch 91: Starting validation phase...
  Epoch 91, Val Batch 1/1: Loading data...
  Epoch 91, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 91, Val Batch 1/1: Forward pass...
  Epoch 91, Val Batch 1/1: Calculating loss...
Epoch 91: Validation phase completed. Average Val Loss: 0.4704
Epoch 91 Summary ---> Train Loss: 0.5224 / Validation Loss: 0.4704
Epoch 91: Checking early stopping... (Current Best Loss: 0.4652, Epochs No Improve: 4)
  Epoch 91: Validation loss did not improve. Epochs without improvement: 5
Epoch 91: Stepping scheduler...
--- Epoch 91 completed in 0.69 seconds ---

--- Starting Epoch 92/1000 ---
Epoch 92: Starting training phase (4 batches)
  Epoch 92, Batch 1/4: Loading data to device...
  Epoch 92, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 92, Batch 1/4: Zeroing gradients...
  Epoch 92, Batch 1/4: Forward pass...
  Epoch 92, Batch 1/4: Calculating loss...
  Epoch 92, Batch 1/4: Backward pass...
  Epoch 92, Batch 1/4: Clipping gradients...
  Epoch 92, Batch 1/4: Optimizer step...
  Epoch 92, Batch 1/4: Completed in 0.20s
  Epoch 92, Batch 2/4: Loading data to device...
  Epoch 92, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 92, Batch 2/4: Zeroing gradients...
  Epoch 92, Batch 2/4: Forward pass...
  Epoch 92, Batch 2/4: Calculating loss...
  Epoch 92, Batch 2/4: Backward pass...
  Epoch 92, Batch 2/4: Clipping gradients...
  Epoch 92, Batch 2/4: Optimizer step...
  Epoch 92, Batch 2/4: Completed in 0.20s
  Epoch 92, Batch 3/4: Loading data to device...
  Epoch 92, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 92, Batch 3/4: Zeroing gradients...
  Epoch 92, Batch 3/4: Forward pass...
  Epoch 92, Batch 3/4: Calculating loss...
  Epoch 92, Batch 3/4: Backward pass...
  Epoch 92, Batch 3/4: Clipping gradients...
  Epoch 92, Batch 3/4: Optimizer step...
  Epoch 92, Batch 3/4: Completed in 0.20s
  Epoch 92, Batch 4/4: Loading data to device...
  Epoch 92, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 92, Batch 4/4: Zeroing gradients...
  Epoch 92, Batch 4/4: Forward pass...
  Epoch 92, Batch 4/4: Calculating loss...
  Epoch 92, Batch 4/4: Backward pass...
  Epoch 92, Batch 4/4: Clipping gradients...
  Epoch 92, Batch 4/4: Optimizer step...
  Epoch 92, Batch 4/4: Completed in 0.03s
Epoch 92: Training phase completed. Average Train Loss: 0.5204
Epoch 92: Starting validation phase...
  Epoch 92, Val Batch 1/1: Loading data...
  Epoch 92, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 92, Val Batch 1/1: Forward pass...
  Epoch 92, Val Batch 1/1: Calculating loss...
Epoch 92: Validation phase completed. Average Val Loss: 0.4696
Epoch 92 Summary ---> Train Loss: 0.5204 / Validation Loss: 0.4696
Epoch 92: Checking early stopping... (Current Best Loss: 0.4652, Epochs No Improve: 5)
  Epoch 92: Validation loss did not improve. Epochs without improvement: 6
Epoch 92: Stepping scheduler...
--- Epoch 92 completed in 0.70 seconds ---

--- Starting Epoch 93/1000 ---
Epoch 93: Starting training phase (4 batches)
  Epoch 93, Batch 1/4: Loading data to device...
  Epoch 93, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 93, Batch 1/4: Zeroing gradients...
  Epoch 93, Batch 1/4: Forward pass...
  Epoch 93, Batch 1/4: Calculating loss...
  Epoch 93, Batch 1/4: Backward pass...
  Epoch 93, Batch 1/4: Clipping gradients...
  Epoch 93, Batch 1/4: Optimizer step...
  Epoch 93, Batch 1/4: Completed in 0.19s
  Epoch 93, Batch 2/4: Loading data to device...
  Epoch 93, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 93, Batch 2/4: Zeroing gradients...
  Epoch 93, Batch 2/4: Forward pass...
  Epoch 93, Batch 2/4: Calculating loss...
  Epoch 93, Batch 2/4: Backward pass...
  Epoch 93, Batch 2/4: Clipping gradients...
  Epoch 93, Batch 2/4: Optimizer step...
  Epoch 93, Batch 2/4: Completed in 0.19s
  Epoch 93, Batch 3/4: Loading data to device...
  Epoch 93, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 93, Batch 3/4: Zeroing gradients...
  Epoch 93, Batch 3/4: Forward pass...
  Epoch 93, Batch 3/4: Calculating loss...
  Epoch 93, Batch 3/4: Backward pass...
  Epoch 93, Batch 3/4: Clipping gradients...
  Epoch 93, Batch 3/4: Optimizer step...
  Epoch 93, Batch 3/4: Completed in 0.19s
  Epoch 93, Batch 4/4: Loading data to device...
  Epoch 93, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 93, Batch 4/4: Zeroing gradients...
  Epoch 93, Batch 4/4: Forward pass...
  Epoch 93, Batch 4/4: Calculating loss...
  Epoch 93, Batch 4/4: Backward pass...
  Epoch 93, Batch 4/4: Clipping gradients...
  Epoch 93, Batch 4/4: Optimizer step...
  Epoch 93, Batch 4/4: Completed in 0.03s
Epoch 93: Training phase completed. Average Train Loss: 0.4688
Epoch 93: Starting validation phase...
  Epoch 93, Val Batch 1/1: Loading data...
  Epoch 93, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 93, Val Batch 1/1: Forward pass...
  Epoch 93, Val Batch 1/1: Calculating loss...
Epoch 93: Validation phase completed. Average Val Loss: 0.4612
Epoch 93 Summary ---> Train Loss: 0.4688 / Validation Loss: 0.4612
Epoch 93: Checking early stopping... (Current Best Loss: 0.4652, Epochs No Improve: 6)
  Epoch 93: Validation loss improved (0.4652 --> 0.4612). Saving model.
Epoch 93: Stepping scheduler...
--- Epoch 93 completed in 0.69 seconds ---

--- Starting Epoch 94/1000 ---
Epoch 94: Starting training phase (4 batches)
  Epoch 94, Batch 1/4: Loading data to device...
  Epoch 94, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 94, Batch 1/4: Zeroing gradients...
  Epoch 94, Batch 1/4: Forward pass...
  Epoch 94, Batch 1/4: Calculating loss...
  Epoch 94, Batch 1/4: Backward pass...
  Epoch 94, Batch 1/4: Clipping gradients...
  Epoch 94, Batch 1/4: Optimizer step...
  Epoch 94, Batch 1/4: Completed in 0.20s
  Epoch 94, Batch 2/4: Loading data to device...
  Epoch 94, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 94, Batch 2/4: Zeroing gradients...
  Epoch 94, Batch 2/4: Forward pass...
  Epoch 94, Batch 2/4: Calculating loss...
  Epoch 94, Batch 2/4: Backward pass...
  Epoch 94, Batch 2/4: Clipping gradients...
  Epoch 94, Batch 2/4: Optimizer step...
  Epoch 94, Batch 2/4: Completed in 0.20s
  Epoch 94, Batch 3/4: Loading data to device...
  Epoch 94, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 94, Batch 3/4: Zeroing gradients...
  Epoch 94, Batch 3/4: Forward pass...
  Epoch 94, Batch 3/4: Calculating loss...
  Epoch 94, Batch 3/4: Backward pass...
  Epoch 94, Batch 3/4: Clipping gradients...
  Epoch 94, Batch 3/4: Optimizer step...
  Epoch 94, Batch 3/4: Completed in 0.20s
  Epoch 94, Batch 4/4: Loading data to device...
  Epoch 94, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 94, Batch 4/4: Zeroing gradients...
  Epoch 94, Batch 4/4: Forward pass...
  Epoch 94, Batch 4/4: Calculating loss...
  Epoch 94, Batch 4/4: Backward pass...
  Epoch 94, Batch 4/4: Clipping gradients...
  Epoch 94, Batch 4/4: Optimizer step...
  Epoch 94, Batch 4/4: Completed in 0.03s
Epoch 94: Training phase completed. Average Train Loss: 0.4796
Epoch 94: Starting validation phase...
  Epoch 94, Val Batch 1/1: Loading data...
  Epoch 94, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 94, Val Batch 1/1: Forward pass...
  Epoch 94, Val Batch 1/1: Calculating loss...
Epoch 94: Validation phase completed. Average Val Loss: 0.4588
Epoch 94 Summary ---> Train Loss: 0.4796 / Validation Loss: 0.4588
Epoch 94: Checking early stopping... (Current Best Loss: 0.4612, Epochs No Improve: 0)
  Epoch 94: Validation loss improved (0.4612 --> 0.4588). Saving model.
Epoch 94: Stepping scheduler...
--- Epoch 94 completed in 0.70 seconds ---

--- Starting Epoch 95/1000 ---
Epoch 95: Starting training phase (4 batches)
  Epoch 95, Batch 1/4: Loading data to device...
  Epoch 95, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 95, Batch 1/4: Zeroing gradients...
  Epoch 95, Batch 1/4: Forward pass...
  Epoch 95, Batch 1/4: Calculating loss...
  Epoch 95, Batch 1/4: Backward pass...
  Epoch 95, Batch 1/4: Clipping gradients...
  Epoch 95, Batch 1/4: Optimizer step...
  Epoch 95, Batch 1/4: Completed in 0.20s
  Epoch 95, Batch 2/4: Loading data to device...
  Epoch 95, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 95, Batch 2/4: Zeroing gradients...
  Epoch 95, Batch 2/4: Forward pass...
  Epoch 95, Batch 2/4: Calculating loss...
  Epoch 95, Batch 2/4: Backward pass...
  Epoch 95, Batch 2/4: Clipping gradients...
  Epoch 95, Batch 2/4: Optimizer step...
  Epoch 95, Batch 2/4: Completed in 0.19s
  Epoch 95, Batch 3/4: Loading data to device...
  Epoch 95, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 95, Batch 3/4: Zeroing gradients...
  Epoch 95, Batch 3/4: Forward pass...
  Epoch 95, Batch 3/4: Calculating loss...
  Epoch 95, Batch 3/4: Backward pass...
  Epoch 95, Batch 3/4: Clipping gradients...
  Epoch 95, Batch 3/4: Optimizer step...
  Epoch 95, Batch 3/4: Completed in 0.20s
  Epoch 95, Batch 4/4: Loading data to device...
  Epoch 95, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 95, Batch 4/4: Zeroing gradients...
  Epoch 95, Batch 4/4: Forward pass...
  Epoch 95, Batch 4/4: Calculating loss...
  Epoch 95, Batch 4/4: Backward pass...
  Epoch 95, Batch 4/4: Clipping gradients...
  Epoch 95, Batch 4/4: Optimizer step...
  Epoch 95, Batch 4/4: Completed in 0.03s
Epoch 95: Training phase completed. Average Train Loss: 0.5823
Epoch 95: Starting validation phase...
  Epoch 95, Val Batch 1/1: Loading data...
  Epoch 95, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 95, Val Batch 1/1: Forward pass...
  Epoch 95, Val Batch 1/1: Calculating loss...
Epoch 95: Validation phase completed. Average Val Loss: 0.4529
Epoch 95 Summary ---> Train Loss: 0.5823 / Validation Loss: 0.4529
Epoch 95: Checking early stopping... (Current Best Loss: 0.4588, Epochs No Improve: 0)
  Epoch 95: Validation loss improved (0.4588 --> 0.4529). Saving model.
Epoch 95: Stepping scheduler...
--- Epoch 95 completed in 0.69 seconds ---

--- Starting Epoch 96/1000 ---
Epoch 96: Starting training phase (4 batches)
  Epoch 96, Batch 1/4: Loading data to device...
  Epoch 96, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 96, Batch 1/4: Zeroing gradients...
  Epoch 96, Batch 1/4: Forward pass...
  Epoch 96, Batch 1/4: Calculating loss...
  Epoch 96, Batch 1/4: Backward pass...
  Epoch 96, Batch 1/4: Clipping gradients...
  Epoch 96, Batch 1/4: Optimizer step...
  Epoch 96, Batch 1/4: Completed in 0.19s
  Epoch 96, Batch 2/4: Loading data to device...
  Epoch 96, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 96, Batch 2/4: Zeroing gradients...
  Epoch 96, Batch 2/4: Forward pass...
  Epoch 96, Batch 2/4: Calculating loss...
  Epoch 96, Batch 2/4: Backward pass...
  Epoch 96, Batch 2/4: Clipping gradients...
  Epoch 96, Batch 2/4: Optimizer step...
  Epoch 96, Batch 2/4: Completed in 0.19s
  Epoch 96, Batch 3/4: Loading data to device...
  Epoch 96, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 96, Batch 3/4: Zeroing gradients...
  Epoch 96, Batch 3/4: Forward pass...
  Epoch 96, Batch 3/4: Calculating loss...
  Epoch 96, Batch 3/4: Backward pass...
  Epoch 96, Batch 3/4: Clipping gradients...
  Epoch 96, Batch 3/4: Optimizer step...
  Epoch 96, Batch 3/4: Completed in 0.19s
  Epoch 96, Batch 4/4: Loading data to device...
  Epoch 96, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 96, Batch 4/4: Zeroing gradients...
  Epoch 96, Batch 4/4: Forward pass...
  Epoch 96, Batch 4/4: Calculating loss...
  Epoch 96, Batch 4/4: Backward pass...
  Epoch 96, Batch 4/4: Clipping gradients...
  Epoch 96, Batch 4/4: Optimizer step...
  Epoch 96, Batch 4/4: Completed in 0.03s
Epoch 96: Training phase completed. Average Train Loss: 0.5047
Epoch 96: Starting validation phase...
  Epoch 96, Val Batch 1/1: Loading data...
  Epoch 96, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 96, Val Batch 1/1: Forward pass...
  Epoch 96, Val Batch 1/1: Calculating loss...
Epoch 96: Validation phase completed. Average Val Loss: 0.4498
Epoch 96 Summary ---> Train Loss: 0.5047 / Validation Loss: 0.4498
Epoch 96: Checking early stopping... (Current Best Loss: 0.4529, Epochs No Improve: 0)
  Epoch 96: Validation loss improved (0.4529 --> 0.4498). Saving model.
Epoch 96: Stepping scheduler...
--- Epoch 96 completed in 0.68 seconds ---

--- Starting Epoch 97/1000 ---
Epoch 97: Starting training phase (4 batches)
  Epoch 97, Batch 1/4: Loading data to device...
  Epoch 97, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 97, Batch 1/4: Zeroing gradients...
  Epoch 97, Batch 1/4: Forward pass...
  Epoch 97, Batch 1/4: Calculating loss...
  Epoch 97, Batch 1/4: Backward pass...
  Epoch 97, Batch 1/4: Clipping gradients...
  Epoch 97, Batch 1/4: Optimizer step...
  Epoch 97, Batch 1/4: Completed in 0.20s
  Epoch 97, Batch 2/4: Loading data to device...
  Epoch 97, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 97, Batch 2/4: Zeroing gradients...
  Epoch 97, Batch 2/4: Forward pass...
  Epoch 97, Batch 2/4: Calculating loss...
  Epoch 97, Batch 2/4: Backward pass...
  Epoch 97, Batch 2/4: Clipping gradients...
  Epoch 97, Batch 2/4: Optimizer step...
  Epoch 97, Batch 2/4: Completed in 0.19s
  Epoch 97, Batch 3/4: Loading data to device...
  Epoch 97, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 97, Batch 3/4: Zeroing gradients...
  Epoch 97, Batch 3/4: Forward pass...
  Epoch 97, Batch 3/4: Calculating loss...
  Epoch 97, Batch 3/4: Backward pass...
  Epoch 97, Batch 3/4: Clipping gradients...
  Epoch 97, Batch 3/4: Optimizer step...
  Epoch 97, Batch 3/4: Completed in 0.19s
  Epoch 97, Batch 4/4: Loading data to device...
  Epoch 97, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 97, Batch 4/4: Zeroing gradients...
  Epoch 97, Batch 4/4: Forward pass...
  Epoch 97, Batch 4/4: Calculating loss...
  Epoch 97, Batch 4/4: Backward pass...
  Epoch 97, Batch 4/4: Clipping gradients...
  Epoch 97, Batch 4/4: Optimizer step...
  Epoch 97, Batch 4/4: Completed in 0.03s
Epoch 97: Training phase completed. Average Train Loss: 0.5406
Epoch 97: Starting validation phase...
  Epoch 97, Val Batch 1/1: Loading data...
  Epoch 97, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 97, Val Batch 1/1: Forward pass...
  Epoch 97, Val Batch 1/1: Calculating loss...
Epoch 97: Validation phase completed. Average Val Loss: 0.4492
Epoch 97 Summary ---> Train Loss: 0.5406 / Validation Loss: 0.4492
Epoch 97: Checking early stopping... (Current Best Loss: 0.4498, Epochs No Improve: 0)
  Epoch 97: Validation loss improved (0.4498 --> 0.4492). Saving model.
Epoch 97: Stepping scheduler...
--- Epoch 97 completed in 0.69 seconds ---

--- Starting Epoch 98/1000 ---
Epoch 98: Starting training phase (4 batches)
  Epoch 98, Batch 1/4: Loading data to device...
  Epoch 98, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 98, Batch 1/4: Zeroing gradients...
  Epoch 98, Batch 1/4: Forward pass...
  Epoch 98, Batch 1/4: Calculating loss...
  Epoch 98, Batch 1/4: Backward pass...
  Epoch 98, Batch 1/4: Clipping gradients...
  Epoch 98, Batch 1/4: Optimizer step...
  Epoch 98, Batch 1/4: Completed in 0.20s
  Epoch 98, Batch 2/4: Loading data to device...
  Epoch 98, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 98, Batch 2/4: Zeroing gradients...
  Epoch 98, Batch 2/4: Forward pass...
  Epoch 98, Batch 2/4: Calculating loss...
  Epoch 98, Batch 2/4: Backward pass...
  Epoch 98, Batch 2/4: Clipping gradients...
  Epoch 98, Batch 2/4: Optimizer step...
  Epoch 98, Batch 2/4: Completed in 0.19s
  Epoch 98, Batch 3/4: Loading data to device...
  Epoch 98, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 98, Batch 3/4: Zeroing gradients...
  Epoch 98, Batch 3/4: Forward pass...
  Epoch 98, Batch 3/4: Calculating loss...
  Epoch 98, Batch 3/4: Backward pass...
  Epoch 98, Batch 3/4: Clipping gradients...
  Epoch 98, Batch 3/4: Optimizer step...
  Epoch 98, Batch 3/4: Completed in 0.20s
  Epoch 98, Batch 4/4: Loading data to device...
  Epoch 98, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 98, Batch 4/4: Zeroing gradients...
  Epoch 98, Batch 4/4: Forward pass...
  Epoch 98, Batch 4/4: Calculating loss...
  Epoch 98, Batch 4/4: Backward pass...
  Epoch 98, Batch 4/4: Clipping gradients...
  Epoch 98, Batch 4/4: Optimizer step...
  Epoch 98, Batch 4/4: Completed in 0.03s
Epoch 98: Training phase completed. Average Train Loss: 0.5095
Epoch 98: Starting validation phase...
  Epoch 98, Val Batch 1/1: Loading data...
  Epoch 98, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 98, Val Batch 1/1: Forward pass...
  Epoch 98, Val Batch 1/1: Calculating loss...
Epoch 98: Validation phase completed. Average Val Loss: 0.4556
Epoch 98 Summary ---> Train Loss: 0.5095 / Validation Loss: 0.4556
Epoch 98: Checking early stopping... (Current Best Loss: 0.4492, Epochs No Improve: 0)
  Epoch 98: Validation loss did not improve. Epochs without improvement: 1
Epoch 98: Stepping scheduler...
--- Epoch 98 completed in 0.69 seconds ---

--- Starting Epoch 99/1000 ---
Epoch 99: Starting training phase (4 batches)
  Epoch 99, Batch 1/4: Loading data to device...
  Epoch 99, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 99, Batch 1/4: Zeroing gradients...
  Epoch 99, Batch 1/4: Forward pass...
  Epoch 99, Batch 1/4: Calculating loss...
  Epoch 99, Batch 1/4: Backward pass...
  Epoch 99, Batch 1/4: Clipping gradients...
  Epoch 99, Batch 1/4: Optimizer step...
  Epoch 99, Batch 1/4: Completed in 0.19s
  Epoch 99, Batch 2/4: Loading data to device...
  Epoch 99, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 99, Batch 2/4: Zeroing gradients...
  Epoch 99, Batch 2/4: Forward pass...
  Epoch 99, Batch 2/4: Calculating loss...
  Epoch 99, Batch 2/4: Backward pass...
  Epoch 99, Batch 2/4: Clipping gradients...
  Epoch 99, Batch 2/4: Optimizer step...
  Epoch 99, Batch 2/4: Completed in 0.19s
  Epoch 99, Batch 3/4: Loading data to device...
  Epoch 99, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 99, Batch 3/4: Zeroing gradients...
  Epoch 99, Batch 3/4: Forward pass...
  Epoch 99, Batch 3/4: Calculating loss...
  Epoch 99, Batch 3/4: Backward pass...
  Epoch 99, Batch 3/4: Clipping gradients...
  Epoch 99, Batch 3/4: Optimizer step...
  Epoch 99, Batch 3/4: Completed in 0.19s
  Epoch 99, Batch 4/4: Loading data to device...
  Epoch 99, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 99, Batch 4/4: Zeroing gradients...
  Epoch 99, Batch 4/4: Forward pass...
  Epoch 99, Batch 4/4: Calculating loss...
  Epoch 99, Batch 4/4: Backward pass...
  Epoch 99, Batch 4/4: Clipping gradients...
  Epoch 99, Batch 4/4: Optimizer step...
  Epoch 99, Batch 4/4: Completed in 0.03s
Epoch 99: Training phase completed. Average Train Loss: 0.4727
Epoch 99: Starting validation phase...
  Epoch 99, Val Batch 1/1: Loading data...
  Epoch 99, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 99, Val Batch 1/1: Forward pass...
  Epoch 99, Val Batch 1/1: Calculating loss...
Epoch 99: Validation phase completed. Average Val Loss: 0.4552
Epoch 99 Summary ---> Train Loss: 0.4727 / Validation Loss: 0.4552
Epoch 99: Checking early stopping... (Current Best Loss: 0.4492, Epochs No Improve: 1)
  Epoch 99: Validation loss did not improve. Epochs without improvement: 2
Epoch 99: Stepping scheduler...
--- Epoch 99 completed in 0.68 seconds ---

--- Starting Epoch 100/1000 ---
Epoch 100: Starting training phase (4 batches)
  Epoch 100, Batch 1/4: Loading data to device...
  Epoch 100, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 100, Batch 1/4: Zeroing gradients...
  Epoch 100, Batch 1/4: Forward pass...
  Epoch 100, Batch 1/4: Calculating loss...
  Epoch 100, Batch 1/4: Backward pass...
  Epoch 100, Batch 1/4: Clipping gradients...
  Epoch 100, Batch 1/4: Optimizer step...
  Epoch 100, Batch 1/4: Completed in 0.19s
  Epoch 100, Batch 2/4: Loading data to device...
  Epoch 100, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 100, Batch 2/4: Zeroing gradients...
  Epoch 100, Batch 2/4: Forward pass...
  Epoch 100, Batch 2/4: Calculating loss...
  Epoch 100, Batch 2/4: Backward pass...
  Epoch 100, Batch 2/4: Clipping gradients...
  Epoch 100, Batch 2/4: Optimizer step...
  Epoch 100, Batch 2/4: Completed in 0.19s
  Epoch 100, Batch 3/4: Loading data to device...
  Epoch 100, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 100, Batch 3/4: Zeroing gradients...
  Epoch 100, Batch 3/4: Forward pass...
  Epoch 100, Batch 3/4: Calculating loss...
  Epoch 100, Batch 3/4: Backward pass...
  Epoch 100, Batch 3/4: Clipping gradients...
  Epoch 100, Batch 3/4: Optimizer step...
  Epoch 100, Batch 3/4: Completed in 0.19s
  Epoch 100, Batch 4/4: Loading data to device...
  Epoch 100, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 100, Batch 4/4: Zeroing gradients...
  Epoch 100, Batch 4/4: Forward pass...
  Epoch 100, Batch 4/4: Calculating loss...
  Epoch 100, Batch 4/4: Backward pass...
  Epoch 100, Batch 4/4: Clipping gradients...
  Epoch 100, Batch 4/4: Optimizer step...
  Epoch 100, Batch 4/4: Completed in 0.03s
Epoch 100: Training phase completed. Average Train Loss: 0.4789
Epoch 100: Starting validation phase...
  Epoch 100, Val Batch 1/1: Loading data...
  Epoch 100, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 100, Val Batch 1/1: Forward pass...
  Epoch 100, Val Batch 1/1: Calculating loss...
Epoch 100: Validation phase completed. Average Val Loss: 0.4521
Epoch 100 Summary ---> Train Loss: 0.4789 / Validation Loss: 0.4521
Epoch 100: Checking early stopping... (Current Best Loss: 0.4492, Epochs No Improve: 2)
  Epoch 100: Validation loss did not improve. Epochs without improvement: 3
Epoch 100: Stepping scheduler...
--- Epoch 100 completed in 0.68 seconds ---

--- Starting Epoch 101/1000 ---
Epoch 101: Starting training phase (4 batches)
  Epoch 101, Batch 1/4: Loading data to device...
  Epoch 101, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 101, Batch 1/4: Zeroing gradients...
  Epoch 101, Batch 1/4: Forward pass...
  Epoch 101, Batch 1/4: Calculating loss...
  Epoch 101, Batch 1/4: Backward pass...
  Epoch 101, Batch 1/4: Clipping gradients...
  Epoch 101, Batch 1/4: Optimizer step...
  Epoch 101, Batch 1/4: Completed in 0.19s
  Epoch 101, Batch 2/4: Loading data to device...
  Epoch 101, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 101, Batch 2/4: Zeroing gradients...
  Epoch 101, Batch 2/4: Forward pass...
  Epoch 101, Batch 2/4: Calculating loss...
  Epoch 101, Batch 2/4: Backward pass...
  Epoch 101, Batch 2/4: Clipping gradients...
  Epoch 101, Batch 2/4: Optimizer step...
  Epoch 101, Batch 2/4: Completed in 0.19s
  Epoch 101, Batch 3/4: Loading data to device...
  Epoch 101, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 101, Batch 3/4: Zeroing gradients...
  Epoch 101, Batch 3/4: Forward pass...
  Epoch 101, Batch 3/4: Calculating loss...
  Epoch 101, Batch 3/4: Backward pass...
  Epoch 101, Batch 3/4: Clipping gradients...
  Epoch 101, Batch 3/4: Optimizer step...
  Epoch 101, Batch 3/4: Completed in 0.19s
  Epoch 101, Batch 4/4: Loading data to device...
  Epoch 101, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 101, Batch 4/4: Zeroing gradients...
  Epoch 101, Batch 4/4: Forward pass...
  Epoch 101, Batch 4/4: Calculating loss...
  Epoch 101, Batch 4/4: Backward pass...
  Epoch 101, Batch 4/4: Clipping gradients...
  Epoch 101, Batch 4/4: Optimizer step...
  Epoch 101, Batch 4/4: Completed in 0.03s
Epoch 101: Training phase completed. Average Train Loss: 0.4959
Epoch 101: Starting validation phase...
  Epoch 101, Val Batch 1/1: Loading data...
  Epoch 101, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 101, Val Batch 1/1: Forward pass...
  Epoch 101, Val Batch 1/1: Calculating loss...
Epoch 101: Validation phase completed. Average Val Loss: 0.4593
Epoch 101 Summary ---> Train Loss: 0.4959 / Validation Loss: 0.4593
Epoch 101: Checking early stopping... (Current Best Loss: 0.4492, Epochs No Improve: 3)
  Epoch 101: Validation loss did not improve. Epochs without improvement: 4
Epoch 101: Stepping scheduler...
--- Epoch 101 completed in 0.68 seconds ---

--- Starting Epoch 102/1000 ---
Epoch 102: Starting training phase (4 batches)
  Epoch 102, Batch 1/4: Loading data to device...
  Epoch 102, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 102, Batch 1/4: Zeroing gradients...
  Epoch 102, Batch 1/4: Forward pass...
  Epoch 102, Batch 1/4: Calculating loss...
  Epoch 102, Batch 1/4: Backward pass...
  Epoch 102, Batch 1/4: Clipping gradients...
  Epoch 102, Batch 1/4: Optimizer step...
  Epoch 102, Batch 1/4: Completed in 0.19s
  Epoch 102, Batch 2/4: Loading data to device...
  Epoch 102, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 102, Batch 2/4: Zeroing gradients...
  Epoch 102, Batch 2/4: Forward pass...
  Epoch 102, Batch 2/4: Calculating loss...
  Epoch 102, Batch 2/4: Backward pass...
  Epoch 102, Batch 2/4: Clipping gradients...
  Epoch 102, Batch 2/4: Optimizer step...
  Epoch 102, Batch 2/4: Completed in 0.19s
  Epoch 102, Batch 3/4: Loading data to device...
  Epoch 102, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 102, Batch 3/4: Zeroing gradients...
  Epoch 102, Batch 3/4: Forward pass...
  Epoch 102, Batch 3/4: Calculating loss...
  Epoch 102, Batch 3/4: Backward pass...
  Epoch 102, Batch 3/4: Clipping gradients...
  Epoch 102, Batch 3/4: Optimizer step...
  Epoch 102, Batch 3/4: Completed in 0.19s
  Epoch 102, Batch 4/4: Loading data to device...
  Epoch 102, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 102, Batch 4/4: Zeroing gradients...
  Epoch 102, Batch 4/4: Forward pass...
  Epoch 102, Batch 4/4: Calculating loss...
  Epoch 102, Batch 4/4: Backward pass...
  Epoch 102, Batch 4/4: Clipping gradients...
  Epoch 102, Batch 4/4: Optimizer step...
  Epoch 102, Batch 4/4: Completed in 0.03s
Epoch 102: Training phase completed. Average Train Loss: 0.4781
Epoch 102: Starting validation phase...
  Epoch 102, Val Batch 1/1: Loading data...
  Epoch 102, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 102, Val Batch 1/1: Forward pass...
  Epoch 102, Val Batch 1/1: Calculating loss...
Epoch 102: Validation phase completed. Average Val Loss: 0.4710
Epoch 102 Summary ---> Train Loss: 0.4781 / Validation Loss: 0.4710
Epoch 102: Checking early stopping... (Current Best Loss: 0.4492, Epochs No Improve: 4)
  Epoch 102: Validation loss did not improve. Epochs without improvement: 5
Epoch 102: Stepping scheduler...
--- Epoch 102 completed in 0.68 seconds ---

--- Starting Epoch 103/1000 ---
Epoch 103: Starting training phase (4 batches)
  Epoch 103, Batch 1/4: Loading data to device...
  Epoch 103, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 103, Batch 1/4: Zeroing gradients...
  Epoch 103, Batch 1/4: Forward pass...
  Epoch 103, Batch 1/4: Calculating loss...
  Epoch 103, Batch 1/4: Backward pass...
  Epoch 103, Batch 1/4: Clipping gradients...
  Epoch 103, Batch 1/4: Optimizer step...
  Epoch 103, Batch 1/4: Completed in 0.19s
  Epoch 103, Batch 2/4: Loading data to device...
  Epoch 103, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 103, Batch 2/4: Zeroing gradients...
  Epoch 103, Batch 2/4: Forward pass...
  Epoch 103, Batch 2/4: Calculating loss...
  Epoch 103, Batch 2/4: Backward pass...
  Epoch 103, Batch 2/4: Clipping gradients...
  Epoch 103, Batch 2/4: Optimizer step...
  Epoch 103, Batch 2/4: Completed in 0.19s
  Epoch 103, Batch 3/4: Loading data to device...
  Epoch 103, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 103, Batch 3/4: Zeroing gradients...
  Epoch 103, Batch 3/4: Forward pass...
  Epoch 103, Batch 3/4: Calculating loss...
  Epoch 103, Batch 3/4: Backward pass...
  Epoch 103, Batch 3/4: Clipping gradients...
  Epoch 103, Batch 3/4: Optimizer step...
  Epoch 103, Batch 3/4: Completed in 0.19s
  Epoch 103, Batch 4/4: Loading data to device...
  Epoch 103, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 103, Batch 4/4: Zeroing gradients...
  Epoch 103, Batch 4/4: Forward pass...
  Epoch 103, Batch 4/4: Calculating loss...
  Epoch 103, Batch 4/4: Backward pass...
  Epoch 103, Batch 4/4: Clipping gradients...
  Epoch 103, Batch 4/4: Optimizer step...
  Epoch 103, Batch 4/4: Completed in 0.03s
Epoch 103: Training phase completed. Average Train Loss: 0.4507
Epoch 103: Starting validation phase...
  Epoch 103, Val Batch 1/1: Loading data...
  Epoch 103, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 103, Val Batch 1/1: Forward pass...
  Epoch 103, Val Batch 1/1: Calculating loss...
Epoch 103: Validation phase completed. Average Val Loss: 0.4586
Epoch 103 Summary ---> Train Loss: 0.4507 / Validation Loss: 0.4586
Epoch 103: Checking early stopping... (Current Best Loss: 0.4492, Epochs No Improve: 5)
  Epoch 103: Validation loss did not improve. Epochs without improvement: 6
Epoch 103: Stepping scheduler...
--- Epoch 103 completed in 0.68 seconds ---

--- Starting Epoch 104/1000 ---
Epoch 104: Starting training phase (4 batches)
  Epoch 104, Batch 1/4: Loading data to device...
  Epoch 104, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 104, Batch 1/4: Zeroing gradients...
  Epoch 104, Batch 1/4: Forward pass...
  Epoch 104, Batch 1/4: Calculating loss...
  Epoch 104, Batch 1/4: Backward pass...
  Epoch 104, Batch 1/4: Clipping gradients...
  Epoch 104, Batch 1/4: Optimizer step...
  Epoch 104, Batch 1/4: Completed in 0.19s
  Epoch 104, Batch 2/4: Loading data to device...
  Epoch 104, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 104, Batch 2/4: Zeroing gradients...
  Epoch 104, Batch 2/4: Forward pass...
  Epoch 104, Batch 2/4: Calculating loss...
  Epoch 104, Batch 2/4: Backward pass...
  Epoch 104, Batch 2/4: Clipping gradients...
  Epoch 104, Batch 2/4: Optimizer step...
  Epoch 104, Batch 2/4: Completed in 0.20s
  Epoch 104, Batch 3/4: Loading data to device...
  Epoch 104, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 104, Batch 3/4: Zeroing gradients...
  Epoch 104, Batch 3/4: Forward pass...
  Epoch 104, Batch 3/4: Calculating loss...
  Epoch 104, Batch 3/4: Backward pass...
  Epoch 104, Batch 3/4: Clipping gradients...
  Epoch 104, Batch 3/4: Optimizer step...
  Epoch 104, Batch 3/4: Completed in 0.20s
  Epoch 104, Batch 4/4: Loading data to device...
  Epoch 104, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 104, Batch 4/4: Zeroing gradients...
  Epoch 104, Batch 4/4: Forward pass...
  Epoch 104, Batch 4/4: Calculating loss...
  Epoch 104, Batch 4/4: Backward pass...
  Epoch 104, Batch 4/4: Clipping gradients...
  Epoch 104, Batch 4/4: Optimizer step...
  Epoch 104, Batch 4/4: Completed in 0.03s
Epoch 104: Training phase completed. Average Train Loss: 0.4867
Epoch 104: Starting validation phase...
  Epoch 104, Val Batch 1/1: Loading data...
  Epoch 104, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 104, Val Batch 1/1: Forward pass...
  Epoch 104, Val Batch 1/1: Calculating loss...
Epoch 104: Validation phase completed. Average Val Loss: 0.4450
Epoch 104 Summary ---> Train Loss: 0.4867 / Validation Loss: 0.4450
Epoch 104: Checking early stopping... (Current Best Loss: 0.4492, Epochs No Improve: 6)
  Epoch 104: Validation loss improved (0.4492 --> 0.4450). Saving model.
Epoch 104: Stepping scheduler...
--- Epoch 104 completed in 0.70 seconds ---

--- Starting Epoch 105/1000 ---
Epoch 105: Starting training phase (4 batches)
  Epoch 105, Batch 1/4: Loading data to device...
  Epoch 105, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 105, Batch 1/4: Zeroing gradients...
  Epoch 105, Batch 1/4: Forward pass...
  Epoch 105, Batch 1/4: Calculating loss...
  Epoch 105, Batch 1/4: Backward pass...
  Epoch 105, Batch 1/4: Clipping gradients...
  Epoch 105, Batch 1/4: Optimizer step...
  Epoch 105, Batch 1/4: Completed in 0.20s
  Epoch 105, Batch 2/4: Loading data to device...
  Epoch 105, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 105, Batch 2/4: Zeroing gradients...
  Epoch 105, Batch 2/4: Forward pass...
  Epoch 105, Batch 2/4: Calculating loss...
  Epoch 105, Batch 2/4: Backward pass...
  Epoch 105, Batch 2/4: Clipping gradients...
  Epoch 105, Batch 2/4: Optimizer step...
  Epoch 105, Batch 2/4: Completed in 0.19s
  Epoch 105, Batch 3/4: Loading data to device...
  Epoch 105, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 105, Batch 3/4: Zeroing gradients...
  Epoch 105, Batch 3/4: Forward pass...
  Epoch 105, Batch 3/4: Calculating loss...
  Epoch 105, Batch 3/4: Backward pass...
  Epoch 105, Batch 3/4: Clipping gradients...
  Epoch 105, Batch 3/4: Optimizer step...
  Epoch 105, Batch 3/4: Completed in 0.19s
  Epoch 105, Batch 4/4: Loading data to device...
  Epoch 105, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 105, Batch 4/4: Zeroing gradients...
  Epoch 105, Batch 4/4: Forward pass...
  Epoch 105, Batch 4/4: Calculating loss...
  Epoch 105, Batch 4/4: Backward pass...
  Epoch 105, Batch 4/4: Clipping gradients...
  Epoch 105, Batch 4/4: Optimizer step...
  Epoch 105, Batch 4/4: Completed in 0.04s
Epoch 105: Training phase completed. Average Train Loss: 0.5105
Epoch 105: Starting validation phase...
  Epoch 105, Val Batch 1/1: Loading data...
  Epoch 105, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 105, Val Batch 1/1: Forward pass...
  Epoch 105, Val Batch 1/1: Calculating loss...
Epoch 105: Validation phase completed. Average Val Loss: 0.4322
Epoch 105 Summary ---> Train Loss: 0.5105 / Validation Loss: 0.4322
Epoch 105: Checking early stopping... (Current Best Loss: 0.4450, Epochs No Improve: 0)
  Epoch 105: Validation loss improved (0.4450 --> 0.4322). Saving model.
Epoch 105: Stepping scheduler...
--- Epoch 105 completed in 0.69 seconds ---

--- Starting Epoch 106/1000 ---
Epoch 106: Starting training phase (4 batches)
  Epoch 106, Batch 1/4: Loading data to device...
  Epoch 106, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 106, Batch 1/4: Zeroing gradients...
  Epoch 106, Batch 1/4: Forward pass...
  Epoch 106, Batch 1/4: Calculating loss...
  Epoch 106, Batch 1/4: Backward pass...
  Epoch 106, Batch 1/4: Clipping gradients...
  Epoch 106, Batch 1/4: Optimizer step...
  Epoch 106, Batch 1/4: Completed in 0.19s
  Epoch 106, Batch 2/4: Loading data to device...
  Epoch 106, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 106, Batch 2/4: Zeroing gradients...
  Epoch 106, Batch 2/4: Forward pass...
  Epoch 106, Batch 2/4: Calculating loss...
  Epoch 106, Batch 2/4: Backward pass...
  Epoch 106, Batch 2/4: Clipping gradients...
  Epoch 106, Batch 2/4: Optimizer step...
  Epoch 106, Batch 2/4: Completed in 0.19s
  Epoch 106, Batch 3/4: Loading data to device...
  Epoch 106, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 106, Batch 3/4: Zeroing gradients...
  Epoch 106, Batch 3/4: Forward pass...
  Epoch 106, Batch 3/4: Calculating loss...
  Epoch 106, Batch 3/4: Backward pass...
  Epoch 106, Batch 3/4: Clipping gradients...
  Epoch 106, Batch 3/4: Optimizer step...
  Epoch 106, Batch 3/4: Completed in 0.19s
  Epoch 106, Batch 4/4: Loading data to device...
  Epoch 106, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 106, Batch 4/4: Zeroing gradients...
  Epoch 106, Batch 4/4: Forward pass...
  Epoch 106, Batch 4/4: Calculating loss...
  Epoch 106, Batch 4/4: Backward pass...
  Epoch 106, Batch 4/4: Clipping gradients...
  Epoch 106, Batch 4/4: Optimizer step...
  Epoch 106, Batch 4/4: Completed in 0.03s
Epoch 106: Training phase completed. Average Train Loss: 0.4908
Epoch 106: Starting validation phase...
  Epoch 106, Val Batch 1/1: Loading data...
  Epoch 106, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 106, Val Batch 1/1: Forward pass...
  Epoch 106, Val Batch 1/1: Calculating loss...
Epoch 106: Validation phase completed. Average Val Loss: 0.4372
Epoch 106 Summary ---> Train Loss: 0.4908 / Validation Loss: 0.4372
Epoch 106: Checking early stopping... (Current Best Loss: 0.4322, Epochs No Improve: 0)
  Epoch 106: Validation loss did not improve. Epochs without improvement: 1
Epoch 106: Stepping scheduler...
--- Epoch 106 completed in 0.67 seconds ---

--- Starting Epoch 107/1000 ---
Epoch 107: Starting training phase (4 batches)
  Epoch 107, Batch 1/4: Loading data to device...
  Epoch 107, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 107, Batch 1/4: Zeroing gradients...
  Epoch 107, Batch 1/4: Forward pass...
  Epoch 107, Batch 1/4: Calculating loss...
  Epoch 107, Batch 1/4: Backward pass...
  Epoch 107, Batch 1/4: Clipping gradients...
  Epoch 107, Batch 1/4: Optimizer step...
  Epoch 107, Batch 1/4: Completed in 0.19s
  Epoch 107, Batch 2/4: Loading data to device...
  Epoch 107, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 107, Batch 2/4: Zeroing gradients...
  Epoch 107, Batch 2/4: Forward pass...
  Epoch 107, Batch 2/4: Calculating loss...
  Epoch 107, Batch 2/4: Backward pass...
  Epoch 107, Batch 2/4: Clipping gradients...
  Epoch 107, Batch 2/4: Optimizer step...
  Epoch 107, Batch 2/4: Completed in 0.19s
  Epoch 107, Batch 3/4: Loading data to device...
  Epoch 107, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 107, Batch 3/4: Zeroing gradients...
  Epoch 107, Batch 3/4: Forward pass...
  Epoch 107, Batch 3/4: Calculating loss...
  Epoch 107, Batch 3/4: Backward pass...
  Epoch 107, Batch 3/4: Clipping gradients...
  Epoch 107, Batch 3/4: Optimizer step...
  Epoch 107, Batch 3/4: Completed in 0.19s
  Epoch 107, Batch 4/4: Loading data to device...
  Epoch 107, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 107, Batch 4/4: Zeroing gradients...
  Epoch 107, Batch 4/4: Forward pass...
  Epoch 107, Batch 4/4: Calculating loss...
  Epoch 107, Batch 4/4: Backward pass...
  Epoch 107, Batch 4/4: Clipping gradients...
  Epoch 107, Batch 4/4: Optimizer step...
  Epoch 107, Batch 4/4: Completed in 0.03s
Epoch 107: Training phase completed. Average Train Loss: 0.4772
Epoch 107: Starting validation phase...
  Epoch 107, Val Batch 1/1: Loading data...
  Epoch 107, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 107, Val Batch 1/1: Forward pass...
  Epoch 107, Val Batch 1/1: Calculating loss...
Epoch 107: Validation phase completed. Average Val Loss: 0.4417
Epoch 107 Summary ---> Train Loss: 0.4772 / Validation Loss: 0.4417
Epoch 107: Checking early stopping... (Current Best Loss: 0.4322, Epochs No Improve: 1)
  Epoch 107: Validation loss did not improve. Epochs without improvement: 2
Epoch 107: Stepping scheduler...
--- Epoch 107 completed in 0.67 seconds ---

--- Starting Epoch 108/1000 ---
Epoch 108: Starting training phase (4 batches)
  Epoch 108, Batch 1/4: Loading data to device...
  Epoch 108, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 108, Batch 1/4: Zeroing gradients...
  Epoch 108, Batch 1/4: Forward pass...
  Epoch 108, Batch 1/4: Calculating loss...
  Epoch 108, Batch 1/4: Backward pass...
  Epoch 108, Batch 1/4: Clipping gradients...
  Epoch 108, Batch 1/4: Optimizer step...
  Epoch 108, Batch 1/4: Completed in 0.20s
  Epoch 108, Batch 2/4: Loading data to device...
  Epoch 108, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 108, Batch 2/4: Zeroing gradients...
  Epoch 108, Batch 2/4: Forward pass...
  Epoch 108, Batch 2/4: Calculating loss...
  Epoch 108, Batch 2/4: Backward pass...
  Epoch 108, Batch 2/4: Clipping gradients...
  Epoch 108, Batch 2/4: Optimizer step...
  Epoch 108, Batch 2/4: Completed in 0.19s
  Epoch 108, Batch 3/4: Loading data to device...
  Epoch 108, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 108, Batch 3/4: Zeroing gradients...
  Epoch 108, Batch 3/4: Forward pass...
  Epoch 108, Batch 3/4: Calculating loss...
  Epoch 108, Batch 3/4: Backward pass...
  Epoch 108, Batch 3/4: Clipping gradients...
  Epoch 108, Batch 3/4: Optimizer step...
  Epoch 108, Batch 3/4: Completed in 0.19s
  Epoch 108, Batch 4/4: Loading data to device...
  Epoch 108, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 108, Batch 4/4: Zeroing gradients...
  Epoch 108, Batch 4/4: Forward pass...
  Epoch 108, Batch 4/4: Calculating loss...
  Epoch 108, Batch 4/4: Backward pass...
  Epoch 108, Batch 4/4: Clipping gradients...
  Epoch 108, Batch 4/4: Optimizer step...
  Epoch 108, Batch 4/4: Completed in 0.04s
Epoch 108: Training phase completed. Average Train Loss: 0.4284
Epoch 108: Starting validation phase...
  Epoch 108, Val Batch 1/1: Loading data...
  Epoch 108, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 108, Val Batch 1/1: Forward pass...
  Epoch 108, Val Batch 1/1: Calculating loss...
Epoch 108: Validation phase completed. Average Val Loss: 0.4405
Epoch 108 Summary ---> Train Loss: 0.4284 / Validation Loss: 0.4405
Epoch 108: Checking early stopping... (Current Best Loss: 0.4322, Epochs No Improve: 2)
  Epoch 108: Validation loss did not improve. Epochs without improvement: 3
Epoch 108: Stepping scheduler...
--- Epoch 108 completed in 0.69 seconds ---

--- Starting Epoch 109/1000 ---
Epoch 109: Starting training phase (4 batches)
  Epoch 109, Batch 1/4: Loading data to device...
  Epoch 109, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 109, Batch 1/4: Zeroing gradients...
  Epoch 109, Batch 1/4: Forward pass...
  Epoch 109, Batch 1/4: Calculating loss...
  Epoch 109, Batch 1/4: Backward pass...
  Epoch 109, Batch 1/4: Clipping gradients...
  Epoch 109, Batch 1/4: Optimizer step...
  Epoch 109, Batch 1/4: Completed in 0.19s
  Epoch 109, Batch 2/4: Loading data to device...
  Epoch 109, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 109, Batch 2/4: Zeroing gradients...
  Epoch 109, Batch 2/4: Forward pass...
  Epoch 109, Batch 2/4: Calculating loss...
  Epoch 109, Batch 2/4: Backward pass...
  Epoch 109, Batch 2/4: Clipping gradients...
  Epoch 109, Batch 2/4: Optimizer step...
  Epoch 109, Batch 2/4: Completed in 0.19s
  Epoch 109, Batch 3/4: Loading data to device...
  Epoch 109, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 109, Batch 3/4: Zeroing gradients...
  Epoch 109, Batch 3/4: Forward pass...
  Epoch 109, Batch 3/4: Calculating loss...
  Epoch 109, Batch 3/4: Backward pass...
  Epoch 109, Batch 3/4: Clipping gradients...
  Epoch 109, Batch 3/4: Optimizer step...
  Epoch 109, Batch 3/4: Completed in 0.19s
  Epoch 109, Batch 4/4: Loading data to device...
  Epoch 109, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 109, Batch 4/4: Zeroing gradients...
  Epoch 109, Batch 4/4: Forward pass...
  Epoch 109, Batch 4/4: Calculating loss...
  Epoch 109, Batch 4/4: Backward pass...
  Epoch 109, Batch 4/4: Clipping gradients...
  Epoch 109, Batch 4/4: Optimizer step...
  Epoch 109, Batch 4/4: Completed in 0.03s
Epoch 109: Training phase completed. Average Train Loss: 0.4656
Epoch 109: Starting validation phase...
  Epoch 109, Val Batch 1/1: Loading data...
  Epoch 109, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 109, Val Batch 1/1: Forward pass...
  Epoch 109, Val Batch 1/1: Calculating loss...
Epoch 109: Validation phase completed. Average Val Loss: 0.4410
Epoch 109 Summary ---> Train Loss: 0.4656 / Validation Loss: 0.4410
Epoch 109: Checking early stopping... (Current Best Loss: 0.4322, Epochs No Improve: 3)
  Epoch 109: Validation loss did not improve. Epochs without improvement: 4
Epoch 109: Stepping scheduler...
--- Epoch 109 completed in 0.68 seconds ---

--- Starting Epoch 110/1000 ---
Epoch 110: Starting training phase (4 batches)
  Epoch 110, Batch 1/4: Loading data to device...
  Epoch 110, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 110, Batch 1/4: Zeroing gradients...
  Epoch 110, Batch 1/4: Forward pass...
  Epoch 110, Batch 1/4: Calculating loss...
  Epoch 110, Batch 1/4: Backward pass...
  Epoch 110, Batch 1/4: Clipping gradients...
  Epoch 110, Batch 1/4: Optimizer step...
  Epoch 110, Batch 1/4: Completed in 0.19s
  Epoch 110, Batch 2/4: Loading data to device...
  Epoch 110, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 110, Batch 2/4: Zeroing gradients...
  Epoch 110, Batch 2/4: Forward pass...
  Epoch 110, Batch 2/4: Calculating loss...
  Epoch 110, Batch 2/4: Backward pass...
  Epoch 110, Batch 2/4: Clipping gradients...
  Epoch 110, Batch 2/4: Optimizer step...
  Epoch 110, Batch 2/4: Completed in 0.19s
  Epoch 110, Batch 3/4: Loading data to device...
  Epoch 110, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 110, Batch 3/4: Zeroing gradients...
  Epoch 110, Batch 3/4: Forward pass...
  Epoch 110, Batch 3/4: Calculating loss...
  Epoch 110, Batch 3/4: Backward pass...
  Epoch 110, Batch 3/4: Clipping gradients...
  Epoch 110, Batch 3/4: Optimizer step...
  Epoch 110, Batch 3/4: Completed in 0.19s
  Epoch 110, Batch 4/4: Loading data to device...
  Epoch 110, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 110, Batch 4/4: Zeroing gradients...
  Epoch 110, Batch 4/4: Forward pass...
  Epoch 110, Batch 4/4: Calculating loss...
  Epoch 110, Batch 4/4: Backward pass...
  Epoch 110, Batch 4/4: Clipping gradients...
  Epoch 110, Batch 4/4: Optimizer step...
  Epoch 110, Batch 4/4: Completed in 0.04s
Epoch 110: Training phase completed. Average Train Loss: 0.4751
Epoch 110: Starting validation phase...
  Epoch 110, Val Batch 1/1: Loading data...
  Epoch 110, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 110, Val Batch 1/1: Forward pass...
  Epoch 110, Val Batch 1/1: Calculating loss...
Epoch 110: Validation phase completed. Average Val Loss: 0.4344
Epoch 110 Summary ---> Train Loss: 0.4751 / Validation Loss: 0.4344
Epoch 110: Checking early stopping... (Current Best Loss: 0.4322, Epochs No Improve: 4)
  Epoch 110: Validation loss did not improve. Epochs without improvement: 5
Epoch 110: Stepping scheduler...
--- Epoch 110 completed in 0.68 seconds ---

--- Starting Epoch 111/1000 ---
Epoch 111: Starting training phase (4 batches)
  Epoch 111, Batch 1/4: Loading data to device...
  Epoch 111, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 111, Batch 1/4: Zeroing gradients...
  Epoch 111, Batch 1/4: Forward pass...
  Epoch 111, Batch 1/4: Calculating loss...
  Epoch 111, Batch 1/4: Backward pass...
  Epoch 111, Batch 1/4: Clipping gradients...
  Epoch 111, Batch 1/4: Optimizer step...
  Epoch 111, Batch 1/4: Completed in 0.19s
  Epoch 111, Batch 2/4: Loading data to device...
  Epoch 111, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 111, Batch 2/4: Zeroing gradients...
  Epoch 111, Batch 2/4: Forward pass...
  Epoch 111, Batch 2/4: Calculating loss...
  Epoch 111, Batch 2/4: Backward pass...
  Epoch 111, Batch 2/4: Clipping gradients...
  Epoch 111, Batch 2/4: Optimizer step...
  Epoch 111, Batch 2/4: Completed in 0.19s
  Epoch 111, Batch 3/4: Loading data to device...
  Epoch 111, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 111, Batch 3/4: Zeroing gradients...
  Epoch 111, Batch 3/4: Forward pass...
  Epoch 111, Batch 3/4: Calculating loss...
  Epoch 111, Batch 3/4: Backward pass...
  Epoch 111, Batch 3/4: Clipping gradients...
  Epoch 111, Batch 3/4: Optimizer step...
  Epoch 111, Batch 3/4: Completed in 0.19s
  Epoch 111, Batch 4/4: Loading data to device...
  Epoch 111, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 111, Batch 4/4: Zeroing gradients...
  Epoch 111, Batch 4/4: Forward pass...
  Epoch 111, Batch 4/4: Calculating loss...
  Epoch 111, Batch 4/4: Backward pass...
  Epoch 111, Batch 4/4: Clipping gradients...
  Epoch 111, Batch 4/4: Optimizer step...
  Epoch 111, Batch 4/4: Completed in 0.03s
Epoch 111: Training phase completed. Average Train Loss: 0.4806
Epoch 111: Starting validation phase...
  Epoch 111, Val Batch 1/1: Loading data...
  Epoch 111, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 111, Val Batch 1/1: Forward pass...
  Epoch 111, Val Batch 1/1: Calculating loss...
Epoch 111: Validation phase completed. Average Val Loss: 0.4343
Epoch 111 Summary ---> Train Loss: 0.4806 / Validation Loss: 0.4343
Epoch 111: Checking early stopping... (Current Best Loss: 0.4322, Epochs No Improve: 5)
  Epoch 111: Validation loss did not improve. Epochs without improvement: 6
Epoch 111: Stepping scheduler...
--- Epoch 111 completed in 0.68 seconds ---

--- Starting Epoch 112/1000 ---
Epoch 112: Starting training phase (4 batches)
  Epoch 112, Batch 1/4: Loading data to device...
  Epoch 112, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 112, Batch 1/4: Zeroing gradients...
  Epoch 112, Batch 1/4: Forward pass...
  Epoch 112, Batch 1/4: Calculating loss...
  Epoch 112, Batch 1/4: Backward pass...
  Epoch 112, Batch 1/4: Clipping gradients...
  Epoch 112, Batch 1/4: Optimizer step...
  Epoch 112, Batch 1/4: Completed in 0.19s
  Epoch 112, Batch 2/4: Loading data to device...
  Epoch 112, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 112, Batch 2/4: Zeroing gradients...
  Epoch 112, Batch 2/4: Forward pass...
  Epoch 112, Batch 2/4: Calculating loss...
  Epoch 112, Batch 2/4: Backward pass...
  Epoch 112, Batch 2/4: Clipping gradients...
  Epoch 112, Batch 2/4: Optimizer step...
  Epoch 112, Batch 2/4: Completed in 0.19s
  Epoch 112, Batch 3/4: Loading data to device...
  Epoch 112, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 112, Batch 3/4: Zeroing gradients...
  Epoch 112, Batch 3/4: Forward pass...
  Epoch 112, Batch 3/4: Calculating loss...
  Epoch 112, Batch 3/4: Backward pass...
  Epoch 112, Batch 3/4: Clipping gradients...
  Epoch 112, Batch 3/4: Optimizer step...
  Epoch 112, Batch 3/4: Completed in 0.20s
  Epoch 112, Batch 4/4: Loading data to device...
  Epoch 112, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 112, Batch 4/4: Zeroing gradients...
  Epoch 112, Batch 4/4: Forward pass...
  Epoch 112, Batch 4/4: Calculating loss...
  Epoch 112, Batch 4/4: Backward pass...
  Epoch 112, Batch 4/4: Clipping gradients...
  Epoch 112, Batch 4/4: Optimizer step...
  Epoch 112, Batch 4/4: Completed in 0.03s
Epoch 112: Training phase completed. Average Train Loss: 0.4746
Epoch 112: Starting validation phase...
  Epoch 112, Val Batch 1/1: Loading data...
  Epoch 112, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 112, Val Batch 1/1: Forward pass...
  Epoch 112, Val Batch 1/1: Calculating loss...
Epoch 112: Validation phase completed. Average Val Loss: 0.4341
Epoch 112 Summary ---> Train Loss: 0.4746 / Validation Loss: 0.4341
Epoch 112: Checking early stopping... (Current Best Loss: 0.4322, Epochs No Improve: 6)
  Epoch 112: Validation loss did not improve. Epochs without improvement: 7
Epoch 112: Stepping scheduler...
--- Epoch 112 completed in 0.68 seconds ---

--- Starting Epoch 113/1000 ---
Epoch 113: Starting training phase (4 batches)
  Epoch 113, Batch 1/4: Loading data to device...
  Epoch 113, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 113, Batch 1/4: Zeroing gradients...
  Epoch 113, Batch 1/4: Forward pass...
  Epoch 113, Batch 1/4: Calculating loss...
  Epoch 113, Batch 1/4: Backward pass...
  Epoch 113, Batch 1/4: Clipping gradients...
  Epoch 113, Batch 1/4: Optimizer step...
  Epoch 113, Batch 1/4: Completed in 0.19s
  Epoch 113, Batch 2/4: Loading data to device...
  Epoch 113, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 113, Batch 2/4: Zeroing gradients...
  Epoch 113, Batch 2/4: Forward pass...
  Epoch 113, Batch 2/4: Calculating loss...
  Epoch 113, Batch 2/4: Backward pass...
  Epoch 113, Batch 2/4: Clipping gradients...
  Epoch 113, Batch 2/4: Optimizer step...
  Epoch 113, Batch 2/4: Completed in 0.20s
  Epoch 113, Batch 3/4: Loading data to device...
  Epoch 113, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 113, Batch 3/4: Zeroing gradients...
  Epoch 113, Batch 3/4: Forward pass...
  Epoch 113, Batch 3/4: Calculating loss...
  Epoch 113, Batch 3/4: Backward pass...
  Epoch 113, Batch 3/4: Clipping gradients...
  Epoch 113, Batch 3/4: Optimizer step...
  Epoch 113, Batch 3/4: Completed in 0.20s
  Epoch 113, Batch 4/4: Loading data to device...
  Epoch 113, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 113, Batch 4/4: Zeroing gradients...
  Epoch 113, Batch 4/4: Forward pass...
  Epoch 113, Batch 4/4: Calculating loss...
  Epoch 113, Batch 4/4: Backward pass...
  Epoch 113, Batch 4/4: Clipping gradients...
  Epoch 113, Batch 4/4: Optimizer step...
  Epoch 113, Batch 4/4: Completed in 0.03s
Epoch 113: Training phase completed. Average Train Loss: 0.4714
Epoch 113: Starting validation phase...
  Epoch 113, Val Batch 1/1: Loading data...
  Epoch 113, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 113, Val Batch 1/1: Forward pass...
  Epoch 113, Val Batch 1/1: Calculating loss...
Epoch 113: Validation phase completed. Average Val Loss: 0.4338
Epoch 113 Summary ---> Train Loss: 0.4714 / Validation Loss: 0.4338
Epoch 113: Checking early stopping... (Current Best Loss: 0.4322, Epochs No Improve: 7)
  Epoch 113: Validation loss did not improve. Epochs without improvement: 8
Epoch 113: Stepping scheduler...
--- Epoch 113 completed in 0.69 seconds ---

--- Starting Epoch 114/1000 ---
Epoch 114: Starting training phase (4 batches)
  Epoch 114, Batch 1/4: Loading data to device...
  Epoch 114, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 114, Batch 1/4: Zeroing gradients...
  Epoch 114, Batch 1/4: Forward pass...
  Epoch 114, Batch 1/4: Calculating loss...
  Epoch 114, Batch 1/4: Backward pass...
  Epoch 114, Batch 1/4: Clipping gradients...
  Epoch 114, Batch 1/4: Optimizer step...
  Epoch 114, Batch 1/4: Completed in 0.19s
  Epoch 114, Batch 2/4: Loading data to device...
  Epoch 114, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 114, Batch 2/4: Zeroing gradients...
  Epoch 114, Batch 2/4: Forward pass...
  Epoch 114, Batch 2/4: Calculating loss...
  Epoch 114, Batch 2/4: Backward pass...
  Epoch 114, Batch 2/4: Clipping gradients...
  Epoch 114, Batch 2/4: Optimizer step...
  Epoch 114, Batch 2/4: Completed in 0.19s
  Epoch 114, Batch 3/4: Loading data to device...
  Epoch 114, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 114, Batch 3/4: Zeroing gradients...
  Epoch 114, Batch 3/4: Forward pass...
  Epoch 114, Batch 3/4: Calculating loss...
  Epoch 114, Batch 3/4: Backward pass...
  Epoch 114, Batch 3/4: Clipping gradients...
  Epoch 114, Batch 3/4: Optimizer step...
  Epoch 114, Batch 3/4: Completed in 0.19s
  Epoch 114, Batch 4/4: Loading data to device...
  Epoch 114, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 114, Batch 4/4: Zeroing gradients...
  Epoch 114, Batch 4/4: Forward pass...
  Epoch 114, Batch 4/4: Calculating loss...
  Epoch 114, Batch 4/4: Backward pass...
  Epoch 114, Batch 4/4: Clipping gradients...
  Epoch 114, Batch 4/4: Optimizer step...
  Epoch 114, Batch 4/4: Completed in 0.03s
Epoch 114: Training phase completed. Average Train Loss: 0.4483
Epoch 114: Starting validation phase...
  Epoch 114, Val Batch 1/1: Loading data...
  Epoch 114, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 114, Val Batch 1/1: Forward pass...
  Epoch 114, Val Batch 1/1: Calculating loss...
Epoch 114: Validation phase completed. Average Val Loss: 0.4408
Epoch 114 Summary ---> Train Loss: 0.4483 / Validation Loss: 0.4408
Epoch 114: Checking early stopping... (Current Best Loss: 0.4322, Epochs No Improve: 8)
  Epoch 114: Validation loss did not improve. Epochs without improvement: 9
Epoch 114: Stepping scheduler...
--- Epoch 114 completed in 0.68 seconds ---

--- Starting Epoch 115/1000 ---
Epoch 115: Starting training phase (4 batches)
  Epoch 115, Batch 1/4: Loading data to device...
  Epoch 115, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 115, Batch 1/4: Zeroing gradients...
  Epoch 115, Batch 1/4: Forward pass...
  Epoch 115, Batch 1/4: Calculating loss...
  Epoch 115, Batch 1/4: Backward pass...
  Epoch 115, Batch 1/4: Clipping gradients...
  Epoch 115, Batch 1/4: Optimizer step...
  Epoch 115, Batch 1/4: Completed in 0.19s
  Epoch 115, Batch 2/4: Loading data to device...
  Epoch 115, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 115, Batch 2/4: Zeroing gradients...
  Epoch 115, Batch 2/4: Forward pass...
  Epoch 115, Batch 2/4: Calculating loss...
  Epoch 115, Batch 2/4: Backward pass...
  Epoch 115, Batch 2/4: Clipping gradients...
  Epoch 115, Batch 2/4: Optimizer step...
  Epoch 115, Batch 2/4: Completed in 0.19s
  Epoch 115, Batch 3/4: Loading data to device...
  Epoch 115, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 115, Batch 3/4: Zeroing gradients...
  Epoch 115, Batch 3/4: Forward pass...
  Epoch 115, Batch 3/4: Calculating loss...
  Epoch 115, Batch 3/4: Backward pass...
  Epoch 115, Batch 3/4: Clipping gradients...
  Epoch 115, Batch 3/4: Optimizer step...
  Epoch 115, Batch 3/4: Completed in 0.19s
  Epoch 115, Batch 4/4: Loading data to device...
  Epoch 115, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 115, Batch 4/4: Zeroing gradients...
  Epoch 115, Batch 4/4: Forward pass...
  Epoch 115, Batch 4/4: Calculating loss...
  Epoch 115, Batch 4/4: Backward pass...
  Epoch 115, Batch 4/4: Clipping gradients...
  Epoch 115, Batch 4/4: Optimizer step...
  Epoch 115, Batch 4/4: Completed in 0.03s
Epoch 115: Training phase completed. Average Train Loss: 0.4781
Epoch 115: Starting validation phase...
  Epoch 115, Val Batch 1/1: Loading data...
  Epoch 115, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 115, Val Batch 1/1: Forward pass...
  Epoch 115, Val Batch 1/1: Calculating loss...
Epoch 115: Validation phase completed. Average Val Loss: 0.4458
Epoch 115 Summary ---> Train Loss: 0.4781 / Validation Loss: 0.4458
Epoch 115: Checking early stopping... (Current Best Loss: 0.4322, Epochs No Improve: 9)
  Epoch 115: Validation loss did not improve. Epochs without improvement: 10
Epoch 115: Stepping scheduler...
--- Epoch 115 completed in 0.67 seconds ---

--- Starting Epoch 116/1000 ---
Epoch 116: Starting training phase (4 batches)
  Epoch 116, Batch 1/4: Loading data to device...
  Epoch 116, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 116, Batch 1/4: Zeroing gradients...
  Epoch 116, Batch 1/4: Forward pass...
  Epoch 116, Batch 1/4: Calculating loss...
  Epoch 116, Batch 1/4: Backward pass...
  Epoch 116, Batch 1/4: Clipping gradients...
  Epoch 116, Batch 1/4: Optimizer step...
  Epoch 116, Batch 1/4: Completed in 0.19s
  Epoch 116, Batch 2/4: Loading data to device...
  Epoch 116, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 116, Batch 2/4: Zeroing gradients...
  Epoch 116, Batch 2/4: Forward pass...
  Epoch 116, Batch 2/4: Calculating loss...
  Epoch 116, Batch 2/4: Backward pass...
  Epoch 116, Batch 2/4: Clipping gradients...
  Epoch 116, Batch 2/4: Optimizer step...
  Epoch 116, Batch 2/4: Completed in 0.19s
  Epoch 116, Batch 3/4: Loading data to device...
  Epoch 116, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 116, Batch 3/4: Zeroing gradients...
  Epoch 116, Batch 3/4: Forward pass...
  Epoch 116, Batch 3/4: Calculating loss...
  Epoch 116, Batch 3/4: Backward pass...
  Epoch 116, Batch 3/4: Clipping gradients...
  Epoch 116, Batch 3/4: Optimizer step...
  Epoch 116, Batch 3/4: Completed in 0.19s
  Epoch 116, Batch 4/4: Loading data to device...
  Epoch 116, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 116, Batch 4/4: Zeroing gradients...
  Epoch 116, Batch 4/4: Forward pass...
  Epoch 116, Batch 4/4: Calculating loss...
  Epoch 116, Batch 4/4: Backward pass...
  Epoch 116, Batch 4/4: Clipping gradients...
  Epoch 116, Batch 4/4: Optimizer step...
  Epoch 116, Batch 4/4: Completed in 0.03s
Epoch 116: Training phase completed. Average Train Loss: 0.4933
Epoch 116: Starting validation phase...
  Epoch 116, Val Batch 1/1: Loading data...
  Epoch 116, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 116, Val Batch 1/1: Forward pass...
  Epoch 116, Val Batch 1/1: Calculating loss...
Epoch 116: Validation phase completed. Average Val Loss: 0.4409
Epoch 116 Summary ---> Train Loss: 0.4933 / Validation Loss: 0.4409
Epoch 116: Checking early stopping... (Current Best Loss: 0.4322, Epochs No Improve: 10)
  Epoch 116: Validation loss did not improve. Epochs without improvement: 11
Epoch 116: Stepping scheduler...
--- Epoch 116 completed in 0.67 seconds ---

--- Starting Epoch 117/1000 ---
Epoch 117: Starting training phase (4 batches)
  Epoch 117, Batch 1/4: Loading data to device...
  Epoch 117, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 117, Batch 1/4: Zeroing gradients...
  Epoch 117, Batch 1/4: Forward pass...
  Epoch 117, Batch 1/4: Calculating loss...
  Epoch 117, Batch 1/4: Backward pass...
  Epoch 117, Batch 1/4: Clipping gradients...
  Epoch 117, Batch 1/4: Optimizer step...
  Epoch 117, Batch 1/4: Completed in 0.19s
  Epoch 117, Batch 2/4: Loading data to device...
  Epoch 117, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 117, Batch 2/4: Zeroing gradients...
  Epoch 117, Batch 2/4: Forward pass...
  Epoch 117, Batch 2/4: Calculating loss...
  Epoch 117, Batch 2/4: Backward pass...
  Epoch 117, Batch 2/4: Clipping gradients...
  Epoch 117, Batch 2/4: Optimizer step...
  Epoch 117, Batch 2/4: Completed in 0.19s
  Epoch 117, Batch 3/4: Loading data to device...
  Epoch 117, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 117, Batch 3/4: Zeroing gradients...
  Epoch 117, Batch 3/4: Forward pass...
  Epoch 117, Batch 3/4: Calculating loss...
  Epoch 117, Batch 3/4: Backward pass...
  Epoch 117, Batch 3/4: Clipping gradients...
  Epoch 117, Batch 3/4: Optimizer step...
  Epoch 117, Batch 3/4: Completed in 0.19s
  Epoch 117, Batch 4/4: Loading data to device...
  Epoch 117, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 117, Batch 4/4: Zeroing gradients...
  Epoch 117, Batch 4/4: Forward pass...
  Epoch 117, Batch 4/4: Calculating loss...
  Epoch 117, Batch 4/4: Backward pass...
  Epoch 117, Batch 4/4: Clipping gradients...
  Epoch 117, Batch 4/4: Optimizer step...
  Epoch 117, Batch 4/4: Completed in 0.03s
Epoch 117: Training phase completed. Average Train Loss: 0.4763
Epoch 117: Starting validation phase...
  Epoch 117, Val Batch 1/1: Loading data...
  Epoch 117, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 117, Val Batch 1/1: Forward pass...
  Epoch 117, Val Batch 1/1: Calculating loss...
Epoch 117: Validation phase completed. Average Val Loss: 0.4295
Epoch 117 Summary ---> Train Loss: 0.4763 / Validation Loss: 0.4295
Epoch 117: Checking early stopping... (Current Best Loss: 0.4322, Epochs No Improve: 11)
  Epoch 117: Validation loss improved (0.4322 --> 0.4295). Saving model.
Epoch 117: Stepping scheduler...
--- Epoch 117 completed in 0.68 seconds ---

--- Starting Epoch 118/1000 ---
Epoch 118: Starting training phase (4 batches)
  Epoch 118, Batch 1/4: Loading data to device...
  Epoch 118, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 118, Batch 1/4: Zeroing gradients...
  Epoch 118, Batch 1/4: Forward pass...
  Epoch 118, Batch 1/4: Calculating loss...
  Epoch 118, Batch 1/4: Backward pass...
  Epoch 118, Batch 1/4: Clipping gradients...
  Epoch 118, Batch 1/4: Optimizer step...
  Epoch 118, Batch 1/4: Completed in 0.19s
  Epoch 118, Batch 2/4: Loading data to device...
  Epoch 118, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 118, Batch 2/4: Zeroing gradients...
  Epoch 118, Batch 2/4: Forward pass...
  Epoch 118, Batch 2/4: Calculating loss...
  Epoch 118, Batch 2/4: Backward pass...
  Epoch 118, Batch 2/4: Clipping gradients...
  Epoch 118, Batch 2/4: Optimizer step...
  Epoch 118, Batch 2/4: Completed in 0.19s
  Epoch 118, Batch 3/4: Loading data to device...
  Epoch 118, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 118, Batch 3/4: Zeroing gradients...
  Epoch 118, Batch 3/4: Forward pass...
  Epoch 118, Batch 3/4: Calculating loss...
  Epoch 118, Batch 3/4: Backward pass...
  Epoch 118, Batch 3/4: Clipping gradients...
  Epoch 118, Batch 3/4: Optimizer step...
  Epoch 118, Batch 3/4: Completed in 0.19s
  Epoch 118, Batch 4/4: Loading data to device...
  Epoch 118, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 118, Batch 4/4: Zeroing gradients...
  Epoch 118, Batch 4/4: Forward pass...
  Epoch 118, Batch 4/4: Calculating loss...
  Epoch 118, Batch 4/4: Backward pass...
  Epoch 118, Batch 4/4: Clipping gradients...
  Epoch 118, Batch 4/4: Optimizer step...
  Epoch 118, Batch 4/4: Completed in 0.03s
Epoch 118: Training phase completed. Average Train Loss: 0.5076
Epoch 118: Starting validation phase...
  Epoch 118, Val Batch 1/1: Loading data...
  Epoch 118, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 118, Val Batch 1/1: Forward pass...
  Epoch 118, Val Batch 1/1: Calculating loss...
Epoch 118: Validation phase completed. Average Val Loss: 0.4295
Epoch 118 Summary ---> Train Loss: 0.5076 / Validation Loss: 0.4295
Epoch 118: Checking early stopping... (Current Best Loss: 0.4295, Epochs No Improve: 0)
  Epoch 118: Validation loss improved (0.4295 --> 0.4295). Saving model.
Epoch 118: Stepping scheduler...
--- Epoch 118 completed in 0.67 seconds ---

--- Starting Epoch 119/1000 ---
Epoch 119: Starting training phase (4 batches)
  Epoch 119, Batch 1/4: Loading data to device...
  Epoch 119, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 119, Batch 1/4: Zeroing gradients...
  Epoch 119, Batch 1/4: Forward pass...
  Epoch 119, Batch 1/4: Calculating loss...
  Epoch 119, Batch 1/4: Backward pass...
  Epoch 119, Batch 1/4: Clipping gradients...
  Epoch 119, Batch 1/4: Optimizer step...
  Epoch 119, Batch 1/4: Completed in 0.19s
  Epoch 119, Batch 2/4: Loading data to device...
  Epoch 119, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 119, Batch 2/4: Zeroing gradients...
  Epoch 119, Batch 2/4: Forward pass...
  Epoch 119, Batch 2/4: Calculating loss...
  Epoch 119, Batch 2/4: Backward pass...
  Epoch 119, Batch 2/4: Clipping gradients...
  Epoch 119, Batch 2/4: Optimizer step...
  Epoch 119, Batch 2/4: Completed in 0.19s
  Epoch 119, Batch 3/4: Loading data to device...
  Epoch 119, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 119, Batch 3/4: Zeroing gradients...
  Epoch 119, Batch 3/4: Forward pass...
  Epoch 119, Batch 3/4: Calculating loss...
  Epoch 119, Batch 3/4: Backward pass...
  Epoch 119, Batch 3/4: Clipping gradients...
  Epoch 119, Batch 3/4: Optimizer step...
  Epoch 119, Batch 3/4: Completed in 0.19s
  Epoch 119, Batch 4/4: Loading data to device...
  Epoch 119, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 119, Batch 4/4: Zeroing gradients...
  Epoch 119, Batch 4/4: Forward pass...
  Epoch 119, Batch 4/4: Calculating loss...
  Epoch 119, Batch 4/4: Backward pass...
  Epoch 119, Batch 4/4: Clipping gradients...
  Epoch 119, Batch 4/4: Optimizer step...
  Epoch 119, Batch 4/4: Completed in 0.04s
Epoch 119: Training phase completed. Average Train Loss: 0.5385
Epoch 119: Starting validation phase...
  Epoch 119, Val Batch 1/1: Loading data...
  Epoch 119, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 119, Val Batch 1/1: Forward pass...
  Epoch 119, Val Batch 1/1: Calculating loss...
Epoch 119: Validation phase completed. Average Val Loss: 0.4166
Epoch 119 Summary ---> Train Loss: 0.5385 / Validation Loss: 0.4166
Epoch 119: Checking early stopping... (Current Best Loss: 0.4295, Epochs No Improve: 0)
  Epoch 119: Validation loss improved (0.4295 --> 0.4166). Saving model.
Epoch 119: Stepping scheduler...
--- Epoch 119 completed in 0.67 seconds ---

--- Starting Epoch 120/1000 ---
Epoch 120: Starting training phase (4 batches)
  Epoch 120, Batch 1/4: Loading data to device...
  Epoch 120, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 120, Batch 1/4: Zeroing gradients...
  Epoch 120, Batch 1/4: Forward pass...
  Epoch 120, Batch 1/4: Calculating loss...
  Epoch 120, Batch 1/4: Backward pass...
  Epoch 120, Batch 1/4: Clipping gradients...
  Epoch 120, Batch 1/4: Optimizer step...
  Epoch 120, Batch 1/4: Completed in 0.19s
  Epoch 120, Batch 2/4: Loading data to device...
  Epoch 120, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 120, Batch 2/4: Zeroing gradients...
  Epoch 120, Batch 2/4: Forward pass...
  Epoch 120, Batch 2/4: Calculating loss...
  Epoch 120, Batch 2/4: Backward pass...
  Epoch 120, Batch 2/4: Clipping gradients...
  Epoch 120, Batch 2/4: Optimizer step...
  Epoch 120, Batch 2/4: Completed in 0.19s
  Epoch 120, Batch 3/4: Loading data to device...
  Epoch 120, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 120, Batch 3/4: Zeroing gradients...
  Epoch 120, Batch 3/4: Forward pass...
  Epoch 120, Batch 3/4: Calculating loss...
  Epoch 120, Batch 3/4: Backward pass...
  Epoch 120, Batch 3/4: Clipping gradients...
  Epoch 120, Batch 3/4: Optimizer step...
  Epoch 120, Batch 3/4: Completed in 0.20s
  Epoch 120, Batch 4/4: Loading data to device...
  Epoch 120, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 120, Batch 4/4: Zeroing gradients...
  Epoch 120, Batch 4/4: Forward pass...
  Epoch 120, Batch 4/4: Calculating loss...
  Epoch 120, Batch 4/4: Backward pass...
  Epoch 120, Batch 4/4: Clipping gradients...
  Epoch 120, Batch 4/4: Optimizer step...
  Epoch 120, Batch 4/4: Completed in 0.03s
Epoch 120: Training phase completed. Average Train Loss: 0.5002
Epoch 120: Starting validation phase...
  Epoch 120, Val Batch 1/1: Loading data...
  Epoch 120, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 120, Val Batch 1/1: Forward pass...
  Epoch 120, Val Batch 1/1: Calculating loss...
Epoch 120: Validation phase completed. Average Val Loss: 0.4161
Epoch 120 Summary ---> Train Loss: 0.5002 / Validation Loss: 0.4161
Epoch 120: Checking early stopping... (Current Best Loss: 0.4166, Epochs No Improve: 0)
  Epoch 120: Validation loss improved (0.4166 --> 0.4161). Saving model.
Epoch 120: Stepping scheduler...
--- Epoch 120 completed in 0.69 seconds ---

--- Starting Epoch 121/1000 ---
Epoch 121: Starting training phase (4 batches)
  Epoch 121, Batch 1/4: Loading data to device...
  Epoch 121, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 121, Batch 1/4: Zeroing gradients...
  Epoch 121, Batch 1/4: Forward pass...
  Epoch 121, Batch 1/4: Calculating loss...
  Epoch 121, Batch 1/4: Backward pass...
  Epoch 121, Batch 1/4: Clipping gradients...
  Epoch 121, Batch 1/4: Optimizer step...
  Epoch 121, Batch 1/4: Completed in 0.19s
  Epoch 121, Batch 2/4: Loading data to device...
  Epoch 121, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 121, Batch 2/4: Zeroing gradients...
  Epoch 121, Batch 2/4: Forward pass...
  Epoch 121, Batch 2/4: Calculating loss...
  Epoch 121, Batch 2/4: Backward pass...
  Epoch 121, Batch 2/4: Clipping gradients...
  Epoch 121, Batch 2/4: Optimizer step...
  Epoch 121, Batch 2/4: Completed in 0.19s
  Epoch 121, Batch 3/4: Loading data to device...
  Epoch 121, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 121, Batch 3/4: Zeroing gradients...
  Epoch 121, Batch 3/4: Forward pass...
  Epoch 121, Batch 3/4: Calculating loss...
  Epoch 121, Batch 3/4: Backward pass...
  Epoch 121, Batch 3/4: Clipping gradients...
  Epoch 121, Batch 3/4: Optimizer step...
  Epoch 121, Batch 3/4: Completed in 0.20s
  Epoch 121, Batch 4/4: Loading data to device...
  Epoch 121, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 121, Batch 4/4: Zeroing gradients...
  Epoch 121, Batch 4/4: Forward pass...
  Epoch 121, Batch 4/4: Calculating loss...
  Epoch 121, Batch 4/4: Backward pass...
  Epoch 121, Batch 4/4: Clipping gradients...
  Epoch 121, Batch 4/4: Optimizer step...
  Epoch 121, Batch 4/4: Completed in 0.04s
Epoch 121: Training phase completed. Average Train Loss: 0.4616
Epoch 121: Starting validation phase...
  Epoch 121, Val Batch 1/1: Loading data...
  Epoch 121, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 121, Val Batch 1/1: Forward pass...
  Epoch 121, Val Batch 1/1: Calculating loss...
Epoch 121: Validation phase completed. Average Val Loss: 0.4161
Epoch 121 Summary ---> Train Loss: 0.4616 / Validation Loss: 0.4161
Epoch 121: Checking early stopping... (Current Best Loss: 0.4161, Epochs No Improve: 0)
  Epoch 121: Validation loss improved (0.4161 --> 0.4161). Saving model.
Epoch 121: Stepping scheduler...
--- Epoch 121 completed in 0.69 seconds ---

--- Starting Epoch 122/1000 ---
Epoch 122: Starting training phase (4 batches)
  Epoch 122, Batch 1/4: Loading data to device...
  Epoch 122, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 122, Batch 1/4: Zeroing gradients...
  Epoch 122, Batch 1/4: Forward pass...
  Epoch 122, Batch 1/4: Calculating loss...
  Epoch 122, Batch 1/4: Backward pass...
  Epoch 122, Batch 1/4: Clipping gradients...
  Epoch 122, Batch 1/4: Optimizer step...
  Epoch 122, Batch 1/4: Completed in 0.19s
  Epoch 122, Batch 2/4: Loading data to device...
  Epoch 122, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 122, Batch 2/4: Zeroing gradients...
  Epoch 122, Batch 2/4: Forward pass...
  Epoch 122, Batch 2/4: Calculating loss...
  Epoch 122, Batch 2/4: Backward pass...
  Epoch 122, Batch 2/4: Clipping gradients...
  Epoch 122, Batch 2/4: Optimizer step...
  Epoch 122, Batch 2/4: Completed in 0.19s
  Epoch 122, Batch 3/4: Loading data to device...
  Epoch 122, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 122, Batch 3/4: Zeroing gradients...
  Epoch 122, Batch 3/4: Forward pass...
  Epoch 122, Batch 3/4: Calculating loss...
  Epoch 122, Batch 3/4: Backward pass...
  Epoch 122, Batch 3/4: Clipping gradients...
  Epoch 122, Batch 3/4: Optimizer step...
  Epoch 122, Batch 3/4: Completed in 0.19s
  Epoch 122, Batch 4/4: Loading data to device...
  Epoch 122, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 122, Batch 4/4: Zeroing gradients...
  Epoch 122, Batch 4/4: Forward pass...
  Epoch 122, Batch 4/4: Calculating loss...
  Epoch 122, Batch 4/4: Backward pass...
  Epoch 122, Batch 4/4: Clipping gradients...
  Epoch 122, Batch 4/4: Optimizer step...
  Epoch 122, Batch 4/4: Completed in 0.03s
Epoch 122: Training phase completed. Average Train Loss: 0.4412
Epoch 122: Starting validation phase...
  Epoch 122, Val Batch 1/1: Loading data...
  Epoch 122, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 122, Val Batch 1/1: Forward pass...
  Epoch 122, Val Batch 1/1: Calculating loss...
Epoch 122: Validation phase completed. Average Val Loss: 0.4175
Epoch 122 Summary ---> Train Loss: 0.4412 / Validation Loss: 0.4175
Epoch 122: Checking early stopping... (Current Best Loss: 0.4161, Epochs No Improve: 0)
  Epoch 122: Validation loss did not improve. Epochs without improvement: 1
Epoch 122: Stepping scheduler...
--- Epoch 122 completed in 0.67 seconds ---

--- Starting Epoch 123/1000 ---
Epoch 123: Starting training phase (4 batches)
  Epoch 123, Batch 1/4: Loading data to device...
  Epoch 123, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 123, Batch 1/4: Zeroing gradients...
  Epoch 123, Batch 1/4: Forward pass...
  Epoch 123, Batch 1/4: Calculating loss...
  Epoch 123, Batch 1/4: Backward pass...
  Epoch 123, Batch 1/4: Clipping gradients...
  Epoch 123, Batch 1/4: Optimizer step...
  Epoch 123, Batch 1/4: Completed in 0.19s
  Epoch 123, Batch 2/4: Loading data to device...
  Epoch 123, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 123, Batch 2/4: Zeroing gradients...
  Epoch 123, Batch 2/4: Forward pass...
  Epoch 123, Batch 2/4: Calculating loss...
  Epoch 123, Batch 2/4: Backward pass...
  Epoch 123, Batch 2/4: Clipping gradients...
  Epoch 123, Batch 2/4: Optimizer step...
  Epoch 123, Batch 2/4: Completed in 0.19s
  Epoch 123, Batch 3/4: Loading data to device...
  Epoch 123, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 123, Batch 3/4: Zeroing gradients...
  Epoch 123, Batch 3/4: Forward pass...
  Epoch 123, Batch 3/4: Calculating loss...
  Epoch 123, Batch 3/4: Backward pass...
  Epoch 123, Batch 3/4: Clipping gradients...
  Epoch 123, Batch 3/4: Optimizer step...
  Epoch 123, Batch 3/4: Completed in 0.19s
  Epoch 123, Batch 4/4: Loading data to device...
  Epoch 123, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 123, Batch 4/4: Zeroing gradients...
  Epoch 123, Batch 4/4: Forward pass...
  Epoch 123, Batch 4/4: Calculating loss...
  Epoch 123, Batch 4/4: Backward pass...
  Epoch 123, Batch 4/4: Clipping gradients...
  Epoch 123, Batch 4/4: Optimizer step...
  Epoch 123, Batch 4/4: Completed in 0.03s
Epoch 123: Training phase completed. Average Train Loss: 0.5546
Epoch 123: Starting validation phase...
  Epoch 123, Val Batch 1/1: Loading data...
  Epoch 123, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 123, Val Batch 1/1: Forward pass...
  Epoch 123, Val Batch 1/1: Calculating loss...
Epoch 123: Validation phase completed. Average Val Loss: 0.4154
Epoch 123 Summary ---> Train Loss: 0.5546 / Validation Loss: 0.4154
Epoch 123: Checking early stopping... (Current Best Loss: 0.4161, Epochs No Improve: 1)
  Epoch 123: Validation loss improved (0.4161 --> 0.4154). Saving model.
Epoch 123: Stepping scheduler...
--- Epoch 123 completed in 0.68 seconds ---

--- Starting Epoch 124/1000 ---
Epoch 124: Starting training phase (4 batches)
  Epoch 124, Batch 1/4: Loading data to device...
  Epoch 124, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 124, Batch 1/4: Zeroing gradients...
  Epoch 124, Batch 1/4: Forward pass...
  Epoch 124, Batch 1/4: Calculating loss...
  Epoch 124, Batch 1/4: Backward pass...
  Epoch 124, Batch 1/4: Clipping gradients...
  Epoch 124, Batch 1/4: Optimizer step...
  Epoch 124, Batch 1/4: Completed in 0.20s
  Epoch 124, Batch 2/4: Loading data to device...
  Epoch 124, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 124, Batch 2/4: Zeroing gradients...
  Epoch 124, Batch 2/4: Forward pass...
  Epoch 124, Batch 2/4: Calculating loss...
  Epoch 124, Batch 2/4: Backward pass...
  Epoch 124, Batch 2/4: Clipping gradients...
  Epoch 124, Batch 2/4: Optimizer step...
  Epoch 124, Batch 2/4: Completed in 0.20s
  Epoch 124, Batch 3/4: Loading data to device...
  Epoch 124, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 124, Batch 3/4: Zeroing gradients...
  Epoch 124, Batch 3/4: Forward pass...
  Epoch 124, Batch 3/4: Calculating loss...
  Epoch 124, Batch 3/4: Backward pass...
  Epoch 124, Batch 3/4: Clipping gradients...
  Epoch 124, Batch 3/4: Optimizer step...
  Epoch 124, Batch 3/4: Completed in 0.20s
  Epoch 124, Batch 4/4: Loading data to device...
  Epoch 124, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 124, Batch 4/4: Zeroing gradients...
  Epoch 124, Batch 4/4: Forward pass...
  Epoch 124, Batch 4/4: Calculating loss...
  Epoch 124, Batch 4/4: Backward pass...
  Epoch 124, Batch 4/4: Clipping gradients...
  Epoch 124, Batch 4/4: Optimizer step...
  Epoch 124, Batch 4/4: Completed in 0.03s
Epoch 124: Training phase completed. Average Train Loss: 0.4915
Epoch 124: Starting validation phase...
  Epoch 124, Val Batch 1/1: Loading data...
  Epoch 124, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 124, Val Batch 1/1: Forward pass...
  Epoch 124, Val Batch 1/1: Calculating loss...
Epoch 124: Validation phase completed. Average Val Loss: 0.4119
Epoch 124 Summary ---> Train Loss: 0.4915 / Validation Loss: 0.4119
Epoch 124: Checking early stopping... (Current Best Loss: 0.4154, Epochs No Improve: 0)
  Epoch 124: Validation loss improved (0.4154 --> 0.4119). Saving model.
Epoch 124: Stepping scheduler...
--- Epoch 124 completed in 0.69 seconds ---

--- Starting Epoch 125/1000 ---
Epoch 125: Starting training phase (4 batches)
  Epoch 125, Batch 1/4: Loading data to device...
  Epoch 125, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 125, Batch 1/4: Zeroing gradients...
  Epoch 125, Batch 1/4: Forward pass...
  Epoch 125, Batch 1/4: Calculating loss...
  Epoch 125, Batch 1/4: Backward pass...
  Epoch 125, Batch 1/4: Clipping gradients...
  Epoch 125, Batch 1/4: Optimizer step...
  Epoch 125, Batch 1/4: Completed in 0.19s
  Epoch 125, Batch 2/4: Loading data to device...
  Epoch 125, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 125, Batch 2/4: Zeroing gradients...
  Epoch 125, Batch 2/4: Forward pass...
  Epoch 125, Batch 2/4: Calculating loss...
  Epoch 125, Batch 2/4: Backward pass...
  Epoch 125, Batch 2/4: Clipping gradients...
  Epoch 125, Batch 2/4: Optimizer step...
  Epoch 125, Batch 2/4: Completed in 0.19s
  Epoch 125, Batch 3/4: Loading data to device...
  Epoch 125, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 125, Batch 3/4: Zeroing gradients...
  Epoch 125, Batch 3/4: Forward pass...
  Epoch 125, Batch 3/4: Calculating loss...
  Epoch 125, Batch 3/4: Backward pass...
  Epoch 125, Batch 3/4: Clipping gradients...
  Epoch 125, Batch 3/4: Optimizer step...
  Epoch 125, Batch 3/4: Completed in 0.19s
  Epoch 125, Batch 4/4: Loading data to device...
  Epoch 125, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 125, Batch 4/4: Zeroing gradients...
  Epoch 125, Batch 4/4: Forward pass...
  Epoch 125, Batch 4/4: Calculating loss...
  Epoch 125, Batch 4/4: Backward pass...
  Epoch 125, Batch 4/4: Clipping gradients...
  Epoch 125, Batch 4/4: Optimizer step...
  Epoch 125, Batch 4/4: Completed in 0.03s
Epoch 125: Training phase completed. Average Train Loss: 0.5040
Epoch 125: Starting validation phase...
  Epoch 125, Val Batch 1/1: Loading data...
  Epoch 125, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 125, Val Batch 1/1: Forward pass...
  Epoch 125, Val Batch 1/1: Calculating loss...
Epoch 125: Validation phase completed. Average Val Loss: 0.4186
Epoch 125 Summary ---> Train Loss: 0.5040 / Validation Loss: 0.4186
Epoch 125: Checking early stopping... (Current Best Loss: 0.4119, Epochs No Improve: 0)
  Epoch 125: Validation loss did not improve. Epochs without improvement: 1
Epoch 125: Stepping scheduler...
--- Epoch 125 completed in 0.68 seconds ---

--- Starting Epoch 126/1000 ---
Epoch 126: Starting training phase (4 batches)
  Epoch 126, Batch 1/4: Loading data to device...
  Epoch 126, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 126, Batch 1/4: Zeroing gradients...
  Epoch 126, Batch 1/4: Forward pass...
  Epoch 126, Batch 1/4: Calculating loss...
  Epoch 126, Batch 1/4: Backward pass...
  Epoch 126, Batch 1/4: Clipping gradients...
  Epoch 126, Batch 1/4: Optimizer step...
  Epoch 126, Batch 1/4: Completed in 0.19s
  Epoch 126, Batch 2/4: Loading data to device...
  Epoch 126, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 126, Batch 2/4: Zeroing gradients...
  Epoch 126, Batch 2/4: Forward pass...
  Epoch 126, Batch 2/4: Calculating loss...
  Epoch 126, Batch 2/4: Backward pass...
  Epoch 126, Batch 2/4: Clipping gradients...
  Epoch 126, Batch 2/4: Optimizer step...
  Epoch 126, Batch 2/4: Completed in 0.19s
  Epoch 126, Batch 3/4: Loading data to device...
  Epoch 126, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 126, Batch 3/4: Zeroing gradients...
  Epoch 126, Batch 3/4: Forward pass...
  Epoch 126, Batch 3/4: Calculating loss...
  Epoch 126, Batch 3/4: Backward pass...
  Epoch 126, Batch 3/4: Clipping gradients...
  Epoch 126, Batch 3/4: Optimizer step...
  Epoch 126, Batch 3/4: Completed in 0.19s
  Epoch 126, Batch 4/4: Loading data to device...
  Epoch 126, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 126, Batch 4/4: Zeroing gradients...
  Epoch 126, Batch 4/4: Forward pass...
  Epoch 126, Batch 4/4: Calculating loss...
  Epoch 126, Batch 4/4: Backward pass...
  Epoch 126, Batch 4/4: Clipping gradients...
  Epoch 126, Batch 4/4: Optimizer step...
  Epoch 126, Batch 4/4: Completed in 0.03s
Epoch 126: Training phase completed. Average Train Loss: 0.4469
Epoch 126: Starting validation phase...
  Epoch 126, Val Batch 1/1: Loading data...
  Epoch 126, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 126, Val Batch 1/1: Forward pass...
  Epoch 126, Val Batch 1/1: Calculating loss...
Epoch 126: Validation phase completed. Average Val Loss: 0.4176
Epoch 126 Summary ---> Train Loss: 0.4469 / Validation Loss: 0.4176
Epoch 126: Checking early stopping... (Current Best Loss: 0.4119, Epochs No Improve: 1)
  Epoch 126: Validation loss did not improve. Epochs without improvement: 2
Epoch 126: Stepping scheduler...
--- Epoch 126 completed in 0.66 seconds ---

--- Starting Epoch 127/1000 ---
Epoch 127: Starting training phase (4 batches)
  Epoch 127, Batch 1/4: Loading data to device...
  Epoch 127, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 127, Batch 1/4: Zeroing gradients...
  Epoch 127, Batch 1/4: Forward pass...
  Epoch 127, Batch 1/4: Calculating loss...
  Epoch 127, Batch 1/4: Backward pass...
  Epoch 127, Batch 1/4: Clipping gradients...
  Epoch 127, Batch 1/4: Optimizer step...
  Epoch 127, Batch 1/4: Completed in 0.20s
  Epoch 127, Batch 2/4: Loading data to device...
  Epoch 127, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 127, Batch 2/4: Zeroing gradients...
  Epoch 127, Batch 2/4: Forward pass...
  Epoch 127, Batch 2/4: Calculating loss...
  Epoch 127, Batch 2/4: Backward pass...
  Epoch 127, Batch 2/4: Clipping gradients...
  Epoch 127, Batch 2/4: Optimizer step...
  Epoch 127, Batch 2/4: Completed in 0.19s
  Epoch 127, Batch 3/4: Loading data to device...
  Epoch 127, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 127, Batch 3/4: Zeroing gradients...
  Epoch 127, Batch 3/4: Forward pass...
  Epoch 127, Batch 3/4: Calculating loss...
  Epoch 127, Batch 3/4: Backward pass...
  Epoch 127, Batch 3/4: Clipping gradients...
  Epoch 127, Batch 3/4: Optimizer step...
  Epoch 127, Batch 3/4: Completed in 0.19s
  Epoch 127, Batch 4/4: Loading data to device...
  Epoch 127, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 127, Batch 4/4: Zeroing gradients...
  Epoch 127, Batch 4/4: Forward pass...
  Epoch 127, Batch 4/4: Calculating loss...
  Epoch 127, Batch 4/4: Backward pass...
  Epoch 127, Batch 4/4: Clipping gradients...
  Epoch 127, Batch 4/4: Optimizer step...
  Epoch 127, Batch 4/4: Completed in 0.03s
Epoch 127: Training phase completed. Average Train Loss: 0.4732
Epoch 127: Starting validation phase...
  Epoch 127, Val Batch 1/1: Loading data...
  Epoch 127, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 127, Val Batch 1/1: Forward pass...
  Epoch 127, Val Batch 1/1: Calculating loss...
Epoch 127: Validation phase completed. Average Val Loss: 0.4028
Epoch 127 Summary ---> Train Loss: 0.4732 / Validation Loss: 0.4028
Epoch 127: Checking early stopping... (Current Best Loss: 0.4119, Epochs No Improve: 2)
  Epoch 127: Validation loss improved (0.4119 --> 0.4028). Saving model.
Epoch 127: Stepping scheduler...
--- Epoch 127 completed in 0.68 seconds ---

--- Starting Epoch 128/1000 ---
Epoch 128: Starting training phase (4 batches)
  Epoch 128, Batch 1/4: Loading data to device...
  Epoch 128, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 128, Batch 1/4: Zeroing gradients...
  Epoch 128, Batch 1/4: Forward pass...
  Epoch 128, Batch 1/4: Calculating loss...
  Epoch 128, Batch 1/4: Backward pass...
  Epoch 128, Batch 1/4: Clipping gradients...
  Epoch 128, Batch 1/4: Optimizer step...
  Epoch 128, Batch 1/4: Completed in 0.19s
  Epoch 128, Batch 2/4: Loading data to device...
  Epoch 128, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 128, Batch 2/4: Zeroing gradients...
  Epoch 128, Batch 2/4: Forward pass...
  Epoch 128, Batch 2/4: Calculating loss...
  Epoch 128, Batch 2/4: Backward pass...
  Epoch 128, Batch 2/4: Clipping gradients...
  Epoch 128, Batch 2/4: Optimizer step...
  Epoch 128, Batch 2/4: Completed in 0.19s
  Epoch 128, Batch 3/4: Loading data to device...
  Epoch 128, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 128, Batch 3/4: Zeroing gradients...
  Epoch 128, Batch 3/4: Forward pass...
  Epoch 128, Batch 3/4: Calculating loss...
  Epoch 128, Batch 3/4: Backward pass...
  Epoch 128, Batch 3/4: Clipping gradients...
  Epoch 128, Batch 3/4: Optimizer step...
  Epoch 128, Batch 3/4: Completed in 0.19s
  Epoch 128, Batch 4/4: Loading data to device...
  Epoch 128, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 128, Batch 4/4: Zeroing gradients...
  Epoch 128, Batch 4/4: Forward pass...
  Epoch 128, Batch 4/4: Calculating loss...
  Epoch 128, Batch 4/4: Backward pass...
  Epoch 128, Batch 4/4: Clipping gradients...
  Epoch 128, Batch 4/4: Optimizer step...
  Epoch 128, Batch 4/4: Completed in 0.04s
Epoch 128: Training phase completed. Average Train Loss: 0.4961
Epoch 128: Starting validation phase...
  Epoch 128, Val Batch 1/1: Loading data...
  Epoch 128, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 128, Val Batch 1/1: Forward pass...
  Epoch 128, Val Batch 1/1: Calculating loss...
Epoch 128: Validation phase completed. Average Val Loss: 0.3963
Epoch 128 Summary ---> Train Loss: 0.4961 / Validation Loss: 0.3963
Epoch 128: Checking early stopping... (Current Best Loss: 0.4028, Epochs No Improve: 0)
  Epoch 128: Validation loss improved (0.4028 --> 0.3963). Saving model.
Epoch 128: Stepping scheduler...
--- Epoch 128 completed in 0.68 seconds ---

--- Starting Epoch 129/1000 ---
Epoch 129: Starting training phase (4 batches)
  Epoch 129, Batch 1/4: Loading data to device...
  Epoch 129, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 129, Batch 1/4: Zeroing gradients...
  Epoch 129, Batch 1/4: Forward pass...
  Epoch 129, Batch 1/4: Calculating loss...
  Epoch 129, Batch 1/4: Backward pass...
  Epoch 129, Batch 1/4: Clipping gradients...
  Epoch 129, Batch 1/4: Optimizer step...
  Epoch 129, Batch 1/4: Completed in 0.19s
  Epoch 129, Batch 2/4: Loading data to device...
  Epoch 129, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 129, Batch 2/4: Zeroing gradients...
  Epoch 129, Batch 2/4: Forward pass...
  Epoch 129, Batch 2/4: Calculating loss...
  Epoch 129, Batch 2/4: Backward pass...
  Epoch 129, Batch 2/4: Clipping gradients...
  Epoch 129, Batch 2/4: Optimizer step...
  Epoch 129, Batch 2/4: Completed in 0.19s
  Epoch 129, Batch 3/4: Loading data to device...
  Epoch 129, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 129, Batch 3/4: Zeroing gradients...
  Epoch 129, Batch 3/4: Forward pass...
  Epoch 129, Batch 3/4: Calculating loss...
  Epoch 129, Batch 3/4: Backward pass...
  Epoch 129, Batch 3/4: Clipping gradients...
  Epoch 129, Batch 3/4: Optimizer step...
  Epoch 129, Batch 3/4: Completed in 0.19s
  Epoch 129, Batch 4/4: Loading data to device...
  Epoch 129, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 129, Batch 4/4: Zeroing gradients...
  Epoch 129, Batch 4/4: Forward pass...
  Epoch 129, Batch 4/4: Calculating loss...
  Epoch 129, Batch 4/4: Backward pass...
  Epoch 129, Batch 4/4: Clipping gradients...
  Epoch 129, Batch 4/4: Optimizer step...
  Epoch 129, Batch 4/4: Completed in 0.03s
Epoch 129: Training phase completed. Average Train Loss: 0.4451
Epoch 129: Starting validation phase...
  Epoch 129, Val Batch 1/1: Loading data...
  Epoch 129, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 129, Val Batch 1/1: Forward pass...
  Epoch 129, Val Batch 1/1: Calculating loss...
Epoch 129: Validation phase completed. Average Val Loss: 0.4067
Epoch 129 Summary ---> Train Loss: 0.4451 / Validation Loss: 0.4067
Epoch 129: Checking early stopping... (Current Best Loss: 0.3963, Epochs No Improve: 0)
  Epoch 129: Validation loss did not improve. Epochs without improvement: 1
Epoch 129: Stepping scheduler...
--- Epoch 129 completed in 0.67 seconds ---

--- Starting Epoch 130/1000 ---
Epoch 130: Starting training phase (4 batches)
  Epoch 130, Batch 1/4: Loading data to device...
  Epoch 130, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 130, Batch 1/4: Zeroing gradients...
  Epoch 130, Batch 1/4: Forward pass...
  Epoch 130, Batch 1/4: Calculating loss...
  Epoch 130, Batch 1/4: Backward pass...
  Epoch 130, Batch 1/4: Clipping gradients...
  Epoch 130, Batch 1/4: Optimizer step...
  Epoch 130, Batch 1/4: Completed in 0.19s
  Epoch 130, Batch 2/4: Loading data to device...
  Epoch 130, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 130, Batch 2/4: Zeroing gradients...
  Epoch 130, Batch 2/4: Forward pass...
  Epoch 130, Batch 2/4: Calculating loss...
  Epoch 130, Batch 2/4: Backward pass...
  Epoch 130, Batch 2/4: Clipping gradients...
  Epoch 130, Batch 2/4: Optimizer step...
  Epoch 130, Batch 2/4: Completed in 0.19s
  Epoch 130, Batch 3/4: Loading data to device...
  Epoch 130, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 130, Batch 3/4: Zeroing gradients...
  Epoch 130, Batch 3/4: Forward pass...
  Epoch 130, Batch 3/4: Calculating loss...
  Epoch 130, Batch 3/4: Backward pass...
  Epoch 130, Batch 3/4: Clipping gradients...
  Epoch 130, Batch 3/4: Optimizer step...
  Epoch 130, Batch 3/4: Completed in 0.20s
  Epoch 130, Batch 4/4: Loading data to device...
  Epoch 130, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 130, Batch 4/4: Zeroing gradients...
  Epoch 130, Batch 4/4: Forward pass...
  Epoch 130, Batch 4/4: Calculating loss...
  Epoch 130, Batch 4/4: Backward pass...
  Epoch 130, Batch 4/4: Clipping gradients...
  Epoch 130, Batch 4/4: Optimizer step...
  Epoch 130, Batch 4/4: Completed in 0.03s
Epoch 130: Training phase completed. Average Train Loss: 0.4573
Epoch 130: Starting validation phase...
  Epoch 130, Val Batch 1/1: Loading data...
  Epoch 130, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 130, Val Batch 1/1: Forward pass...
  Epoch 130, Val Batch 1/1: Calculating loss...
Epoch 130: Validation phase completed. Average Val Loss: 0.4104
Epoch 130 Summary ---> Train Loss: 0.4573 / Validation Loss: 0.4104
Epoch 130: Checking early stopping... (Current Best Loss: 0.3963, Epochs No Improve: 1)
  Epoch 130: Validation loss did not improve. Epochs without improvement: 2
Epoch 130: Stepping scheduler...
--- Epoch 130 completed in 0.69 seconds ---

--- Starting Epoch 131/1000 ---
Epoch 131: Starting training phase (4 batches)
  Epoch 131, Batch 1/4: Loading data to device...
  Epoch 131, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 131, Batch 1/4: Zeroing gradients...
  Epoch 131, Batch 1/4: Forward pass...
  Epoch 131, Batch 1/4: Calculating loss...
  Epoch 131, Batch 1/4: Backward pass...
  Epoch 131, Batch 1/4: Clipping gradients...
  Epoch 131, Batch 1/4: Optimizer step...
  Epoch 131, Batch 1/4: Completed in 0.20s
  Epoch 131, Batch 2/4: Loading data to device...
  Epoch 131, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 131, Batch 2/4: Zeroing gradients...
  Epoch 131, Batch 2/4: Forward pass...
  Epoch 131, Batch 2/4: Calculating loss...
  Epoch 131, Batch 2/4: Backward pass...
  Epoch 131, Batch 2/4: Clipping gradients...
  Epoch 131, Batch 2/4: Optimizer step...
  Epoch 131, Batch 2/4: Completed in 0.19s
  Epoch 131, Batch 3/4: Loading data to device...
  Epoch 131, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 131, Batch 3/4: Zeroing gradients...
  Epoch 131, Batch 3/4: Forward pass...
  Epoch 131, Batch 3/4: Calculating loss...
  Epoch 131, Batch 3/4: Backward pass...
  Epoch 131, Batch 3/4: Clipping gradients...
  Epoch 131, Batch 3/4: Optimizer step...
  Epoch 131, Batch 3/4: Completed in 0.19s
  Epoch 131, Batch 4/4: Loading data to device...
  Epoch 131, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 131, Batch 4/4: Zeroing gradients...
  Epoch 131, Batch 4/4: Forward pass...
  Epoch 131, Batch 4/4: Calculating loss...
  Epoch 131, Batch 4/4: Backward pass...
  Epoch 131, Batch 4/4: Clipping gradients...
  Epoch 131, Batch 4/4: Optimizer step...
  Epoch 131, Batch 4/4: Completed in 0.03s
Epoch 131: Training phase completed. Average Train Loss: 0.4696
Epoch 131: Starting validation phase...
  Epoch 131, Val Batch 1/1: Loading data...
  Epoch 131, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 131, Val Batch 1/1: Forward pass...
  Epoch 131, Val Batch 1/1: Calculating loss...
Epoch 131: Validation phase completed. Average Val Loss: 0.4051
Epoch 131 Summary ---> Train Loss: 0.4696 / Validation Loss: 0.4051
Epoch 131: Checking early stopping... (Current Best Loss: 0.3963, Epochs No Improve: 2)
  Epoch 131: Validation loss did not improve. Epochs without improvement: 3
Epoch 131: Stepping scheduler...
--- Epoch 131 completed in 0.68 seconds ---

--- Starting Epoch 132/1000 ---
Epoch 132: Starting training phase (4 batches)
  Epoch 132, Batch 1/4: Loading data to device...
  Epoch 132, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 132, Batch 1/4: Zeroing gradients...
  Epoch 132, Batch 1/4: Forward pass...
  Epoch 132, Batch 1/4: Calculating loss...
  Epoch 132, Batch 1/4: Backward pass...
  Epoch 132, Batch 1/4: Clipping gradients...
  Epoch 132, Batch 1/4: Optimizer step...
  Epoch 132, Batch 1/4: Completed in 0.19s
  Epoch 132, Batch 2/4: Loading data to device...
  Epoch 132, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 132, Batch 2/4: Zeroing gradients...
  Epoch 132, Batch 2/4: Forward pass...
  Epoch 132, Batch 2/4: Calculating loss...
  Epoch 132, Batch 2/4: Backward pass...
  Epoch 132, Batch 2/4: Clipping gradients...
  Epoch 132, Batch 2/4: Optimizer step...
  Epoch 132, Batch 2/4: Completed in 0.19s
  Epoch 132, Batch 3/4: Loading data to device...
  Epoch 132, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 132, Batch 3/4: Zeroing gradients...
  Epoch 132, Batch 3/4: Forward pass...
  Epoch 132, Batch 3/4: Calculating loss...
  Epoch 132, Batch 3/4: Backward pass...
  Epoch 132, Batch 3/4: Clipping gradients...
  Epoch 132, Batch 3/4: Optimizer step...
  Epoch 132, Batch 3/4: Completed in 0.19s
  Epoch 132, Batch 4/4: Loading data to device...
  Epoch 132, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 132, Batch 4/4: Zeroing gradients...
  Epoch 132, Batch 4/4: Forward pass...
  Epoch 132, Batch 4/4: Calculating loss...
  Epoch 132, Batch 4/4: Backward pass...
  Epoch 132, Batch 4/4: Clipping gradients...
  Epoch 132, Batch 4/4: Optimizer step...
  Epoch 132, Batch 4/4: Completed in 0.04s
Epoch 132: Training phase completed. Average Train Loss: 0.4363
Epoch 132: Starting validation phase...
  Epoch 132, Val Batch 1/1: Loading data...
  Epoch 132, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 132, Val Batch 1/1: Forward pass...
  Epoch 132, Val Batch 1/1: Calculating loss...
Epoch 132: Validation phase completed. Average Val Loss: 0.4013
Epoch 132 Summary ---> Train Loss: 0.4363 / Validation Loss: 0.4013
Epoch 132: Checking early stopping... (Current Best Loss: 0.3963, Epochs No Improve: 3)
  Epoch 132: Validation loss did not improve. Epochs without improvement: 4
Epoch 132: Stepping scheduler...
--- Epoch 132 completed in 0.69 seconds ---

--- Starting Epoch 133/1000 ---
Epoch 133: Starting training phase (4 batches)
  Epoch 133, Batch 1/4: Loading data to device...
  Epoch 133, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 133, Batch 1/4: Zeroing gradients...
  Epoch 133, Batch 1/4: Forward pass...
  Epoch 133, Batch 1/4: Calculating loss...
  Epoch 133, Batch 1/4: Backward pass...
  Epoch 133, Batch 1/4: Clipping gradients...
  Epoch 133, Batch 1/4: Optimizer step...
  Epoch 133, Batch 1/4: Completed in 0.20s
  Epoch 133, Batch 2/4: Loading data to device...
  Epoch 133, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 133, Batch 2/4: Zeroing gradients...
  Epoch 133, Batch 2/4: Forward pass...
  Epoch 133, Batch 2/4: Calculating loss...
  Epoch 133, Batch 2/4: Backward pass...
  Epoch 133, Batch 2/4: Clipping gradients...
  Epoch 133, Batch 2/4: Optimizer step...
  Epoch 133, Batch 2/4: Completed in 0.19s
  Epoch 133, Batch 3/4: Loading data to device...
  Epoch 133, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 133, Batch 3/4: Zeroing gradients...
  Epoch 133, Batch 3/4: Forward pass...
  Epoch 133, Batch 3/4: Calculating loss...
  Epoch 133, Batch 3/4: Backward pass...
  Epoch 133, Batch 3/4: Clipping gradients...
  Epoch 133, Batch 3/4: Optimizer step...
  Epoch 133, Batch 3/4: Completed in 0.19s
  Epoch 133, Batch 4/4: Loading data to device...
  Epoch 133, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 133, Batch 4/4: Zeroing gradients...
  Epoch 133, Batch 4/4: Forward pass...
  Epoch 133, Batch 4/4: Calculating loss...
  Epoch 133, Batch 4/4: Backward pass...
  Epoch 133, Batch 4/4: Clipping gradients...
  Epoch 133, Batch 4/4: Optimizer step...
  Epoch 133, Batch 4/4: Completed in 0.03s
Epoch 133: Training phase completed. Average Train Loss: 0.5022
Epoch 133: Starting validation phase...
  Epoch 133, Val Batch 1/1: Loading data...
  Epoch 133, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 133, Val Batch 1/1: Forward pass...
  Epoch 133, Val Batch 1/1: Calculating loss...
Epoch 133: Validation phase completed. Average Val Loss: 0.3937
Epoch 133 Summary ---> Train Loss: 0.5022 / Validation Loss: 0.3937
Epoch 133: Checking early stopping... (Current Best Loss: 0.3963, Epochs No Improve: 4)
  Epoch 133: Validation loss improved (0.3963 --> 0.3937). Saving model.
Epoch 133: Stepping scheduler...
--- Epoch 133 completed in 0.69 seconds ---

--- Starting Epoch 134/1000 ---
Epoch 134: Starting training phase (4 batches)
  Epoch 134, Batch 1/4: Loading data to device...
  Epoch 134, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 134, Batch 1/4: Zeroing gradients...
  Epoch 134, Batch 1/4: Forward pass...
  Epoch 134, Batch 1/4: Calculating loss...
  Epoch 134, Batch 1/4: Backward pass...
  Epoch 134, Batch 1/4: Clipping gradients...
  Epoch 134, Batch 1/4: Optimizer step...
  Epoch 134, Batch 1/4: Completed in 0.20s
  Epoch 134, Batch 2/4: Loading data to device...
  Epoch 134, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 134, Batch 2/4: Zeroing gradients...
  Epoch 134, Batch 2/4: Forward pass...
  Epoch 134, Batch 2/4: Calculating loss...
  Epoch 134, Batch 2/4: Backward pass...
  Epoch 134, Batch 2/4: Clipping gradients...
  Epoch 134, Batch 2/4: Optimizer step...
  Epoch 134, Batch 2/4: Completed in 0.19s
  Epoch 134, Batch 3/4: Loading data to device...
  Epoch 134, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 134, Batch 3/4: Zeroing gradients...
  Epoch 134, Batch 3/4: Forward pass...
  Epoch 134, Batch 3/4: Calculating loss...
  Epoch 134, Batch 3/4: Backward pass...
  Epoch 134, Batch 3/4: Clipping gradients...
  Epoch 134, Batch 3/4: Optimizer step...
  Epoch 134, Batch 3/4: Completed in 0.20s
  Epoch 134, Batch 4/4: Loading data to device...
  Epoch 134, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 134, Batch 4/4: Zeroing gradients...
  Epoch 134, Batch 4/4: Forward pass...
  Epoch 134, Batch 4/4: Calculating loss...
  Epoch 134, Batch 4/4: Backward pass...
  Epoch 134, Batch 4/4: Clipping gradients...
  Epoch 134, Batch 4/4: Optimizer step...
  Epoch 134, Batch 4/4: Completed in 0.03s
Epoch 134: Training phase completed. Average Train Loss: 0.5390
Epoch 134: Starting validation phase...
  Epoch 134, Val Batch 1/1: Loading data...
  Epoch 134, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 134, Val Batch 1/1: Forward pass...
  Epoch 134, Val Batch 1/1: Calculating loss...
Epoch 134: Validation phase completed. Average Val Loss: 0.3881
Epoch 134 Summary ---> Train Loss: 0.5390 / Validation Loss: 0.3881
Epoch 134: Checking early stopping... (Current Best Loss: 0.3937, Epochs No Improve: 0)
  Epoch 134: Validation loss improved (0.3937 --> 0.3881). Saving model.
Epoch 134: Stepping scheduler...
--- Epoch 134 completed in 0.69 seconds ---

--- Starting Epoch 135/1000 ---
Epoch 135: Starting training phase (4 batches)
  Epoch 135, Batch 1/4: Loading data to device...
  Epoch 135, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 135, Batch 1/4: Zeroing gradients...
  Epoch 135, Batch 1/4: Forward pass...
  Epoch 135, Batch 1/4: Calculating loss...
  Epoch 135, Batch 1/4: Backward pass...
  Epoch 135, Batch 1/4: Clipping gradients...
  Epoch 135, Batch 1/4: Optimizer step...
  Epoch 135, Batch 1/4: Completed in 0.20s
  Epoch 135, Batch 2/4: Loading data to device...
  Epoch 135, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 135, Batch 2/4: Zeroing gradients...
  Epoch 135, Batch 2/4: Forward pass...
  Epoch 135, Batch 2/4: Calculating loss...
  Epoch 135, Batch 2/4: Backward pass...
  Epoch 135, Batch 2/4: Clipping gradients...
  Epoch 135, Batch 2/4: Optimizer step...
  Epoch 135, Batch 2/4: Completed in 0.20s
  Epoch 135, Batch 3/4: Loading data to device...
  Epoch 135, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 135, Batch 3/4: Zeroing gradients...
  Epoch 135, Batch 3/4: Forward pass...
  Epoch 135, Batch 3/4: Calculating loss...
  Epoch 135, Batch 3/4: Backward pass...
  Epoch 135, Batch 3/4: Clipping gradients...
  Epoch 135, Batch 3/4: Optimizer step...
  Epoch 135, Batch 3/4: Completed in 0.19s
  Epoch 135, Batch 4/4: Loading data to device...
  Epoch 135, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 135, Batch 4/4: Zeroing gradients...
  Epoch 135, Batch 4/4: Forward pass...
  Epoch 135, Batch 4/4: Calculating loss...
  Epoch 135, Batch 4/4: Backward pass...
  Epoch 135, Batch 4/4: Clipping gradients...
  Epoch 135, Batch 4/4: Optimizer step...
  Epoch 135, Batch 4/4: Completed in 0.03s
Epoch 135: Training phase completed. Average Train Loss: 0.4796
Epoch 135: Starting validation phase...
  Epoch 135, Val Batch 1/1: Loading data...
  Epoch 135, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 135, Val Batch 1/1: Forward pass...
  Epoch 135, Val Batch 1/1: Calculating loss...
Epoch 135: Validation phase completed. Average Val Loss: 0.3780
Epoch 135 Summary ---> Train Loss: 0.4796 / Validation Loss: 0.3780
Epoch 135: Checking early stopping... (Current Best Loss: 0.3881, Epochs No Improve: 0)
  Epoch 135: Validation loss improved (0.3881 --> 0.3780). Saving model.
Epoch 135: Stepping scheduler...
--- Epoch 135 completed in 0.69 seconds ---

--- Starting Epoch 136/1000 ---
Epoch 136: Starting training phase (4 batches)
  Epoch 136, Batch 1/4: Loading data to device...
  Epoch 136, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 136, Batch 1/4: Zeroing gradients...
  Epoch 136, Batch 1/4: Forward pass...
  Epoch 136, Batch 1/4: Calculating loss...
  Epoch 136, Batch 1/4: Backward pass...
  Epoch 136, Batch 1/4: Clipping gradients...
  Epoch 136, Batch 1/4: Optimizer step...
  Epoch 136, Batch 1/4: Completed in 0.20s
  Epoch 136, Batch 2/4: Loading data to device...
  Epoch 136, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 136, Batch 2/4: Zeroing gradients...
  Epoch 136, Batch 2/4: Forward pass...
  Epoch 136, Batch 2/4: Calculating loss...
  Epoch 136, Batch 2/4: Backward pass...
  Epoch 136, Batch 2/4: Clipping gradients...
  Epoch 136, Batch 2/4: Optimizer step...
  Epoch 136, Batch 2/4: Completed in 0.19s
  Epoch 136, Batch 3/4: Loading data to device...
  Epoch 136, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 136, Batch 3/4: Zeroing gradients...
  Epoch 136, Batch 3/4: Forward pass...
  Epoch 136, Batch 3/4: Calculating loss...
  Epoch 136, Batch 3/4: Backward pass...
  Epoch 136, Batch 3/4: Clipping gradients...
  Epoch 136, Batch 3/4: Optimizer step...
  Epoch 136, Batch 3/4: Completed in 0.19s
  Epoch 136, Batch 4/4: Loading data to device...
  Epoch 136, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 136, Batch 4/4: Zeroing gradients...
  Epoch 136, Batch 4/4: Forward pass...
  Epoch 136, Batch 4/4: Calculating loss...
  Epoch 136, Batch 4/4: Backward pass...
  Epoch 136, Batch 4/4: Clipping gradients...
  Epoch 136, Batch 4/4: Optimizer step...
  Epoch 136, Batch 4/4: Completed in 0.03s
Epoch 136: Training phase completed. Average Train Loss: 0.4342
Epoch 136: Starting validation phase...
  Epoch 136, Val Batch 1/1: Loading data...
  Epoch 136, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 136, Val Batch 1/1: Forward pass...
  Epoch 136, Val Batch 1/1: Calculating loss...
Epoch 136: Validation phase completed. Average Val Loss: 0.3758
Epoch 136 Summary ---> Train Loss: 0.4342 / Validation Loss: 0.3758
Epoch 136: Checking early stopping... (Current Best Loss: 0.3780, Epochs No Improve: 0)
  Epoch 136: Validation loss improved (0.3780 --> 0.3758). Saving model.
Epoch 136: Stepping scheduler...
--- Epoch 136 completed in 0.68 seconds ---

--- Starting Epoch 137/1000 ---
Epoch 137: Starting training phase (4 batches)
  Epoch 137, Batch 1/4: Loading data to device...
  Epoch 137, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 137, Batch 1/4: Zeroing gradients...
  Epoch 137, Batch 1/4: Forward pass...
  Epoch 137, Batch 1/4: Calculating loss...
  Epoch 137, Batch 1/4: Backward pass...
  Epoch 137, Batch 1/4: Clipping gradients...
  Epoch 137, Batch 1/4: Optimizer step...
  Epoch 137, Batch 1/4: Completed in 0.19s
  Epoch 137, Batch 2/4: Loading data to device...
  Epoch 137, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 137, Batch 2/4: Zeroing gradients...
  Epoch 137, Batch 2/4: Forward pass...
  Epoch 137, Batch 2/4: Calculating loss...
  Epoch 137, Batch 2/4: Backward pass...
  Epoch 137, Batch 2/4: Clipping gradients...
  Epoch 137, Batch 2/4: Optimizer step...
  Epoch 137, Batch 2/4: Completed in 0.19s
  Epoch 137, Batch 3/4: Loading data to device...
  Epoch 137, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 137, Batch 3/4: Zeroing gradients...
  Epoch 137, Batch 3/4: Forward pass...
  Epoch 137, Batch 3/4: Calculating loss...
  Epoch 137, Batch 3/4: Backward pass...
  Epoch 137, Batch 3/4: Clipping gradients...
  Epoch 137, Batch 3/4: Optimizer step...
  Epoch 137, Batch 3/4: Completed in 0.19s
  Epoch 137, Batch 4/4: Loading data to device...
  Epoch 137, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 137, Batch 4/4: Zeroing gradients...
  Epoch 137, Batch 4/4: Forward pass...
  Epoch 137, Batch 4/4: Calculating loss...
  Epoch 137, Batch 4/4: Backward pass...
  Epoch 137, Batch 4/4: Clipping gradients...
  Epoch 137, Batch 4/4: Optimizer step...
  Epoch 137, Batch 4/4: Completed in 0.03s
Epoch 137: Training phase completed. Average Train Loss: 0.5079
Epoch 137: Starting validation phase...
  Epoch 137, Val Batch 1/1: Loading data...
  Epoch 137, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 137, Val Batch 1/1: Forward pass...
  Epoch 137, Val Batch 1/1: Calculating loss...
Epoch 137: Validation phase completed. Average Val Loss: 0.3751
Epoch 137 Summary ---> Train Loss: 0.5079 / Validation Loss: 0.3751
Epoch 137: Checking early stopping... (Current Best Loss: 0.3758, Epochs No Improve: 0)
  Epoch 137: Validation loss improved (0.3758 --> 0.3751). Saving model.
Epoch 137: Stepping scheduler...
--- Epoch 137 completed in 0.68 seconds ---

--- Starting Epoch 138/1000 ---
Epoch 138: Starting training phase (4 batches)
  Epoch 138, Batch 1/4: Loading data to device...
  Epoch 138, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 138, Batch 1/4: Zeroing gradients...
  Epoch 138, Batch 1/4: Forward pass...
  Epoch 138, Batch 1/4: Calculating loss...
  Epoch 138, Batch 1/4: Backward pass...
  Epoch 138, Batch 1/4: Clipping gradients...
  Epoch 138, Batch 1/4: Optimizer step...
  Epoch 138, Batch 1/4: Completed in 0.19s
  Epoch 138, Batch 2/4: Loading data to device...
  Epoch 138, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 138, Batch 2/4: Zeroing gradients...
  Epoch 138, Batch 2/4: Forward pass...
  Epoch 138, Batch 2/4: Calculating loss...
  Epoch 138, Batch 2/4: Backward pass...
  Epoch 138, Batch 2/4: Clipping gradients...
  Epoch 138, Batch 2/4: Optimizer step...
  Epoch 138, Batch 2/4: Completed in 0.19s
  Epoch 138, Batch 3/4: Loading data to device...
  Epoch 138, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 138, Batch 3/4: Zeroing gradients...
  Epoch 138, Batch 3/4: Forward pass...
  Epoch 138, Batch 3/4: Calculating loss...
  Epoch 138, Batch 3/4: Backward pass...
  Epoch 138, Batch 3/4: Clipping gradients...
  Epoch 138, Batch 3/4: Optimizer step...
  Epoch 138, Batch 3/4: Completed in 0.19s
  Epoch 138, Batch 4/4: Loading data to device...
  Epoch 138, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 138, Batch 4/4: Zeroing gradients...
  Epoch 138, Batch 4/4: Forward pass...
  Epoch 138, Batch 4/4: Calculating loss...
  Epoch 138, Batch 4/4: Backward pass...
  Epoch 138, Batch 4/4: Clipping gradients...
  Epoch 138, Batch 4/4: Optimizer step...
  Epoch 138, Batch 4/4: Completed in 0.03s
Epoch 138: Training phase completed. Average Train Loss: 0.4292
Epoch 138: Starting validation phase...
  Epoch 138, Val Batch 1/1: Loading data...
  Epoch 138, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 138, Val Batch 1/1: Forward pass...
  Epoch 138, Val Batch 1/1: Calculating loss...
Epoch 138: Validation phase completed. Average Val Loss: 0.3769
Epoch 138 Summary ---> Train Loss: 0.4292 / Validation Loss: 0.3769
Epoch 138: Checking early stopping... (Current Best Loss: 0.3751, Epochs No Improve: 0)
  Epoch 138: Validation loss did not improve. Epochs without improvement: 1
Epoch 138: Stepping scheduler...
--- Epoch 138 completed in 0.67 seconds ---

--- Starting Epoch 139/1000 ---
Epoch 139: Starting training phase (4 batches)
  Epoch 139, Batch 1/4: Loading data to device...
  Epoch 139, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 139, Batch 1/4: Zeroing gradients...
  Epoch 139, Batch 1/4: Forward pass...
  Epoch 139, Batch 1/4: Calculating loss...
  Epoch 139, Batch 1/4: Backward pass...
  Epoch 139, Batch 1/4: Clipping gradients...
  Epoch 139, Batch 1/4: Optimizer step...
  Epoch 139, Batch 1/4: Completed in 0.19s
  Epoch 139, Batch 2/4: Loading data to device...
  Epoch 139, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 139, Batch 2/4: Zeroing gradients...
  Epoch 139, Batch 2/4: Forward pass...
  Epoch 139, Batch 2/4: Calculating loss...
  Epoch 139, Batch 2/4: Backward pass...
  Epoch 139, Batch 2/4: Clipping gradients...
  Epoch 139, Batch 2/4: Optimizer step...
  Epoch 139, Batch 2/4: Completed in 0.19s
  Epoch 139, Batch 3/4: Loading data to device...
  Epoch 139, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 139, Batch 3/4: Zeroing gradients...
  Epoch 139, Batch 3/4: Forward pass...
  Epoch 139, Batch 3/4: Calculating loss...
  Epoch 139, Batch 3/4: Backward pass...
  Epoch 139, Batch 3/4: Clipping gradients...
  Epoch 139, Batch 3/4: Optimizer step...
  Epoch 139, Batch 3/4: Completed in 0.19s
  Epoch 139, Batch 4/4: Loading data to device...
  Epoch 139, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 139, Batch 4/4: Zeroing gradients...
  Epoch 139, Batch 4/4: Forward pass...
  Epoch 139, Batch 4/4: Calculating loss...
  Epoch 139, Batch 4/4: Backward pass...
  Epoch 139, Batch 4/4: Clipping gradients...
  Epoch 139, Batch 4/4: Optimizer step...
  Epoch 139, Batch 4/4: Completed in 0.03s
Epoch 139: Training phase completed. Average Train Loss: 0.4613
Epoch 139: Starting validation phase...
  Epoch 139, Val Batch 1/1: Loading data...
  Epoch 139, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 139, Val Batch 1/1: Forward pass...
  Epoch 139, Val Batch 1/1: Calculating loss...
Epoch 139: Validation phase completed. Average Val Loss: 0.3785
Epoch 139 Summary ---> Train Loss: 0.4613 / Validation Loss: 0.3785
Epoch 139: Checking early stopping... (Current Best Loss: 0.3751, Epochs No Improve: 1)
  Epoch 139: Validation loss did not improve. Epochs without improvement: 2
Epoch 139: Stepping scheduler...
--- Epoch 139 completed in 0.68 seconds ---

--- Starting Epoch 140/1000 ---
Epoch 140: Starting training phase (4 batches)
  Epoch 140, Batch 1/4: Loading data to device...
  Epoch 140, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 140, Batch 1/4: Zeroing gradients...
  Epoch 140, Batch 1/4: Forward pass...
  Epoch 140, Batch 1/4: Calculating loss...
  Epoch 140, Batch 1/4: Backward pass...
  Epoch 140, Batch 1/4: Clipping gradients...
  Epoch 140, Batch 1/4: Optimizer step...
  Epoch 140, Batch 1/4: Completed in 0.19s
  Epoch 140, Batch 2/4: Loading data to device...
  Epoch 140, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 140, Batch 2/4: Zeroing gradients...
  Epoch 140, Batch 2/4: Forward pass...
  Epoch 140, Batch 2/4: Calculating loss...
  Epoch 140, Batch 2/4: Backward pass...
  Epoch 140, Batch 2/4: Clipping gradients...
  Epoch 140, Batch 2/4: Optimizer step...
  Epoch 140, Batch 2/4: Completed in 0.19s
  Epoch 140, Batch 3/4: Loading data to device...
  Epoch 140, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 140, Batch 3/4: Zeroing gradients...
  Epoch 140, Batch 3/4: Forward pass...
  Epoch 140, Batch 3/4: Calculating loss...
  Epoch 140, Batch 3/4: Backward pass...
  Epoch 140, Batch 3/4: Clipping gradients...
  Epoch 140, Batch 3/4: Optimizer step...
  Epoch 140, Batch 3/4: Completed in 0.19s
  Epoch 140, Batch 4/4: Loading data to device...
  Epoch 140, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 140, Batch 4/4: Zeroing gradients...
  Epoch 140, Batch 4/4: Forward pass...
  Epoch 140, Batch 4/4: Calculating loss...
  Epoch 140, Batch 4/4: Backward pass...
  Epoch 140, Batch 4/4: Clipping gradients...
  Epoch 140, Batch 4/4: Optimizer step...
  Epoch 140, Batch 4/4: Completed in 0.04s
Epoch 140: Training phase completed. Average Train Loss: 0.4419
Epoch 140: Starting validation phase...
  Epoch 140, Val Batch 1/1: Loading data...
  Epoch 140, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 140, Val Batch 1/1: Forward pass...
  Epoch 140, Val Batch 1/1: Calculating loss...
Epoch 140: Validation phase completed. Average Val Loss: 0.3820
Epoch 140 Summary ---> Train Loss: 0.4419 / Validation Loss: 0.3820
Epoch 140: Checking early stopping... (Current Best Loss: 0.3751, Epochs No Improve: 2)
  Epoch 140: Validation loss did not improve. Epochs without improvement: 3
Epoch 140: Stepping scheduler...
--- Epoch 140 completed in 0.67 seconds ---

--- Starting Epoch 141/1000 ---
Epoch 141: Starting training phase (4 batches)
  Epoch 141, Batch 1/4: Loading data to device...
  Epoch 141, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 141, Batch 1/4: Zeroing gradients...
  Epoch 141, Batch 1/4: Forward pass...
  Epoch 141, Batch 1/4: Calculating loss...
  Epoch 141, Batch 1/4: Backward pass...
  Epoch 141, Batch 1/4: Clipping gradients...
  Epoch 141, Batch 1/4: Optimizer step...
  Epoch 141, Batch 1/4: Completed in 0.20s
  Epoch 141, Batch 2/4: Loading data to device...
  Epoch 141, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 141, Batch 2/4: Zeroing gradients...
  Epoch 141, Batch 2/4: Forward pass...
  Epoch 141, Batch 2/4: Calculating loss...
  Epoch 141, Batch 2/4: Backward pass...
  Epoch 141, Batch 2/4: Clipping gradients...
  Epoch 141, Batch 2/4: Optimizer step...
  Epoch 141, Batch 2/4: Completed in 0.20s
  Epoch 141, Batch 3/4: Loading data to device...
  Epoch 141, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 141, Batch 3/4: Zeroing gradients...
  Epoch 141, Batch 3/4: Forward pass...
  Epoch 141, Batch 3/4: Calculating loss...
  Epoch 141, Batch 3/4: Backward pass...
  Epoch 141, Batch 3/4: Clipping gradients...
  Epoch 141, Batch 3/4: Optimizer step...
  Epoch 141, Batch 3/4: Completed in 0.20s
  Epoch 141, Batch 4/4: Loading data to device...
  Epoch 141, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 141, Batch 4/4: Zeroing gradients...
  Epoch 141, Batch 4/4: Forward pass...
  Epoch 141, Batch 4/4: Calculating loss...
  Epoch 141, Batch 4/4: Backward pass...
  Epoch 141, Batch 4/4: Clipping gradients...
  Epoch 141, Batch 4/4: Optimizer step...
  Epoch 141, Batch 4/4: Completed in 0.03s
Epoch 141: Training phase completed. Average Train Loss: 0.4234
Epoch 141: Starting validation phase...
  Epoch 141, Val Batch 1/1: Loading data...
  Epoch 141, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 141, Val Batch 1/1: Forward pass...
  Epoch 141, Val Batch 1/1: Calculating loss...
Epoch 141: Validation phase completed. Average Val Loss: 0.3941
Epoch 141 Summary ---> Train Loss: 0.4234 / Validation Loss: 0.3941
Epoch 141: Checking early stopping... (Current Best Loss: 0.3751, Epochs No Improve: 3)
  Epoch 141: Validation loss did not improve. Epochs without improvement: 4
Epoch 141: Stepping scheduler...
--- Epoch 141 completed in 0.69 seconds ---

--- Starting Epoch 142/1000 ---
Epoch 142: Starting training phase (4 batches)
  Epoch 142, Batch 1/4: Loading data to device...
  Epoch 142, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 142, Batch 1/4: Zeroing gradients...
  Epoch 142, Batch 1/4: Forward pass...
  Epoch 142, Batch 1/4: Calculating loss...
  Epoch 142, Batch 1/4: Backward pass...
  Epoch 142, Batch 1/4: Clipping gradients...
  Epoch 142, Batch 1/4: Optimizer step...
  Epoch 142, Batch 1/4: Completed in 0.19s
  Epoch 142, Batch 2/4: Loading data to device...
  Epoch 142, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 142, Batch 2/4: Zeroing gradients...
  Epoch 142, Batch 2/4: Forward pass...
  Epoch 142, Batch 2/4: Calculating loss...
  Epoch 142, Batch 2/4: Backward pass...
  Epoch 142, Batch 2/4: Clipping gradients...
  Epoch 142, Batch 2/4: Optimizer step...
  Epoch 142, Batch 2/4: Completed in 0.19s
  Epoch 142, Batch 3/4: Loading data to device...
  Epoch 142, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 142, Batch 3/4: Zeroing gradients...
  Epoch 142, Batch 3/4: Forward pass...
  Epoch 142, Batch 3/4: Calculating loss...
  Epoch 142, Batch 3/4: Backward pass...
  Epoch 142, Batch 3/4: Clipping gradients...
  Epoch 142, Batch 3/4: Optimizer step...
  Epoch 142, Batch 3/4: Completed in 0.19s
  Epoch 142, Batch 4/4: Loading data to device...
  Epoch 142, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 142, Batch 4/4: Zeroing gradients...
  Epoch 142, Batch 4/4: Forward pass...
  Epoch 142, Batch 4/4: Calculating loss...
  Epoch 142, Batch 4/4: Backward pass...
  Epoch 142, Batch 4/4: Clipping gradients...
  Epoch 142, Batch 4/4: Optimizer step...
  Epoch 142, Batch 4/4: Completed in 0.03s
Epoch 142: Training phase completed. Average Train Loss: 0.5246
Epoch 142: Starting validation phase...
  Epoch 142, Val Batch 1/1: Loading data...
  Epoch 142, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 142, Val Batch 1/1: Forward pass...
  Epoch 142, Val Batch 1/1: Calculating loss...
Epoch 142: Validation phase completed. Average Val Loss: 0.3779
Epoch 142 Summary ---> Train Loss: 0.5246 / Validation Loss: 0.3779
Epoch 142: Checking early stopping... (Current Best Loss: 0.3751, Epochs No Improve: 4)
  Epoch 142: Validation loss did not improve. Epochs without improvement: 5
Epoch 142: Stepping scheduler...
--- Epoch 142 completed in 0.67 seconds ---

--- Starting Epoch 143/1000 ---
Epoch 143: Starting training phase (4 batches)
  Epoch 143, Batch 1/4: Loading data to device...
  Epoch 143, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 143, Batch 1/4: Zeroing gradients...
  Epoch 143, Batch 1/4: Forward pass...
  Epoch 143, Batch 1/4: Calculating loss...
  Epoch 143, Batch 1/4: Backward pass...
  Epoch 143, Batch 1/4: Clipping gradients...
  Epoch 143, Batch 1/4: Optimizer step...
  Epoch 143, Batch 1/4: Completed in 0.19s
  Epoch 143, Batch 2/4: Loading data to device...
  Epoch 143, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 143, Batch 2/4: Zeroing gradients...
  Epoch 143, Batch 2/4: Forward pass...
  Epoch 143, Batch 2/4: Calculating loss...
  Epoch 143, Batch 2/4: Backward pass...
  Epoch 143, Batch 2/4: Clipping gradients...
  Epoch 143, Batch 2/4: Optimizer step...
  Epoch 143, Batch 2/4: Completed in 0.19s
  Epoch 143, Batch 3/4: Loading data to device...
  Epoch 143, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 143, Batch 3/4: Zeroing gradients...
  Epoch 143, Batch 3/4: Forward pass...
  Epoch 143, Batch 3/4: Calculating loss...
  Epoch 143, Batch 3/4: Backward pass...
  Epoch 143, Batch 3/4: Clipping gradients...
  Epoch 143, Batch 3/4: Optimizer step...
  Epoch 143, Batch 3/4: Completed in 0.19s
  Epoch 143, Batch 4/4: Loading data to device...
  Epoch 143, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 143, Batch 4/4: Zeroing gradients...
  Epoch 143, Batch 4/4: Forward pass...
  Epoch 143, Batch 4/4: Calculating loss...
  Epoch 143, Batch 4/4: Backward pass...
  Epoch 143, Batch 4/4: Clipping gradients...
  Epoch 143, Batch 4/4: Optimizer step...
  Epoch 143, Batch 4/4: Completed in 0.03s
Epoch 143: Training phase completed. Average Train Loss: 0.4435
Epoch 143: Starting validation phase...
  Epoch 143, Val Batch 1/1: Loading data...
  Epoch 143, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 143, Val Batch 1/1: Forward pass...
  Epoch 143, Val Batch 1/1: Calculating loss...
Epoch 143: Validation phase completed. Average Val Loss: 0.3731
Epoch 143 Summary ---> Train Loss: 0.4435 / Validation Loss: 0.3731
Epoch 143: Checking early stopping... (Current Best Loss: 0.3751, Epochs No Improve: 5)
  Epoch 143: Validation loss improved (0.3751 --> 0.3731). Saving model.
Epoch 143: Stepping scheduler...
--- Epoch 143 completed in 0.68 seconds ---

--- Starting Epoch 144/1000 ---
Epoch 144: Starting training phase (4 batches)
  Epoch 144, Batch 1/4: Loading data to device...
  Epoch 144, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 144, Batch 1/4: Zeroing gradients...
  Epoch 144, Batch 1/4: Forward pass...
  Epoch 144, Batch 1/4: Calculating loss...
  Epoch 144, Batch 1/4: Backward pass...
  Epoch 144, Batch 1/4: Clipping gradients...
  Epoch 144, Batch 1/4: Optimizer step...
  Epoch 144, Batch 1/4: Completed in 0.19s
  Epoch 144, Batch 2/4: Loading data to device...
  Epoch 144, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 144, Batch 2/4: Zeroing gradients...
  Epoch 144, Batch 2/4: Forward pass...
  Epoch 144, Batch 2/4: Calculating loss...
  Epoch 144, Batch 2/4: Backward pass...
  Epoch 144, Batch 2/4: Clipping gradients...
  Epoch 144, Batch 2/4: Optimizer step...
  Epoch 144, Batch 2/4: Completed in 0.19s
  Epoch 144, Batch 3/4: Loading data to device...
  Epoch 144, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 144, Batch 3/4: Zeroing gradients...
  Epoch 144, Batch 3/4: Forward pass...
  Epoch 144, Batch 3/4: Calculating loss...
  Epoch 144, Batch 3/4: Backward pass...
  Epoch 144, Batch 3/4: Clipping gradients...
  Epoch 144, Batch 3/4: Optimizer step...
  Epoch 144, Batch 3/4: Completed in 0.19s
  Epoch 144, Batch 4/4: Loading data to device...
  Epoch 144, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 144, Batch 4/4: Zeroing gradients...
  Epoch 144, Batch 4/4: Forward pass...
  Epoch 144, Batch 4/4: Calculating loss...
  Epoch 144, Batch 4/4: Backward pass...
  Epoch 144, Batch 4/4: Clipping gradients...
  Epoch 144, Batch 4/4: Optimizer step...
  Epoch 144, Batch 4/4: Completed in 0.04s
Epoch 144: Training phase completed. Average Train Loss: 0.4865
Epoch 144: Starting validation phase...
  Epoch 144, Val Batch 1/1: Loading data...
  Epoch 144, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 144, Val Batch 1/1: Forward pass...
  Epoch 144, Val Batch 1/1: Calculating loss...
Epoch 144: Validation phase completed. Average Val Loss: 0.3802
Epoch 144 Summary ---> Train Loss: 0.4865 / Validation Loss: 0.3802
Epoch 144: Checking early stopping... (Current Best Loss: 0.3731, Epochs No Improve: 0)
  Epoch 144: Validation loss did not improve. Epochs without improvement: 1
Epoch 144: Stepping scheduler...
--- Epoch 144 completed in 0.68 seconds ---

--- Starting Epoch 145/1000 ---
Epoch 145: Starting training phase (4 batches)
  Epoch 145, Batch 1/4: Loading data to device...
  Epoch 145, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 145, Batch 1/4: Zeroing gradients...
  Epoch 145, Batch 1/4: Forward pass...
  Epoch 145, Batch 1/4: Calculating loss...
  Epoch 145, Batch 1/4: Backward pass...
  Epoch 145, Batch 1/4: Clipping gradients...
  Epoch 145, Batch 1/4: Optimizer step...
  Epoch 145, Batch 1/4: Completed in 0.19s
  Epoch 145, Batch 2/4: Loading data to device...
  Epoch 145, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 145, Batch 2/4: Zeroing gradients...
  Epoch 145, Batch 2/4: Forward pass...
  Epoch 145, Batch 2/4: Calculating loss...
  Epoch 145, Batch 2/4: Backward pass...
  Epoch 145, Batch 2/4: Clipping gradients...
  Epoch 145, Batch 2/4: Optimizer step...
  Epoch 145, Batch 2/4: Completed in 0.19s
  Epoch 145, Batch 3/4: Loading data to device...
  Epoch 145, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 145, Batch 3/4: Zeroing gradients...
  Epoch 145, Batch 3/4: Forward pass...
  Epoch 145, Batch 3/4: Calculating loss...
  Epoch 145, Batch 3/4: Backward pass...
  Epoch 145, Batch 3/4: Clipping gradients...
  Epoch 145, Batch 3/4: Optimizer step...
  Epoch 145, Batch 3/4: Completed in 0.20s
  Epoch 145, Batch 4/4: Loading data to device...
  Epoch 145, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 145, Batch 4/4: Zeroing gradients...
  Epoch 145, Batch 4/4: Forward pass...
  Epoch 145, Batch 4/4: Calculating loss...
  Epoch 145, Batch 4/4: Backward pass...
  Epoch 145, Batch 4/4: Clipping gradients...
  Epoch 145, Batch 4/4: Optimizer step...
  Epoch 145, Batch 4/4: Completed in 0.03s
Epoch 145: Training phase completed. Average Train Loss: 0.4054
Epoch 145: Starting validation phase...
  Epoch 145, Val Batch 1/1: Loading data...
  Epoch 145, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 145, Val Batch 1/1: Forward pass...
  Epoch 145, Val Batch 1/1: Calculating loss...
Epoch 145: Validation phase completed. Average Val Loss: 0.3831
Epoch 145 Summary ---> Train Loss: 0.4054 / Validation Loss: 0.3831
Epoch 145: Checking early stopping... (Current Best Loss: 0.3731, Epochs No Improve: 1)
  Epoch 145: Validation loss did not improve. Epochs without improvement: 2
Epoch 145: Stepping scheduler...
--- Epoch 145 completed in 0.69 seconds ---

--- Starting Epoch 146/1000 ---
Epoch 146: Starting training phase (4 batches)
  Epoch 146, Batch 1/4: Loading data to device...
  Epoch 146, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 146, Batch 1/4: Zeroing gradients...
  Epoch 146, Batch 1/4: Forward pass...
  Epoch 146, Batch 1/4: Calculating loss...
  Epoch 146, Batch 1/4: Backward pass...
  Epoch 146, Batch 1/4: Clipping gradients...
  Epoch 146, Batch 1/4: Optimizer step...
  Epoch 146, Batch 1/4: Completed in 0.20s
  Epoch 146, Batch 2/4: Loading data to device...
  Epoch 146, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 146, Batch 2/4: Zeroing gradients...
  Epoch 146, Batch 2/4: Forward pass...
  Epoch 146, Batch 2/4: Calculating loss...
  Epoch 146, Batch 2/4: Backward pass...
  Epoch 146, Batch 2/4: Clipping gradients...
  Epoch 146, Batch 2/4: Optimizer step...
  Epoch 146, Batch 2/4: Completed in 0.19s
  Epoch 146, Batch 3/4: Loading data to device...
  Epoch 146, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 146, Batch 3/4: Zeroing gradients...
  Epoch 146, Batch 3/4: Forward pass...
  Epoch 146, Batch 3/4: Calculating loss...
  Epoch 146, Batch 3/4: Backward pass...
  Epoch 146, Batch 3/4: Clipping gradients...
  Epoch 146, Batch 3/4: Optimizer step...
  Epoch 146, Batch 3/4: Completed in 0.19s
  Epoch 146, Batch 4/4: Loading data to device...
  Epoch 146, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 146, Batch 4/4: Zeroing gradients...
  Epoch 146, Batch 4/4: Forward pass...
  Epoch 146, Batch 4/4: Calculating loss...
  Epoch 146, Batch 4/4: Backward pass...
  Epoch 146, Batch 4/4: Clipping gradients...
  Epoch 146, Batch 4/4: Optimizer step...
  Epoch 146, Batch 4/4: Completed in 0.03s
Epoch 146: Training phase completed. Average Train Loss: 0.4652
Epoch 146: Starting validation phase...
  Epoch 146, Val Batch 1/1: Loading data...
  Epoch 146, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 146, Val Batch 1/1: Forward pass...
  Epoch 146, Val Batch 1/1: Calculating loss...
Epoch 146: Validation phase completed. Average Val Loss: 0.3794
Epoch 146 Summary ---> Train Loss: 0.4652 / Validation Loss: 0.3794
Epoch 146: Checking early stopping... (Current Best Loss: 0.3731, Epochs No Improve: 2)
  Epoch 146: Validation loss did not improve. Epochs without improvement: 3
Epoch 146: Stepping scheduler...
--- Epoch 146 completed in 0.68 seconds ---

--- Starting Epoch 147/1000 ---
Epoch 147: Starting training phase (4 batches)
  Epoch 147, Batch 1/4: Loading data to device...
  Epoch 147, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 147, Batch 1/4: Zeroing gradients...
  Epoch 147, Batch 1/4: Forward pass...
  Epoch 147, Batch 1/4: Calculating loss...
  Epoch 147, Batch 1/4: Backward pass...
  Epoch 147, Batch 1/4: Clipping gradients...
  Epoch 147, Batch 1/4: Optimizer step...
  Epoch 147, Batch 1/4: Completed in 0.19s
  Epoch 147, Batch 2/4: Loading data to device...
  Epoch 147, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 147, Batch 2/4: Zeroing gradients...
  Epoch 147, Batch 2/4: Forward pass...
  Epoch 147, Batch 2/4: Calculating loss...
  Epoch 147, Batch 2/4: Backward pass...
  Epoch 147, Batch 2/4: Clipping gradients...
  Epoch 147, Batch 2/4: Optimizer step...
  Epoch 147, Batch 2/4: Completed in 0.19s
  Epoch 147, Batch 3/4: Loading data to device...
  Epoch 147, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 147, Batch 3/4: Zeroing gradients...
  Epoch 147, Batch 3/4: Forward pass...
  Epoch 147, Batch 3/4: Calculating loss...
  Epoch 147, Batch 3/4: Backward pass...
  Epoch 147, Batch 3/4: Clipping gradients...
  Epoch 147, Batch 3/4: Optimizer step...
  Epoch 147, Batch 3/4: Completed in 0.20s
  Epoch 147, Batch 4/4: Loading data to device...
  Epoch 147, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 147, Batch 4/4: Zeroing gradients...
  Epoch 147, Batch 4/4: Forward pass...
  Epoch 147, Batch 4/4: Calculating loss...
  Epoch 147, Batch 4/4: Backward pass...
  Epoch 147, Batch 4/4: Clipping gradients...
  Epoch 147, Batch 4/4: Optimizer step...
  Epoch 147, Batch 4/4: Completed in 0.03s
Epoch 147: Training phase completed. Average Train Loss: 0.4771
Epoch 147: Starting validation phase...
  Epoch 147, Val Batch 1/1: Loading data...
  Epoch 147, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 147, Val Batch 1/1: Forward pass...
  Epoch 147, Val Batch 1/1: Calculating loss...
Epoch 147: Validation phase completed. Average Val Loss: 0.3792
Epoch 147 Summary ---> Train Loss: 0.4771 / Validation Loss: 0.3792
Epoch 147: Checking early stopping... (Current Best Loss: 0.3731, Epochs No Improve: 3)
  Epoch 147: Validation loss did not improve. Epochs without improvement: 4
Epoch 147: Stepping scheduler...
--- Epoch 147 completed in 0.68 seconds ---

--- Starting Epoch 148/1000 ---
Epoch 148: Starting training phase (4 batches)
  Epoch 148, Batch 1/4: Loading data to device...
  Epoch 148, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 148, Batch 1/4: Zeroing gradients...
  Epoch 148, Batch 1/4: Forward pass...
  Epoch 148, Batch 1/4: Calculating loss...
  Epoch 148, Batch 1/4: Backward pass...
  Epoch 148, Batch 1/4: Clipping gradients...
  Epoch 148, Batch 1/4: Optimizer step...
  Epoch 148, Batch 1/4: Completed in 0.19s
  Epoch 148, Batch 2/4: Loading data to device...
  Epoch 148, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 148, Batch 2/4: Zeroing gradients...
  Epoch 148, Batch 2/4: Forward pass...
  Epoch 148, Batch 2/4: Calculating loss...
  Epoch 148, Batch 2/4: Backward pass...
  Epoch 148, Batch 2/4: Clipping gradients...
  Epoch 148, Batch 2/4: Optimizer step...
  Epoch 148, Batch 2/4: Completed in 0.19s
  Epoch 148, Batch 3/4: Loading data to device...
  Epoch 148, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 148, Batch 3/4: Zeroing gradients...
  Epoch 148, Batch 3/4: Forward pass...
  Epoch 148, Batch 3/4: Calculating loss...
  Epoch 148, Batch 3/4: Backward pass...
  Epoch 148, Batch 3/4: Clipping gradients...
  Epoch 148, Batch 3/4: Optimizer step...
  Epoch 148, Batch 3/4: Completed in 0.19s
  Epoch 148, Batch 4/4: Loading data to device...
  Epoch 148, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 148, Batch 4/4: Zeroing gradients...
  Epoch 148, Batch 4/4: Forward pass...
  Epoch 148, Batch 4/4: Calculating loss...
  Epoch 148, Batch 4/4: Backward pass...
  Epoch 148, Batch 4/4: Clipping gradients...
  Epoch 148, Batch 4/4: Optimizer step...
  Epoch 148, Batch 4/4: Completed in 0.03s
Epoch 148: Training phase completed. Average Train Loss: 0.4527
Epoch 148: Starting validation phase...
  Epoch 148, Val Batch 1/1: Loading data...
  Epoch 148, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 148, Val Batch 1/1: Forward pass...
  Epoch 148, Val Batch 1/1: Calculating loss...
Epoch 148: Validation phase completed. Average Val Loss: 0.3791
Epoch 148 Summary ---> Train Loss: 0.4527 / Validation Loss: 0.3791
Epoch 148: Checking early stopping... (Current Best Loss: 0.3731, Epochs No Improve: 4)
  Epoch 148: Validation loss did not improve. Epochs without improvement: 5
Epoch 148: Stepping scheduler...
--- Epoch 148 completed in 0.67 seconds ---

--- Starting Epoch 149/1000 ---
Epoch 149: Starting training phase (4 batches)
  Epoch 149, Batch 1/4: Loading data to device...
  Epoch 149, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 149, Batch 1/4: Zeroing gradients...
  Epoch 149, Batch 1/4: Forward pass...
  Epoch 149, Batch 1/4: Calculating loss...
  Epoch 149, Batch 1/4: Backward pass...
  Epoch 149, Batch 1/4: Clipping gradients...
  Epoch 149, Batch 1/4: Optimizer step...
  Epoch 149, Batch 1/4: Completed in 0.19s
  Epoch 149, Batch 2/4: Loading data to device...
  Epoch 149, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 149, Batch 2/4: Zeroing gradients...
  Epoch 149, Batch 2/4: Forward pass...
  Epoch 149, Batch 2/4: Calculating loss...
  Epoch 149, Batch 2/4: Backward pass...
  Epoch 149, Batch 2/4: Clipping gradients...
  Epoch 149, Batch 2/4: Optimizer step...
  Epoch 149, Batch 2/4: Completed in 0.20s
  Epoch 149, Batch 3/4: Loading data to device...
  Epoch 149, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 149, Batch 3/4: Zeroing gradients...
  Epoch 149, Batch 3/4: Forward pass...
  Epoch 149, Batch 3/4: Calculating loss...
  Epoch 149, Batch 3/4: Backward pass...
  Epoch 149, Batch 3/4: Clipping gradients...
  Epoch 149, Batch 3/4: Optimizer step...
  Epoch 149, Batch 3/4: Completed in 0.19s
  Epoch 149, Batch 4/4: Loading data to device...
  Epoch 149, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 149, Batch 4/4: Zeroing gradients...
  Epoch 149, Batch 4/4: Forward pass...
  Epoch 149, Batch 4/4: Calculating loss...
  Epoch 149, Batch 4/4: Backward pass...
  Epoch 149, Batch 4/4: Clipping gradients...
  Epoch 149, Batch 4/4: Optimizer step...
  Epoch 149, Batch 4/4: Completed in 0.03s
Epoch 149: Training phase completed. Average Train Loss: 0.4410
Epoch 149: Starting validation phase...
  Epoch 149, Val Batch 1/1: Loading data...
  Epoch 149, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 149, Val Batch 1/1: Forward pass...
  Epoch 149, Val Batch 1/1: Calculating loss...
Epoch 149: Validation phase completed. Average Val Loss: 0.3786
Epoch 149 Summary ---> Train Loss: 0.4410 / Validation Loss: 0.3786
Epoch 149: Checking early stopping... (Current Best Loss: 0.3731, Epochs No Improve: 5)
  Epoch 149: Validation loss did not improve. Epochs without improvement: 6
Epoch 149: Stepping scheduler...
--- Epoch 149 completed in 0.69 seconds ---

--- Starting Epoch 150/1000 ---
Epoch 150: Starting training phase (4 batches)
  Epoch 150, Batch 1/4: Loading data to device...
  Epoch 150, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 150, Batch 1/4: Zeroing gradients...
  Epoch 150, Batch 1/4: Forward pass...
  Epoch 150, Batch 1/4: Calculating loss...
  Epoch 150, Batch 1/4: Backward pass...
  Epoch 150, Batch 1/4: Clipping gradients...
  Epoch 150, Batch 1/4: Optimizer step...
  Epoch 150, Batch 1/4: Completed in 0.19s
  Epoch 150, Batch 2/4: Loading data to device...
  Epoch 150, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 150, Batch 2/4: Zeroing gradients...
  Epoch 150, Batch 2/4: Forward pass...
  Epoch 150, Batch 2/4: Calculating loss...
  Epoch 150, Batch 2/4: Backward pass...
  Epoch 150, Batch 2/4: Clipping gradients...
  Epoch 150, Batch 2/4: Optimizer step...
  Epoch 150, Batch 2/4: Completed in 0.20s
  Epoch 150, Batch 3/4: Loading data to device...
  Epoch 150, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 150, Batch 3/4: Zeroing gradients...
  Epoch 150, Batch 3/4: Forward pass...
  Epoch 150, Batch 3/4: Calculating loss...
  Epoch 150, Batch 3/4: Backward pass...
  Epoch 150, Batch 3/4: Clipping gradients...
  Epoch 150, Batch 3/4: Optimizer step...
  Epoch 150, Batch 3/4: Completed in 0.20s
  Epoch 150, Batch 4/4: Loading data to device...
  Epoch 150, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 150, Batch 4/4: Zeroing gradients...
  Epoch 150, Batch 4/4: Forward pass...
  Epoch 150, Batch 4/4: Calculating loss...
  Epoch 150, Batch 4/4: Backward pass...
  Epoch 150, Batch 4/4: Clipping gradients...
  Epoch 150, Batch 4/4: Optimizer step...
  Epoch 150, Batch 4/4: Completed in 0.03s
Epoch 150: Training phase completed. Average Train Loss: 0.4486
Epoch 150: Starting validation phase...
  Epoch 150, Val Batch 1/1: Loading data...
  Epoch 150, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 150, Val Batch 1/1: Forward pass...
  Epoch 150, Val Batch 1/1: Calculating loss...
Epoch 150: Validation phase completed. Average Val Loss: 0.3811
Epoch 150 Summary ---> Train Loss: 0.4486 / Validation Loss: 0.3811
Epoch 150: Checking early stopping... (Current Best Loss: 0.3731, Epochs No Improve: 6)
  Epoch 150: Validation loss did not improve. Epochs without improvement: 7
Epoch 150: Stepping scheduler...
--- Epoch 150 completed in 0.69 seconds ---

--- Starting Epoch 151/1000 ---
Epoch 151: Starting training phase (4 batches)
  Epoch 151, Batch 1/4: Loading data to device...
  Epoch 151, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 151, Batch 1/4: Zeroing gradients...
  Epoch 151, Batch 1/4: Forward pass...
  Epoch 151, Batch 1/4: Calculating loss...
  Epoch 151, Batch 1/4: Backward pass...
  Epoch 151, Batch 1/4: Clipping gradients...
  Epoch 151, Batch 1/4: Optimizer step...
  Epoch 151, Batch 1/4: Completed in 0.19s
  Epoch 151, Batch 2/4: Loading data to device...
  Epoch 151, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 151, Batch 2/4: Zeroing gradients...
  Epoch 151, Batch 2/4: Forward pass...
  Epoch 151, Batch 2/4: Calculating loss...
  Epoch 151, Batch 2/4: Backward pass...
  Epoch 151, Batch 2/4: Clipping gradients...
  Epoch 151, Batch 2/4: Optimizer step...
  Epoch 151, Batch 2/4: Completed in 0.19s
  Epoch 151, Batch 3/4: Loading data to device...
  Epoch 151, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 151, Batch 3/4: Zeroing gradients...
  Epoch 151, Batch 3/4: Forward pass...
  Epoch 151, Batch 3/4: Calculating loss...
  Epoch 151, Batch 3/4: Backward pass...
  Epoch 151, Batch 3/4: Clipping gradients...
  Epoch 151, Batch 3/4: Optimizer step...
  Epoch 151, Batch 3/4: Completed in 0.19s
  Epoch 151, Batch 4/4: Loading data to device...
  Epoch 151, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 151, Batch 4/4: Zeroing gradients...
  Epoch 151, Batch 4/4: Forward pass...
  Epoch 151, Batch 4/4: Calculating loss...
  Epoch 151, Batch 4/4: Backward pass...
  Epoch 151, Batch 4/4: Clipping gradients...
  Epoch 151, Batch 4/4: Optimizer step...
  Epoch 151, Batch 4/4: Completed in 0.04s
Epoch 151: Training phase completed. Average Train Loss: 0.4686
Epoch 151: Starting validation phase...
  Epoch 151, Val Batch 1/1: Loading data...
  Epoch 151, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 151, Val Batch 1/1: Forward pass...
  Epoch 151, Val Batch 1/1: Calculating loss...
Epoch 151: Validation phase completed. Average Val Loss: 0.3850
Epoch 151 Summary ---> Train Loss: 0.4686 / Validation Loss: 0.3850
Epoch 151: Checking early stopping... (Current Best Loss: 0.3731, Epochs No Improve: 7)
  Epoch 151: Validation loss did not improve. Epochs without improvement: 8
Epoch 151: Stepping scheduler...
--- Epoch 151 completed in 0.69 seconds ---

--- Starting Epoch 152/1000 ---
Epoch 152: Starting training phase (4 batches)
  Epoch 152, Batch 1/4: Loading data to device...
  Epoch 152, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 152, Batch 1/4: Zeroing gradients...
  Epoch 152, Batch 1/4: Forward pass...
  Epoch 152, Batch 1/4: Calculating loss...
  Epoch 152, Batch 1/4: Backward pass...
  Epoch 152, Batch 1/4: Clipping gradients...
  Epoch 152, Batch 1/4: Optimizer step...
  Epoch 152, Batch 1/4: Completed in 0.19s
  Epoch 152, Batch 2/4: Loading data to device...
  Epoch 152, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 152, Batch 2/4: Zeroing gradients...
  Epoch 152, Batch 2/4: Forward pass...
  Epoch 152, Batch 2/4: Calculating loss...
  Epoch 152, Batch 2/4: Backward pass...
  Epoch 152, Batch 2/4: Clipping gradients...
  Epoch 152, Batch 2/4: Optimizer step...
  Epoch 152, Batch 2/4: Completed in 0.19s
  Epoch 152, Batch 3/4: Loading data to device...
  Epoch 152, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 152, Batch 3/4: Zeroing gradients...
  Epoch 152, Batch 3/4: Forward pass...
  Epoch 152, Batch 3/4: Calculating loss...
  Epoch 152, Batch 3/4: Backward pass...
  Epoch 152, Batch 3/4: Clipping gradients...
  Epoch 152, Batch 3/4: Optimizer step...
  Epoch 152, Batch 3/4: Completed in 0.19s
  Epoch 152, Batch 4/4: Loading data to device...
  Epoch 152, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 152, Batch 4/4: Zeroing gradients...
  Epoch 152, Batch 4/4: Forward pass...
  Epoch 152, Batch 4/4: Calculating loss...
  Epoch 152, Batch 4/4: Backward pass...
  Epoch 152, Batch 4/4: Clipping gradients...
  Epoch 152, Batch 4/4: Optimizer step...
  Epoch 152, Batch 4/4: Completed in 0.03s
Epoch 152: Training phase completed. Average Train Loss: 0.4030
Epoch 152: Starting validation phase...
  Epoch 152, Val Batch 1/1: Loading data...
  Epoch 152, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 152, Val Batch 1/1: Forward pass...
  Epoch 152, Val Batch 1/1: Calculating loss...
Epoch 152: Validation phase completed. Average Val Loss: 0.3910
Epoch 152 Summary ---> Train Loss: 0.4030 / Validation Loss: 0.3910
Epoch 152: Checking early stopping... (Current Best Loss: 0.3731, Epochs No Improve: 8)
  Epoch 152: Validation loss did not improve. Epochs without improvement: 9
Epoch 152: Stepping scheduler...
--- Epoch 152 completed in 0.67 seconds ---

--- Starting Epoch 153/1000 ---
Epoch 153: Starting training phase (4 batches)
  Epoch 153, Batch 1/4: Loading data to device...
  Epoch 153, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 153, Batch 1/4: Zeroing gradients...
  Epoch 153, Batch 1/4: Forward pass...
  Epoch 153, Batch 1/4: Calculating loss...
  Epoch 153, Batch 1/4: Backward pass...
  Epoch 153, Batch 1/4: Clipping gradients...
  Epoch 153, Batch 1/4: Optimizer step...
  Epoch 153, Batch 1/4: Completed in 0.19s
  Epoch 153, Batch 2/4: Loading data to device...
  Epoch 153, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 153, Batch 2/4: Zeroing gradients...
  Epoch 153, Batch 2/4: Forward pass...
  Epoch 153, Batch 2/4: Calculating loss...
  Epoch 153, Batch 2/4: Backward pass...
  Epoch 153, Batch 2/4: Clipping gradients...
  Epoch 153, Batch 2/4: Optimizer step...
  Epoch 153, Batch 2/4: Completed in 0.19s
  Epoch 153, Batch 3/4: Loading data to device...
  Epoch 153, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 153, Batch 3/4: Zeroing gradients...
  Epoch 153, Batch 3/4: Forward pass...
  Epoch 153, Batch 3/4: Calculating loss...
  Epoch 153, Batch 3/4: Backward pass...
  Epoch 153, Batch 3/4: Clipping gradients...
  Epoch 153, Batch 3/4: Optimizer step...
  Epoch 153, Batch 3/4: Completed in 0.19s
  Epoch 153, Batch 4/4: Loading data to device...
  Epoch 153, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 153, Batch 4/4: Zeroing gradients...
  Epoch 153, Batch 4/4: Forward pass...
  Epoch 153, Batch 4/4: Calculating loss...
  Epoch 153, Batch 4/4: Backward pass...
  Epoch 153, Batch 4/4: Clipping gradients...
  Epoch 153, Batch 4/4: Optimizer step...
  Epoch 153, Batch 4/4: Completed in 0.03s
Epoch 153: Training phase completed. Average Train Loss: 0.4751
Epoch 153: Starting validation phase...
  Epoch 153, Val Batch 1/1: Loading data...
  Epoch 153, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 153, Val Batch 1/1: Forward pass...
  Epoch 153, Val Batch 1/1: Calculating loss...
Epoch 153: Validation phase completed. Average Val Loss: 0.3845
Epoch 153 Summary ---> Train Loss: 0.4751 / Validation Loss: 0.3845
Epoch 153: Checking early stopping... (Current Best Loss: 0.3731, Epochs No Improve: 9)
  Epoch 153: Validation loss did not improve. Epochs without improvement: 10
Epoch 153: Stepping scheduler...
--- Epoch 153 completed in 0.66 seconds ---

--- Starting Epoch 154/1000 ---
Epoch 154: Starting training phase (4 batches)
  Epoch 154, Batch 1/4: Loading data to device...
  Epoch 154, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 154, Batch 1/4: Zeroing gradients...
  Epoch 154, Batch 1/4: Forward pass...
  Epoch 154, Batch 1/4: Calculating loss...
  Epoch 154, Batch 1/4: Backward pass...
  Epoch 154, Batch 1/4: Clipping gradients...
  Epoch 154, Batch 1/4: Optimizer step...
  Epoch 154, Batch 1/4: Completed in 0.19s
  Epoch 154, Batch 2/4: Loading data to device...
  Epoch 154, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 154, Batch 2/4: Zeroing gradients...
  Epoch 154, Batch 2/4: Forward pass...
  Epoch 154, Batch 2/4: Calculating loss...
  Epoch 154, Batch 2/4: Backward pass...
  Epoch 154, Batch 2/4: Clipping gradients...
  Epoch 154, Batch 2/4: Optimizer step...
  Epoch 154, Batch 2/4: Completed in 0.19s
  Epoch 154, Batch 3/4: Loading data to device...
  Epoch 154, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 154, Batch 3/4: Zeroing gradients...
  Epoch 154, Batch 3/4: Forward pass...
  Epoch 154, Batch 3/4: Calculating loss...
  Epoch 154, Batch 3/4: Backward pass...
  Epoch 154, Batch 3/4: Clipping gradients...
  Epoch 154, Batch 3/4: Optimizer step...
  Epoch 154, Batch 3/4: Completed in 0.19s
  Epoch 154, Batch 4/4: Loading data to device...
  Epoch 154, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 154, Batch 4/4: Zeroing gradients...
  Epoch 154, Batch 4/4: Forward pass...
  Epoch 154, Batch 4/4: Calculating loss...
  Epoch 154, Batch 4/4: Backward pass...
  Epoch 154, Batch 4/4: Clipping gradients...
  Epoch 154, Batch 4/4: Optimizer step...
  Epoch 154, Batch 4/4: Completed in 0.04s
Epoch 154: Training phase completed. Average Train Loss: 0.4223
Epoch 154: Starting validation phase...
  Epoch 154, Val Batch 1/1: Loading data...
  Epoch 154, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 154, Val Batch 1/1: Forward pass...
  Epoch 154, Val Batch 1/1: Calculating loss...
Epoch 154: Validation phase completed. Average Val Loss: 0.3834
Epoch 154 Summary ---> Train Loss: 0.4223 / Validation Loss: 0.3834
Epoch 154: Checking early stopping... (Current Best Loss: 0.3731, Epochs No Improve: 10)
  Epoch 154: Validation loss did not improve. Epochs without improvement: 11
Epoch 154: Stepping scheduler...
--- Epoch 154 completed in 0.68 seconds ---

--- Starting Epoch 155/1000 ---
Epoch 155: Starting training phase (4 batches)
  Epoch 155, Batch 1/4: Loading data to device...
  Epoch 155, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 155, Batch 1/4: Zeroing gradients...
  Epoch 155, Batch 1/4: Forward pass...
  Epoch 155, Batch 1/4: Calculating loss...
  Epoch 155, Batch 1/4: Backward pass...
  Epoch 155, Batch 1/4: Clipping gradients...
  Epoch 155, Batch 1/4: Optimizer step...
  Epoch 155, Batch 1/4: Completed in 0.20s
  Epoch 155, Batch 2/4: Loading data to device...
  Epoch 155, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 155, Batch 2/4: Zeroing gradients...
  Epoch 155, Batch 2/4: Forward pass...
  Epoch 155, Batch 2/4: Calculating loss...
  Epoch 155, Batch 2/4: Backward pass...
  Epoch 155, Batch 2/4: Clipping gradients...
  Epoch 155, Batch 2/4: Optimizer step...
  Epoch 155, Batch 2/4: Completed in 0.19s
  Epoch 155, Batch 3/4: Loading data to device...
  Epoch 155, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 155, Batch 3/4: Zeroing gradients...
  Epoch 155, Batch 3/4: Forward pass...
  Epoch 155, Batch 3/4: Calculating loss...
  Epoch 155, Batch 3/4: Backward pass...
  Epoch 155, Batch 3/4: Clipping gradients...
  Epoch 155, Batch 3/4: Optimizer step...
  Epoch 155, Batch 3/4: Completed in 0.19s
  Epoch 155, Batch 4/4: Loading data to device...
  Epoch 155, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 155, Batch 4/4: Zeroing gradients...
  Epoch 155, Batch 4/4: Forward pass...
  Epoch 155, Batch 4/4: Calculating loss...
  Epoch 155, Batch 4/4: Backward pass...
  Epoch 155, Batch 4/4: Clipping gradients...
  Epoch 155, Batch 4/4: Optimizer step...
  Epoch 155, Batch 4/4: Completed in 0.03s
Epoch 155: Training phase completed. Average Train Loss: 0.4639
Epoch 155: Starting validation phase...
  Epoch 155, Val Batch 1/1: Loading data...
  Epoch 155, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 155, Val Batch 1/1: Forward pass...
  Epoch 155, Val Batch 1/1: Calculating loss...
Epoch 155: Validation phase completed. Average Val Loss: 0.3715
Epoch 155 Summary ---> Train Loss: 0.4639 / Validation Loss: 0.3715
Epoch 155: Checking early stopping... (Current Best Loss: 0.3731, Epochs No Improve: 11)
  Epoch 155: Validation loss improved (0.3731 --> 0.3715). Saving model.
Epoch 155: Stepping scheduler...
--- Epoch 155 completed in 0.69 seconds ---

--- Starting Epoch 156/1000 ---
Epoch 156: Starting training phase (4 batches)
  Epoch 156, Batch 1/4: Loading data to device...
  Epoch 156, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 156, Batch 1/4: Zeroing gradients...
  Epoch 156, Batch 1/4: Forward pass...
  Epoch 156, Batch 1/4: Calculating loss...
  Epoch 156, Batch 1/4: Backward pass...
  Epoch 156, Batch 1/4: Clipping gradients...
  Epoch 156, Batch 1/4: Optimizer step...
  Epoch 156, Batch 1/4: Completed in 0.20s
  Epoch 156, Batch 2/4: Loading data to device...
  Epoch 156, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 156, Batch 2/4: Zeroing gradients...
  Epoch 156, Batch 2/4: Forward pass...
  Epoch 156, Batch 2/4: Calculating loss...
  Epoch 156, Batch 2/4: Backward pass...
  Epoch 156, Batch 2/4: Clipping gradients...
  Epoch 156, Batch 2/4: Optimizer step...
  Epoch 156, Batch 2/4: Completed in 0.19s
  Epoch 156, Batch 3/4: Loading data to device...
  Epoch 156, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 156, Batch 3/4: Zeroing gradients...
  Epoch 156, Batch 3/4: Forward pass...
  Epoch 156, Batch 3/4: Calculating loss...
  Epoch 156, Batch 3/4: Backward pass...
  Epoch 156, Batch 3/4: Clipping gradients...
  Epoch 156, Batch 3/4: Optimizer step...
  Epoch 156, Batch 3/4: Completed in 0.19s
  Epoch 156, Batch 4/4: Loading data to device...
  Epoch 156, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 156, Batch 4/4: Zeroing gradients...
  Epoch 156, Batch 4/4: Forward pass...
  Epoch 156, Batch 4/4: Calculating loss...
  Epoch 156, Batch 4/4: Backward pass...
  Epoch 156, Batch 4/4: Clipping gradients...
  Epoch 156, Batch 4/4: Optimizer step...
  Epoch 156, Batch 4/4: Completed in 0.03s
Epoch 156: Training phase completed. Average Train Loss: 0.4127
Epoch 156: Starting validation phase...
  Epoch 156, Val Batch 1/1: Loading data...
  Epoch 156, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 156, Val Batch 1/1: Forward pass...
  Epoch 156, Val Batch 1/1: Calculating loss...
Epoch 156: Validation phase completed. Average Val Loss: 0.3772
Epoch 156 Summary ---> Train Loss: 0.4127 / Validation Loss: 0.3772
Epoch 156: Checking early stopping... (Current Best Loss: 0.3715, Epochs No Improve: 0)
  Epoch 156: Validation loss did not improve. Epochs without improvement: 1
Epoch 156: Stepping scheduler...
--- Epoch 156 completed in 0.68 seconds ---

--- Starting Epoch 157/1000 ---
Epoch 157: Starting training phase (4 batches)
  Epoch 157, Batch 1/4: Loading data to device...
  Epoch 157, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 157, Batch 1/4: Zeroing gradients...
  Epoch 157, Batch 1/4: Forward pass...
  Epoch 157, Batch 1/4: Calculating loss...
  Epoch 157, Batch 1/4: Backward pass...
  Epoch 157, Batch 1/4: Clipping gradients...
  Epoch 157, Batch 1/4: Optimizer step...
  Epoch 157, Batch 1/4: Completed in 0.19s
  Epoch 157, Batch 2/4: Loading data to device...
  Epoch 157, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 157, Batch 2/4: Zeroing gradients...
  Epoch 157, Batch 2/4: Forward pass...
  Epoch 157, Batch 2/4: Calculating loss...
  Epoch 157, Batch 2/4: Backward pass...
  Epoch 157, Batch 2/4: Clipping gradients...
  Epoch 157, Batch 2/4: Optimizer step...
  Epoch 157, Batch 2/4: Completed in 0.19s
  Epoch 157, Batch 3/4: Loading data to device...
  Epoch 157, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 157, Batch 3/4: Zeroing gradients...
  Epoch 157, Batch 3/4: Forward pass...
  Epoch 157, Batch 3/4: Calculating loss...
  Epoch 157, Batch 3/4: Backward pass...
  Epoch 157, Batch 3/4: Clipping gradients...
  Epoch 157, Batch 3/4: Optimizer step...
  Epoch 157, Batch 3/4: Completed in 0.19s
  Epoch 157, Batch 4/4: Loading data to device...
  Epoch 157, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 157, Batch 4/4: Zeroing gradients...
  Epoch 157, Batch 4/4: Forward pass...
  Epoch 157, Batch 4/4: Calculating loss...
  Epoch 157, Batch 4/4: Backward pass...
  Epoch 157, Batch 4/4: Clipping gradients...
  Epoch 157, Batch 4/4: Optimizer step...
  Epoch 157, Batch 4/4: Completed in 0.03s
Epoch 157: Training phase completed. Average Train Loss: 0.4351
Epoch 157: Starting validation phase...
  Epoch 157, Val Batch 1/1: Loading data...
  Epoch 157, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 157, Val Batch 1/1: Forward pass...
  Epoch 157, Val Batch 1/1: Calculating loss...
Epoch 157: Validation phase completed. Average Val Loss: 0.3751
Epoch 157 Summary ---> Train Loss: 0.4351 / Validation Loss: 0.3751
Epoch 157: Checking early stopping... (Current Best Loss: 0.3715, Epochs No Improve: 1)
  Epoch 157: Validation loss did not improve. Epochs without improvement: 2
Epoch 157: Stepping scheduler...
--- Epoch 157 completed in 0.67 seconds ---

--- Starting Epoch 158/1000 ---
Epoch 158: Starting training phase (4 batches)
  Epoch 158, Batch 1/4: Loading data to device...
  Epoch 158, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 158, Batch 1/4: Zeroing gradients...
  Epoch 158, Batch 1/4: Forward pass...
  Epoch 158, Batch 1/4: Calculating loss...
  Epoch 158, Batch 1/4: Backward pass...
  Epoch 158, Batch 1/4: Clipping gradients...
  Epoch 158, Batch 1/4: Optimizer step...
  Epoch 158, Batch 1/4: Completed in 0.20s
  Epoch 158, Batch 2/4: Loading data to device...
  Epoch 158, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 158, Batch 2/4: Zeroing gradients...
  Epoch 158, Batch 2/4: Forward pass...
  Epoch 158, Batch 2/4: Calculating loss...
  Epoch 158, Batch 2/4: Backward pass...
  Epoch 158, Batch 2/4: Clipping gradients...
  Epoch 158, Batch 2/4: Optimizer step...
  Epoch 158, Batch 2/4: Completed in 0.20s
  Epoch 158, Batch 3/4: Loading data to device...
  Epoch 158, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 158, Batch 3/4: Zeroing gradients...
  Epoch 158, Batch 3/4: Forward pass...
  Epoch 158, Batch 3/4: Calculating loss...
  Epoch 158, Batch 3/4: Backward pass...
  Epoch 158, Batch 3/4: Clipping gradients...
  Epoch 158, Batch 3/4: Optimizer step...
  Epoch 158, Batch 3/4: Completed in 0.20s
  Epoch 158, Batch 4/4: Loading data to device...
  Epoch 158, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 158, Batch 4/4: Zeroing gradients...
  Epoch 158, Batch 4/4: Forward pass...
  Epoch 158, Batch 4/4: Calculating loss...
  Epoch 158, Batch 4/4: Backward pass...
  Epoch 158, Batch 4/4: Clipping gradients...
  Epoch 158, Batch 4/4: Optimizer step...
  Epoch 158, Batch 4/4: Completed in 0.03s
Epoch 158: Training phase completed. Average Train Loss: 0.3979
Epoch 158: Starting validation phase...
  Epoch 158, Val Batch 1/1: Loading data...
  Epoch 158, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 158, Val Batch 1/1: Forward pass...
  Epoch 158, Val Batch 1/1: Calculating loss...
Epoch 158: Validation phase completed. Average Val Loss: 0.3740
Epoch 158 Summary ---> Train Loss: 0.3979 / Validation Loss: 0.3740
Epoch 158: Checking early stopping... (Current Best Loss: 0.3715, Epochs No Improve: 2)
  Epoch 158: Validation loss did not improve. Epochs without improvement: 3
Epoch 158: Stepping scheduler...
--- Epoch 158 completed in 0.69 seconds ---

--- Starting Epoch 159/1000 ---
Epoch 159: Starting training phase (4 batches)
  Epoch 159, Batch 1/4: Loading data to device...
  Epoch 159, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 159, Batch 1/4: Zeroing gradients...
  Epoch 159, Batch 1/4: Forward pass...
  Epoch 159, Batch 1/4: Calculating loss...
  Epoch 159, Batch 1/4: Backward pass...
  Epoch 159, Batch 1/4: Clipping gradients...
  Epoch 159, Batch 1/4: Optimizer step...
  Epoch 159, Batch 1/4: Completed in 0.20s
  Epoch 159, Batch 2/4: Loading data to device...
  Epoch 159, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 159, Batch 2/4: Zeroing gradients...
  Epoch 159, Batch 2/4: Forward pass...
  Epoch 159, Batch 2/4: Calculating loss...
  Epoch 159, Batch 2/4: Backward pass...
  Epoch 159, Batch 2/4: Clipping gradients...
  Epoch 159, Batch 2/4: Optimizer step...
  Epoch 159, Batch 2/4: Completed in 0.19s
  Epoch 159, Batch 3/4: Loading data to device...
  Epoch 159, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 159, Batch 3/4: Zeroing gradients...
  Epoch 159, Batch 3/4: Forward pass...
  Epoch 159, Batch 3/4: Calculating loss...
  Epoch 159, Batch 3/4: Backward pass...
  Epoch 159, Batch 3/4: Clipping gradients...
  Epoch 159, Batch 3/4: Optimizer step...
  Epoch 159, Batch 3/4: Completed in 0.20s
  Epoch 159, Batch 4/4: Loading data to device...
  Epoch 159, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 159, Batch 4/4: Zeroing gradients...
  Epoch 159, Batch 4/4: Forward pass...
  Epoch 159, Batch 4/4: Calculating loss...
  Epoch 159, Batch 4/4: Backward pass...
  Epoch 159, Batch 4/4: Clipping gradients...
  Epoch 159, Batch 4/4: Optimizer step...
  Epoch 159, Batch 4/4: Completed in 0.03s
Epoch 159: Training phase completed. Average Train Loss: 0.4825
Epoch 159: Starting validation phase...
  Epoch 159, Val Batch 1/1: Loading data...
  Epoch 159, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 159, Val Batch 1/1: Forward pass...
  Epoch 159, Val Batch 1/1: Calculating loss...
Epoch 159: Validation phase completed. Average Val Loss: 0.3754
Epoch 159 Summary ---> Train Loss: 0.4825 / Validation Loss: 0.3754
Epoch 159: Checking early stopping... (Current Best Loss: 0.3715, Epochs No Improve: 3)
  Epoch 159: Validation loss did not improve. Epochs without improvement: 4
Epoch 159: Stepping scheduler...
--- Epoch 159 completed in 0.69 seconds ---

--- Starting Epoch 160/1000 ---
Epoch 160: Starting training phase (4 batches)
  Epoch 160, Batch 1/4: Loading data to device...
  Epoch 160, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 160, Batch 1/4: Zeroing gradients...
  Epoch 160, Batch 1/4: Forward pass...
  Epoch 160, Batch 1/4: Calculating loss...
  Epoch 160, Batch 1/4: Backward pass...
  Epoch 160, Batch 1/4: Clipping gradients...
  Epoch 160, Batch 1/4: Optimizer step...
  Epoch 160, Batch 1/4: Completed in 0.19s
  Epoch 160, Batch 2/4: Loading data to device...
  Epoch 160, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 160, Batch 2/4: Zeroing gradients...
  Epoch 160, Batch 2/4: Forward pass...
  Epoch 160, Batch 2/4: Calculating loss...
  Epoch 160, Batch 2/4: Backward pass...
  Epoch 160, Batch 2/4: Clipping gradients...
  Epoch 160, Batch 2/4: Optimizer step...
  Epoch 160, Batch 2/4: Completed in 0.19s
  Epoch 160, Batch 3/4: Loading data to device...
  Epoch 160, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 160, Batch 3/4: Zeroing gradients...
  Epoch 160, Batch 3/4: Forward pass...
  Epoch 160, Batch 3/4: Calculating loss...
  Epoch 160, Batch 3/4: Backward pass...
  Epoch 160, Batch 3/4: Clipping gradients...
  Epoch 160, Batch 3/4: Optimizer step...
  Epoch 160, Batch 3/4: Completed in 0.19s
  Epoch 160, Batch 4/4: Loading data to device...
  Epoch 160, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 160, Batch 4/4: Zeroing gradients...
  Epoch 160, Batch 4/4: Forward pass...
  Epoch 160, Batch 4/4: Calculating loss...
  Epoch 160, Batch 4/4: Backward pass...
  Epoch 160, Batch 4/4: Clipping gradients...
  Epoch 160, Batch 4/4: Optimizer step...
  Epoch 160, Batch 4/4: Completed in 0.03s
Epoch 160: Training phase completed. Average Train Loss: 0.4564
Epoch 160: Starting validation phase...
  Epoch 160, Val Batch 1/1: Loading data...
  Epoch 160, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 160, Val Batch 1/1: Forward pass...
  Epoch 160, Val Batch 1/1: Calculating loss...
Epoch 160: Validation phase completed. Average Val Loss: 0.3678
Epoch 160 Summary ---> Train Loss: 0.4564 / Validation Loss: 0.3678
Epoch 160: Checking early stopping... (Current Best Loss: 0.3715, Epochs No Improve: 4)
  Epoch 160: Validation loss improved (0.3715 --> 0.3678). Saving model.
Epoch 160: Stepping scheduler...
--- Epoch 160 completed in 0.68 seconds ---

--- Starting Epoch 161/1000 ---
Epoch 161: Starting training phase (4 batches)
  Epoch 161, Batch 1/4: Loading data to device...
  Epoch 161, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 161, Batch 1/4: Zeroing gradients...
  Epoch 161, Batch 1/4: Forward pass...
  Epoch 161, Batch 1/4: Calculating loss...
  Epoch 161, Batch 1/4: Backward pass...
  Epoch 161, Batch 1/4: Clipping gradients...
  Epoch 161, Batch 1/4: Optimizer step...
  Epoch 161, Batch 1/4: Completed in 0.20s
  Epoch 161, Batch 2/4: Loading data to device...
  Epoch 161, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 161, Batch 2/4: Zeroing gradients...
  Epoch 161, Batch 2/4: Forward pass...
  Epoch 161, Batch 2/4: Calculating loss...
  Epoch 161, Batch 2/4: Backward pass...
  Epoch 161, Batch 2/4: Clipping gradients...
  Epoch 161, Batch 2/4: Optimizer step...
  Epoch 161, Batch 2/4: Completed in 0.20s
  Epoch 161, Batch 3/4: Loading data to device...
  Epoch 161, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 161, Batch 3/4: Zeroing gradients...
  Epoch 161, Batch 3/4: Forward pass...
  Epoch 161, Batch 3/4: Calculating loss...
  Epoch 161, Batch 3/4: Backward pass...
  Epoch 161, Batch 3/4: Clipping gradients...
  Epoch 161, Batch 3/4: Optimizer step...
  Epoch 161, Batch 3/4: Completed in 0.19s
  Epoch 161, Batch 4/4: Loading data to device...
  Epoch 161, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 161, Batch 4/4: Zeroing gradients...
  Epoch 161, Batch 4/4: Forward pass...
  Epoch 161, Batch 4/4: Calculating loss...
  Epoch 161, Batch 4/4: Backward pass...
  Epoch 161, Batch 4/4: Clipping gradients...
  Epoch 161, Batch 4/4: Optimizer step...
  Epoch 161, Batch 4/4: Completed in 0.03s
Epoch 161: Training phase completed. Average Train Loss: 0.3940
Epoch 161: Starting validation phase...
  Epoch 161, Val Batch 1/1: Loading data...
  Epoch 161, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 161, Val Batch 1/1: Forward pass...
  Epoch 161, Val Batch 1/1: Calculating loss...
Epoch 161: Validation phase completed. Average Val Loss: 0.3671
Epoch 161 Summary ---> Train Loss: 0.3940 / Validation Loss: 0.3671
Epoch 161: Checking early stopping... (Current Best Loss: 0.3678, Epochs No Improve: 0)
  Epoch 161: Validation loss improved (0.3678 --> 0.3671). Saving model.
Epoch 161: Stepping scheduler...
--- Epoch 161 completed in 0.69 seconds ---

--- Starting Epoch 162/1000 ---
Epoch 162: Starting training phase (4 batches)
  Epoch 162, Batch 1/4: Loading data to device...
  Epoch 162, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 162, Batch 1/4: Zeroing gradients...
  Epoch 162, Batch 1/4: Forward pass...
  Epoch 162, Batch 1/4: Calculating loss...
  Epoch 162, Batch 1/4: Backward pass...
  Epoch 162, Batch 1/4: Clipping gradients...
  Epoch 162, Batch 1/4: Optimizer step...
  Epoch 162, Batch 1/4: Completed in 0.20s
  Epoch 162, Batch 2/4: Loading data to device...
  Epoch 162, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 162, Batch 2/4: Zeroing gradients...
  Epoch 162, Batch 2/4: Forward pass...
  Epoch 162, Batch 2/4: Calculating loss...
  Epoch 162, Batch 2/4: Backward pass...
  Epoch 162, Batch 2/4: Clipping gradients...
  Epoch 162, Batch 2/4: Optimizer step...
  Epoch 162, Batch 2/4: Completed in 0.20s
  Epoch 162, Batch 3/4: Loading data to device...
  Epoch 162, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 162, Batch 3/4: Zeroing gradients...
  Epoch 162, Batch 3/4: Forward pass...
  Epoch 162, Batch 3/4: Calculating loss...
  Epoch 162, Batch 3/4: Backward pass...
  Epoch 162, Batch 3/4: Clipping gradients...
  Epoch 162, Batch 3/4: Optimizer step...
  Epoch 162, Batch 3/4: Completed in 0.20s
  Epoch 162, Batch 4/4: Loading data to device...
  Epoch 162, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 162, Batch 4/4: Zeroing gradients...
  Epoch 162, Batch 4/4: Forward pass...
  Epoch 162, Batch 4/4: Calculating loss...
  Epoch 162, Batch 4/4: Backward pass...
  Epoch 162, Batch 4/4: Clipping gradients...
  Epoch 162, Batch 4/4: Optimizer step...
  Epoch 162, Batch 4/4: Completed in 0.03s
Epoch 162: Training phase completed. Average Train Loss: 0.4558
Epoch 162: Starting validation phase...
  Epoch 162, Val Batch 1/1: Loading data...
  Epoch 162, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 162, Val Batch 1/1: Forward pass...
  Epoch 162, Val Batch 1/1: Calculating loss...
Epoch 162: Validation phase completed. Average Val Loss: 0.3548
Epoch 162 Summary ---> Train Loss: 0.4558 / Validation Loss: 0.3548
Epoch 162: Checking early stopping... (Current Best Loss: 0.3671, Epochs No Improve: 0)
  Epoch 162: Validation loss improved (0.3671 --> 0.3548). Saving model.
Epoch 162: Stepping scheduler...
--- Epoch 162 completed in 0.70 seconds ---

--- Starting Epoch 163/1000 ---
Epoch 163: Starting training phase (4 batches)
  Epoch 163, Batch 1/4: Loading data to device...
  Epoch 163, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 163, Batch 1/4: Zeroing gradients...
  Epoch 163, Batch 1/4: Forward pass...
  Epoch 163, Batch 1/4: Calculating loss...
  Epoch 163, Batch 1/4: Backward pass...
  Epoch 163, Batch 1/4: Clipping gradients...
  Epoch 163, Batch 1/4: Optimizer step...
  Epoch 163, Batch 1/4: Completed in 0.19s
  Epoch 163, Batch 2/4: Loading data to device...
  Epoch 163, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 163, Batch 2/4: Zeroing gradients...
  Epoch 163, Batch 2/4: Forward pass...
  Epoch 163, Batch 2/4: Calculating loss...
  Epoch 163, Batch 2/4: Backward pass...
  Epoch 163, Batch 2/4: Clipping gradients...
  Epoch 163, Batch 2/4: Optimizer step...
  Epoch 163, Batch 2/4: Completed in 0.19s
  Epoch 163, Batch 3/4: Loading data to device...
  Epoch 163, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 163, Batch 3/4: Zeroing gradients...
  Epoch 163, Batch 3/4: Forward pass...
  Epoch 163, Batch 3/4: Calculating loss...
  Epoch 163, Batch 3/4: Backward pass...
  Epoch 163, Batch 3/4: Clipping gradients...
  Epoch 163, Batch 3/4: Optimizer step...
  Epoch 163, Batch 3/4: Completed in 0.19s
  Epoch 163, Batch 4/4: Loading data to device...
  Epoch 163, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 163, Batch 4/4: Zeroing gradients...
  Epoch 163, Batch 4/4: Forward pass...
  Epoch 163, Batch 4/4: Calculating loss...
  Epoch 163, Batch 4/4: Backward pass...
  Epoch 163, Batch 4/4: Clipping gradients...
  Epoch 163, Batch 4/4: Optimizer step...
  Epoch 163, Batch 4/4: Completed in 0.04s
Epoch 163: Training phase completed. Average Train Loss: 0.4842
Epoch 163: Starting validation phase...
  Epoch 163, Val Batch 1/1: Loading data...
  Epoch 163, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 163, Val Batch 1/1: Forward pass...
  Epoch 163, Val Batch 1/1: Calculating loss...
Epoch 163: Validation phase completed. Average Val Loss: 0.3569
Epoch 163 Summary ---> Train Loss: 0.4842 / Validation Loss: 0.3569
Epoch 163: Checking early stopping... (Current Best Loss: 0.3548, Epochs No Improve: 0)
  Epoch 163: Validation loss did not improve. Epochs without improvement: 1
Epoch 163: Stepping scheduler...
--- Epoch 163 completed in 0.67 seconds ---

--- Starting Epoch 164/1000 ---
Epoch 164: Starting training phase (4 batches)
  Epoch 164, Batch 1/4: Loading data to device...
  Epoch 164, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 164, Batch 1/4: Zeroing gradients...
  Epoch 164, Batch 1/4: Forward pass...
  Epoch 164, Batch 1/4: Calculating loss...
  Epoch 164, Batch 1/4: Backward pass...
  Epoch 164, Batch 1/4: Clipping gradients...
  Epoch 164, Batch 1/4: Optimizer step...
  Epoch 164, Batch 1/4: Completed in 0.19s
  Epoch 164, Batch 2/4: Loading data to device...
  Epoch 164, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 164, Batch 2/4: Zeroing gradients...
  Epoch 164, Batch 2/4: Forward pass...
  Epoch 164, Batch 2/4: Calculating loss...
  Epoch 164, Batch 2/4: Backward pass...
  Epoch 164, Batch 2/4: Clipping gradients...
  Epoch 164, Batch 2/4: Optimizer step...
  Epoch 164, Batch 2/4: Completed in 0.19s
  Epoch 164, Batch 3/4: Loading data to device...
  Epoch 164, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 164, Batch 3/4: Zeroing gradients...
  Epoch 164, Batch 3/4: Forward pass...
  Epoch 164, Batch 3/4: Calculating loss...
  Epoch 164, Batch 3/4: Backward pass...
  Epoch 164, Batch 3/4: Clipping gradients...
  Epoch 164, Batch 3/4: Optimizer step...
  Epoch 164, Batch 3/4: Completed in 0.19s
  Epoch 164, Batch 4/4: Loading data to device...
  Epoch 164, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 164, Batch 4/4: Zeroing gradients...
  Epoch 164, Batch 4/4: Forward pass...
  Epoch 164, Batch 4/4: Calculating loss...
  Epoch 164, Batch 4/4: Backward pass...
  Epoch 164, Batch 4/4: Clipping gradients...
  Epoch 164, Batch 4/4: Optimizer step...
  Epoch 164, Batch 4/4: Completed in 0.03s
Epoch 164: Training phase completed. Average Train Loss: 0.4084
Epoch 164: Starting validation phase...
  Epoch 164, Val Batch 1/1: Loading data...
  Epoch 164, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 164, Val Batch 1/1: Forward pass...
  Epoch 164, Val Batch 1/1: Calculating loss...
Epoch 164: Validation phase completed. Average Val Loss: 0.3584
Epoch 164 Summary ---> Train Loss: 0.4084 / Validation Loss: 0.3584
Epoch 164: Checking early stopping... (Current Best Loss: 0.3548, Epochs No Improve: 1)
  Epoch 164: Validation loss did not improve. Epochs without improvement: 2
Epoch 164: Stepping scheduler...
--- Epoch 164 completed in 0.68 seconds ---

--- Starting Epoch 165/1000 ---
Epoch 165: Starting training phase (4 batches)
  Epoch 165, Batch 1/4: Loading data to device...
  Epoch 165, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 165, Batch 1/4: Zeroing gradients...
  Epoch 165, Batch 1/4: Forward pass...
  Epoch 165, Batch 1/4: Calculating loss...
  Epoch 165, Batch 1/4: Backward pass...
  Epoch 165, Batch 1/4: Clipping gradients...
  Epoch 165, Batch 1/4: Optimizer step...
  Epoch 165, Batch 1/4: Completed in 0.19s
  Epoch 165, Batch 2/4: Loading data to device...
  Epoch 165, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 165, Batch 2/4: Zeroing gradients...
  Epoch 165, Batch 2/4: Forward pass...
  Epoch 165, Batch 2/4: Calculating loss...
  Epoch 165, Batch 2/4: Backward pass...
  Epoch 165, Batch 2/4: Clipping gradients...
  Epoch 165, Batch 2/4: Optimizer step...
  Epoch 165, Batch 2/4: Completed in 0.19s
  Epoch 165, Batch 3/4: Loading data to device...
  Epoch 165, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 165, Batch 3/4: Zeroing gradients...
  Epoch 165, Batch 3/4: Forward pass...
  Epoch 165, Batch 3/4: Calculating loss...
  Epoch 165, Batch 3/4: Backward pass...
  Epoch 165, Batch 3/4: Clipping gradients...
  Epoch 165, Batch 3/4: Optimizer step...
  Epoch 165, Batch 3/4: Completed in 0.20s
  Epoch 165, Batch 4/4: Loading data to device...
  Epoch 165, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 165, Batch 4/4: Zeroing gradients...
  Epoch 165, Batch 4/4: Forward pass...
  Epoch 165, Batch 4/4: Calculating loss...
  Epoch 165, Batch 4/4: Backward pass...
  Epoch 165, Batch 4/4: Clipping gradients...
  Epoch 165, Batch 4/4: Optimizer step...
  Epoch 165, Batch 4/4: Completed in 0.03s
Epoch 165: Training phase completed. Average Train Loss: 0.4000
Epoch 165: Starting validation phase...
  Epoch 165, Val Batch 1/1: Loading data...
  Epoch 165, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 165, Val Batch 1/1: Forward pass...
  Epoch 165, Val Batch 1/1: Calculating loss...
Epoch 165: Validation phase completed. Average Val Loss: 0.3518
Epoch 165 Summary ---> Train Loss: 0.4000 / Validation Loss: 0.3518
Epoch 165: Checking early stopping... (Current Best Loss: 0.3548, Epochs No Improve: 2)
  Epoch 165: Validation loss improved (0.3548 --> 0.3518). Saving model.
Epoch 165: Stepping scheduler...
--- Epoch 165 completed in 0.68 seconds ---

--- Starting Epoch 166/1000 ---
Epoch 166: Starting training phase (4 batches)
  Epoch 166, Batch 1/4: Loading data to device...
  Epoch 166, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 166, Batch 1/4: Zeroing gradients...
  Epoch 166, Batch 1/4: Forward pass...
  Epoch 166, Batch 1/4: Calculating loss...
  Epoch 166, Batch 1/4: Backward pass...
  Epoch 166, Batch 1/4: Clipping gradients...
  Epoch 166, Batch 1/4: Optimizer step...
  Epoch 166, Batch 1/4: Completed in 0.19s
  Epoch 166, Batch 2/4: Loading data to device...
  Epoch 166, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 166, Batch 2/4: Zeroing gradients...
  Epoch 166, Batch 2/4: Forward pass...
  Epoch 166, Batch 2/4: Calculating loss...
  Epoch 166, Batch 2/4: Backward pass...
  Epoch 166, Batch 2/4: Clipping gradients...
  Epoch 166, Batch 2/4: Optimizer step...
  Epoch 166, Batch 2/4: Completed in 0.19s
  Epoch 166, Batch 3/4: Loading data to device...
  Epoch 166, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 166, Batch 3/4: Zeroing gradients...
  Epoch 166, Batch 3/4: Forward pass...
  Epoch 166, Batch 3/4: Calculating loss...
  Epoch 166, Batch 3/4: Backward pass...
  Epoch 166, Batch 3/4: Clipping gradients...
  Epoch 166, Batch 3/4: Optimizer step...
  Epoch 166, Batch 3/4: Completed in 0.19s
  Epoch 166, Batch 4/4: Loading data to device...
  Epoch 166, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 166, Batch 4/4: Zeroing gradients...
  Epoch 166, Batch 4/4: Forward pass...
  Epoch 166, Batch 4/4: Calculating loss...
  Epoch 166, Batch 4/4: Backward pass...
  Epoch 166, Batch 4/4: Clipping gradients...
  Epoch 166, Batch 4/4: Optimizer step...
  Epoch 166, Batch 4/4: Completed in 0.03s
Epoch 166: Training phase completed. Average Train Loss: 0.4601
Epoch 166: Starting validation phase...
  Epoch 166, Val Batch 1/1: Loading data...
  Epoch 166, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 166, Val Batch 1/1: Forward pass...
  Epoch 166, Val Batch 1/1: Calculating loss...
Epoch 166: Validation phase completed. Average Val Loss: 0.3562
Epoch 166 Summary ---> Train Loss: 0.4601 / Validation Loss: 0.3562
Epoch 166: Checking early stopping... (Current Best Loss: 0.3518, Epochs No Improve: 0)
  Epoch 166: Validation loss did not improve. Epochs without improvement: 1
Epoch 166: Stepping scheduler...
--- Epoch 166 completed in 0.68 seconds ---

--- Starting Epoch 167/1000 ---
Epoch 167: Starting training phase (4 batches)
  Epoch 167, Batch 1/4: Loading data to device...
  Epoch 167, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 167, Batch 1/4: Zeroing gradients...
  Epoch 167, Batch 1/4: Forward pass...
  Epoch 167, Batch 1/4: Calculating loss...
  Epoch 167, Batch 1/4: Backward pass...
  Epoch 167, Batch 1/4: Clipping gradients...
  Epoch 167, Batch 1/4: Optimizer step...
  Epoch 167, Batch 1/4: Completed in 0.20s
  Epoch 167, Batch 2/4: Loading data to device...
  Epoch 167, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 167, Batch 2/4: Zeroing gradients...
  Epoch 167, Batch 2/4: Forward pass...
  Epoch 167, Batch 2/4: Calculating loss...
  Epoch 167, Batch 2/4: Backward pass...
  Epoch 167, Batch 2/4: Clipping gradients...
  Epoch 167, Batch 2/4: Optimizer step...
  Epoch 167, Batch 2/4: Completed in 0.19s
  Epoch 167, Batch 3/4: Loading data to device...
  Epoch 167, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 167, Batch 3/4: Zeroing gradients...
  Epoch 167, Batch 3/4: Forward pass...
  Epoch 167, Batch 3/4: Calculating loss...
  Epoch 167, Batch 3/4: Backward pass...
  Epoch 167, Batch 3/4: Clipping gradients...
  Epoch 167, Batch 3/4: Optimizer step...
  Epoch 167, Batch 3/4: Completed in 0.19s
  Epoch 167, Batch 4/4: Loading data to device...
  Epoch 167, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 167, Batch 4/4: Zeroing gradients...
  Epoch 167, Batch 4/4: Forward pass...
  Epoch 167, Batch 4/4: Calculating loss...
  Epoch 167, Batch 4/4: Backward pass...
  Epoch 167, Batch 4/4: Clipping gradients...
  Epoch 167, Batch 4/4: Optimizer step...
  Epoch 167, Batch 4/4: Completed in 0.03s
Epoch 167: Training phase completed. Average Train Loss: 0.4460
Epoch 167: Starting validation phase...
  Epoch 167, Val Batch 1/1: Loading data...
  Epoch 167, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 167, Val Batch 1/1: Forward pass...
  Epoch 167, Val Batch 1/1: Calculating loss...
Epoch 167: Validation phase completed. Average Val Loss: 0.3607
Epoch 167 Summary ---> Train Loss: 0.4460 / Validation Loss: 0.3607
Epoch 167: Checking early stopping... (Current Best Loss: 0.3518, Epochs No Improve: 1)
  Epoch 167: Validation loss did not improve. Epochs without improvement: 2
Epoch 167: Stepping scheduler...
--- Epoch 167 completed in 0.69 seconds ---

--- Starting Epoch 168/1000 ---
Epoch 168: Starting training phase (4 batches)
  Epoch 168, Batch 1/4: Loading data to device...
  Epoch 168, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 168, Batch 1/4: Zeroing gradients...
  Epoch 168, Batch 1/4: Forward pass...
  Epoch 168, Batch 1/4: Calculating loss...
  Epoch 168, Batch 1/4: Backward pass...
  Epoch 168, Batch 1/4: Clipping gradients...
  Epoch 168, Batch 1/4: Optimizer step...
  Epoch 168, Batch 1/4: Completed in 0.20s
  Epoch 168, Batch 2/4: Loading data to device...
  Epoch 168, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 168, Batch 2/4: Zeroing gradients...
  Epoch 168, Batch 2/4: Forward pass...
  Epoch 168, Batch 2/4: Calculating loss...
  Epoch 168, Batch 2/4: Backward pass...
  Epoch 168, Batch 2/4: Clipping gradients...
  Epoch 168, Batch 2/4: Optimizer step...
  Epoch 168, Batch 2/4: Completed in 0.20s
  Epoch 168, Batch 3/4: Loading data to device...
  Epoch 168, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 168, Batch 3/4: Zeroing gradients...
  Epoch 168, Batch 3/4: Forward pass...
  Epoch 168, Batch 3/4: Calculating loss...
  Epoch 168, Batch 3/4: Backward pass...
  Epoch 168, Batch 3/4: Clipping gradients...
  Epoch 168, Batch 3/4: Optimizer step...
  Epoch 168, Batch 3/4: Completed in 0.19s
  Epoch 168, Batch 4/4: Loading data to device...
  Epoch 168, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 168, Batch 4/4: Zeroing gradients...
  Epoch 168, Batch 4/4: Forward pass...
  Epoch 168, Batch 4/4: Calculating loss...
  Epoch 168, Batch 4/4: Backward pass...
  Epoch 168, Batch 4/4: Clipping gradients...
  Epoch 168, Batch 4/4: Optimizer step...
  Epoch 168, Batch 4/4: Completed in 0.03s
Epoch 168: Training phase completed. Average Train Loss: 0.4590
Epoch 168: Starting validation phase...
  Epoch 168, Val Batch 1/1: Loading data...
  Epoch 168, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 168, Val Batch 1/1: Forward pass...
  Epoch 168, Val Batch 1/1: Calculating loss...
Epoch 168: Validation phase completed. Average Val Loss: 0.3702
Epoch 168 Summary ---> Train Loss: 0.4590 / Validation Loss: 0.3702
Epoch 168: Checking early stopping... (Current Best Loss: 0.3518, Epochs No Improve: 2)
  Epoch 168: Validation loss did not improve. Epochs without improvement: 3
Epoch 168: Stepping scheduler...
--- Epoch 168 completed in 0.69 seconds ---

--- Starting Epoch 169/1000 ---
Epoch 169: Starting training phase (4 batches)
  Epoch 169, Batch 1/4: Loading data to device...
  Epoch 169, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 169, Batch 1/4: Zeroing gradients...
  Epoch 169, Batch 1/4: Forward pass...
  Epoch 169, Batch 1/4: Calculating loss...
  Epoch 169, Batch 1/4: Backward pass...
  Epoch 169, Batch 1/4: Clipping gradients...
  Epoch 169, Batch 1/4: Optimizer step...
  Epoch 169, Batch 1/4: Completed in 0.20s
  Epoch 169, Batch 2/4: Loading data to device...
  Epoch 169, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 169, Batch 2/4: Zeroing gradients...
  Epoch 169, Batch 2/4: Forward pass...
  Epoch 169, Batch 2/4: Calculating loss...
  Epoch 169, Batch 2/4: Backward pass...
  Epoch 169, Batch 2/4: Clipping gradients...
  Epoch 169, Batch 2/4: Optimizer step...
  Epoch 169, Batch 2/4: Completed in 0.20s
  Epoch 169, Batch 3/4: Loading data to device...
  Epoch 169, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 169, Batch 3/4: Zeroing gradients...
  Epoch 169, Batch 3/4: Forward pass...
  Epoch 169, Batch 3/4: Calculating loss...
  Epoch 169, Batch 3/4: Backward pass...
  Epoch 169, Batch 3/4: Clipping gradients...
  Epoch 169, Batch 3/4: Optimizer step...
  Epoch 169, Batch 3/4: Completed in 0.20s
  Epoch 169, Batch 4/4: Loading data to device...
  Epoch 169, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 169, Batch 4/4: Zeroing gradients...
  Epoch 169, Batch 4/4: Forward pass...
  Epoch 169, Batch 4/4: Calculating loss...
  Epoch 169, Batch 4/4: Backward pass...
  Epoch 169, Batch 4/4: Clipping gradients...
  Epoch 169, Batch 4/4: Optimizer step...
  Epoch 169, Batch 4/4: Completed in 0.03s
Epoch 169: Training phase completed. Average Train Loss: 0.5235
Epoch 169: Starting validation phase...
  Epoch 169, Val Batch 1/1: Loading data...
  Epoch 169, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 169, Val Batch 1/1: Forward pass...
  Epoch 169, Val Batch 1/1: Calculating loss...
Epoch 169: Validation phase completed. Average Val Loss: 0.3639
Epoch 169 Summary ---> Train Loss: 0.5235 / Validation Loss: 0.3639
Epoch 169: Checking early stopping... (Current Best Loss: 0.3518, Epochs No Improve: 3)
  Epoch 169: Validation loss did not improve. Epochs without improvement: 4
Epoch 169: Stepping scheduler...
--- Epoch 169 completed in 0.69 seconds ---

--- Starting Epoch 170/1000 ---
Epoch 170: Starting training phase (4 batches)
  Epoch 170, Batch 1/4: Loading data to device...
  Epoch 170, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 170, Batch 1/4: Zeroing gradients...
  Epoch 170, Batch 1/4: Forward pass...
  Epoch 170, Batch 1/4: Calculating loss...
  Epoch 170, Batch 1/4: Backward pass...
  Epoch 170, Batch 1/4: Clipping gradients...
  Epoch 170, Batch 1/4: Optimizer step...
  Epoch 170, Batch 1/4: Completed in 0.20s
  Epoch 170, Batch 2/4: Loading data to device...
  Epoch 170, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 170, Batch 2/4: Zeroing gradients...
  Epoch 170, Batch 2/4: Forward pass...
  Epoch 170, Batch 2/4: Calculating loss...
  Epoch 170, Batch 2/4: Backward pass...
  Epoch 170, Batch 2/4: Clipping gradients...
  Epoch 170, Batch 2/4: Optimizer step...
  Epoch 170, Batch 2/4: Completed in 0.20s
  Epoch 170, Batch 3/4: Loading data to device...
  Epoch 170, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 170, Batch 3/4: Zeroing gradients...
  Epoch 170, Batch 3/4: Forward pass...
  Epoch 170, Batch 3/4: Calculating loss...
  Epoch 170, Batch 3/4: Backward pass...
  Epoch 170, Batch 3/4: Clipping gradients...
  Epoch 170, Batch 3/4: Optimizer step...
  Epoch 170, Batch 3/4: Completed in 0.20s
  Epoch 170, Batch 4/4: Loading data to device...
  Epoch 170, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 170, Batch 4/4: Zeroing gradients...
  Epoch 170, Batch 4/4: Forward pass...
  Epoch 170, Batch 4/4: Calculating loss...
  Epoch 170, Batch 4/4: Backward pass...
  Epoch 170, Batch 4/4: Clipping gradients...
  Epoch 170, Batch 4/4: Optimizer step...
  Epoch 170, Batch 4/4: Completed in 0.03s
Epoch 170: Training phase completed. Average Train Loss: 0.3993
Epoch 170: Starting validation phase...
  Epoch 170, Val Batch 1/1: Loading data...
  Epoch 170, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 170, Val Batch 1/1: Forward pass...
  Epoch 170, Val Batch 1/1: Calculating loss...
Epoch 170: Validation phase completed. Average Val Loss: 0.3741
Epoch 170 Summary ---> Train Loss: 0.3993 / Validation Loss: 0.3741
Epoch 170: Checking early stopping... (Current Best Loss: 0.3518, Epochs No Improve: 4)
  Epoch 170: Validation loss did not improve. Epochs without improvement: 5
Epoch 170: Stepping scheduler...
--- Epoch 170 completed in 0.69 seconds ---

--- Starting Epoch 171/1000 ---
Epoch 171: Starting training phase (4 batches)
  Epoch 171, Batch 1/4: Loading data to device...
  Epoch 171, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 171, Batch 1/4: Zeroing gradients...
  Epoch 171, Batch 1/4: Forward pass...
  Epoch 171, Batch 1/4: Calculating loss...
  Epoch 171, Batch 1/4: Backward pass...
  Epoch 171, Batch 1/4: Clipping gradients...
  Epoch 171, Batch 1/4: Optimizer step...
  Epoch 171, Batch 1/4: Completed in 0.20s
  Epoch 171, Batch 2/4: Loading data to device...
  Epoch 171, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 171, Batch 2/4: Zeroing gradients...
  Epoch 171, Batch 2/4: Forward pass...
  Epoch 171, Batch 2/4: Calculating loss...
  Epoch 171, Batch 2/4: Backward pass...
  Epoch 171, Batch 2/4: Clipping gradients...
  Epoch 171, Batch 2/4: Optimizer step...
  Epoch 171, Batch 2/4: Completed in 0.19s
  Epoch 171, Batch 3/4: Loading data to device...
  Epoch 171, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 171, Batch 3/4: Zeroing gradients...
  Epoch 171, Batch 3/4: Forward pass...
  Epoch 171, Batch 3/4: Calculating loss...
  Epoch 171, Batch 3/4: Backward pass...
  Epoch 171, Batch 3/4: Clipping gradients...
  Epoch 171, Batch 3/4: Optimizer step...
  Epoch 171, Batch 3/4: Completed in 0.19s
  Epoch 171, Batch 4/4: Loading data to device...
  Epoch 171, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 171, Batch 4/4: Zeroing gradients...
  Epoch 171, Batch 4/4: Forward pass...
  Epoch 171, Batch 4/4: Calculating loss...
  Epoch 171, Batch 4/4: Backward pass...
  Epoch 171, Batch 4/4: Clipping gradients...
  Epoch 171, Batch 4/4: Optimizer step...
  Epoch 171, Batch 4/4: Completed in 0.03s
Epoch 171: Training phase completed. Average Train Loss: 0.4152
Epoch 171: Starting validation phase...
  Epoch 171, Val Batch 1/1: Loading data...
  Epoch 171, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 171, Val Batch 1/1: Forward pass...
  Epoch 171, Val Batch 1/1: Calculating loss...
Epoch 171: Validation phase completed. Average Val Loss: 0.3670
Epoch 171 Summary ---> Train Loss: 0.4152 / Validation Loss: 0.3670
Epoch 171: Checking early stopping... (Current Best Loss: 0.3518, Epochs No Improve: 5)
  Epoch 171: Validation loss did not improve. Epochs without improvement: 6
Epoch 171: Stepping scheduler...
--- Epoch 171 completed in 0.68 seconds ---

--- Starting Epoch 172/1000 ---
Epoch 172: Starting training phase (4 batches)
  Epoch 172, Batch 1/4: Loading data to device...
  Epoch 172, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 172, Batch 1/4: Zeroing gradients...
  Epoch 172, Batch 1/4: Forward pass...
  Epoch 172, Batch 1/4: Calculating loss...
  Epoch 172, Batch 1/4: Backward pass...
  Epoch 172, Batch 1/4: Clipping gradients...
  Epoch 172, Batch 1/4: Optimizer step...
  Epoch 172, Batch 1/4: Completed in 0.19s
  Epoch 172, Batch 2/4: Loading data to device...
  Epoch 172, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 172, Batch 2/4: Zeroing gradients...
  Epoch 172, Batch 2/4: Forward pass...
  Epoch 172, Batch 2/4: Calculating loss...
  Epoch 172, Batch 2/4: Backward pass...
  Epoch 172, Batch 2/4: Clipping gradients...
  Epoch 172, Batch 2/4: Optimizer step...
  Epoch 172, Batch 2/4: Completed in 0.19s
  Epoch 172, Batch 3/4: Loading data to device...
  Epoch 172, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 172, Batch 3/4: Zeroing gradients...
  Epoch 172, Batch 3/4: Forward pass...
  Epoch 172, Batch 3/4: Calculating loss...
  Epoch 172, Batch 3/4: Backward pass...
  Epoch 172, Batch 3/4: Clipping gradients...
  Epoch 172, Batch 3/4: Optimizer step...
  Epoch 172, Batch 3/4: Completed in 0.19s
  Epoch 172, Batch 4/4: Loading data to device...
  Epoch 172, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 172, Batch 4/4: Zeroing gradients...
  Epoch 172, Batch 4/4: Forward pass...
  Epoch 172, Batch 4/4: Calculating loss...
  Epoch 172, Batch 4/4: Backward pass...
  Epoch 172, Batch 4/4: Clipping gradients...
  Epoch 172, Batch 4/4: Optimizer step...
  Epoch 172, Batch 4/4: Completed in 0.03s
Epoch 172: Training phase completed. Average Train Loss: 0.4068
Epoch 172: Starting validation phase...
  Epoch 172, Val Batch 1/1: Loading data...
  Epoch 172, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 172, Val Batch 1/1: Forward pass...
  Epoch 172, Val Batch 1/1: Calculating loss...
Epoch 172: Validation phase completed. Average Val Loss: 0.3586
Epoch 172 Summary ---> Train Loss: 0.4068 / Validation Loss: 0.3586
Epoch 172: Checking early stopping... (Current Best Loss: 0.3518, Epochs No Improve: 6)
  Epoch 172: Validation loss did not improve. Epochs without improvement: 7
Epoch 172: Stepping scheduler...
--- Epoch 172 completed in 0.66 seconds ---

--- Starting Epoch 173/1000 ---
Epoch 173: Starting training phase (4 batches)
  Epoch 173, Batch 1/4: Loading data to device...
  Epoch 173, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 173, Batch 1/4: Zeroing gradients...
  Epoch 173, Batch 1/4: Forward pass...
  Epoch 173, Batch 1/4: Calculating loss...
  Epoch 173, Batch 1/4: Backward pass...
  Epoch 173, Batch 1/4: Clipping gradients...
  Epoch 173, Batch 1/4: Optimizer step...
  Epoch 173, Batch 1/4: Completed in 0.19s
  Epoch 173, Batch 2/4: Loading data to device...
  Epoch 173, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 173, Batch 2/4: Zeroing gradients...
  Epoch 173, Batch 2/4: Forward pass...
  Epoch 173, Batch 2/4: Calculating loss...
  Epoch 173, Batch 2/4: Backward pass...
  Epoch 173, Batch 2/4: Clipping gradients...
  Epoch 173, Batch 2/4: Optimizer step...
  Epoch 173, Batch 2/4: Completed in 0.19s
  Epoch 173, Batch 3/4: Loading data to device...
  Epoch 173, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 173, Batch 3/4: Zeroing gradients...
  Epoch 173, Batch 3/4: Forward pass...
  Epoch 173, Batch 3/4: Calculating loss...
  Epoch 173, Batch 3/4: Backward pass...
  Epoch 173, Batch 3/4: Clipping gradients...
  Epoch 173, Batch 3/4: Optimizer step...
  Epoch 173, Batch 3/4: Completed in 0.19s
  Epoch 173, Batch 4/4: Loading data to device...
  Epoch 173, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 173, Batch 4/4: Zeroing gradients...
  Epoch 173, Batch 4/4: Forward pass...
  Epoch 173, Batch 4/4: Calculating loss...
  Epoch 173, Batch 4/4: Backward pass...
  Epoch 173, Batch 4/4: Clipping gradients...
  Epoch 173, Batch 4/4: Optimizer step...
  Epoch 173, Batch 4/4: Completed in 0.04s
Epoch 173: Training phase completed. Average Train Loss: 0.4179
Epoch 173: Starting validation phase...
  Epoch 173, Val Batch 1/1: Loading data...
  Epoch 173, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 173, Val Batch 1/1: Forward pass...
  Epoch 173, Val Batch 1/1: Calculating loss...
Epoch 173: Validation phase completed. Average Val Loss: 0.3551
Epoch 173 Summary ---> Train Loss: 0.4179 / Validation Loss: 0.3551
Epoch 173: Checking early stopping... (Current Best Loss: 0.3518, Epochs No Improve: 7)
  Epoch 173: Validation loss did not improve. Epochs without improvement: 8
Epoch 173: Stepping scheduler...
--- Epoch 173 completed in 0.68 seconds ---

--- Starting Epoch 174/1000 ---
Epoch 174: Starting training phase (4 batches)
  Epoch 174, Batch 1/4: Loading data to device...
  Epoch 174, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 174, Batch 1/4: Zeroing gradients...
  Epoch 174, Batch 1/4: Forward pass...
  Epoch 174, Batch 1/4: Calculating loss...
  Epoch 174, Batch 1/4: Backward pass...
  Epoch 174, Batch 1/4: Clipping gradients...
  Epoch 174, Batch 1/4: Optimizer step...
  Epoch 174, Batch 1/4: Completed in 0.19s
  Epoch 174, Batch 2/4: Loading data to device...
  Epoch 174, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 174, Batch 2/4: Zeroing gradients...
  Epoch 174, Batch 2/4: Forward pass...
  Epoch 174, Batch 2/4: Calculating loss...
  Epoch 174, Batch 2/4: Backward pass...
  Epoch 174, Batch 2/4: Clipping gradients...
  Epoch 174, Batch 2/4: Optimizer step...
  Epoch 174, Batch 2/4: Completed in 0.19s
  Epoch 174, Batch 3/4: Loading data to device...
  Epoch 174, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 174, Batch 3/4: Zeroing gradients...
  Epoch 174, Batch 3/4: Forward pass...
  Epoch 174, Batch 3/4: Calculating loss...
  Epoch 174, Batch 3/4: Backward pass...
  Epoch 174, Batch 3/4: Clipping gradients...
  Epoch 174, Batch 3/4: Optimizer step...
  Epoch 174, Batch 3/4: Completed in 0.19s
  Epoch 174, Batch 4/4: Loading data to device...
  Epoch 174, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 174, Batch 4/4: Zeroing gradients...
  Epoch 174, Batch 4/4: Forward pass...
  Epoch 174, Batch 4/4: Calculating loss...
  Epoch 174, Batch 4/4: Backward pass...
  Epoch 174, Batch 4/4: Clipping gradients...
  Epoch 174, Batch 4/4: Optimizer step...
  Epoch 174, Batch 4/4: Completed in 0.03s
Epoch 174: Training phase completed. Average Train Loss: 0.4390
Epoch 174: Starting validation phase...
  Epoch 174, Val Batch 1/1: Loading data...
  Epoch 174, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 174, Val Batch 1/1: Forward pass...
  Epoch 174, Val Batch 1/1: Calculating loss...
Epoch 174: Validation phase completed. Average Val Loss: 0.3494
Epoch 174 Summary ---> Train Loss: 0.4390 / Validation Loss: 0.3494
Epoch 174: Checking early stopping... (Current Best Loss: 0.3518, Epochs No Improve: 8)
  Epoch 174: Validation loss improved (0.3518 --> 0.3494). Saving model.
Epoch 174: Stepping scheduler...
--- Epoch 174 completed in 0.68 seconds ---

--- Starting Epoch 175/1000 ---
Epoch 175: Starting training phase (4 batches)
  Epoch 175, Batch 1/4: Loading data to device...
  Epoch 175, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 175, Batch 1/4: Zeroing gradients...
  Epoch 175, Batch 1/4: Forward pass...
  Epoch 175, Batch 1/4: Calculating loss...
  Epoch 175, Batch 1/4: Backward pass...
  Epoch 175, Batch 1/4: Clipping gradients...
  Epoch 175, Batch 1/4: Optimizer step...
  Epoch 175, Batch 1/4: Completed in 0.19s
  Epoch 175, Batch 2/4: Loading data to device...
  Epoch 175, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 175, Batch 2/4: Zeroing gradients...
  Epoch 175, Batch 2/4: Forward pass...
  Epoch 175, Batch 2/4: Calculating loss...
  Epoch 175, Batch 2/4: Backward pass...
  Epoch 175, Batch 2/4: Clipping gradients...
  Epoch 175, Batch 2/4: Optimizer step...
  Epoch 175, Batch 2/4: Completed in 0.20s
  Epoch 175, Batch 3/4: Loading data to device...
  Epoch 175, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 175, Batch 3/4: Zeroing gradients...
  Epoch 175, Batch 3/4: Forward pass...
  Epoch 175, Batch 3/4: Calculating loss...
  Epoch 175, Batch 3/4: Backward pass...
  Epoch 175, Batch 3/4: Clipping gradients...
  Epoch 175, Batch 3/4: Optimizer step...
  Epoch 175, Batch 3/4: Completed in 0.20s
  Epoch 175, Batch 4/4: Loading data to device...
  Epoch 175, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 175, Batch 4/4: Zeroing gradients...
  Epoch 175, Batch 4/4: Forward pass...
  Epoch 175, Batch 4/4: Calculating loss...
  Epoch 175, Batch 4/4: Backward pass...
  Epoch 175, Batch 4/4: Clipping gradients...
  Epoch 175, Batch 4/4: Optimizer step...
  Epoch 175, Batch 4/4: Completed in 0.03s
Epoch 175: Training phase completed. Average Train Loss: 0.4236
Epoch 175: Starting validation phase...
  Epoch 175, Val Batch 1/1: Loading data...
  Epoch 175, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 175, Val Batch 1/1: Forward pass...
  Epoch 175, Val Batch 1/1: Calculating loss...
Epoch 175: Validation phase completed. Average Val Loss: 0.3498
Epoch 175 Summary ---> Train Loss: 0.4236 / Validation Loss: 0.3498
Epoch 175: Checking early stopping... (Current Best Loss: 0.3494, Epochs No Improve: 0)
  Epoch 175: Validation loss did not improve. Epochs without improvement: 1
Epoch 175: Stepping scheduler...
--- Epoch 175 completed in 0.69 seconds ---

--- Starting Epoch 176/1000 ---
Epoch 176: Starting training phase (4 batches)
  Epoch 176, Batch 1/4: Loading data to device...
  Epoch 176, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 176, Batch 1/4: Zeroing gradients...
  Epoch 176, Batch 1/4: Forward pass...
  Epoch 176, Batch 1/4: Calculating loss...
  Epoch 176, Batch 1/4: Backward pass...
  Epoch 176, Batch 1/4: Clipping gradients...
  Epoch 176, Batch 1/4: Optimizer step...
  Epoch 176, Batch 1/4: Completed in 0.20s
  Epoch 176, Batch 2/4: Loading data to device...
  Epoch 176, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 176, Batch 2/4: Zeroing gradients...
  Epoch 176, Batch 2/4: Forward pass...
  Epoch 176, Batch 2/4: Calculating loss...
  Epoch 176, Batch 2/4: Backward pass...
  Epoch 176, Batch 2/4: Clipping gradients...
  Epoch 176, Batch 2/4: Optimizer step...
  Epoch 176, Batch 2/4: Completed in 0.21s
  Epoch 176, Batch 3/4: Loading data to device...
  Epoch 176, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 176, Batch 3/4: Zeroing gradients...
  Epoch 176, Batch 3/4: Forward pass...
  Epoch 176, Batch 3/4: Calculating loss...
  Epoch 176, Batch 3/4: Backward pass...
  Epoch 176, Batch 3/4: Clipping gradients...
  Epoch 176, Batch 3/4: Optimizer step...
  Epoch 176, Batch 3/4: Completed in 0.21s
  Epoch 176, Batch 4/4: Loading data to device...
  Epoch 176, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 176, Batch 4/4: Zeroing gradients...
  Epoch 176, Batch 4/4: Forward pass...
  Epoch 176, Batch 4/4: Calculating loss...
  Epoch 176, Batch 4/4: Backward pass...
  Epoch 176, Batch 4/4: Clipping gradients...
  Epoch 176, Batch 4/4: Optimizer step...
  Epoch 176, Batch 4/4: Completed in 0.03s
Epoch 176: Training phase completed. Average Train Loss: 0.3888
Epoch 176: Starting validation phase...
  Epoch 176, Val Batch 1/1: Loading data...
  Epoch 176, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 176, Val Batch 1/1: Forward pass...
  Epoch 176, Val Batch 1/1: Calculating loss...
Epoch 176: Validation phase completed. Average Val Loss: 0.3478
Epoch 176 Summary ---> Train Loss: 0.3888 / Validation Loss: 0.3478
Epoch 176: Checking early stopping... (Current Best Loss: 0.3494, Epochs No Improve: 1)
  Epoch 176: Validation loss improved (0.3494 --> 0.3478). Saving model.
Epoch 176: Stepping scheduler...
--- Epoch 176 completed in 0.72 seconds ---

--- Starting Epoch 177/1000 ---
Epoch 177: Starting training phase (4 batches)
  Epoch 177, Batch 1/4: Loading data to device...
  Epoch 177, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 177, Batch 1/4: Zeroing gradients...
  Epoch 177, Batch 1/4: Forward pass...
  Epoch 177, Batch 1/4: Calculating loss...
  Epoch 177, Batch 1/4: Backward pass...
  Epoch 177, Batch 1/4: Clipping gradients...
  Epoch 177, Batch 1/4: Optimizer step...
  Epoch 177, Batch 1/4: Completed in 0.21s
  Epoch 177, Batch 2/4: Loading data to device...
  Epoch 177, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 177, Batch 2/4: Zeroing gradients...
  Epoch 177, Batch 2/4: Forward pass...
  Epoch 177, Batch 2/4: Calculating loss...
  Epoch 177, Batch 2/4: Backward pass...
  Epoch 177, Batch 2/4: Clipping gradients...
  Epoch 177, Batch 2/4: Optimizer step...
  Epoch 177, Batch 2/4: Completed in 0.21s
  Epoch 177, Batch 3/4: Loading data to device...
  Epoch 177, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 177, Batch 3/4: Zeroing gradients...
  Epoch 177, Batch 3/4: Forward pass...
  Epoch 177, Batch 3/4: Calculating loss...
  Epoch 177, Batch 3/4: Backward pass...
  Epoch 177, Batch 3/4: Clipping gradients...
  Epoch 177, Batch 3/4: Optimizer step...
  Epoch 177, Batch 3/4: Completed in 0.20s
  Epoch 177, Batch 4/4: Loading data to device...
  Epoch 177, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 177, Batch 4/4: Zeroing gradients...
  Epoch 177, Batch 4/4: Forward pass...
  Epoch 177, Batch 4/4: Calculating loss...
  Epoch 177, Batch 4/4: Backward pass...
  Epoch 177, Batch 4/4: Clipping gradients...
  Epoch 177, Batch 4/4: Optimizer step...
  Epoch 177, Batch 4/4: Completed in 0.04s
Epoch 177: Training phase completed. Average Train Loss: 0.3980
Epoch 177: Starting validation phase...
  Epoch 177, Val Batch 1/1: Loading data...
  Epoch 177, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 177, Val Batch 1/1: Forward pass...
  Epoch 177, Val Batch 1/1: Calculating loss...
Epoch 177: Validation phase completed. Average Val Loss: 0.3524
Epoch 177 Summary ---> Train Loss: 0.3980 / Validation Loss: 0.3524
Epoch 177: Checking early stopping... (Current Best Loss: 0.3478, Epochs No Improve: 0)
  Epoch 177: Validation loss did not improve. Epochs without improvement: 1
Epoch 177: Stepping scheduler...
--- Epoch 177 completed in 0.72 seconds ---

--- Starting Epoch 178/1000 ---
Epoch 178: Starting training phase (4 batches)
  Epoch 178, Batch 1/4: Loading data to device...
  Epoch 178, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 178, Batch 1/4: Zeroing gradients...
  Epoch 178, Batch 1/4: Forward pass...
  Epoch 178, Batch 1/4: Calculating loss...
  Epoch 178, Batch 1/4: Backward pass...
  Epoch 178, Batch 1/4: Clipping gradients...
  Epoch 178, Batch 1/4: Optimizer step...
  Epoch 178, Batch 1/4: Completed in 0.20s
  Epoch 178, Batch 2/4: Loading data to device...
  Epoch 178, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 178, Batch 2/4: Zeroing gradients...
  Epoch 178, Batch 2/4: Forward pass...
  Epoch 178, Batch 2/4: Calculating loss...
  Epoch 178, Batch 2/4: Backward pass...
  Epoch 178, Batch 2/4: Clipping gradients...
  Epoch 178, Batch 2/4: Optimizer step...
  Epoch 178, Batch 2/4: Completed in 0.19s
  Epoch 178, Batch 3/4: Loading data to device...
  Epoch 178, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 178, Batch 3/4: Zeroing gradients...
  Epoch 178, Batch 3/4: Forward pass...
  Epoch 178, Batch 3/4: Calculating loss...
  Epoch 178, Batch 3/4: Backward pass...
  Epoch 178, Batch 3/4: Clipping gradients...
  Epoch 178, Batch 3/4: Optimizer step...
  Epoch 178, Batch 3/4: Completed in 0.20s
  Epoch 178, Batch 4/4: Loading data to device...
  Epoch 178, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 178, Batch 4/4: Zeroing gradients...
  Epoch 178, Batch 4/4: Forward pass...
  Epoch 178, Batch 4/4: Calculating loss...
  Epoch 178, Batch 4/4: Backward pass...
  Epoch 178, Batch 4/4: Clipping gradients...
  Epoch 178, Batch 4/4: Optimizer step...
  Epoch 178, Batch 4/4: Completed in 0.03s
Epoch 178: Training phase completed. Average Train Loss: 0.4580
Epoch 178: Starting validation phase...
  Epoch 178, Val Batch 1/1: Loading data...
  Epoch 178, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 178, Val Batch 1/1: Forward pass...
  Epoch 178, Val Batch 1/1: Calculating loss...
Epoch 178: Validation phase completed. Average Val Loss: 0.3594
Epoch 178 Summary ---> Train Loss: 0.4580 / Validation Loss: 0.3594
Epoch 178: Checking early stopping... (Current Best Loss: 0.3478, Epochs No Improve: 1)
  Epoch 178: Validation loss did not improve. Epochs without improvement: 2
Epoch 178: Stepping scheduler...
--- Epoch 178 completed in 0.69 seconds ---

--- Starting Epoch 179/1000 ---
Epoch 179: Starting training phase (4 batches)
  Epoch 179, Batch 1/4: Loading data to device...
  Epoch 179, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 179, Batch 1/4: Zeroing gradients...
  Epoch 179, Batch 1/4: Forward pass...
  Epoch 179, Batch 1/4: Calculating loss...
  Epoch 179, Batch 1/4: Backward pass...
  Epoch 179, Batch 1/4: Clipping gradients...
  Epoch 179, Batch 1/4: Optimizer step...
  Epoch 179, Batch 1/4: Completed in 0.19s
  Epoch 179, Batch 2/4: Loading data to device...
  Epoch 179, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 179, Batch 2/4: Zeroing gradients...
  Epoch 179, Batch 2/4: Forward pass...
  Epoch 179, Batch 2/4: Calculating loss...
  Epoch 179, Batch 2/4: Backward pass...
  Epoch 179, Batch 2/4: Clipping gradients...
  Epoch 179, Batch 2/4: Optimizer step...
  Epoch 179, Batch 2/4: Completed in 0.20s
  Epoch 179, Batch 3/4: Loading data to device...
  Epoch 179, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 179, Batch 3/4: Zeroing gradients...
  Epoch 179, Batch 3/4: Forward pass...
  Epoch 179, Batch 3/4: Calculating loss...
  Epoch 179, Batch 3/4: Backward pass...
  Epoch 179, Batch 3/4: Clipping gradients...
  Epoch 179, Batch 3/4: Optimizer step...
  Epoch 179, Batch 3/4: Completed in 0.20s
  Epoch 179, Batch 4/4: Loading data to device...
  Epoch 179, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 179, Batch 4/4: Zeroing gradients...
  Epoch 179, Batch 4/4: Forward pass...
  Epoch 179, Batch 4/4: Calculating loss...
  Epoch 179, Batch 4/4: Backward pass...
  Epoch 179, Batch 4/4: Clipping gradients...
  Epoch 179, Batch 4/4: Optimizer step...
  Epoch 179, Batch 4/4: Completed in 0.03s
Epoch 179: Training phase completed. Average Train Loss: 0.3920
Epoch 179: Starting validation phase...
  Epoch 179, Val Batch 1/1: Loading data...
  Epoch 179, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 179, Val Batch 1/1: Forward pass...
  Epoch 179, Val Batch 1/1: Calculating loss...
Epoch 179: Validation phase completed. Average Val Loss: 0.3607
Epoch 179 Summary ---> Train Loss: 0.3920 / Validation Loss: 0.3607
Epoch 179: Checking early stopping... (Current Best Loss: 0.3478, Epochs No Improve: 2)
  Epoch 179: Validation loss did not improve. Epochs without improvement: 3
Epoch 179: Stepping scheduler...
--- Epoch 179 completed in 0.69 seconds ---

--- Starting Epoch 180/1000 ---
Epoch 180: Starting training phase (4 batches)
  Epoch 180, Batch 1/4: Loading data to device...
  Epoch 180, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 180, Batch 1/4: Zeroing gradients...
  Epoch 180, Batch 1/4: Forward pass...
  Epoch 180, Batch 1/4: Calculating loss...
  Epoch 180, Batch 1/4: Backward pass...
  Epoch 180, Batch 1/4: Clipping gradients...
  Epoch 180, Batch 1/4: Optimizer step...
  Epoch 180, Batch 1/4: Completed in 0.19s
  Epoch 180, Batch 2/4: Loading data to device...
  Epoch 180, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 180, Batch 2/4: Zeroing gradients...
  Epoch 180, Batch 2/4: Forward pass...
  Epoch 180, Batch 2/4: Calculating loss...
  Epoch 180, Batch 2/4: Backward pass...
  Epoch 180, Batch 2/4: Clipping gradients...
  Epoch 180, Batch 2/4: Optimizer step...
  Epoch 180, Batch 2/4: Completed in 0.19s
  Epoch 180, Batch 3/4: Loading data to device...
  Epoch 180, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 180, Batch 3/4: Zeroing gradients...
  Epoch 180, Batch 3/4: Forward pass...
  Epoch 180, Batch 3/4: Calculating loss...
  Epoch 180, Batch 3/4: Backward pass...
  Epoch 180, Batch 3/4: Clipping gradients...
  Epoch 180, Batch 3/4: Optimizer step...
  Epoch 180, Batch 3/4: Completed in 0.19s
  Epoch 180, Batch 4/4: Loading data to device...
  Epoch 180, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 180, Batch 4/4: Zeroing gradients...
  Epoch 180, Batch 4/4: Forward pass...
  Epoch 180, Batch 4/4: Calculating loss...
  Epoch 180, Batch 4/4: Backward pass...
  Epoch 180, Batch 4/4: Clipping gradients...
  Epoch 180, Batch 4/4: Optimizer step...
  Epoch 180, Batch 4/4: Completed in 0.03s
Epoch 180: Training phase completed. Average Train Loss: 0.4129
Epoch 180: Starting validation phase...
  Epoch 180, Val Batch 1/1: Loading data...
  Epoch 180, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 180, Val Batch 1/1: Forward pass...
  Epoch 180, Val Batch 1/1: Calculating loss...
Epoch 180: Validation phase completed. Average Val Loss: 0.3582
Epoch 180 Summary ---> Train Loss: 0.4129 / Validation Loss: 0.3582
Epoch 180: Checking early stopping... (Current Best Loss: 0.3478, Epochs No Improve: 3)
  Epoch 180: Validation loss did not improve. Epochs without improvement: 4
Epoch 180: Stepping scheduler...
--- Epoch 180 completed in 0.68 seconds ---

--- Starting Epoch 181/1000 ---
Epoch 181: Starting training phase (4 batches)
  Epoch 181, Batch 1/4: Loading data to device...
  Epoch 181, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 181, Batch 1/4: Zeroing gradients...
  Epoch 181, Batch 1/4: Forward pass...
  Epoch 181, Batch 1/4: Calculating loss...
  Epoch 181, Batch 1/4: Backward pass...
  Epoch 181, Batch 1/4: Clipping gradients...
  Epoch 181, Batch 1/4: Optimizer step...
  Epoch 181, Batch 1/4: Completed in 0.20s
  Epoch 181, Batch 2/4: Loading data to device...
  Epoch 181, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 181, Batch 2/4: Zeroing gradients...
  Epoch 181, Batch 2/4: Forward pass...
  Epoch 181, Batch 2/4: Calculating loss...
  Epoch 181, Batch 2/4: Backward pass...
  Epoch 181, Batch 2/4: Clipping gradients...
  Epoch 181, Batch 2/4: Optimizer step...
  Epoch 181, Batch 2/4: Completed in 0.19s
  Epoch 181, Batch 3/4: Loading data to device...
  Epoch 181, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 181, Batch 3/4: Zeroing gradients...
  Epoch 181, Batch 3/4: Forward pass...
  Epoch 181, Batch 3/4: Calculating loss...
  Epoch 181, Batch 3/4: Backward pass...
  Epoch 181, Batch 3/4: Clipping gradients...
  Epoch 181, Batch 3/4: Optimizer step...
  Epoch 181, Batch 3/4: Completed in 0.20s
  Epoch 181, Batch 4/4: Loading data to device...
  Epoch 181, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 181, Batch 4/4: Zeroing gradients...
  Epoch 181, Batch 4/4: Forward pass...
  Epoch 181, Batch 4/4: Calculating loss...
  Epoch 181, Batch 4/4: Backward pass...
  Epoch 181, Batch 4/4: Clipping gradients...
  Epoch 181, Batch 4/4: Optimizer step...
  Epoch 181, Batch 4/4: Completed in 0.03s
Epoch 181: Training phase completed. Average Train Loss: 0.3727
Epoch 181: Starting validation phase...
  Epoch 181, Val Batch 1/1: Loading data...
  Epoch 181, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 181, Val Batch 1/1: Forward pass...
  Epoch 181, Val Batch 1/1: Calculating loss...
Epoch 181: Validation phase completed. Average Val Loss: 0.3724
Epoch 181 Summary ---> Train Loss: 0.3727 / Validation Loss: 0.3724
Epoch 181: Checking early stopping... (Current Best Loss: 0.3478, Epochs No Improve: 4)
  Epoch 181: Validation loss did not improve. Epochs without improvement: 5
Epoch 181: Stepping scheduler...
--- Epoch 181 completed in 0.69 seconds ---

--- Starting Epoch 182/1000 ---
Epoch 182: Starting training phase (4 batches)
  Epoch 182, Batch 1/4: Loading data to device...
  Epoch 182, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 182, Batch 1/4: Zeroing gradients...
  Epoch 182, Batch 1/4: Forward pass...
  Epoch 182, Batch 1/4: Calculating loss...
  Epoch 182, Batch 1/4: Backward pass...
  Epoch 182, Batch 1/4: Clipping gradients...
  Epoch 182, Batch 1/4: Optimizer step...
  Epoch 182, Batch 1/4: Completed in 0.19s
  Epoch 182, Batch 2/4: Loading data to device...
  Epoch 182, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 182, Batch 2/4: Zeroing gradients...
  Epoch 182, Batch 2/4: Forward pass...
  Epoch 182, Batch 2/4: Calculating loss...
  Epoch 182, Batch 2/4: Backward pass...
  Epoch 182, Batch 2/4: Clipping gradients...
  Epoch 182, Batch 2/4: Optimizer step...
  Epoch 182, Batch 2/4: Completed in 0.19s
  Epoch 182, Batch 3/4: Loading data to device...
  Epoch 182, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 182, Batch 3/4: Zeroing gradients...
  Epoch 182, Batch 3/4: Forward pass...
  Epoch 182, Batch 3/4: Calculating loss...
  Epoch 182, Batch 3/4: Backward pass...
  Epoch 182, Batch 3/4: Clipping gradients...
  Epoch 182, Batch 3/4: Optimizer step...
  Epoch 182, Batch 3/4: Completed in 0.19s
  Epoch 182, Batch 4/4: Loading data to device...
  Epoch 182, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 182, Batch 4/4: Zeroing gradients...
  Epoch 182, Batch 4/4: Forward pass...
  Epoch 182, Batch 4/4: Calculating loss...
  Epoch 182, Batch 4/4: Backward pass...
  Epoch 182, Batch 4/4: Clipping gradients...
  Epoch 182, Batch 4/4: Optimizer step...
  Epoch 182, Batch 4/4: Completed in 0.03s
Epoch 182: Training phase completed. Average Train Loss: 0.4322
Epoch 182: Starting validation phase...
  Epoch 182, Val Batch 1/1: Loading data...
  Epoch 182, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 182, Val Batch 1/1: Forward pass...
  Epoch 182, Val Batch 1/1: Calculating loss...
Epoch 182: Validation phase completed. Average Val Loss: 0.3802
Epoch 182 Summary ---> Train Loss: 0.4322 / Validation Loss: 0.3802
Epoch 182: Checking early stopping... (Current Best Loss: 0.3478, Epochs No Improve: 5)
  Epoch 182: Validation loss did not improve. Epochs without improvement: 6
Epoch 182: Stepping scheduler...
--- Epoch 182 completed in 0.68 seconds ---

--- Starting Epoch 183/1000 ---
Epoch 183: Starting training phase (4 batches)
  Epoch 183, Batch 1/4: Loading data to device...
  Epoch 183, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 183, Batch 1/4: Zeroing gradients...
  Epoch 183, Batch 1/4: Forward pass...
  Epoch 183, Batch 1/4: Calculating loss...
  Epoch 183, Batch 1/4: Backward pass...
  Epoch 183, Batch 1/4: Clipping gradients...
  Epoch 183, Batch 1/4: Optimizer step...
  Epoch 183, Batch 1/4: Completed in 0.20s
  Epoch 183, Batch 2/4: Loading data to device...
  Epoch 183, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 183, Batch 2/4: Zeroing gradients...
  Epoch 183, Batch 2/4: Forward pass...
  Epoch 183, Batch 2/4: Calculating loss...
  Epoch 183, Batch 2/4: Backward pass...
  Epoch 183, Batch 2/4: Clipping gradients...
  Epoch 183, Batch 2/4: Optimizer step...
  Epoch 183, Batch 2/4: Completed in 0.20s
  Epoch 183, Batch 3/4: Loading data to device...
  Epoch 183, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 183, Batch 3/4: Zeroing gradients...
  Epoch 183, Batch 3/4: Forward pass...
  Epoch 183, Batch 3/4: Calculating loss...
  Epoch 183, Batch 3/4: Backward pass...
  Epoch 183, Batch 3/4: Clipping gradients...
  Epoch 183, Batch 3/4: Optimizer step...
  Epoch 183, Batch 3/4: Completed in 0.20s
  Epoch 183, Batch 4/4: Loading data to device...
  Epoch 183, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 183, Batch 4/4: Zeroing gradients...
  Epoch 183, Batch 4/4: Forward pass...
  Epoch 183, Batch 4/4: Calculating loss...
  Epoch 183, Batch 4/4: Backward pass...
  Epoch 183, Batch 4/4: Clipping gradients...
  Epoch 183, Batch 4/4: Optimizer step...
  Epoch 183, Batch 4/4: Completed in 0.03s
Epoch 183: Training phase completed. Average Train Loss: 0.4216
Epoch 183: Starting validation phase...
  Epoch 183, Val Batch 1/1: Loading data...
  Epoch 183, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 183, Val Batch 1/1: Forward pass...
  Epoch 183, Val Batch 1/1: Calculating loss...
Epoch 183: Validation phase completed. Average Val Loss: 0.3690
Epoch 183 Summary ---> Train Loss: 0.4216 / Validation Loss: 0.3690
Epoch 183: Checking early stopping... (Current Best Loss: 0.3478, Epochs No Improve: 6)
  Epoch 183: Validation loss did not improve. Epochs without improvement: 7
Epoch 183: Stepping scheduler...
--- Epoch 183 completed in 0.70 seconds ---

--- Starting Epoch 184/1000 ---
Epoch 184: Starting training phase (4 batches)
  Epoch 184, Batch 1/4: Loading data to device...
  Epoch 184, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 184, Batch 1/4: Zeroing gradients...
  Epoch 184, Batch 1/4: Forward pass...
  Epoch 184, Batch 1/4: Calculating loss...
  Epoch 184, Batch 1/4: Backward pass...
  Epoch 184, Batch 1/4: Clipping gradients...
  Epoch 184, Batch 1/4: Optimizer step...
  Epoch 184, Batch 1/4: Completed in 0.20s
  Epoch 184, Batch 2/4: Loading data to device...
  Epoch 184, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 184, Batch 2/4: Zeroing gradients...
  Epoch 184, Batch 2/4: Forward pass...
  Epoch 184, Batch 2/4: Calculating loss...
  Epoch 184, Batch 2/4: Backward pass...
  Epoch 184, Batch 2/4: Clipping gradients...
  Epoch 184, Batch 2/4: Optimizer step...
  Epoch 184, Batch 2/4: Completed in 0.19s
  Epoch 184, Batch 3/4: Loading data to device...
  Epoch 184, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 184, Batch 3/4: Zeroing gradients...
  Epoch 184, Batch 3/4: Forward pass...
  Epoch 184, Batch 3/4: Calculating loss...
  Epoch 184, Batch 3/4: Backward pass...
  Epoch 184, Batch 3/4: Clipping gradients...
  Epoch 184, Batch 3/4: Optimizer step...
  Epoch 184, Batch 3/4: Completed in 0.20s
  Epoch 184, Batch 4/4: Loading data to device...
  Epoch 184, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 184, Batch 4/4: Zeroing gradients...
  Epoch 184, Batch 4/4: Forward pass...
  Epoch 184, Batch 4/4: Calculating loss...
  Epoch 184, Batch 4/4: Backward pass...
  Epoch 184, Batch 4/4: Clipping gradients...
  Epoch 184, Batch 4/4: Optimizer step...
  Epoch 184, Batch 4/4: Completed in 0.03s
Epoch 184: Training phase completed. Average Train Loss: 0.4089
Epoch 184: Starting validation phase...
  Epoch 184, Val Batch 1/1: Loading data...
  Epoch 184, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 184, Val Batch 1/1: Forward pass...
  Epoch 184, Val Batch 1/1: Calculating loss...
Epoch 184: Validation phase completed. Average Val Loss: 0.3601
Epoch 184 Summary ---> Train Loss: 0.4089 / Validation Loss: 0.3601
Epoch 184: Checking early stopping... (Current Best Loss: 0.3478, Epochs No Improve: 7)
  Epoch 184: Validation loss did not improve. Epochs without improvement: 8
Epoch 184: Stepping scheduler...
--- Epoch 184 completed in 0.69 seconds ---

--- Starting Epoch 185/1000 ---
Epoch 185: Starting training phase (4 batches)
  Epoch 185, Batch 1/4: Loading data to device...
  Epoch 185, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 185, Batch 1/4: Zeroing gradients...
  Epoch 185, Batch 1/4: Forward pass...
  Epoch 185, Batch 1/4: Calculating loss...
  Epoch 185, Batch 1/4: Backward pass...
  Epoch 185, Batch 1/4: Clipping gradients...
  Epoch 185, Batch 1/4: Optimizer step...
  Epoch 185, Batch 1/4: Completed in 0.19s
  Epoch 185, Batch 2/4: Loading data to device...
  Epoch 185, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 185, Batch 2/4: Zeroing gradients...
  Epoch 185, Batch 2/4: Forward pass...
  Epoch 185, Batch 2/4: Calculating loss...
  Epoch 185, Batch 2/4: Backward pass...
  Epoch 185, Batch 2/4: Clipping gradients...
  Epoch 185, Batch 2/4: Optimizer step...
  Epoch 185, Batch 2/4: Completed in 0.19s
  Epoch 185, Batch 3/4: Loading data to device...
  Epoch 185, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 185, Batch 3/4: Zeroing gradients...
  Epoch 185, Batch 3/4: Forward pass...
  Epoch 185, Batch 3/4: Calculating loss...
  Epoch 185, Batch 3/4: Backward pass...
  Epoch 185, Batch 3/4: Clipping gradients...
  Epoch 185, Batch 3/4: Optimizer step...
  Epoch 185, Batch 3/4: Completed in 0.19s
  Epoch 185, Batch 4/4: Loading data to device...
  Epoch 185, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 185, Batch 4/4: Zeroing gradients...
  Epoch 185, Batch 4/4: Forward pass...
  Epoch 185, Batch 4/4: Calculating loss...
  Epoch 185, Batch 4/4: Backward pass...
  Epoch 185, Batch 4/4: Clipping gradients...
  Epoch 185, Batch 4/4: Optimizer step...
  Epoch 185, Batch 4/4: Completed in 0.03s
Epoch 185: Training phase completed. Average Train Loss: 0.3962
Epoch 185: Starting validation phase...
  Epoch 185, Val Batch 1/1: Loading data...
  Epoch 185, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 185, Val Batch 1/1: Forward pass...
  Epoch 185, Val Batch 1/1: Calculating loss...
Epoch 185: Validation phase completed. Average Val Loss: 0.3575
Epoch 185 Summary ---> Train Loss: 0.3962 / Validation Loss: 0.3575
Epoch 185: Checking early stopping... (Current Best Loss: 0.3478, Epochs No Improve: 8)
  Epoch 185: Validation loss did not improve. Epochs without improvement: 9
Epoch 185: Stepping scheduler...
--- Epoch 185 completed in 0.66 seconds ---

--- Starting Epoch 186/1000 ---
Epoch 186: Starting training phase (4 batches)
  Epoch 186, Batch 1/4: Loading data to device...
  Epoch 186, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 186, Batch 1/4: Zeroing gradients...
  Epoch 186, Batch 1/4: Forward pass...
  Epoch 186, Batch 1/4: Calculating loss...
  Epoch 186, Batch 1/4: Backward pass...
  Epoch 186, Batch 1/4: Clipping gradients...
  Epoch 186, Batch 1/4: Optimizer step...
  Epoch 186, Batch 1/4: Completed in 0.20s
  Epoch 186, Batch 2/4: Loading data to device...
  Epoch 186, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 186, Batch 2/4: Zeroing gradients...
  Epoch 186, Batch 2/4: Forward pass...
  Epoch 186, Batch 2/4: Calculating loss...
  Epoch 186, Batch 2/4: Backward pass...
  Epoch 186, Batch 2/4: Clipping gradients...
  Epoch 186, Batch 2/4: Optimizer step...
  Epoch 186, Batch 2/4: Completed in 0.19s
  Epoch 186, Batch 3/4: Loading data to device...
  Epoch 186, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 186, Batch 3/4: Zeroing gradients...
  Epoch 186, Batch 3/4: Forward pass...
  Epoch 186, Batch 3/4: Calculating loss...
  Epoch 186, Batch 3/4: Backward pass...
  Epoch 186, Batch 3/4: Clipping gradients...
  Epoch 186, Batch 3/4: Optimizer step...
  Epoch 186, Batch 3/4: Completed in 0.20s
  Epoch 186, Batch 4/4: Loading data to device...
  Epoch 186, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 186, Batch 4/4: Zeroing gradients...
  Epoch 186, Batch 4/4: Forward pass...
  Epoch 186, Batch 4/4: Calculating loss...
  Epoch 186, Batch 4/4: Backward pass...
  Epoch 186, Batch 4/4: Clipping gradients...
  Epoch 186, Batch 4/4: Optimizer step...
  Epoch 186, Batch 4/4: Completed in 0.03s
Epoch 186: Training phase completed. Average Train Loss: 0.4371
Epoch 186: Starting validation phase...
  Epoch 186, Val Batch 1/1: Loading data...
  Epoch 186, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 186, Val Batch 1/1: Forward pass...
  Epoch 186, Val Batch 1/1: Calculating loss...
Epoch 186: Validation phase completed. Average Val Loss: 0.3467
Epoch 186 Summary ---> Train Loss: 0.4371 / Validation Loss: 0.3467
Epoch 186: Checking early stopping... (Current Best Loss: 0.3478, Epochs No Improve: 9)
  Epoch 186: Validation loss improved (0.3478 --> 0.3467). Saving model.
Epoch 186: Stepping scheduler...
--- Epoch 186 completed in 0.69 seconds ---

--- Starting Epoch 187/1000 ---
Epoch 187: Starting training phase (4 batches)
  Epoch 187, Batch 1/4: Loading data to device...
  Epoch 187, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 187, Batch 1/4: Zeroing gradients...
  Epoch 187, Batch 1/4: Forward pass...
  Epoch 187, Batch 1/4: Calculating loss...
  Epoch 187, Batch 1/4: Backward pass...
  Epoch 187, Batch 1/4: Clipping gradients...
  Epoch 187, Batch 1/4: Optimizer step...
  Epoch 187, Batch 1/4: Completed in 0.20s
  Epoch 187, Batch 2/4: Loading data to device...
  Epoch 187, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 187, Batch 2/4: Zeroing gradients...
  Epoch 187, Batch 2/4: Forward pass...
  Epoch 187, Batch 2/4: Calculating loss...
  Epoch 187, Batch 2/4: Backward pass...
  Epoch 187, Batch 2/4: Clipping gradients...
  Epoch 187, Batch 2/4: Optimizer step...
  Epoch 187, Batch 2/4: Completed in 0.20s
  Epoch 187, Batch 3/4: Loading data to device...
  Epoch 187, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 187, Batch 3/4: Zeroing gradients...
  Epoch 187, Batch 3/4: Forward pass...
  Epoch 187, Batch 3/4: Calculating loss...
  Epoch 187, Batch 3/4: Backward pass...
  Epoch 187, Batch 3/4: Clipping gradients...
  Epoch 187, Batch 3/4: Optimizer step...
  Epoch 187, Batch 3/4: Completed in 0.19s
  Epoch 187, Batch 4/4: Loading data to device...
  Epoch 187, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 187, Batch 4/4: Zeroing gradients...
  Epoch 187, Batch 4/4: Forward pass...
  Epoch 187, Batch 4/4: Calculating loss...
  Epoch 187, Batch 4/4: Backward pass...
  Epoch 187, Batch 4/4: Clipping gradients...
  Epoch 187, Batch 4/4: Optimizer step...
  Epoch 187, Batch 4/4: Completed in 0.03s
Epoch 187: Training phase completed. Average Train Loss: 0.4659
Epoch 187: Starting validation phase...
  Epoch 187, Val Batch 1/1: Loading data...
  Epoch 187, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 187, Val Batch 1/1: Forward pass...
  Epoch 187, Val Batch 1/1: Calculating loss...
Epoch 187: Validation phase completed. Average Val Loss: 0.3429
Epoch 187 Summary ---> Train Loss: 0.4659 / Validation Loss: 0.3429
Epoch 187: Checking early stopping... (Current Best Loss: 0.3467, Epochs No Improve: 0)
  Epoch 187: Validation loss improved (0.3467 --> 0.3429). Saving model.
Epoch 187: Stepping scheduler...
--- Epoch 187 completed in 0.69 seconds ---

--- Starting Epoch 188/1000 ---
Epoch 188: Starting training phase (4 batches)
  Epoch 188, Batch 1/4: Loading data to device...
  Epoch 188, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 188, Batch 1/4: Zeroing gradients...
  Epoch 188, Batch 1/4: Forward pass...
  Epoch 188, Batch 1/4: Calculating loss...
  Epoch 188, Batch 1/4: Backward pass...
  Epoch 188, Batch 1/4: Clipping gradients...
  Epoch 188, Batch 1/4: Optimizer step...
  Epoch 188, Batch 1/4: Completed in 0.20s
  Epoch 188, Batch 2/4: Loading data to device...
  Epoch 188, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 188, Batch 2/4: Zeroing gradients...
  Epoch 188, Batch 2/4: Forward pass...
  Epoch 188, Batch 2/4: Calculating loss...
  Epoch 188, Batch 2/4: Backward pass...
  Epoch 188, Batch 2/4: Clipping gradients...
  Epoch 188, Batch 2/4: Optimizer step...
  Epoch 188, Batch 2/4: Completed in 0.19s
  Epoch 188, Batch 3/4: Loading data to device...
  Epoch 188, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 188, Batch 3/4: Zeroing gradients...
  Epoch 188, Batch 3/4: Forward pass...
  Epoch 188, Batch 3/4: Calculating loss...
  Epoch 188, Batch 3/4: Backward pass...
  Epoch 188, Batch 3/4: Clipping gradients...
  Epoch 188, Batch 3/4: Optimizer step...
  Epoch 188, Batch 3/4: Completed in 0.19s
  Epoch 188, Batch 4/4: Loading data to device...
  Epoch 188, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 188, Batch 4/4: Zeroing gradients...
  Epoch 188, Batch 4/4: Forward pass...
  Epoch 188, Batch 4/4: Calculating loss...
  Epoch 188, Batch 4/4: Backward pass...
  Epoch 188, Batch 4/4: Clipping gradients...
  Epoch 188, Batch 4/4: Optimizer step...
  Epoch 188, Batch 4/4: Completed in 0.03s
Epoch 188: Training phase completed. Average Train Loss: 0.3930
Epoch 188: Starting validation phase...
  Epoch 188, Val Batch 1/1: Loading data...
  Epoch 188, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 188, Val Batch 1/1: Forward pass...
  Epoch 188, Val Batch 1/1: Calculating loss...
Epoch 188: Validation phase completed. Average Val Loss: 0.3441
Epoch 188 Summary ---> Train Loss: 0.3930 / Validation Loss: 0.3441
Epoch 188: Checking early stopping... (Current Best Loss: 0.3429, Epochs No Improve: 0)
  Epoch 188: Validation loss did not improve. Epochs without improvement: 1
Epoch 188: Stepping scheduler...
--- Epoch 188 completed in 0.68 seconds ---

--- Starting Epoch 189/1000 ---
Epoch 189: Starting training phase (4 batches)
  Epoch 189, Batch 1/4: Loading data to device...
  Epoch 189, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 189, Batch 1/4: Zeroing gradients...
  Epoch 189, Batch 1/4: Forward pass...
  Epoch 189, Batch 1/4: Calculating loss...
  Epoch 189, Batch 1/4: Backward pass...
  Epoch 189, Batch 1/4: Clipping gradients...
  Epoch 189, Batch 1/4: Optimizer step...
  Epoch 189, Batch 1/4: Completed in 0.20s
  Epoch 189, Batch 2/4: Loading data to device...
  Epoch 189, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 189, Batch 2/4: Zeroing gradients...
  Epoch 189, Batch 2/4: Forward pass...
  Epoch 189, Batch 2/4: Calculating loss...
  Epoch 189, Batch 2/4: Backward pass...
  Epoch 189, Batch 2/4: Clipping gradients...
  Epoch 189, Batch 2/4: Optimizer step...
  Epoch 189, Batch 2/4: Completed in 0.19s
  Epoch 189, Batch 3/4: Loading data to device...
  Epoch 189, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 189, Batch 3/4: Zeroing gradients...
  Epoch 189, Batch 3/4: Forward pass...
  Epoch 189, Batch 3/4: Calculating loss...
  Epoch 189, Batch 3/4: Backward pass...
  Epoch 189, Batch 3/4: Clipping gradients...
  Epoch 189, Batch 3/4: Optimizer step...
  Epoch 189, Batch 3/4: Completed in 0.19s
  Epoch 189, Batch 4/4: Loading data to device...
  Epoch 189, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 189, Batch 4/4: Zeroing gradients...
  Epoch 189, Batch 4/4: Forward pass...
  Epoch 189, Batch 4/4: Calculating loss...
  Epoch 189, Batch 4/4: Backward pass...
  Epoch 189, Batch 4/4: Clipping gradients...
  Epoch 189, Batch 4/4: Optimizer step...
  Epoch 189, Batch 4/4: Completed in 0.03s
Epoch 189: Training phase completed. Average Train Loss: 0.4132
Epoch 189: Starting validation phase...
  Epoch 189, Val Batch 1/1: Loading data...
  Epoch 189, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 189, Val Batch 1/1: Forward pass...
  Epoch 189, Val Batch 1/1: Calculating loss...
Epoch 189: Validation phase completed. Average Val Loss: 0.3466
Epoch 189 Summary ---> Train Loss: 0.4132 / Validation Loss: 0.3466
Epoch 189: Checking early stopping... (Current Best Loss: 0.3429, Epochs No Improve: 1)
  Epoch 189: Validation loss did not improve. Epochs without improvement: 2
Epoch 189: Stepping scheduler...
--- Epoch 189 completed in 0.68 seconds ---

--- Starting Epoch 190/1000 ---
Epoch 190: Starting training phase (4 batches)
  Epoch 190, Batch 1/4: Loading data to device...
  Epoch 190, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 190, Batch 1/4: Zeroing gradients...
  Epoch 190, Batch 1/4: Forward pass...
  Epoch 190, Batch 1/4: Calculating loss...
  Epoch 190, Batch 1/4: Backward pass...
  Epoch 190, Batch 1/4: Clipping gradients...
  Epoch 190, Batch 1/4: Optimizer step...
  Epoch 190, Batch 1/4: Completed in 0.19s
  Epoch 190, Batch 2/4: Loading data to device...
  Epoch 190, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 190, Batch 2/4: Zeroing gradients...
  Epoch 190, Batch 2/4: Forward pass...
  Epoch 190, Batch 2/4: Calculating loss...
  Epoch 190, Batch 2/4: Backward pass...
  Epoch 190, Batch 2/4: Clipping gradients...
  Epoch 190, Batch 2/4: Optimizer step...
  Epoch 190, Batch 2/4: Completed in 0.19s
  Epoch 190, Batch 3/4: Loading data to device...
  Epoch 190, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 190, Batch 3/4: Zeroing gradients...
  Epoch 190, Batch 3/4: Forward pass...
  Epoch 190, Batch 3/4: Calculating loss...
  Epoch 190, Batch 3/4: Backward pass...
  Epoch 190, Batch 3/4: Clipping gradients...
  Epoch 190, Batch 3/4: Optimizer step...
  Epoch 190, Batch 3/4: Completed in 0.19s
  Epoch 190, Batch 4/4: Loading data to device...
  Epoch 190, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 190, Batch 4/4: Zeroing gradients...
  Epoch 190, Batch 4/4: Forward pass...
  Epoch 190, Batch 4/4: Calculating loss...
  Epoch 190, Batch 4/4: Backward pass...
  Epoch 190, Batch 4/4: Clipping gradients...
  Epoch 190, Batch 4/4: Optimizer step...
  Epoch 190, Batch 4/4: Completed in 0.03s
Epoch 190: Training phase completed. Average Train Loss: 0.3738
Epoch 190: Starting validation phase...
  Epoch 190, Val Batch 1/1: Loading data...
  Epoch 190, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 190, Val Batch 1/1: Forward pass...
  Epoch 190, Val Batch 1/1: Calculating loss...
Epoch 190: Validation phase completed. Average Val Loss: 0.3383
Epoch 190 Summary ---> Train Loss: 0.3738 / Validation Loss: 0.3383
Epoch 190: Checking early stopping... (Current Best Loss: 0.3429, Epochs No Improve: 2)
  Epoch 190: Validation loss improved (0.3429 --> 0.3383). Saving model.
Epoch 190: Stepping scheduler...
--- Epoch 190 completed in 0.68 seconds ---

--- Starting Epoch 191/1000 ---
Epoch 191: Starting training phase (4 batches)
  Epoch 191, Batch 1/4: Loading data to device...
  Epoch 191, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 191, Batch 1/4: Zeroing gradients...
  Epoch 191, Batch 1/4: Forward pass...
  Epoch 191, Batch 1/4: Calculating loss...
  Epoch 191, Batch 1/4: Backward pass...
  Epoch 191, Batch 1/4: Clipping gradients...
  Epoch 191, Batch 1/4: Optimizer step...
  Epoch 191, Batch 1/4: Completed in 0.20s
  Epoch 191, Batch 2/4: Loading data to device...
  Epoch 191, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 191, Batch 2/4: Zeroing gradients...
  Epoch 191, Batch 2/4: Forward pass...
  Epoch 191, Batch 2/4: Calculating loss...
  Epoch 191, Batch 2/4: Backward pass...
  Epoch 191, Batch 2/4: Clipping gradients...
  Epoch 191, Batch 2/4: Optimizer step...
  Epoch 191, Batch 2/4: Completed in 0.20s
  Epoch 191, Batch 3/4: Loading data to device...
  Epoch 191, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 191, Batch 3/4: Zeroing gradients...
  Epoch 191, Batch 3/4: Forward pass...
  Epoch 191, Batch 3/4: Calculating loss...
  Epoch 191, Batch 3/4: Backward pass...
  Epoch 191, Batch 3/4: Clipping gradients...
  Epoch 191, Batch 3/4: Optimizer step...
  Epoch 191, Batch 3/4: Completed in 0.19s
  Epoch 191, Batch 4/4: Loading data to device...
  Epoch 191, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 191, Batch 4/4: Zeroing gradients...
  Epoch 191, Batch 4/4: Forward pass...
  Epoch 191, Batch 4/4: Calculating loss...
  Epoch 191, Batch 4/4: Backward pass...
  Epoch 191, Batch 4/4: Clipping gradients...
  Epoch 191, Batch 4/4: Optimizer step...
  Epoch 191, Batch 4/4: Completed in 0.03s
Epoch 191: Training phase completed. Average Train Loss: 0.4229
Epoch 191: Starting validation phase...
  Epoch 191, Val Batch 1/1: Loading data...
  Epoch 191, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 191, Val Batch 1/1: Forward pass...
  Epoch 191, Val Batch 1/1: Calculating loss...
Epoch 191: Validation phase completed. Average Val Loss: 0.3387
Epoch 191 Summary ---> Train Loss: 0.4229 / Validation Loss: 0.3387
Epoch 191: Checking early stopping... (Current Best Loss: 0.3383, Epochs No Improve: 0)
  Epoch 191: Validation loss did not improve. Epochs without improvement: 1
Epoch 191: Stepping scheduler...
--- Epoch 191 completed in 0.69 seconds ---

--- Starting Epoch 192/1000 ---
Epoch 192: Starting training phase (4 batches)
  Epoch 192, Batch 1/4: Loading data to device...
  Epoch 192, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 192, Batch 1/4: Zeroing gradients...
  Epoch 192, Batch 1/4: Forward pass...
  Epoch 192, Batch 1/4: Calculating loss...
  Epoch 192, Batch 1/4: Backward pass...
  Epoch 192, Batch 1/4: Clipping gradients...
  Epoch 192, Batch 1/4: Optimizer step...
  Epoch 192, Batch 1/4: Completed in 0.19s
  Epoch 192, Batch 2/4: Loading data to device...
  Epoch 192, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 192, Batch 2/4: Zeroing gradients...
  Epoch 192, Batch 2/4: Forward pass...
  Epoch 192, Batch 2/4: Calculating loss...
  Epoch 192, Batch 2/4: Backward pass...
  Epoch 192, Batch 2/4: Clipping gradients...
  Epoch 192, Batch 2/4: Optimizer step...
  Epoch 192, Batch 2/4: Completed in 0.19s
  Epoch 192, Batch 3/4: Loading data to device...
  Epoch 192, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 192, Batch 3/4: Zeroing gradients...
  Epoch 192, Batch 3/4: Forward pass...
  Epoch 192, Batch 3/4: Calculating loss...
  Epoch 192, Batch 3/4: Backward pass...
  Epoch 192, Batch 3/4: Clipping gradients...
  Epoch 192, Batch 3/4: Optimizer step...
  Epoch 192, Batch 3/4: Completed in 0.19s
  Epoch 192, Batch 4/4: Loading data to device...
  Epoch 192, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 192, Batch 4/4: Zeroing gradients...
  Epoch 192, Batch 4/4: Forward pass...
  Epoch 192, Batch 4/4: Calculating loss...
  Epoch 192, Batch 4/4: Backward pass...
  Epoch 192, Batch 4/4: Clipping gradients...
  Epoch 192, Batch 4/4: Optimizer step...
  Epoch 192, Batch 4/4: Completed in 0.03s
Epoch 192: Training phase completed. Average Train Loss: 0.3621
Epoch 192: Starting validation phase...
  Epoch 192, Val Batch 1/1: Loading data...
  Epoch 192, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 192, Val Batch 1/1: Forward pass...
  Epoch 192, Val Batch 1/1: Calculating loss...
Epoch 192: Validation phase completed. Average Val Loss: 0.3409
Epoch 192 Summary ---> Train Loss: 0.3621 / Validation Loss: 0.3409
Epoch 192: Checking early stopping... (Current Best Loss: 0.3383, Epochs No Improve: 1)
  Epoch 192: Validation loss did not improve. Epochs without improvement: 2
Epoch 192: Stepping scheduler...
--- Epoch 192 completed in 0.68 seconds ---

--- Starting Epoch 193/1000 ---
Epoch 193: Starting training phase (4 batches)
  Epoch 193, Batch 1/4: Loading data to device...
  Epoch 193, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 193, Batch 1/4: Zeroing gradients...
  Epoch 193, Batch 1/4: Forward pass...
  Epoch 193, Batch 1/4: Calculating loss...
  Epoch 193, Batch 1/4: Backward pass...
  Epoch 193, Batch 1/4: Clipping gradients...
  Epoch 193, Batch 1/4: Optimizer step...
  Epoch 193, Batch 1/4: Completed in 0.20s
  Epoch 193, Batch 2/4: Loading data to device...
  Epoch 193, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 193, Batch 2/4: Zeroing gradients...
  Epoch 193, Batch 2/4: Forward pass...
  Epoch 193, Batch 2/4: Calculating loss...
  Epoch 193, Batch 2/4: Backward pass...
  Epoch 193, Batch 2/4: Clipping gradients...
  Epoch 193, Batch 2/4: Optimizer step...
  Epoch 193, Batch 2/4: Completed in 0.20s
  Epoch 193, Batch 3/4: Loading data to device...
  Epoch 193, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 193, Batch 3/4: Zeroing gradients...
  Epoch 193, Batch 3/4: Forward pass...
  Epoch 193, Batch 3/4: Calculating loss...
  Epoch 193, Batch 3/4: Backward pass...
  Epoch 193, Batch 3/4: Clipping gradients...
  Epoch 193, Batch 3/4: Optimizer step...
  Epoch 193, Batch 3/4: Completed in 0.19s
  Epoch 193, Batch 4/4: Loading data to device...
  Epoch 193, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 193, Batch 4/4: Zeroing gradients...
  Epoch 193, Batch 4/4: Forward pass...
  Epoch 193, Batch 4/4: Calculating loss...
  Epoch 193, Batch 4/4: Backward pass...
  Epoch 193, Batch 4/4: Clipping gradients...
  Epoch 193, Batch 4/4: Optimizer step...
  Epoch 193, Batch 4/4: Completed in 0.03s
Epoch 193: Training phase completed. Average Train Loss: 0.4399
Epoch 193: Starting validation phase...
  Epoch 193, Val Batch 1/1: Loading data...
  Epoch 193, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 193, Val Batch 1/1: Forward pass...
  Epoch 193, Val Batch 1/1: Calculating loss...
Epoch 193: Validation phase completed. Average Val Loss: 0.3382
Epoch 193 Summary ---> Train Loss: 0.4399 / Validation Loss: 0.3382
Epoch 193: Checking early stopping... (Current Best Loss: 0.3383, Epochs No Improve: 2)
  Epoch 193: Validation loss improved (0.3383 --> 0.3382). Saving model.
Epoch 193: Stepping scheduler...
--- Epoch 193 completed in 0.69 seconds ---

--- Starting Epoch 194/1000 ---
Epoch 194: Starting training phase (4 batches)
  Epoch 194, Batch 1/4: Loading data to device...
  Epoch 194, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 194, Batch 1/4: Zeroing gradients...
  Epoch 194, Batch 1/4: Forward pass...
  Epoch 194, Batch 1/4: Calculating loss...
  Epoch 194, Batch 1/4: Backward pass...
  Epoch 194, Batch 1/4: Clipping gradients...
  Epoch 194, Batch 1/4: Optimizer step...
  Epoch 194, Batch 1/4: Completed in 0.19s
  Epoch 194, Batch 2/4: Loading data to device...
  Epoch 194, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 194, Batch 2/4: Zeroing gradients...
  Epoch 194, Batch 2/4: Forward pass...
  Epoch 194, Batch 2/4: Calculating loss...
  Epoch 194, Batch 2/4: Backward pass...
  Epoch 194, Batch 2/4: Clipping gradients...
  Epoch 194, Batch 2/4: Optimizer step...
  Epoch 194, Batch 2/4: Completed in 0.19s
  Epoch 194, Batch 3/4: Loading data to device...
  Epoch 194, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 194, Batch 3/4: Zeroing gradients...
  Epoch 194, Batch 3/4: Forward pass...
  Epoch 194, Batch 3/4: Calculating loss...
  Epoch 194, Batch 3/4: Backward pass...
  Epoch 194, Batch 3/4: Clipping gradients...
  Epoch 194, Batch 3/4: Optimizer step...
  Epoch 194, Batch 3/4: Completed in 0.20s
  Epoch 194, Batch 4/4: Loading data to device...
  Epoch 194, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 194, Batch 4/4: Zeroing gradients...
  Epoch 194, Batch 4/4: Forward pass...
  Epoch 194, Batch 4/4: Calculating loss...
  Epoch 194, Batch 4/4: Backward pass...
  Epoch 194, Batch 4/4: Clipping gradients...
  Epoch 194, Batch 4/4: Optimizer step...
  Epoch 194, Batch 4/4: Completed in 0.03s
Epoch 194: Training phase completed. Average Train Loss: 0.4478
Epoch 194: Starting validation phase...
  Epoch 194, Val Batch 1/1: Loading data...
  Epoch 194, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 194, Val Batch 1/1: Forward pass...
  Epoch 194, Val Batch 1/1: Calculating loss...
Epoch 194: Validation phase completed. Average Val Loss: 0.3301
Epoch 194 Summary ---> Train Loss: 0.4478 / Validation Loss: 0.3301
Epoch 194: Checking early stopping... (Current Best Loss: 0.3382, Epochs No Improve: 0)
  Epoch 194: Validation loss improved (0.3382 --> 0.3301). Saving model.
Epoch 194: Stepping scheduler...
--- Epoch 194 completed in 0.68 seconds ---

--- Starting Epoch 195/1000 ---
Epoch 195: Starting training phase (4 batches)
  Epoch 195, Batch 1/4: Loading data to device...
  Epoch 195, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 195, Batch 1/4: Zeroing gradients...
  Epoch 195, Batch 1/4: Forward pass...
  Epoch 195, Batch 1/4: Calculating loss...
  Epoch 195, Batch 1/4: Backward pass...
  Epoch 195, Batch 1/4: Clipping gradients...
  Epoch 195, Batch 1/4: Optimizer step...
  Epoch 195, Batch 1/4: Completed in 0.19s
  Epoch 195, Batch 2/4: Loading data to device...
  Epoch 195, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 195, Batch 2/4: Zeroing gradients...
  Epoch 195, Batch 2/4: Forward pass...
  Epoch 195, Batch 2/4: Calculating loss...
  Epoch 195, Batch 2/4: Backward pass...
  Epoch 195, Batch 2/4: Clipping gradients...
  Epoch 195, Batch 2/4: Optimizer step...
  Epoch 195, Batch 2/4: Completed in 0.19s
  Epoch 195, Batch 3/4: Loading data to device...
  Epoch 195, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 195, Batch 3/4: Zeroing gradients...
  Epoch 195, Batch 3/4: Forward pass...
  Epoch 195, Batch 3/4: Calculating loss...
  Epoch 195, Batch 3/4: Backward pass...
  Epoch 195, Batch 3/4: Clipping gradients...
  Epoch 195, Batch 3/4: Optimizer step...
  Epoch 195, Batch 3/4: Completed in 0.19s
  Epoch 195, Batch 4/4: Loading data to device...
  Epoch 195, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 195, Batch 4/4: Zeroing gradients...
  Epoch 195, Batch 4/4: Forward pass...
  Epoch 195, Batch 4/4: Calculating loss...
  Epoch 195, Batch 4/4: Backward pass...
  Epoch 195, Batch 4/4: Clipping gradients...
  Epoch 195, Batch 4/4: Optimizer step...
  Epoch 195, Batch 4/4: Completed in 0.03s
Epoch 195: Training phase completed. Average Train Loss: 0.3714
Epoch 195: Starting validation phase...
  Epoch 195, Val Batch 1/1: Loading data...
  Epoch 195, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 195, Val Batch 1/1: Forward pass...
  Epoch 195, Val Batch 1/1: Calculating loss...
Epoch 195: Validation phase completed. Average Val Loss: 0.3280
Epoch 195 Summary ---> Train Loss: 0.3714 / Validation Loss: 0.3280
Epoch 195: Checking early stopping... (Current Best Loss: 0.3301, Epochs No Improve: 0)
  Epoch 195: Validation loss improved (0.3301 --> 0.3280). Saving model.
Epoch 195: Stepping scheduler...
--- Epoch 195 completed in 0.69 seconds ---

--- Starting Epoch 196/1000 ---
Epoch 196: Starting training phase (4 batches)
  Epoch 196, Batch 1/4: Loading data to device...
  Epoch 196, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 196, Batch 1/4: Zeroing gradients...
  Epoch 196, Batch 1/4: Forward pass...
  Epoch 196, Batch 1/4: Calculating loss...
  Epoch 196, Batch 1/4: Backward pass...
  Epoch 196, Batch 1/4: Clipping gradients...
  Epoch 196, Batch 1/4: Optimizer step...
  Epoch 196, Batch 1/4: Completed in 0.21s
  Epoch 196, Batch 2/4: Loading data to device...
  Epoch 196, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 196, Batch 2/4: Zeroing gradients...
  Epoch 196, Batch 2/4: Forward pass...
  Epoch 196, Batch 2/4: Calculating loss...
  Epoch 196, Batch 2/4: Backward pass...
  Epoch 196, Batch 2/4: Clipping gradients...
  Epoch 196, Batch 2/4: Optimizer step...
  Epoch 196, Batch 2/4: Completed in 0.20s
  Epoch 196, Batch 3/4: Loading data to device...
  Epoch 196, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 196, Batch 3/4: Zeroing gradients...
  Epoch 196, Batch 3/4: Forward pass...
  Epoch 196, Batch 3/4: Calculating loss...
  Epoch 196, Batch 3/4: Backward pass...
  Epoch 196, Batch 3/4: Clipping gradients...
  Epoch 196, Batch 3/4: Optimizer step...
  Epoch 196, Batch 3/4: Completed in 0.19s
  Epoch 196, Batch 4/4: Loading data to device...
  Epoch 196, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 196, Batch 4/4: Zeroing gradients...
  Epoch 196, Batch 4/4: Forward pass...
  Epoch 196, Batch 4/4: Calculating loss...
  Epoch 196, Batch 4/4: Backward pass...
  Epoch 196, Batch 4/4: Clipping gradients...
  Epoch 196, Batch 4/4: Optimizer step...
  Epoch 196, Batch 4/4: Completed in 0.03s
Epoch 196: Training phase completed. Average Train Loss: 0.3689
Epoch 196: Starting validation phase...
  Epoch 196, Val Batch 1/1: Loading data...
  Epoch 196, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 196, Val Batch 1/1: Forward pass...
  Epoch 196, Val Batch 1/1: Calculating loss...
Epoch 196: Validation phase completed. Average Val Loss: 0.3293
Epoch 196 Summary ---> Train Loss: 0.3689 / Validation Loss: 0.3293
Epoch 196: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 0)
  Epoch 196: Validation loss did not improve. Epochs without improvement: 1
Epoch 196: Stepping scheduler...
--- Epoch 196 completed in 0.70 seconds ---

--- Starting Epoch 197/1000 ---
Epoch 197: Starting training phase (4 batches)
  Epoch 197, Batch 1/4: Loading data to device...
  Epoch 197, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 197, Batch 1/4: Zeroing gradients...
  Epoch 197, Batch 1/4: Forward pass...
  Epoch 197, Batch 1/4: Calculating loss...
  Epoch 197, Batch 1/4: Backward pass...
  Epoch 197, Batch 1/4: Clipping gradients...
  Epoch 197, Batch 1/4: Optimizer step...
  Epoch 197, Batch 1/4: Completed in 0.20s
  Epoch 197, Batch 2/4: Loading data to device...
  Epoch 197, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 197, Batch 2/4: Zeroing gradients...
  Epoch 197, Batch 2/4: Forward pass...
  Epoch 197, Batch 2/4: Calculating loss...
  Epoch 197, Batch 2/4: Backward pass...
  Epoch 197, Batch 2/4: Clipping gradients...
  Epoch 197, Batch 2/4: Optimizer step...
  Epoch 197, Batch 2/4: Completed in 0.19s
  Epoch 197, Batch 3/4: Loading data to device...
  Epoch 197, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 197, Batch 3/4: Zeroing gradients...
  Epoch 197, Batch 3/4: Forward pass...
  Epoch 197, Batch 3/4: Calculating loss...
  Epoch 197, Batch 3/4: Backward pass...
  Epoch 197, Batch 3/4: Clipping gradients...
  Epoch 197, Batch 3/4: Optimizer step...
  Epoch 197, Batch 3/4: Completed in 0.19s
  Epoch 197, Batch 4/4: Loading data to device...
  Epoch 197, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 197, Batch 4/4: Zeroing gradients...
  Epoch 197, Batch 4/4: Forward pass...
  Epoch 197, Batch 4/4: Calculating loss...
  Epoch 197, Batch 4/4: Backward pass...
  Epoch 197, Batch 4/4: Clipping gradients...
  Epoch 197, Batch 4/4: Optimizer step...
  Epoch 197, Batch 4/4: Completed in 0.03s
Epoch 197: Training phase completed. Average Train Loss: 0.4149
Epoch 197: Starting validation phase...
  Epoch 197, Val Batch 1/1: Loading data...
  Epoch 197, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 197, Val Batch 1/1: Forward pass...
  Epoch 197, Val Batch 1/1: Calculating loss...
Epoch 197: Validation phase completed. Average Val Loss: 0.3308
Epoch 197 Summary ---> Train Loss: 0.4149 / Validation Loss: 0.3308
Epoch 197: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 1)
  Epoch 197: Validation loss did not improve. Epochs without improvement: 2
Epoch 197: Stepping scheduler...
--- Epoch 197 completed in 0.69 seconds ---

--- Starting Epoch 198/1000 ---
Epoch 198: Starting training phase (4 batches)
  Epoch 198, Batch 1/4: Loading data to device...
  Epoch 198, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 198, Batch 1/4: Zeroing gradients...
  Epoch 198, Batch 1/4: Forward pass...
  Epoch 198, Batch 1/4: Calculating loss...
  Epoch 198, Batch 1/4: Backward pass...
  Epoch 198, Batch 1/4: Clipping gradients...
  Epoch 198, Batch 1/4: Optimizer step...
  Epoch 198, Batch 1/4: Completed in 0.20s
  Epoch 198, Batch 2/4: Loading data to device...
  Epoch 198, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 198, Batch 2/4: Zeroing gradients...
  Epoch 198, Batch 2/4: Forward pass...
  Epoch 198, Batch 2/4: Calculating loss...
  Epoch 198, Batch 2/4: Backward pass...
  Epoch 198, Batch 2/4: Clipping gradients...
  Epoch 198, Batch 2/4: Optimizer step...
  Epoch 198, Batch 2/4: Completed in 0.20s
  Epoch 198, Batch 3/4: Loading data to device...
  Epoch 198, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 198, Batch 3/4: Zeroing gradients...
  Epoch 198, Batch 3/4: Forward pass...
  Epoch 198, Batch 3/4: Calculating loss...
  Epoch 198, Batch 3/4: Backward pass...
  Epoch 198, Batch 3/4: Clipping gradients...
  Epoch 198, Batch 3/4: Optimizer step...
  Epoch 198, Batch 3/4: Completed in 0.20s
  Epoch 198, Batch 4/4: Loading data to device...
  Epoch 198, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 198, Batch 4/4: Zeroing gradients...
  Epoch 198, Batch 4/4: Forward pass...
  Epoch 198, Batch 4/4: Calculating loss...
  Epoch 198, Batch 4/4: Backward pass...
  Epoch 198, Batch 4/4: Clipping gradients...
  Epoch 198, Batch 4/4: Optimizer step...
  Epoch 198, Batch 4/4: Completed in 0.04s
Epoch 198: Training phase completed. Average Train Loss: 0.4027
Epoch 198: Starting validation phase...
  Epoch 198, Val Batch 1/1: Loading data...
  Epoch 198, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 198, Val Batch 1/1: Forward pass...
  Epoch 198, Val Batch 1/1: Calculating loss...
Epoch 198: Validation phase completed. Average Val Loss: 0.3344
Epoch 198 Summary ---> Train Loss: 0.4027 / Validation Loss: 0.3344
Epoch 198: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 2)
  Epoch 198: Validation loss did not improve. Epochs without improvement: 3
Epoch 198: Stepping scheduler...
--- Epoch 198 completed in 0.70 seconds ---

--- Starting Epoch 199/1000 ---
Epoch 199: Starting training phase (4 batches)
  Epoch 199, Batch 1/4: Loading data to device...
  Epoch 199, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 199, Batch 1/4: Zeroing gradients...
  Epoch 199, Batch 1/4: Forward pass...
  Epoch 199, Batch 1/4: Calculating loss...
  Epoch 199, Batch 1/4: Backward pass...
  Epoch 199, Batch 1/4: Clipping gradients...
  Epoch 199, Batch 1/4: Optimizer step...
  Epoch 199, Batch 1/4: Completed in 0.19s
  Epoch 199, Batch 2/4: Loading data to device...
  Epoch 199, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 199, Batch 2/4: Zeroing gradients...
  Epoch 199, Batch 2/4: Forward pass...
  Epoch 199, Batch 2/4: Calculating loss...
  Epoch 199, Batch 2/4: Backward pass...
  Epoch 199, Batch 2/4: Clipping gradients...
  Epoch 199, Batch 2/4: Optimizer step...
  Epoch 199, Batch 2/4: Completed in 0.19s
  Epoch 199, Batch 3/4: Loading data to device...
  Epoch 199, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 199, Batch 3/4: Zeroing gradients...
  Epoch 199, Batch 3/4: Forward pass...
  Epoch 199, Batch 3/4: Calculating loss...
  Epoch 199, Batch 3/4: Backward pass...
  Epoch 199, Batch 3/4: Clipping gradients...
  Epoch 199, Batch 3/4: Optimizer step...
  Epoch 199, Batch 3/4: Completed in 0.19s
  Epoch 199, Batch 4/4: Loading data to device...
  Epoch 199, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 199, Batch 4/4: Zeroing gradients...
  Epoch 199, Batch 4/4: Forward pass...
  Epoch 199, Batch 4/4: Calculating loss...
  Epoch 199, Batch 4/4: Backward pass...
  Epoch 199, Batch 4/4: Clipping gradients...
  Epoch 199, Batch 4/4: Optimizer step...
  Epoch 199, Batch 4/4: Completed in 0.03s
Epoch 199: Training phase completed. Average Train Loss: 0.3928
Epoch 199: Starting validation phase...
  Epoch 199, Val Batch 1/1: Loading data...
  Epoch 199, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 199, Val Batch 1/1: Forward pass...
  Epoch 199, Val Batch 1/1: Calculating loss...
Epoch 199: Validation phase completed. Average Val Loss: 0.3374
Epoch 199 Summary ---> Train Loss: 0.3928 / Validation Loss: 0.3374
Epoch 199: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 3)
  Epoch 199: Validation loss did not improve. Epochs without improvement: 4
Epoch 199: Stepping scheduler...
--- Epoch 199 completed in 0.68 seconds ---

--- Starting Epoch 200/1000 ---
Epoch 200: Starting training phase (4 batches)
  Epoch 200, Batch 1/4: Loading data to device...
  Epoch 200, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 200, Batch 1/4: Zeroing gradients...
  Epoch 200, Batch 1/4: Forward pass...
  Epoch 200, Batch 1/4: Calculating loss...
  Epoch 200, Batch 1/4: Backward pass...
  Epoch 200, Batch 1/4: Clipping gradients...
  Epoch 200, Batch 1/4: Optimizer step...
  Epoch 200, Batch 1/4: Completed in 0.20s
  Epoch 200, Batch 2/4: Loading data to device...
  Epoch 200, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 200, Batch 2/4: Zeroing gradients...
  Epoch 200, Batch 2/4: Forward pass...
  Epoch 200, Batch 2/4: Calculating loss...
  Epoch 200, Batch 2/4: Backward pass...
  Epoch 200, Batch 2/4: Clipping gradients...
  Epoch 200, Batch 2/4: Optimizer step...
  Epoch 200, Batch 2/4: Completed in 0.20s
  Epoch 200, Batch 3/4: Loading data to device...
  Epoch 200, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 200, Batch 3/4: Zeroing gradients...
  Epoch 200, Batch 3/4: Forward pass...
  Epoch 200, Batch 3/4: Calculating loss...
  Epoch 200, Batch 3/4: Backward pass...
  Epoch 200, Batch 3/4: Clipping gradients...
  Epoch 200, Batch 3/4: Optimizer step...
  Epoch 200, Batch 3/4: Completed in 0.19s
  Epoch 200, Batch 4/4: Loading data to device...
  Epoch 200, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 200, Batch 4/4: Zeroing gradients...
  Epoch 200, Batch 4/4: Forward pass...
  Epoch 200, Batch 4/4: Calculating loss...
  Epoch 200, Batch 4/4: Backward pass...
  Epoch 200, Batch 4/4: Clipping gradients...
  Epoch 200, Batch 4/4: Optimizer step...
  Epoch 200, Batch 4/4: Completed in 0.03s
Epoch 200: Training phase completed. Average Train Loss: 0.3505
Epoch 200: Starting validation phase...
  Epoch 200, Val Batch 1/1: Loading data...
  Epoch 200, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 200, Val Batch 1/1: Forward pass...
  Epoch 200, Val Batch 1/1: Calculating loss...
Epoch 200: Validation phase completed. Average Val Loss: 0.3413
Epoch 200 Summary ---> Train Loss: 0.3505 / Validation Loss: 0.3413
Epoch 200: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 4)
  Epoch 200: Validation loss did not improve. Epochs without improvement: 5
Epoch 200: Stepping scheduler...
--- Epoch 200 completed in 0.69 seconds ---

--- Starting Epoch 201/1000 ---
Epoch 201: Starting training phase (4 batches)
  Epoch 201, Batch 1/4: Loading data to device...
  Epoch 201, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 201, Batch 1/4: Zeroing gradients...
  Epoch 201, Batch 1/4: Forward pass...
  Epoch 201, Batch 1/4: Calculating loss...
  Epoch 201, Batch 1/4: Backward pass...
  Epoch 201, Batch 1/4: Clipping gradients...
  Epoch 201, Batch 1/4: Optimizer step...
  Epoch 201, Batch 1/4: Completed in 0.19s
  Epoch 201, Batch 2/4: Loading data to device...
  Epoch 201, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 201, Batch 2/4: Zeroing gradients...
  Epoch 201, Batch 2/4: Forward pass...
  Epoch 201, Batch 2/4: Calculating loss...
  Epoch 201, Batch 2/4: Backward pass...
  Epoch 201, Batch 2/4: Clipping gradients...
  Epoch 201, Batch 2/4: Optimizer step...
  Epoch 201, Batch 2/4: Completed in 0.19s
  Epoch 201, Batch 3/4: Loading data to device...
  Epoch 201, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 201, Batch 3/4: Zeroing gradients...
  Epoch 201, Batch 3/4: Forward pass...
  Epoch 201, Batch 3/4: Calculating loss...
  Epoch 201, Batch 3/4: Backward pass...
  Epoch 201, Batch 3/4: Clipping gradients...
  Epoch 201, Batch 3/4: Optimizer step...
  Epoch 201, Batch 3/4: Completed in 0.19s
  Epoch 201, Batch 4/4: Loading data to device...
  Epoch 201, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 201, Batch 4/4: Zeroing gradients...
  Epoch 201, Batch 4/4: Forward pass...
  Epoch 201, Batch 4/4: Calculating loss...
  Epoch 201, Batch 4/4: Backward pass...
  Epoch 201, Batch 4/4: Clipping gradients...
  Epoch 201, Batch 4/4: Optimizer step...
  Epoch 201, Batch 4/4: Completed in 0.03s
Epoch 201: Training phase completed. Average Train Loss: 0.3563
Epoch 201: Starting validation phase...
  Epoch 201, Val Batch 1/1: Loading data...
  Epoch 201, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 201, Val Batch 1/1: Forward pass...
  Epoch 201, Val Batch 1/1: Calculating loss...
Epoch 201: Validation phase completed. Average Val Loss: 0.3433
Epoch 201 Summary ---> Train Loss: 0.3563 / Validation Loss: 0.3433
Epoch 201: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 5)
  Epoch 201: Validation loss did not improve. Epochs without improvement: 6
Epoch 201: Stepping scheduler...
--- Epoch 201 completed in 0.68 seconds ---

--- Starting Epoch 202/1000 ---
Epoch 202: Starting training phase (4 batches)
  Epoch 202, Batch 1/4: Loading data to device...
  Epoch 202, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 202, Batch 1/4: Zeroing gradients...
  Epoch 202, Batch 1/4: Forward pass...
  Epoch 202, Batch 1/4: Calculating loss...
  Epoch 202, Batch 1/4: Backward pass...
  Epoch 202, Batch 1/4: Clipping gradients...
  Epoch 202, Batch 1/4: Optimizer step...
  Epoch 202, Batch 1/4: Completed in 0.19s
  Epoch 202, Batch 2/4: Loading data to device...
  Epoch 202, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 202, Batch 2/4: Zeroing gradients...
  Epoch 202, Batch 2/4: Forward pass...
  Epoch 202, Batch 2/4: Calculating loss...
  Epoch 202, Batch 2/4: Backward pass...
  Epoch 202, Batch 2/4: Clipping gradients...
  Epoch 202, Batch 2/4: Optimizer step...
  Epoch 202, Batch 2/4: Completed in 0.20s
  Epoch 202, Batch 3/4: Loading data to device...
  Epoch 202, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 202, Batch 3/4: Zeroing gradients...
  Epoch 202, Batch 3/4: Forward pass...
  Epoch 202, Batch 3/4: Calculating loss...
  Epoch 202, Batch 3/4: Backward pass...
  Epoch 202, Batch 3/4: Clipping gradients...
  Epoch 202, Batch 3/4: Optimizer step...
  Epoch 202, Batch 3/4: Completed in 0.20s
  Epoch 202, Batch 4/4: Loading data to device...
  Epoch 202, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 202, Batch 4/4: Zeroing gradients...
  Epoch 202, Batch 4/4: Forward pass...
  Epoch 202, Batch 4/4: Calculating loss...
  Epoch 202, Batch 4/4: Backward pass...
  Epoch 202, Batch 4/4: Clipping gradients...
  Epoch 202, Batch 4/4: Optimizer step...
  Epoch 202, Batch 4/4: Completed in 0.03s
Epoch 202: Training phase completed. Average Train Loss: 0.4273
Epoch 202: Starting validation phase...
  Epoch 202, Val Batch 1/1: Loading data...
  Epoch 202, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 202, Val Batch 1/1: Forward pass...
  Epoch 202, Val Batch 1/1: Calculating loss...
Epoch 202: Validation phase completed. Average Val Loss: 0.3364
Epoch 202 Summary ---> Train Loss: 0.4273 / Validation Loss: 0.3364
Epoch 202: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 6)
  Epoch 202: Validation loss did not improve. Epochs without improvement: 7
Epoch 202: Stepping scheduler...
--- Epoch 202 completed in 0.69 seconds ---

--- Starting Epoch 203/1000 ---
Epoch 203: Starting training phase (4 batches)
  Epoch 203, Batch 1/4: Loading data to device...
  Epoch 203, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 203, Batch 1/4: Zeroing gradients...
  Epoch 203, Batch 1/4: Forward pass...
  Epoch 203, Batch 1/4: Calculating loss...
  Epoch 203, Batch 1/4: Backward pass...
  Epoch 203, Batch 1/4: Clipping gradients...
  Epoch 203, Batch 1/4: Optimizer step...
  Epoch 203, Batch 1/4: Completed in 0.19s
  Epoch 203, Batch 2/4: Loading data to device...
  Epoch 203, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 203, Batch 2/4: Zeroing gradients...
  Epoch 203, Batch 2/4: Forward pass...
  Epoch 203, Batch 2/4: Calculating loss...
  Epoch 203, Batch 2/4: Backward pass...
  Epoch 203, Batch 2/4: Clipping gradients...
  Epoch 203, Batch 2/4: Optimizer step...
  Epoch 203, Batch 2/4: Completed in 0.19s
  Epoch 203, Batch 3/4: Loading data to device...
  Epoch 203, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 203, Batch 3/4: Zeroing gradients...
  Epoch 203, Batch 3/4: Forward pass...
  Epoch 203, Batch 3/4: Calculating loss...
  Epoch 203, Batch 3/4: Backward pass...
  Epoch 203, Batch 3/4: Clipping gradients...
  Epoch 203, Batch 3/4: Optimizer step...
  Epoch 203, Batch 3/4: Completed in 0.19s
  Epoch 203, Batch 4/4: Loading data to device...
  Epoch 203, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 203, Batch 4/4: Zeroing gradients...
  Epoch 203, Batch 4/4: Forward pass...
  Epoch 203, Batch 4/4: Calculating loss...
  Epoch 203, Batch 4/4: Backward pass...
  Epoch 203, Batch 4/4: Clipping gradients...
  Epoch 203, Batch 4/4: Optimizer step...
  Epoch 203, Batch 4/4: Completed in 0.03s
Epoch 203: Training phase completed. Average Train Loss: 0.4378
Epoch 203: Starting validation phase...
  Epoch 203, Val Batch 1/1: Loading data...
  Epoch 203, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 203, Val Batch 1/1: Forward pass...
  Epoch 203, Val Batch 1/1: Calculating loss...
Epoch 203: Validation phase completed. Average Val Loss: 0.3339
Epoch 203 Summary ---> Train Loss: 0.4378 / Validation Loss: 0.3339
Epoch 203: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 7)
  Epoch 203: Validation loss did not improve. Epochs without improvement: 8
Epoch 203: Stepping scheduler...
--- Epoch 203 completed in 0.68 seconds ---

--- Starting Epoch 204/1000 ---
Epoch 204: Starting training phase (4 batches)
  Epoch 204, Batch 1/4: Loading data to device...
  Epoch 204, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 204, Batch 1/4: Zeroing gradients...
  Epoch 204, Batch 1/4: Forward pass...
  Epoch 204, Batch 1/4: Calculating loss...
  Epoch 204, Batch 1/4: Backward pass...
  Epoch 204, Batch 1/4: Clipping gradients...
  Epoch 204, Batch 1/4: Optimizer step...
  Epoch 204, Batch 1/4: Completed in 0.19s
  Epoch 204, Batch 2/4: Loading data to device...
  Epoch 204, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 204, Batch 2/4: Zeroing gradients...
  Epoch 204, Batch 2/4: Forward pass...
  Epoch 204, Batch 2/4: Calculating loss...
  Epoch 204, Batch 2/4: Backward pass...
  Epoch 204, Batch 2/4: Clipping gradients...
  Epoch 204, Batch 2/4: Optimizer step...
  Epoch 204, Batch 2/4: Completed in 0.19s
  Epoch 204, Batch 3/4: Loading data to device...
  Epoch 204, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 204, Batch 3/4: Zeroing gradients...
  Epoch 204, Batch 3/4: Forward pass...
  Epoch 204, Batch 3/4: Calculating loss...
  Epoch 204, Batch 3/4: Backward pass...
  Epoch 204, Batch 3/4: Clipping gradients...
  Epoch 204, Batch 3/4: Optimizer step...
  Epoch 204, Batch 3/4: Completed in 0.19s
  Epoch 204, Batch 4/4: Loading data to device...
  Epoch 204, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 204, Batch 4/4: Zeroing gradients...
  Epoch 204, Batch 4/4: Forward pass...
  Epoch 204, Batch 4/4: Calculating loss...
  Epoch 204, Batch 4/4: Backward pass...
  Epoch 204, Batch 4/4: Clipping gradients...
  Epoch 204, Batch 4/4: Optimizer step...
  Epoch 204, Batch 4/4: Completed in 0.03s
Epoch 204: Training phase completed. Average Train Loss: 0.3979
Epoch 204: Starting validation phase...
  Epoch 204, Val Batch 1/1: Loading data...
  Epoch 204, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 204, Val Batch 1/1: Forward pass...
  Epoch 204, Val Batch 1/1: Calculating loss...
Epoch 204: Validation phase completed. Average Val Loss: 0.3372
Epoch 204 Summary ---> Train Loss: 0.3979 / Validation Loss: 0.3372
Epoch 204: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 8)
  Epoch 204: Validation loss did not improve. Epochs without improvement: 9
Epoch 204: Stepping scheduler...
--- Epoch 204 completed in 0.68 seconds ---

--- Starting Epoch 205/1000 ---
Epoch 205: Starting training phase (4 batches)
  Epoch 205, Batch 1/4: Loading data to device...
  Epoch 205, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 205, Batch 1/4: Zeroing gradients...
  Epoch 205, Batch 1/4: Forward pass...
  Epoch 205, Batch 1/4: Calculating loss...
  Epoch 205, Batch 1/4: Backward pass...
  Epoch 205, Batch 1/4: Clipping gradients...
  Epoch 205, Batch 1/4: Optimizer step...
  Epoch 205, Batch 1/4: Completed in 0.20s
  Epoch 205, Batch 2/4: Loading data to device...
  Epoch 205, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 205, Batch 2/4: Zeroing gradients...
  Epoch 205, Batch 2/4: Forward pass...
  Epoch 205, Batch 2/4: Calculating loss...
  Epoch 205, Batch 2/4: Backward pass...
  Epoch 205, Batch 2/4: Clipping gradients...
  Epoch 205, Batch 2/4: Optimizer step...
  Epoch 205, Batch 2/4: Completed in 0.20s
  Epoch 205, Batch 3/4: Loading data to device...
  Epoch 205, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 205, Batch 3/4: Zeroing gradients...
  Epoch 205, Batch 3/4: Forward pass...
  Epoch 205, Batch 3/4: Calculating loss...
  Epoch 205, Batch 3/4: Backward pass...
  Epoch 205, Batch 3/4: Clipping gradients...
  Epoch 205, Batch 3/4: Optimizer step...
  Epoch 205, Batch 3/4: Completed in 0.20s
  Epoch 205, Batch 4/4: Loading data to device...
  Epoch 205, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 205, Batch 4/4: Zeroing gradients...
  Epoch 205, Batch 4/4: Forward pass...
  Epoch 205, Batch 4/4: Calculating loss...
  Epoch 205, Batch 4/4: Backward pass...
  Epoch 205, Batch 4/4: Clipping gradients...
  Epoch 205, Batch 4/4: Optimizer step...
  Epoch 205, Batch 4/4: Completed in 0.03s
Epoch 205: Training phase completed. Average Train Loss: 0.3729
Epoch 205: Starting validation phase...
  Epoch 205, Val Batch 1/1: Loading data...
  Epoch 205, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 205, Val Batch 1/1: Forward pass...
  Epoch 205, Val Batch 1/1: Calculating loss...
Epoch 205: Validation phase completed. Average Val Loss: 0.3429
Epoch 205 Summary ---> Train Loss: 0.3729 / Validation Loss: 0.3429
Epoch 205: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 9)
  Epoch 205: Validation loss did not improve. Epochs without improvement: 10
Epoch 205: Stepping scheduler...
--- Epoch 205 completed in 0.70 seconds ---

--- Starting Epoch 206/1000 ---
Epoch 206: Starting training phase (4 batches)
  Epoch 206, Batch 1/4: Loading data to device...
  Epoch 206, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 206, Batch 1/4: Zeroing gradients...
  Epoch 206, Batch 1/4: Forward pass...
  Epoch 206, Batch 1/4: Calculating loss...
  Epoch 206, Batch 1/4: Backward pass...
  Epoch 206, Batch 1/4: Clipping gradients...
  Epoch 206, Batch 1/4: Optimizer step...
  Epoch 206, Batch 1/4: Completed in 0.20s
  Epoch 206, Batch 2/4: Loading data to device...
  Epoch 206, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 206, Batch 2/4: Zeroing gradients...
  Epoch 206, Batch 2/4: Forward pass...
  Epoch 206, Batch 2/4: Calculating loss...
  Epoch 206, Batch 2/4: Backward pass...
  Epoch 206, Batch 2/4: Clipping gradients...
  Epoch 206, Batch 2/4: Optimizer step...
  Epoch 206, Batch 2/4: Completed in 0.20s
  Epoch 206, Batch 3/4: Loading data to device...
  Epoch 206, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 206, Batch 3/4: Zeroing gradients...
  Epoch 206, Batch 3/4: Forward pass...
  Epoch 206, Batch 3/4: Calculating loss...
  Epoch 206, Batch 3/4: Backward pass...
  Epoch 206, Batch 3/4: Clipping gradients...
  Epoch 206, Batch 3/4: Optimizer step...
  Epoch 206, Batch 3/4: Completed in 0.19s
  Epoch 206, Batch 4/4: Loading data to device...
  Epoch 206, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 206, Batch 4/4: Zeroing gradients...
  Epoch 206, Batch 4/4: Forward pass...
  Epoch 206, Batch 4/4: Calculating loss...
  Epoch 206, Batch 4/4: Backward pass...
  Epoch 206, Batch 4/4: Clipping gradients...
  Epoch 206, Batch 4/4: Optimizer step...
  Epoch 206, Batch 4/4: Completed in 0.03s
Epoch 206: Training phase completed. Average Train Loss: 0.3665
Epoch 206: Starting validation phase...
  Epoch 206, Val Batch 1/1: Loading data...
  Epoch 206, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 206, Val Batch 1/1: Forward pass...
  Epoch 206, Val Batch 1/1: Calculating loss...
Epoch 206: Validation phase completed. Average Val Loss: 0.3495
Epoch 206 Summary ---> Train Loss: 0.3665 / Validation Loss: 0.3495
Epoch 206: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 10)
  Epoch 206: Validation loss did not improve. Epochs without improvement: 11
Epoch 206: Stepping scheduler...
--- Epoch 206 completed in 0.69 seconds ---

--- Starting Epoch 207/1000 ---
Epoch 207: Starting training phase (4 batches)
  Epoch 207, Batch 1/4: Loading data to device...
  Epoch 207, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 207, Batch 1/4: Zeroing gradients...
  Epoch 207, Batch 1/4: Forward pass...
  Epoch 207, Batch 1/4: Calculating loss...
  Epoch 207, Batch 1/4: Backward pass...
  Epoch 207, Batch 1/4: Clipping gradients...
  Epoch 207, Batch 1/4: Optimizer step...
  Epoch 207, Batch 1/4: Completed in 0.19s
  Epoch 207, Batch 2/4: Loading data to device...
  Epoch 207, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 207, Batch 2/4: Zeroing gradients...
  Epoch 207, Batch 2/4: Forward pass...
  Epoch 207, Batch 2/4: Calculating loss...
  Epoch 207, Batch 2/4: Backward pass...
  Epoch 207, Batch 2/4: Clipping gradients...
  Epoch 207, Batch 2/4: Optimizer step...
  Epoch 207, Batch 2/4: Completed in 0.19s
  Epoch 207, Batch 3/4: Loading data to device...
  Epoch 207, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 207, Batch 3/4: Zeroing gradients...
  Epoch 207, Batch 3/4: Forward pass...
  Epoch 207, Batch 3/4: Calculating loss...
  Epoch 207, Batch 3/4: Backward pass...
  Epoch 207, Batch 3/4: Clipping gradients...
  Epoch 207, Batch 3/4: Optimizer step...
  Epoch 207, Batch 3/4: Completed in 0.19s
  Epoch 207, Batch 4/4: Loading data to device...
  Epoch 207, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 207, Batch 4/4: Zeroing gradients...
  Epoch 207, Batch 4/4: Forward pass...
  Epoch 207, Batch 4/4: Calculating loss...
  Epoch 207, Batch 4/4: Backward pass...
  Epoch 207, Batch 4/4: Clipping gradients...
  Epoch 207, Batch 4/4: Optimizer step...
  Epoch 207, Batch 4/4: Completed in 0.03s
Epoch 207: Training phase completed. Average Train Loss: 0.3932
Epoch 207: Starting validation phase...
  Epoch 207, Val Batch 1/1: Loading data...
  Epoch 207, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 207, Val Batch 1/1: Forward pass...
  Epoch 207, Val Batch 1/1: Calculating loss...
Epoch 207: Validation phase completed. Average Val Loss: 0.3484
Epoch 207 Summary ---> Train Loss: 0.3932 / Validation Loss: 0.3484
Epoch 207: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 11)
  Epoch 207: Validation loss did not improve. Epochs without improvement: 12
Epoch 207: Stepping scheduler...
--- Epoch 207 completed in 0.67 seconds ---

--- Starting Epoch 208/1000 ---
Epoch 208: Starting training phase (4 batches)
  Epoch 208, Batch 1/4: Loading data to device...
  Epoch 208, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 208, Batch 1/4: Zeroing gradients...
  Epoch 208, Batch 1/4: Forward pass...
  Epoch 208, Batch 1/4: Calculating loss...
  Epoch 208, Batch 1/4: Backward pass...
  Epoch 208, Batch 1/4: Clipping gradients...
  Epoch 208, Batch 1/4: Optimizer step...
  Epoch 208, Batch 1/4: Completed in 0.19s
  Epoch 208, Batch 2/4: Loading data to device...
  Epoch 208, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 208, Batch 2/4: Zeroing gradients...
  Epoch 208, Batch 2/4: Forward pass...
  Epoch 208, Batch 2/4: Calculating loss...
  Epoch 208, Batch 2/4: Backward pass...
  Epoch 208, Batch 2/4: Clipping gradients...
  Epoch 208, Batch 2/4: Optimizer step...
  Epoch 208, Batch 2/4: Completed in 0.19s
  Epoch 208, Batch 3/4: Loading data to device...
  Epoch 208, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 208, Batch 3/4: Zeroing gradients...
  Epoch 208, Batch 3/4: Forward pass...
  Epoch 208, Batch 3/4: Calculating loss...
  Epoch 208, Batch 3/4: Backward pass...
  Epoch 208, Batch 3/4: Clipping gradients...
  Epoch 208, Batch 3/4: Optimizer step...
  Epoch 208, Batch 3/4: Completed in 0.19s
  Epoch 208, Batch 4/4: Loading data to device...
  Epoch 208, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 208, Batch 4/4: Zeroing gradients...
  Epoch 208, Batch 4/4: Forward pass...
  Epoch 208, Batch 4/4: Calculating loss...
  Epoch 208, Batch 4/4: Backward pass...
  Epoch 208, Batch 4/4: Clipping gradients...
  Epoch 208, Batch 4/4: Optimizer step...
  Epoch 208, Batch 4/4: Completed in 0.03s
Epoch 208: Training phase completed. Average Train Loss: 0.4491
Epoch 208: Starting validation phase...
  Epoch 208, Val Batch 1/1: Loading data...
  Epoch 208, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 208, Val Batch 1/1: Forward pass...
  Epoch 208, Val Batch 1/1: Calculating loss...
Epoch 208: Validation phase completed. Average Val Loss: 0.3471
Epoch 208 Summary ---> Train Loss: 0.4491 / Validation Loss: 0.3471
Epoch 208: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 12)
  Epoch 208: Validation loss did not improve. Epochs without improvement: 13
Epoch 208: Stepping scheduler...
--- Epoch 208 completed in 0.66 seconds ---

--- Starting Epoch 209/1000 ---
Epoch 209: Starting training phase (4 batches)
  Epoch 209, Batch 1/4: Loading data to device...
  Epoch 209, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 209, Batch 1/4: Zeroing gradients...
  Epoch 209, Batch 1/4: Forward pass...
  Epoch 209, Batch 1/4: Calculating loss...
  Epoch 209, Batch 1/4: Backward pass...
  Epoch 209, Batch 1/4: Clipping gradients...
  Epoch 209, Batch 1/4: Optimizer step...
  Epoch 209, Batch 1/4: Completed in 0.20s
  Epoch 209, Batch 2/4: Loading data to device...
  Epoch 209, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 209, Batch 2/4: Zeroing gradients...
  Epoch 209, Batch 2/4: Forward pass...
  Epoch 209, Batch 2/4: Calculating loss...
  Epoch 209, Batch 2/4: Backward pass...
  Epoch 209, Batch 2/4: Clipping gradients...
  Epoch 209, Batch 2/4: Optimizer step...
  Epoch 209, Batch 2/4: Completed in 0.21s
  Epoch 209, Batch 3/4: Loading data to device...
  Epoch 209, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 209, Batch 3/4: Zeroing gradients...
  Epoch 209, Batch 3/4: Forward pass...
  Epoch 209, Batch 3/4: Calculating loss...
  Epoch 209, Batch 3/4: Backward pass...
  Epoch 209, Batch 3/4: Clipping gradients...
  Epoch 209, Batch 3/4: Optimizer step...
  Epoch 209, Batch 3/4: Completed in 0.20s
  Epoch 209, Batch 4/4: Loading data to device...
  Epoch 209, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 209, Batch 4/4: Zeroing gradients...
  Epoch 209, Batch 4/4: Forward pass...
  Epoch 209, Batch 4/4: Calculating loss...
  Epoch 209, Batch 4/4: Backward pass...
  Epoch 209, Batch 4/4: Clipping gradients...
  Epoch 209, Batch 4/4: Optimizer step...
  Epoch 209, Batch 4/4: Completed in 0.03s
Epoch 209: Training phase completed. Average Train Loss: 0.3496
Epoch 209: Starting validation phase...
  Epoch 209, Val Batch 1/1: Loading data...
  Epoch 209, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 209, Val Batch 1/1: Forward pass...
  Epoch 209, Val Batch 1/1: Calculating loss...
Epoch 209: Validation phase completed. Average Val Loss: 0.3393
Epoch 209 Summary ---> Train Loss: 0.3496 / Validation Loss: 0.3393
Epoch 209: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 13)
  Epoch 209: Validation loss did not improve. Epochs without improvement: 14
Epoch 209: Stepping scheduler...
--- Epoch 209 completed in 0.71 seconds ---

--- Starting Epoch 210/1000 ---
Epoch 210: Starting training phase (4 batches)
  Epoch 210, Batch 1/4: Loading data to device...
  Epoch 210, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 210, Batch 1/4: Zeroing gradients...
  Epoch 210, Batch 1/4: Forward pass...
  Epoch 210, Batch 1/4: Calculating loss...
  Epoch 210, Batch 1/4: Backward pass...
  Epoch 210, Batch 1/4: Clipping gradients...
  Epoch 210, Batch 1/4: Optimizer step...
  Epoch 210, Batch 1/4: Completed in 0.21s
  Epoch 210, Batch 2/4: Loading data to device...
  Epoch 210, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 210, Batch 2/4: Zeroing gradients...
  Epoch 210, Batch 2/4: Forward pass...
  Epoch 210, Batch 2/4: Calculating loss...
  Epoch 210, Batch 2/4: Backward pass...
  Epoch 210, Batch 2/4: Clipping gradients...
  Epoch 210, Batch 2/4: Optimizer step...
  Epoch 210, Batch 2/4: Completed in 0.21s
  Epoch 210, Batch 3/4: Loading data to device...
  Epoch 210, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 210, Batch 3/4: Zeroing gradients...
  Epoch 210, Batch 3/4: Forward pass...
  Epoch 210, Batch 3/4: Calculating loss...
  Epoch 210, Batch 3/4: Backward pass...
  Epoch 210, Batch 3/4: Clipping gradients...
  Epoch 210, Batch 3/4: Optimizer step...
  Epoch 210, Batch 3/4: Completed in 0.21s
  Epoch 210, Batch 4/4: Loading data to device...
  Epoch 210, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 210, Batch 4/4: Zeroing gradients...
  Epoch 210, Batch 4/4: Forward pass...
  Epoch 210, Batch 4/4: Calculating loss...
  Epoch 210, Batch 4/4: Backward pass...
  Epoch 210, Batch 4/4: Clipping gradients...
  Epoch 210, Batch 4/4: Optimizer step...
  Epoch 210, Batch 4/4: Completed in 0.03s
Epoch 210: Training phase completed. Average Train Loss: 0.4051
Epoch 210: Starting validation phase...
  Epoch 210, Val Batch 1/1: Loading data...
  Epoch 210, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 210, Val Batch 1/1: Forward pass...
  Epoch 210, Val Batch 1/1: Calculating loss...
Epoch 210: Validation phase completed. Average Val Loss: 0.3310
Epoch 210 Summary ---> Train Loss: 0.4051 / Validation Loss: 0.3310
Epoch 210: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 14)
  Epoch 210: Validation loss did not improve. Epochs without improvement: 15
Epoch 210: Stepping scheduler...
--- Epoch 210 completed in 0.74 seconds ---

--- Starting Epoch 211/1000 ---
Epoch 211: Starting training phase (4 batches)
  Epoch 211, Batch 1/4: Loading data to device...
  Epoch 211, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 211, Batch 1/4: Zeroing gradients...
  Epoch 211, Batch 1/4: Forward pass...
  Epoch 211, Batch 1/4: Calculating loss...
  Epoch 211, Batch 1/4: Backward pass...
  Epoch 211, Batch 1/4: Clipping gradients...
  Epoch 211, Batch 1/4: Optimizer step...
  Epoch 211, Batch 1/4: Completed in 0.21s
  Epoch 211, Batch 2/4: Loading data to device...
  Epoch 211, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 211, Batch 2/4: Zeroing gradients...
  Epoch 211, Batch 2/4: Forward pass...
  Epoch 211, Batch 2/4: Calculating loss...
  Epoch 211, Batch 2/4: Backward pass...
  Epoch 211, Batch 2/4: Clipping gradients...
  Epoch 211, Batch 2/4: Optimizer step...
  Epoch 211, Batch 2/4: Completed in 0.21s
  Epoch 211, Batch 3/4: Loading data to device...
  Epoch 211, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 211, Batch 3/4: Zeroing gradients...
  Epoch 211, Batch 3/4: Forward pass...
  Epoch 211, Batch 3/4: Calculating loss...
  Epoch 211, Batch 3/4: Backward pass...
  Epoch 211, Batch 3/4: Clipping gradients...
  Epoch 211, Batch 3/4: Optimizer step...
  Epoch 211, Batch 3/4: Completed in 0.21s
  Epoch 211, Batch 4/4: Loading data to device...
  Epoch 211, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 211, Batch 4/4: Zeroing gradients...
  Epoch 211, Batch 4/4: Forward pass...
  Epoch 211, Batch 4/4: Calculating loss...
  Epoch 211, Batch 4/4: Backward pass...
  Epoch 211, Batch 4/4: Clipping gradients...
  Epoch 211, Batch 4/4: Optimizer step...
  Epoch 211, Batch 4/4: Completed in 0.03s
Epoch 211: Training phase completed. Average Train Loss: 0.3890
Epoch 211: Starting validation phase...
  Epoch 211, Val Batch 1/1: Loading data...
  Epoch 211, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 211, Val Batch 1/1: Forward pass...
  Epoch 211, Val Batch 1/1: Calculating loss...
Epoch 211: Validation phase completed. Average Val Loss: 0.3243
Epoch 211 Summary ---> Train Loss: 0.3890 / Validation Loss: 0.3243
Epoch 211: Checking early stopping... (Current Best Loss: 0.3280, Epochs No Improve: 15)
  Epoch 211: Validation loss improved (0.3280 --> 0.3243). Saving model.
Epoch 211: Stepping scheduler...
--- Epoch 211 completed in 0.74 seconds ---

--- Starting Epoch 212/1000 ---
Epoch 212: Starting training phase (4 batches)
  Epoch 212, Batch 1/4: Loading data to device...
  Epoch 212, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 212, Batch 1/4: Zeroing gradients...
  Epoch 212, Batch 1/4: Forward pass...
  Epoch 212, Batch 1/4: Calculating loss...
  Epoch 212, Batch 1/4: Backward pass...
  Epoch 212, Batch 1/4: Clipping gradients...
  Epoch 212, Batch 1/4: Optimizer step...
  Epoch 212, Batch 1/4: Completed in 0.21s
  Epoch 212, Batch 2/4: Loading data to device...
  Epoch 212, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 212, Batch 2/4: Zeroing gradients...
  Epoch 212, Batch 2/4: Forward pass...
  Epoch 212, Batch 2/4: Calculating loss...
  Epoch 212, Batch 2/4: Backward pass...
  Epoch 212, Batch 2/4: Clipping gradients...
  Epoch 212, Batch 2/4: Optimizer step...
  Epoch 212, Batch 2/4: Completed in 0.19s
  Epoch 212, Batch 3/4: Loading data to device...
  Epoch 212, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 212, Batch 3/4: Zeroing gradients...
  Epoch 212, Batch 3/4: Forward pass...
  Epoch 212, Batch 3/4: Calculating loss...
  Epoch 212, Batch 3/4: Backward pass...
  Epoch 212, Batch 3/4: Clipping gradients...
  Epoch 212, Batch 3/4: Optimizer step...
  Epoch 212, Batch 3/4: Completed in 0.20s
  Epoch 212, Batch 4/4: Loading data to device...
  Epoch 212, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 212, Batch 4/4: Zeroing gradients...
  Epoch 212, Batch 4/4: Forward pass...
  Epoch 212, Batch 4/4: Calculating loss...
  Epoch 212, Batch 4/4: Backward pass...
  Epoch 212, Batch 4/4: Clipping gradients...
  Epoch 212, Batch 4/4: Optimizer step...
  Epoch 212, Batch 4/4: Completed in 0.03s
Epoch 212: Training phase completed. Average Train Loss: 0.3883
Epoch 212: Starting validation phase...
  Epoch 212, Val Batch 1/1: Loading data...
  Epoch 212, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 212, Val Batch 1/1: Forward pass...
  Epoch 212, Val Batch 1/1: Calculating loss...
Epoch 212: Validation phase completed. Average Val Loss: 0.3194
Epoch 212 Summary ---> Train Loss: 0.3883 / Validation Loss: 0.3194
Epoch 212: Checking early stopping... (Current Best Loss: 0.3243, Epochs No Improve: 0)
  Epoch 212: Validation loss improved (0.3243 --> 0.3194). Saving model.
Epoch 212: Stepping scheduler...
--- Epoch 212 completed in 0.70 seconds ---

--- Starting Epoch 213/1000 ---
Epoch 213: Starting training phase (4 batches)
  Epoch 213, Batch 1/4: Loading data to device...
  Epoch 213, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 213, Batch 1/4: Zeroing gradients...
  Epoch 213, Batch 1/4: Forward pass...
  Epoch 213, Batch 1/4: Calculating loss...
  Epoch 213, Batch 1/4: Backward pass...
  Epoch 213, Batch 1/4: Clipping gradients...
  Epoch 213, Batch 1/4: Optimizer step...
  Epoch 213, Batch 1/4: Completed in 0.19s
  Epoch 213, Batch 2/4: Loading data to device...
  Epoch 213, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 213, Batch 2/4: Zeroing gradients...
  Epoch 213, Batch 2/4: Forward pass...
  Epoch 213, Batch 2/4: Calculating loss...
  Epoch 213, Batch 2/4: Backward pass...
  Epoch 213, Batch 2/4: Clipping gradients...
  Epoch 213, Batch 2/4: Optimizer step...
  Epoch 213, Batch 2/4: Completed in 0.19s
  Epoch 213, Batch 3/4: Loading data to device...
  Epoch 213, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 213, Batch 3/4: Zeroing gradients...
  Epoch 213, Batch 3/4: Forward pass...
  Epoch 213, Batch 3/4: Calculating loss...
  Epoch 213, Batch 3/4: Backward pass...
  Epoch 213, Batch 3/4: Clipping gradients...
  Epoch 213, Batch 3/4: Optimizer step...
  Epoch 213, Batch 3/4: Completed in 0.19s
  Epoch 213, Batch 4/4: Loading data to device...
  Epoch 213, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 213, Batch 4/4: Zeroing gradients...
  Epoch 213, Batch 4/4: Forward pass...
  Epoch 213, Batch 4/4: Calculating loss...
  Epoch 213, Batch 4/4: Backward pass...
  Epoch 213, Batch 4/4: Clipping gradients...
  Epoch 213, Batch 4/4: Optimizer step...
  Epoch 213, Batch 4/4: Completed in 0.04s
Epoch 213: Training phase completed. Average Train Loss: 0.4389
Epoch 213: Starting validation phase...
  Epoch 213, Val Batch 1/1: Loading data...
  Epoch 213, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 213, Val Batch 1/1: Forward pass...
  Epoch 213, Val Batch 1/1: Calculating loss...
Epoch 213: Validation phase completed. Average Val Loss: 0.3276
Epoch 213 Summary ---> Train Loss: 0.4389 / Validation Loss: 0.3276
Epoch 213: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 0)
  Epoch 213: Validation loss did not improve. Epochs without improvement: 1
Epoch 213: Stepping scheduler...
--- Epoch 213 completed in 0.67 seconds ---

--- Starting Epoch 214/1000 ---
Epoch 214: Starting training phase (4 batches)
  Epoch 214, Batch 1/4: Loading data to device...
  Epoch 214, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 214, Batch 1/4: Zeroing gradients...
  Epoch 214, Batch 1/4: Forward pass...
  Epoch 214, Batch 1/4: Calculating loss...
  Epoch 214, Batch 1/4: Backward pass...
  Epoch 214, Batch 1/4: Clipping gradients...
  Epoch 214, Batch 1/4: Optimizer step...
  Epoch 214, Batch 1/4: Completed in 0.20s
  Epoch 214, Batch 2/4: Loading data to device...
  Epoch 214, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 214, Batch 2/4: Zeroing gradients...
  Epoch 214, Batch 2/4: Forward pass...
  Epoch 214, Batch 2/4: Calculating loss...
  Epoch 214, Batch 2/4: Backward pass...
  Epoch 214, Batch 2/4: Clipping gradients...
  Epoch 214, Batch 2/4: Optimizer step...
  Epoch 214, Batch 2/4: Completed in 0.20s
  Epoch 214, Batch 3/4: Loading data to device...
  Epoch 214, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 214, Batch 3/4: Zeroing gradients...
  Epoch 214, Batch 3/4: Forward pass...
  Epoch 214, Batch 3/4: Calculating loss...
  Epoch 214, Batch 3/4: Backward pass...
  Epoch 214, Batch 3/4: Clipping gradients...
  Epoch 214, Batch 3/4: Optimizer step...
  Epoch 214, Batch 3/4: Completed in 0.19s
  Epoch 214, Batch 4/4: Loading data to device...
  Epoch 214, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 214, Batch 4/4: Zeroing gradients...
  Epoch 214, Batch 4/4: Forward pass...
  Epoch 214, Batch 4/4: Calculating loss...
  Epoch 214, Batch 4/4: Backward pass...
  Epoch 214, Batch 4/4: Clipping gradients...
  Epoch 214, Batch 4/4: Optimizer step...
  Epoch 214, Batch 4/4: Completed in 0.03s
Epoch 214: Training phase completed. Average Train Loss: 0.4263
Epoch 214: Starting validation phase...
  Epoch 214, Val Batch 1/1: Loading data...
  Epoch 214, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 214, Val Batch 1/1: Forward pass...
  Epoch 214, Val Batch 1/1: Calculating loss...
Epoch 214: Validation phase completed. Average Val Loss: 0.3372
Epoch 214 Summary ---> Train Loss: 0.4263 / Validation Loss: 0.3372
Epoch 214: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 1)
  Epoch 214: Validation loss did not improve. Epochs without improvement: 2
Epoch 214: Stepping scheduler...
--- Epoch 214 completed in 0.68 seconds ---

--- Starting Epoch 215/1000 ---
Epoch 215: Starting training phase (4 batches)
  Epoch 215, Batch 1/4: Loading data to device...
  Epoch 215, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 215, Batch 1/4: Zeroing gradients...
  Epoch 215, Batch 1/4: Forward pass...
  Epoch 215, Batch 1/4: Calculating loss...
  Epoch 215, Batch 1/4: Backward pass...
  Epoch 215, Batch 1/4: Clipping gradients...
  Epoch 215, Batch 1/4: Optimizer step...
  Epoch 215, Batch 1/4: Completed in 0.20s
  Epoch 215, Batch 2/4: Loading data to device...
  Epoch 215, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 215, Batch 2/4: Zeroing gradients...
  Epoch 215, Batch 2/4: Forward pass...
  Epoch 215, Batch 2/4: Calculating loss...
  Epoch 215, Batch 2/4: Backward pass...
  Epoch 215, Batch 2/4: Clipping gradients...
  Epoch 215, Batch 2/4: Optimizer step...
  Epoch 215, Batch 2/4: Completed in 0.19s
  Epoch 215, Batch 3/4: Loading data to device...
  Epoch 215, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 215, Batch 3/4: Zeroing gradients...
  Epoch 215, Batch 3/4: Forward pass...
  Epoch 215, Batch 3/4: Calculating loss...
  Epoch 215, Batch 3/4: Backward pass...
  Epoch 215, Batch 3/4: Clipping gradients...
  Epoch 215, Batch 3/4: Optimizer step...
  Epoch 215, Batch 3/4: Completed in 0.19s
  Epoch 215, Batch 4/4: Loading data to device...
  Epoch 215, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 215, Batch 4/4: Zeroing gradients...
  Epoch 215, Batch 4/4: Forward pass...
  Epoch 215, Batch 4/4: Calculating loss...
  Epoch 215, Batch 4/4: Backward pass...
  Epoch 215, Batch 4/4: Clipping gradients...
  Epoch 215, Batch 4/4: Optimizer step...
  Epoch 215, Batch 4/4: Completed in 0.03s
Epoch 215: Training phase completed. Average Train Loss: 0.4410
Epoch 215: Starting validation phase...
  Epoch 215, Val Batch 1/1: Loading data...
  Epoch 215, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 215, Val Batch 1/1: Forward pass...
  Epoch 215, Val Batch 1/1: Calculating loss...
Epoch 215: Validation phase completed. Average Val Loss: 0.3393
Epoch 215 Summary ---> Train Loss: 0.4410 / Validation Loss: 0.3393
Epoch 215: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 2)
  Epoch 215: Validation loss did not improve. Epochs without improvement: 3
Epoch 215: Stepping scheduler...
--- Epoch 215 completed in 0.68 seconds ---

--- Starting Epoch 216/1000 ---
Epoch 216: Starting training phase (4 batches)
  Epoch 216, Batch 1/4: Loading data to device...
  Epoch 216, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 216, Batch 1/4: Zeroing gradients...
  Epoch 216, Batch 1/4: Forward pass...
  Epoch 216, Batch 1/4: Calculating loss...
  Epoch 216, Batch 1/4: Backward pass...
  Epoch 216, Batch 1/4: Clipping gradients...
  Epoch 216, Batch 1/4: Optimizer step...
  Epoch 216, Batch 1/4: Completed in 0.19s
  Epoch 216, Batch 2/4: Loading data to device...
  Epoch 216, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 216, Batch 2/4: Zeroing gradients...
  Epoch 216, Batch 2/4: Forward pass...
  Epoch 216, Batch 2/4: Calculating loss...
  Epoch 216, Batch 2/4: Backward pass...
  Epoch 216, Batch 2/4: Clipping gradients...
  Epoch 216, Batch 2/4: Optimizer step...
  Epoch 216, Batch 2/4: Completed in 0.19s
  Epoch 216, Batch 3/4: Loading data to device...
  Epoch 216, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 216, Batch 3/4: Zeroing gradients...
  Epoch 216, Batch 3/4: Forward pass...
  Epoch 216, Batch 3/4: Calculating loss...
  Epoch 216, Batch 3/4: Backward pass...
  Epoch 216, Batch 3/4: Clipping gradients...
  Epoch 216, Batch 3/4: Optimizer step...
  Epoch 216, Batch 3/4: Completed in 0.19s
  Epoch 216, Batch 4/4: Loading data to device...
  Epoch 216, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 216, Batch 4/4: Zeroing gradients...
  Epoch 216, Batch 4/4: Forward pass...
  Epoch 216, Batch 4/4: Calculating loss...
  Epoch 216, Batch 4/4: Backward pass...
  Epoch 216, Batch 4/4: Clipping gradients...
  Epoch 216, Batch 4/4: Optimizer step...
  Epoch 216, Batch 4/4: Completed in 0.03s
Epoch 216: Training phase completed. Average Train Loss: 0.3997
Epoch 216: Starting validation phase...
  Epoch 216, Val Batch 1/1: Loading data...
  Epoch 216, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 216, Val Batch 1/1: Forward pass...
  Epoch 216, Val Batch 1/1: Calculating loss...
Epoch 216: Validation phase completed. Average Val Loss: 0.3304
Epoch 216 Summary ---> Train Loss: 0.3997 / Validation Loss: 0.3304
Epoch 216: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 3)
  Epoch 216: Validation loss did not improve. Epochs without improvement: 4
Epoch 216: Stepping scheduler...
--- Epoch 216 completed in 0.66 seconds ---

--- Starting Epoch 217/1000 ---
Epoch 217: Starting training phase (4 batches)
  Epoch 217, Batch 1/4: Loading data to device...
  Epoch 217, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 217, Batch 1/4: Zeroing gradients...
  Epoch 217, Batch 1/4: Forward pass...
  Epoch 217, Batch 1/4: Calculating loss...
  Epoch 217, Batch 1/4: Backward pass...
  Epoch 217, Batch 1/4: Clipping gradients...
  Epoch 217, Batch 1/4: Optimizer step...
  Epoch 217, Batch 1/4: Completed in 0.19s
  Epoch 217, Batch 2/4: Loading data to device...
  Epoch 217, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 217, Batch 2/4: Zeroing gradients...
  Epoch 217, Batch 2/4: Forward pass...
  Epoch 217, Batch 2/4: Calculating loss...
  Epoch 217, Batch 2/4: Backward pass...
  Epoch 217, Batch 2/4: Clipping gradients...
  Epoch 217, Batch 2/4: Optimizer step...
  Epoch 217, Batch 2/4: Completed in 0.19s
  Epoch 217, Batch 3/4: Loading data to device...
  Epoch 217, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 217, Batch 3/4: Zeroing gradients...
  Epoch 217, Batch 3/4: Forward pass...
  Epoch 217, Batch 3/4: Calculating loss...
  Epoch 217, Batch 3/4: Backward pass...
  Epoch 217, Batch 3/4: Clipping gradients...
  Epoch 217, Batch 3/4: Optimizer step...
  Epoch 217, Batch 3/4: Completed in 0.20s
  Epoch 217, Batch 4/4: Loading data to device...
  Epoch 217, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 217, Batch 4/4: Zeroing gradients...
  Epoch 217, Batch 4/4: Forward pass...
  Epoch 217, Batch 4/4: Calculating loss...
  Epoch 217, Batch 4/4: Backward pass...
  Epoch 217, Batch 4/4: Clipping gradients...
  Epoch 217, Batch 4/4: Optimizer step...
  Epoch 217, Batch 4/4: Completed in 0.03s
Epoch 217: Training phase completed. Average Train Loss: 0.3785
Epoch 217: Starting validation phase...
  Epoch 217, Val Batch 1/1: Loading data...
  Epoch 217, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 217, Val Batch 1/1: Forward pass...
  Epoch 217, Val Batch 1/1: Calculating loss...
Epoch 217: Validation phase completed. Average Val Loss: 0.3359
Epoch 217 Summary ---> Train Loss: 0.3785 / Validation Loss: 0.3359
Epoch 217: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 4)
  Epoch 217: Validation loss did not improve. Epochs without improvement: 5
Epoch 217: Stepping scheduler...
--- Epoch 217 completed in 0.67 seconds ---

--- Starting Epoch 218/1000 ---
Epoch 218: Starting training phase (4 batches)
  Epoch 218, Batch 1/4: Loading data to device...
  Epoch 218, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 218, Batch 1/4: Zeroing gradients...
  Epoch 218, Batch 1/4: Forward pass...
  Epoch 218, Batch 1/4: Calculating loss...
  Epoch 218, Batch 1/4: Backward pass...
  Epoch 218, Batch 1/4: Clipping gradients...
  Epoch 218, Batch 1/4: Optimizer step...
  Epoch 218, Batch 1/4: Completed in 0.19s
  Epoch 218, Batch 2/4: Loading data to device...
  Epoch 218, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 218, Batch 2/4: Zeroing gradients...
  Epoch 218, Batch 2/4: Forward pass...
  Epoch 218, Batch 2/4: Calculating loss...
  Epoch 218, Batch 2/4: Backward pass...
  Epoch 218, Batch 2/4: Clipping gradients...
  Epoch 218, Batch 2/4: Optimizer step...
  Epoch 218, Batch 2/4: Completed in 0.18s
  Epoch 218, Batch 3/4: Loading data to device...
  Epoch 218, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 218, Batch 3/4: Zeroing gradients...
  Epoch 218, Batch 3/4: Forward pass...
  Epoch 218, Batch 3/4: Calculating loss...
  Epoch 218, Batch 3/4: Backward pass...
  Epoch 218, Batch 3/4: Clipping gradients...
  Epoch 218, Batch 3/4: Optimizer step...
  Epoch 218, Batch 3/4: Completed in 0.18s
  Epoch 218, Batch 4/4: Loading data to device...
  Epoch 218, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 218, Batch 4/4: Zeroing gradients...
  Epoch 218, Batch 4/4: Forward pass...
  Epoch 218, Batch 4/4: Calculating loss...
  Epoch 218, Batch 4/4: Backward pass...
  Epoch 218, Batch 4/4: Clipping gradients...
  Epoch 218, Batch 4/4: Optimizer step...
  Epoch 218, Batch 4/4: Completed in 0.03s
Epoch 218: Training phase completed. Average Train Loss: 0.3761
Epoch 218: Starting validation phase...
  Epoch 218, Val Batch 1/1: Loading data...
  Epoch 218, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 218, Val Batch 1/1: Forward pass...
  Epoch 218, Val Batch 1/1: Calculating loss...
Epoch 218: Validation phase completed. Average Val Loss: 0.3323
Epoch 218 Summary ---> Train Loss: 0.3761 / Validation Loss: 0.3323
Epoch 218: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 5)
  Epoch 218: Validation loss did not improve. Epochs without improvement: 6
Epoch 218: Stepping scheduler...
--- Epoch 218 completed in 0.65 seconds ---

--- Starting Epoch 219/1000 ---
Epoch 219: Starting training phase (4 batches)
  Epoch 219, Batch 1/4: Loading data to device...
  Epoch 219, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 219, Batch 1/4: Zeroing gradients...
  Epoch 219, Batch 1/4: Forward pass...
  Epoch 219, Batch 1/4: Calculating loss...
  Epoch 219, Batch 1/4: Backward pass...
  Epoch 219, Batch 1/4: Clipping gradients...
  Epoch 219, Batch 1/4: Optimizer step...
  Epoch 219, Batch 1/4: Completed in 0.19s
  Epoch 219, Batch 2/4: Loading data to device...
  Epoch 219, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 219, Batch 2/4: Zeroing gradients...
  Epoch 219, Batch 2/4: Forward pass...
  Epoch 219, Batch 2/4: Calculating loss...
  Epoch 219, Batch 2/4: Backward pass...
  Epoch 219, Batch 2/4: Clipping gradients...
  Epoch 219, Batch 2/4: Optimizer step...
  Epoch 219, Batch 2/4: Completed in 0.19s
  Epoch 219, Batch 3/4: Loading data to device...
  Epoch 219, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 219, Batch 3/4: Zeroing gradients...
  Epoch 219, Batch 3/4: Forward pass...
  Epoch 219, Batch 3/4: Calculating loss...
  Epoch 219, Batch 3/4: Backward pass...
  Epoch 219, Batch 3/4: Clipping gradients...
  Epoch 219, Batch 3/4: Optimizer step...
  Epoch 219, Batch 3/4: Completed in 0.20s
  Epoch 219, Batch 4/4: Loading data to device...
  Epoch 219, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 219, Batch 4/4: Zeroing gradients...
  Epoch 219, Batch 4/4: Forward pass...
  Epoch 219, Batch 4/4: Calculating loss...
  Epoch 219, Batch 4/4: Backward pass...
  Epoch 219, Batch 4/4: Clipping gradients...
  Epoch 219, Batch 4/4: Optimizer step...
  Epoch 219, Batch 4/4: Completed in 0.03s
Epoch 219: Training phase completed. Average Train Loss: 0.4088
Epoch 219: Starting validation phase...
  Epoch 219, Val Batch 1/1: Loading data...
  Epoch 219, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 219, Val Batch 1/1: Forward pass...
  Epoch 219, Val Batch 1/1: Calculating loss...
Epoch 219: Validation phase completed. Average Val Loss: 0.3307
Epoch 219 Summary ---> Train Loss: 0.4088 / Validation Loss: 0.3307
Epoch 219: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 6)
  Epoch 219: Validation loss did not improve. Epochs without improvement: 7
Epoch 219: Stepping scheduler...
--- Epoch 219 completed in 0.67 seconds ---

--- Starting Epoch 220/1000 ---
Epoch 220: Starting training phase (4 batches)
  Epoch 220, Batch 1/4: Loading data to device...
  Epoch 220, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 220, Batch 1/4: Zeroing gradients...
  Epoch 220, Batch 1/4: Forward pass...
  Epoch 220, Batch 1/4: Calculating loss...
  Epoch 220, Batch 1/4: Backward pass...
  Epoch 220, Batch 1/4: Clipping gradients...
  Epoch 220, Batch 1/4: Optimizer step...
  Epoch 220, Batch 1/4: Completed in 0.19s
  Epoch 220, Batch 2/4: Loading data to device...
  Epoch 220, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 220, Batch 2/4: Zeroing gradients...
  Epoch 220, Batch 2/4: Forward pass...
  Epoch 220, Batch 2/4: Calculating loss...
  Epoch 220, Batch 2/4: Backward pass...
  Epoch 220, Batch 2/4: Clipping gradients...
  Epoch 220, Batch 2/4: Optimizer step...
  Epoch 220, Batch 2/4: Completed in 0.19s
  Epoch 220, Batch 3/4: Loading data to device...
  Epoch 220, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 220, Batch 3/4: Zeroing gradients...
  Epoch 220, Batch 3/4: Forward pass...
  Epoch 220, Batch 3/4: Calculating loss...
  Epoch 220, Batch 3/4: Backward pass...
  Epoch 220, Batch 3/4: Clipping gradients...
  Epoch 220, Batch 3/4: Optimizer step...
  Epoch 220, Batch 3/4: Completed in 0.19s
  Epoch 220, Batch 4/4: Loading data to device...
  Epoch 220, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 220, Batch 4/4: Zeroing gradients...
  Epoch 220, Batch 4/4: Forward pass...
  Epoch 220, Batch 4/4: Calculating loss...
  Epoch 220, Batch 4/4: Backward pass...
  Epoch 220, Batch 4/4: Clipping gradients...
  Epoch 220, Batch 4/4: Optimizer step...
  Epoch 220, Batch 4/4: Completed in 0.03s
Epoch 220: Training phase completed. Average Train Loss: 0.3808
Epoch 220: Starting validation phase...
  Epoch 220, Val Batch 1/1: Loading data...
  Epoch 220, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 220, Val Batch 1/1: Forward pass...
  Epoch 220, Val Batch 1/1: Calculating loss...
Epoch 220: Validation phase completed. Average Val Loss: 0.3276
Epoch 220 Summary ---> Train Loss: 0.3808 / Validation Loss: 0.3276
Epoch 220: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 7)
  Epoch 220: Validation loss did not improve. Epochs without improvement: 8
Epoch 220: Stepping scheduler...
--- Epoch 220 completed in 0.66 seconds ---

--- Starting Epoch 221/1000 ---
Epoch 221: Starting training phase (4 batches)
  Epoch 221, Batch 1/4: Loading data to device...
  Epoch 221, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 221, Batch 1/4: Zeroing gradients...
  Epoch 221, Batch 1/4: Forward pass...
  Epoch 221, Batch 1/4: Calculating loss...
  Epoch 221, Batch 1/4: Backward pass...
  Epoch 221, Batch 1/4: Clipping gradients...
  Epoch 221, Batch 1/4: Optimizer step...
  Epoch 221, Batch 1/4: Completed in 0.19s
  Epoch 221, Batch 2/4: Loading data to device...
  Epoch 221, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 221, Batch 2/4: Zeroing gradients...
  Epoch 221, Batch 2/4: Forward pass...
  Epoch 221, Batch 2/4: Calculating loss...
  Epoch 221, Batch 2/4: Backward pass...
  Epoch 221, Batch 2/4: Clipping gradients...
  Epoch 221, Batch 2/4: Optimizer step...
  Epoch 221, Batch 2/4: Completed in 0.19s
  Epoch 221, Batch 3/4: Loading data to device...
  Epoch 221, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 221, Batch 3/4: Zeroing gradients...
  Epoch 221, Batch 3/4: Forward pass...
  Epoch 221, Batch 3/4: Calculating loss...
  Epoch 221, Batch 3/4: Backward pass...
  Epoch 221, Batch 3/4: Clipping gradients...
  Epoch 221, Batch 3/4: Optimizer step...
  Epoch 221, Batch 3/4: Completed in 0.19s
  Epoch 221, Batch 4/4: Loading data to device...
  Epoch 221, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 221, Batch 4/4: Zeroing gradients...
  Epoch 221, Batch 4/4: Forward pass...
  Epoch 221, Batch 4/4: Calculating loss...
  Epoch 221, Batch 4/4: Backward pass...
  Epoch 221, Batch 4/4: Clipping gradients...
  Epoch 221, Batch 4/4: Optimizer step...
  Epoch 221, Batch 4/4: Completed in 0.03s
Epoch 221: Training phase completed. Average Train Loss: 0.3571
Epoch 221: Starting validation phase...
  Epoch 221, Val Batch 1/1: Loading data...
  Epoch 221, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 221, Val Batch 1/1: Forward pass...
  Epoch 221, Val Batch 1/1: Calculating loss...
Epoch 221: Validation phase completed. Average Val Loss: 0.3348
Epoch 221 Summary ---> Train Loss: 0.3571 / Validation Loss: 0.3348
Epoch 221: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 8)
  Epoch 221: Validation loss did not improve. Epochs without improvement: 9
Epoch 221: Stepping scheduler...
--- Epoch 221 completed in 0.67 seconds ---

--- Starting Epoch 222/1000 ---
Epoch 222: Starting training phase (4 batches)
  Epoch 222, Batch 1/4: Loading data to device...
  Epoch 222, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 222, Batch 1/4: Zeroing gradients...
  Epoch 222, Batch 1/4: Forward pass...
  Epoch 222, Batch 1/4: Calculating loss...
  Epoch 222, Batch 1/4: Backward pass...
  Epoch 222, Batch 1/4: Clipping gradients...
  Epoch 222, Batch 1/4: Optimizer step...
  Epoch 222, Batch 1/4: Completed in 0.20s
  Epoch 222, Batch 2/4: Loading data to device...
  Epoch 222, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 222, Batch 2/4: Zeroing gradients...
  Epoch 222, Batch 2/4: Forward pass...
  Epoch 222, Batch 2/4: Calculating loss...
  Epoch 222, Batch 2/4: Backward pass...
  Epoch 222, Batch 2/4: Clipping gradients...
  Epoch 222, Batch 2/4: Optimizer step...
  Epoch 222, Batch 2/4: Completed in 0.19s
  Epoch 222, Batch 3/4: Loading data to device...
  Epoch 222, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 222, Batch 3/4: Zeroing gradients...
  Epoch 222, Batch 3/4: Forward pass...
  Epoch 222, Batch 3/4: Calculating loss...
  Epoch 222, Batch 3/4: Backward pass...
  Epoch 222, Batch 3/4: Clipping gradients...
  Epoch 222, Batch 3/4: Optimizer step...
  Epoch 222, Batch 3/4: Completed in 0.19s
  Epoch 222, Batch 4/4: Loading data to device...
  Epoch 222, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 222, Batch 4/4: Zeroing gradients...
  Epoch 222, Batch 4/4: Forward pass...
  Epoch 222, Batch 4/4: Calculating loss...
  Epoch 222, Batch 4/4: Backward pass...
  Epoch 222, Batch 4/4: Clipping gradients...
  Epoch 222, Batch 4/4: Optimizer step...
  Epoch 222, Batch 4/4: Completed in 0.03s
Epoch 222: Training phase completed. Average Train Loss: 0.3907
Epoch 222: Starting validation phase...
  Epoch 222, Val Batch 1/1: Loading data...
  Epoch 222, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 222, Val Batch 1/1: Forward pass...
  Epoch 222, Val Batch 1/1: Calculating loss...
Epoch 222: Validation phase completed. Average Val Loss: 0.3302
Epoch 222 Summary ---> Train Loss: 0.3907 / Validation Loss: 0.3302
Epoch 222: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 9)
  Epoch 222: Validation loss did not improve. Epochs without improvement: 10
Epoch 222: Stepping scheduler...
--- Epoch 222 completed in 0.69 seconds ---

--- Starting Epoch 223/1000 ---
Epoch 223: Starting training phase (4 batches)
  Epoch 223, Batch 1/4: Loading data to device...
  Epoch 223, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 223, Batch 1/4: Zeroing gradients...
  Epoch 223, Batch 1/4: Forward pass...
  Epoch 223, Batch 1/4: Calculating loss...
  Epoch 223, Batch 1/4: Backward pass...
  Epoch 223, Batch 1/4: Clipping gradients...
  Epoch 223, Batch 1/4: Optimizer step...
  Epoch 223, Batch 1/4: Completed in 0.19s
  Epoch 223, Batch 2/4: Loading data to device...
  Epoch 223, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 223, Batch 2/4: Zeroing gradients...
  Epoch 223, Batch 2/4: Forward pass...
  Epoch 223, Batch 2/4: Calculating loss...
  Epoch 223, Batch 2/4: Backward pass...
  Epoch 223, Batch 2/4: Clipping gradients...
  Epoch 223, Batch 2/4: Optimizer step...
  Epoch 223, Batch 2/4: Completed in 0.19s
  Epoch 223, Batch 3/4: Loading data to device...
  Epoch 223, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 223, Batch 3/4: Zeroing gradients...
  Epoch 223, Batch 3/4: Forward pass...
  Epoch 223, Batch 3/4: Calculating loss...
  Epoch 223, Batch 3/4: Backward pass...
  Epoch 223, Batch 3/4: Clipping gradients...
  Epoch 223, Batch 3/4: Optimizer step...
  Epoch 223, Batch 3/4: Completed in 0.19s
  Epoch 223, Batch 4/4: Loading data to device...
  Epoch 223, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 223, Batch 4/4: Zeroing gradients...
  Epoch 223, Batch 4/4: Forward pass...
  Epoch 223, Batch 4/4: Calculating loss...
  Epoch 223, Batch 4/4: Backward pass...
  Epoch 223, Batch 4/4: Clipping gradients...
  Epoch 223, Batch 4/4: Optimizer step...
  Epoch 223, Batch 4/4: Completed in 0.03s
Epoch 223: Training phase completed. Average Train Loss: 0.3744
Epoch 223: Starting validation phase...
  Epoch 223, Val Batch 1/1: Loading data...
  Epoch 223, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 223, Val Batch 1/1: Forward pass...
  Epoch 223, Val Batch 1/1: Calculating loss...
Epoch 223: Validation phase completed. Average Val Loss: 0.3270
Epoch 223 Summary ---> Train Loss: 0.3744 / Validation Loss: 0.3270
Epoch 223: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 10)
  Epoch 223: Validation loss did not improve. Epochs without improvement: 11
Epoch 223: Stepping scheduler...
--- Epoch 223 completed in 0.66 seconds ---

--- Starting Epoch 224/1000 ---
Epoch 224: Starting training phase (4 batches)
  Epoch 224, Batch 1/4: Loading data to device...
  Epoch 224, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 224, Batch 1/4: Zeroing gradients...
  Epoch 224, Batch 1/4: Forward pass...
  Epoch 224, Batch 1/4: Calculating loss...
  Epoch 224, Batch 1/4: Backward pass...
  Epoch 224, Batch 1/4: Clipping gradients...
  Epoch 224, Batch 1/4: Optimizer step...
  Epoch 224, Batch 1/4: Completed in 0.19s
  Epoch 224, Batch 2/4: Loading data to device...
  Epoch 224, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 224, Batch 2/4: Zeroing gradients...
  Epoch 224, Batch 2/4: Forward pass...
  Epoch 224, Batch 2/4: Calculating loss...
  Epoch 224, Batch 2/4: Backward pass...
  Epoch 224, Batch 2/4: Clipping gradients...
  Epoch 224, Batch 2/4: Optimizer step...
  Epoch 224, Batch 2/4: Completed in 0.19s
  Epoch 224, Batch 3/4: Loading data to device...
  Epoch 224, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 224, Batch 3/4: Zeroing gradients...
  Epoch 224, Batch 3/4: Forward pass...
  Epoch 224, Batch 3/4: Calculating loss...
  Epoch 224, Batch 3/4: Backward pass...
  Epoch 224, Batch 3/4: Clipping gradients...
  Epoch 224, Batch 3/4: Optimizer step...
  Epoch 224, Batch 3/4: Completed in 0.19s
  Epoch 224, Batch 4/4: Loading data to device...
  Epoch 224, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 224, Batch 4/4: Zeroing gradients...
  Epoch 224, Batch 4/4: Forward pass...
  Epoch 224, Batch 4/4: Calculating loss...
  Epoch 224, Batch 4/4: Backward pass...
  Epoch 224, Batch 4/4: Clipping gradients...
  Epoch 224, Batch 4/4: Optimizer step...
  Epoch 224, Batch 4/4: Completed in 0.03s
Epoch 224: Training phase completed. Average Train Loss: 0.3731
Epoch 224: Starting validation phase...
  Epoch 224, Val Batch 1/1: Loading data...
  Epoch 224, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 224, Val Batch 1/1: Forward pass...
  Epoch 224, Val Batch 1/1: Calculating loss...
Epoch 224: Validation phase completed. Average Val Loss: 0.3252
Epoch 224 Summary ---> Train Loss: 0.3731 / Validation Loss: 0.3252
Epoch 224: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 11)
  Epoch 224: Validation loss did not improve. Epochs without improvement: 12
Epoch 224: Stepping scheduler...
--- Epoch 224 completed in 0.66 seconds ---

--- Starting Epoch 225/1000 ---
Epoch 225: Starting training phase (4 batches)
  Epoch 225, Batch 1/4: Loading data to device...
  Epoch 225, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 225, Batch 1/4: Zeroing gradients...
  Epoch 225, Batch 1/4: Forward pass...
  Epoch 225, Batch 1/4: Calculating loss...
  Epoch 225, Batch 1/4: Backward pass...
  Epoch 225, Batch 1/4: Clipping gradients...
  Epoch 225, Batch 1/4: Optimizer step...
  Epoch 225, Batch 1/4: Completed in 0.19s
  Epoch 225, Batch 2/4: Loading data to device...
  Epoch 225, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 225, Batch 2/4: Zeroing gradients...
  Epoch 225, Batch 2/4: Forward pass...
  Epoch 225, Batch 2/4: Calculating loss...
  Epoch 225, Batch 2/4: Backward pass...
  Epoch 225, Batch 2/4: Clipping gradients...
  Epoch 225, Batch 2/4: Optimizer step...
  Epoch 225, Batch 2/4: Completed in 0.19s
  Epoch 225, Batch 3/4: Loading data to device...
  Epoch 225, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 225, Batch 3/4: Zeroing gradients...
  Epoch 225, Batch 3/4: Forward pass...
  Epoch 225, Batch 3/4: Calculating loss...
  Epoch 225, Batch 3/4: Backward pass...
  Epoch 225, Batch 3/4: Clipping gradients...
  Epoch 225, Batch 3/4: Optimizer step...
  Epoch 225, Batch 3/4: Completed in 0.19s
  Epoch 225, Batch 4/4: Loading data to device...
  Epoch 225, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 225, Batch 4/4: Zeroing gradients...
  Epoch 225, Batch 4/4: Forward pass...
  Epoch 225, Batch 4/4: Calculating loss...
  Epoch 225, Batch 4/4: Backward pass...
  Epoch 225, Batch 4/4: Clipping gradients...
  Epoch 225, Batch 4/4: Optimizer step...
  Epoch 225, Batch 4/4: Completed in 0.03s
Epoch 225: Training phase completed. Average Train Loss: 0.4033
Epoch 225: Starting validation phase...
  Epoch 225, Val Batch 1/1: Loading data...
  Epoch 225, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 225, Val Batch 1/1: Forward pass...
  Epoch 225, Val Batch 1/1: Calculating loss...
Epoch 225: Validation phase completed. Average Val Loss: 0.3250
Epoch 225 Summary ---> Train Loss: 0.4033 / Validation Loss: 0.3250
Epoch 225: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 12)
  Epoch 225: Validation loss did not improve. Epochs without improvement: 13
Epoch 225: Stepping scheduler...
--- Epoch 225 completed in 0.66 seconds ---

--- Starting Epoch 226/1000 ---
Epoch 226: Starting training phase (4 batches)
  Epoch 226, Batch 1/4: Loading data to device...
  Epoch 226, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 226, Batch 1/4: Zeroing gradients...
  Epoch 226, Batch 1/4: Forward pass...
  Epoch 226, Batch 1/4: Calculating loss...
  Epoch 226, Batch 1/4: Backward pass...
  Epoch 226, Batch 1/4: Clipping gradients...
  Epoch 226, Batch 1/4: Optimizer step...
  Epoch 226, Batch 1/4: Completed in 0.19s
  Epoch 226, Batch 2/4: Loading data to device...
  Epoch 226, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 226, Batch 2/4: Zeroing gradients...
  Epoch 226, Batch 2/4: Forward pass...
  Epoch 226, Batch 2/4: Calculating loss...
  Epoch 226, Batch 2/4: Backward pass...
  Epoch 226, Batch 2/4: Clipping gradients...
  Epoch 226, Batch 2/4: Optimizer step...
  Epoch 226, Batch 2/4: Completed in 0.19s
  Epoch 226, Batch 3/4: Loading data to device...
  Epoch 226, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 226, Batch 3/4: Zeroing gradients...
  Epoch 226, Batch 3/4: Forward pass...
  Epoch 226, Batch 3/4: Calculating loss...
  Epoch 226, Batch 3/4: Backward pass...
  Epoch 226, Batch 3/4: Clipping gradients...
  Epoch 226, Batch 3/4: Optimizer step...
  Epoch 226, Batch 3/4: Completed in 0.19s
  Epoch 226, Batch 4/4: Loading data to device...
  Epoch 226, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 226, Batch 4/4: Zeroing gradients...
  Epoch 226, Batch 4/4: Forward pass...
  Epoch 226, Batch 4/4: Calculating loss...
  Epoch 226, Batch 4/4: Backward pass...
  Epoch 226, Batch 4/4: Clipping gradients...
  Epoch 226, Batch 4/4: Optimizer step...
  Epoch 226, Batch 4/4: Completed in 0.03s
Epoch 226: Training phase completed. Average Train Loss: 0.3969
Epoch 226: Starting validation phase...
  Epoch 226, Val Batch 1/1: Loading data...
  Epoch 226, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 226, Val Batch 1/1: Forward pass...
  Epoch 226, Val Batch 1/1: Calculating loss...
Epoch 226: Validation phase completed. Average Val Loss: 0.3278
Epoch 226 Summary ---> Train Loss: 0.3969 / Validation Loss: 0.3278
Epoch 226: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 13)
  Epoch 226: Validation loss did not improve. Epochs without improvement: 14
Epoch 226: Stepping scheduler...
--- Epoch 226 completed in 0.67 seconds ---

--- Starting Epoch 227/1000 ---
Epoch 227: Starting training phase (4 batches)
  Epoch 227, Batch 1/4: Loading data to device...
  Epoch 227, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 227, Batch 1/4: Zeroing gradients...
  Epoch 227, Batch 1/4: Forward pass...
  Epoch 227, Batch 1/4: Calculating loss...
  Epoch 227, Batch 1/4: Backward pass...
  Epoch 227, Batch 1/4: Clipping gradients...
  Epoch 227, Batch 1/4: Optimizer step...
  Epoch 227, Batch 1/4: Completed in 0.19s
  Epoch 227, Batch 2/4: Loading data to device...
  Epoch 227, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 227, Batch 2/4: Zeroing gradients...
  Epoch 227, Batch 2/4: Forward pass...
  Epoch 227, Batch 2/4: Calculating loss...
  Epoch 227, Batch 2/4: Backward pass...
  Epoch 227, Batch 2/4: Clipping gradients...
  Epoch 227, Batch 2/4: Optimizer step...
  Epoch 227, Batch 2/4: Completed in 0.19s
  Epoch 227, Batch 3/4: Loading data to device...
  Epoch 227, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 227, Batch 3/4: Zeroing gradients...
  Epoch 227, Batch 3/4: Forward pass...
  Epoch 227, Batch 3/4: Calculating loss...
  Epoch 227, Batch 3/4: Backward pass...
  Epoch 227, Batch 3/4: Clipping gradients...
  Epoch 227, Batch 3/4: Optimizer step...
  Epoch 227, Batch 3/4: Completed in 0.19s
  Epoch 227, Batch 4/4: Loading data to device...
  Epoch 227, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 227, Batch 4/4: Zeroing gradients...
  Epoch 227, Batch 4/4: Forward pass...
  Epoch 227, Batch 4/4: Calculating loss...
  Epoch 227, Batch 4/4: Backward pass...
  Epoch 227, Batch 4/4: Clipping gradients...
  Epoch 227, Batch 4/4: Optimizer step...
  Epoch 227, Batch 4/4: Completed in 0.03s
Epoch 227: Training phase completed. Average Train Loss: 0.4328
Epoch 227: Starting validation phase...
  Epoch 227, Val Batch 1/1: Loading data...
  Epoch 227, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 227, Val Batch 1/1: Forward pass...
  Epoch 227, Val Batch 1/1: Calculating loss...
Epoch 227: Validation phase completed. Average Val Loss: 0.3310
Epoch 227 Summary ---> Train Loss: 0.4328 / Validation Loss: 0.3310
Epoch 227: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 14)
  Epoch 227: Validation loss did not improve. Epochs without improvement: 15
Epoch 227: Stepping scheduler...
--- Epoch 227 completed in 0.67 seconds ---

--- Starting Epoch 228/1000 ---
Epoch 228: Starting training phase (4 batches)
  Epoch 228, Batch 1/4: Loading data to device...
  Epoch 228, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 228, Batch 1/4: Zeroing gradients...
  Epoch 228, Batch 1/4: Forward pass...
  Epoch 228, Batch 1/4: Calculating loss...
  Epoch 228, Batch 1/4: Backward pass...
  Epoch 228, Batch 1/4: Clipping gradients...
  Epoch 228, Batch 1/4: Optimizer step...
  Epoch 228, Batch 1/4: Completed in 0.19s
  Epoch 228, Batch 2/4: Loading data to device...
  Epoch 228, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 228, Batch 2/4: Zeroing gradients...
  Epoch 228, Batch 2/4: Forward pass...
  Epoch 228, Batch 2/4: Calculating loss...
  Epoch 228, Batch 2/4: Backward pass...
  Epoch 228, Batch 2/4: Clipping gradients...
  Epoch 228, Batch 2/4: Optimizer step...
  Epoch 228, Batch 2/4: Completed in 0.19s
  Epoch 228, Batch 3/4: Loading data to device...
  Epoch 228, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 228, Batch 3/4: Zeroing gradients...
  Epoch 228, Batch 3/4: Forward pass...
  Epoch 228, Batch 3/4: Calculating loss...
  Epoch 228, Batch 3/4: Backward pass...
  Epoch 228, Batch 3/4: Clipping gradients...
  Epoch 228, Batch 3/4: Optimizer step...
  Epoch 228, Batch 3/4: Completed in 0.19s
  Epoch 228, Batch 4/4: Loading data to device...
  Epoch 228, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 228, Batch 4/4: Zeroing gradients...
  Epoch 228, Batch 4/4: Forward pass...
  Epoch 228, Batch 4/4: Calculating loss...
  Epoch 228, Batch 4/4: Backward pass...
  Epoch 228, Batch 4/4: Clipping gradients...
  Epoch 228, Batch 4/4: Optimizer step...
  Epoch 228, Batch 4/4: Completed in 0.03s
Epoch 228: Training phase completed. Average Train Loss: 0.3354
Epoch 228: Starting validation phase...
  Epoch 228, Val Batch 1/1: Loading data...
  Epoch 228, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 228, Val Batch 1/1: Forward pass...
  Epoch 228, Val Batch 1/1: Calculating loss...
Epoch 228: Validation phase completed. Average Val Loss: 0.3287
Epoch 228 Summary ---> Train Loss: 0.3354 / Validation Loss: 0.3287
Epoch 228: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 15)
  Epoch 228: Validation loss did not improve. Epochs without improvement: 16
Epoch 228: Stepping scheduler...
--- Epoch 228 completed in 0.66 seconds ---

--- Starting Epoch 229/1000 ---
Epoch 229: Starting training phase (4 batches)
  Epoch 229, Batch 1/4: Loading data to device...
  Epoch 229, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 229, Batch 1/4: Zeroing gradients...
  Epoch 229, Batch 1/4: Forward pass...
  Epoch 229, Batch 1/4: Calculating loss...
  Epoch 229, Batch 1/4: Backward pass...
  Epoch 229, Batch 1/4: Clipping gradients...
  Epoch 229, Batch 1/4: Optimizer step...
  Epoch 229, Batch 1/4: Completed in 0.19s
  Epoch 229, Batch 2/4: Loading data to device...
  Epoch 229, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 229, Batch 2/4: Zeroing gradients...
  Epoch 229, Batch 2/4: Forward pass...
  Epoch 229, Batch 2/4: Calculating loss...
  Epoch 229, Batch 2/4: Backward pass...
  Epoch 229, Batch 2/4: Clipping gradients...
  Epoch 229, Batch 2/4: Optimizer step...
  Epoch 229, Batch 2/4: Completed in 0.19s
  Epoch 229, Batch 3/4: Loading data to device...
  Epoch 229, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 229, Batch 3/4: Zeroing gradients...
  Epoch 229, Batch 3/4: Forward pass...
  Epoch 229, Batch 3/4: Calculating loss...
  Epoch 229, Batch 3/4: Backward pass...
  Epoch 229, Batch 3/4: Clipping gradients...
  Epoch 229, Batch 3/4: Optimizer step...
  Epoch 229, Batch 3/4: Completed in 0.20s
  Epoch 229, Batch 4/4: Loading data to device...
  Epoch 229, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 229, Batch 4/4: Zeroing gradients...
  Epoch 229, Batch 4/4: Forward pass...
  Epoch 229, Batch 4/4: Calculating loss...
  Epoch 229, Batch 4/4: Backward pass...
  Epoch 229, Batch 4/4: Clipping gradients...
  Epoch 229, Batch 4/4: Optimizer step...
  Epoch 229, Batch 4/4: Completed in 0.03s
Epoch 229: Training phase completed. Average Train Loss: 0.4063
Epoch 229: Starting validation phase...
  Epoch 229, Val Batch 1/1: Loading data...
  Epoch 229, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 229, Val Batch 1/1: Forward pass...
  Epoch 229, Val Batch 1/1: Calculating loss...
Epoch 229: Validation phase completed. Average Val Loss: 0.3388
Epoch 229 Summary ---> Train Loss: 0.4063 / Validation Loss: 0.3388
Epoch 229: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 16)
  Epoch 229: Validation loss did not improve. Epochs without improvement: 17
Epoch 229: Stepping scheduler...
--- Epoch 229 completed in 0.68 seconds ---

--- Starting Epoch 230/1000 ---
Epoch 230: Starting training phase (4 batches)
  Epoch 230, Batch 1/4: Loading data to device...
  Epoch 230, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 230, Batch 1/4: Zeroing gradients...
  Epoch 230, Batch 1/4: Forward pass...
  Epoch 230, Batch 1/4: Calculating loss...
  Epoch 230, Batch 1/4: Backward pass...
  Epoch 230, Batch 1/4: Clipping gradients...
  Epoch 230, Batch 1/4: Optimizer step...
  Epoch 230, Batch 1/4: Completed in 0.20s
  Epoch 230, Batch 2/4: Loading data to device...
  Epoch 230, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 230, Batch 2/4: Zeroing gradients...
  Epoch 230, Batch 2/4: Forward pass...
  Epoch 230, Batch 2/4: Calculating loss...
  Epoch 230, Batch 2/4: Backward pass...
  Epoch 230, Batch 2/4: Clipping gradients...
  Epoch 230, Batch 2/4: Optimizer step...
  Epoch 230, Batch 2/4: Completed in 0.20s
  Epoch 230, Batch 3/4: Loading data to device...
  Epoch 230, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 230, Batch 3/4: Zeroing gradients...
  Epoch 230, Batch 3/4: Forward pass...
  Epoch 230, Batch 3/4: Calculating loss...
  Epoch 230, Batch 3/4: Backward pass...
  Epoch 230, Batch 3/4: Clipping gradients...
  Epoch 230, Batch 3/4: Optimizer step...
  Epoch 230, Batch 3/4: Completed in 0.19s
  Epoch 230, Batch 4/4: Loading data to device...
  Epoch 230, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 230, Batch 4/4: Zeroing gradients...
  Epoch 230, Batch 4/4: Forward pass...
  Epoch 230, Batch 4/4: Calculating loss...
  Epoch 230, Batch 4/4: Backward pass...
  Epoch 230, Batch 4/4: Clipping gradients...
  Epoch 230, Batch 4/4: Optimizer step...
  Epoch 230, Batch 4/4: Completed in 0.03s
Epoch 230: Training phase completed. Average Train Loss: 0.3678
Epoch 230: Starting validation phase...
  Epoch 230, Val Batch 1/1: Loading data...
  Epoch 230, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 230, Val Batch 1/1: Forward pass...
  Epoch 230, Val Batch 1/1: Calculating loss...
Epoch 230: Validation phase completed. Average Val Loss: 0.3292
Epoch 230 Summary ---> Train Loss: 0.3678 / Validation Loss: 0.3292
Epoch 230: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 17)
  Epoch 230: Validation loss did not improve. Epochs without improvement: 18
Epoch 230: Stepping scheduler...
--- Epoch 230 completed in 0.69 seconds ---

--- Starting Epoch 231/1000 ---
Epoch 231: Starting training phase (4 batches)
  Epoch 231, Batch 1/4: Loading data to device...
  Epoch 231, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 231, Batch 1/4: Zeroing gradients...
  Epoch 231, Batch 1/4: Forward pass...
  Epoch 231, Batch 1/4: Calculating loss...
  Epoch 231, Batch 1/4: Backward pass...
  Epoch 231, Batch 1/4: Clipping gradients...
  Epoch 231, Batch 1/4: Optimizer step...
  Epoch 231, Batch 1/4: Completed in 0.19s
  Epoch 231, Batch 2/4: Loading data to device...
  Epoch 231, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 231, Batch 2/4: Zeroing gradients...
  Epoch 231, Batch 2/4: Forward pass...
  Epoch 231, Batch 2/4: Calculating loss...
  Epoch 231, Batch 2/4: Backward pass...
  Epoch 231, Batch 2/4: Clipping gradients...
  Epoch 231, Batch 2/4: Optimizer step...
  Epoch 231, Batch 2/4: Completed in 0.20s
  Epoch 231, Batch 3/4: Loading data to device...
  Epoch 231, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 231, Batch 3/4: Zeroing gradients...
  Epoch 231, Batch 3/4: Forward pass...
  Epoch 231, Batch 3/4: Calculating loss...
  Epoch 231, Batch 3/4: Backward pass...
  Epoch 231, Batch 3/4: Clipping gradients...
  Epoch 231, Batch 3/4: Optimizer step...
  Epoch 231, Batch 3/4: Completed in 0.20s
  Epoch 231, Batch 4/4: Loading data to device...
  Epoch 231, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 231, Batch 4/4: Zeroing gradients...
  Epoch 231, Batch 4/4: Forward pass...
  Epoch 231, Batch 4/4: Calculating loss...
  Epoch 231, Batch 4/4: Backward pass...
  Epoch 231, Batch 4/4: Clipping gradients...
  Epoch 231, Batch 4/4: Optimizer step...
  Epoch 231, Batch 4/4: Completed in 0.03s
Epoch 231: Training phase completed. Average Train Loss: 0.4269
Epoch 231: Starting validation phase...
  Epoch 231, Val Batch 1/1: Loading data...
  Epoch 231, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 231, Val Batch 1/1: Forward pass...
  Epoch 231, Val Batch 1/1: Calculating loss...
Epoch 231: Validation phase completed. Average Val Loss: 0.3095
Epoch 231 Summary ---> Train Loss: 0.4269 / Validation Loss: 0.3095
Epoch 231: Checking early stopping... (Current Best Loss: 0.3194, Epochs No Improve: 18)
  Epoch 231: Validation loss improved (0.3194 --> 0.3095). Saving model.
Epoch 231: Stepping scheduler...
--- Epoch 231 completed in 0.69 seconds ---

--- Starting Epoch 232/1000 ---
Epoch 232: Starting training phase (4 batches)
  Epoch 232, Batch 1/4: Loading data to device...
  Epoch 232, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 232, Batch 1/4: Zeroing gradients...
  Epoch 232, Batch 1/4: Forward pass...
  Epoch 232, Batch 1/4: Calculating loss...
  Epoch 232, Batch 1/4: Backward pass...
  Epoch 232, Batch 1/4: Clipping gradients...
  Epoch 232, Batch 1/4: Optimizer step...
  Epoch 232, Batch 1/4: Completed in 0.19s
  Epoch 232, Batch 2/4: Loading data to device...
  Epoch 232, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 232, Batch 2/4: Zeroing gradients...
  Epoch 232, Batch 2/4: Forward pass...
  Epoch 232, Batch 2/4: Calculating loss...
  Epoch 232, Batch 2/4: Backward pass...
  Epoch 232, Batch 2/4: Clipping gradients...
  Epoch 232, Batch 2/4: Optimizer step...
  Epoch 232, Batch 2/4: Completed in 0.19s
  Epoch 232, Batch 3/4: Loading data to device...
  Epoch 232, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 232, Batch 3/4: Zeroing gradients...
  Epoch 232, Batch 3/4: Forward pass...
  Epoch 232, Batch 3/4: Calculating loss...
  Epoch 232, Batch 3/4: Backward pass...
  Epoch 232, Batch 3/4: Clipping gradients...
  Epoch 232, Batch 3/4: Optimizer step...
  Epoch 232, Batch 3/4: Completed in 0.19s
  Epoch 232, Batch 4/4: Loading data to device...
  Epoch 232, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 232, Batch 4/4: Zeroing gradients...
  Epoch 232, Batch 4/4: Forward pass...
  Epoch 232, Batch 4/4: Calculating loss...
  Epoch 232, Batch 4/4: Backward pass...
  Epoch 232, Batch 4/4: Clipping gradients...
  Epoch 232, Batch 4/4: Optimizer step...
  Epoch 232, Batch 4/4: Completed in 0.03s
Epoch 232: Training phase completed. Average Train Loss: 0.4215
Epoch 232: Starting validation phase...
  Epoch 232, Val Batch 1/1: Loading data...
  Epoch 232, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 232, Val Batch 1/1: Forward pass...
  Epoch 232, Val Batch 1/1: Calculating loss...
Epoch 232: Validation phase completed. Average Val Loss: 0.3153
Epoch 232 Summary ---> Train Loss: 0.4215 / Validation Loss: 0.3153
Epoch 232: Checking early stopping... (Current Best Loss: 0.3095, Epochs No Improve: 0)
  Epoch 232: Validation loss did not improve. Epochs without improvement: 1
Epoch 232: Stepping scheduler...
--- Epoch 232 completed in 0.67 seconds ---

--- Starting Epoch 233/1000 ---
Epoch 233: Starting training phase (4 batches)
  Epoch 233, Batch 1/4: Loading data to device...
  Epoch 233, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 233, Batch 1/4: Zeroing gradients...
  Epoch 233, Batch 1/4: Forward pass...
  Epoch 233, Batch 1/4: Calculating loss...
  Epoch 233, Batch 1/4: Backward pass...
  Epoch 233, Batch 1/4: Clipping gradients...
  Epoch 233, Batch 1/4: Optimizer step...
  Epoch 233, Batch 1/4: Completed in 0.19s
  Epoch 233, Batch 2/4: Loading data to device...
  Epoch 233, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 233, Batch 2/4: Zeroing gradients...
  Epoch 233, Batch 2/4: Forward pass...
  Epoch 233, Batch 2/4: Calculating loss...
  Epoch 233, Batch 2/4: Backward pass...
  Epoch 233, Batch 2/4: Clipping gradients...
  Epoch 233, Batch 2/4: Optimizer step...
  Epoch 233, Batch 2/4: Completed in 0.20s
  Epoch 233, Batch 3/4: Loading data to device...
  Epoch 233, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 233, Batch 3/4: Zeroing gradients...
  Epoch 233, Batch 3/4: Forward pass...
  Epoch 233, Batch 3/4: Calculating loss...
  Epoch 233, Batch 3/4: Backward pass...
  Epoch 233, Batch 3/4: Clipping gradients...
  Epoch 233, Batch 3/4: Optimizer step...
  Epoch 233, Batch 3/4: Completed in 0.20s
  Epoch 233, Batch 4/4: Loading data to device...
  Epoch 233, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 233, Batch 4/4: Zeroing gradients...
  Epoch 233, Batch 4/4: Forward pass...
  Epoch 233, Batch 4/4: Calculating loss...
  Epoch 233, Batch 4/4: Backward pass...
  Epoch 233, Batch 4/4: Clipping gradients...
  Epoch 233, Batch 4/4: Optimizer step...
  Epoch 233, Batch 4/4: Completed in 0.03s
Epoch 233: Training phase completed. Average Train Loss: 0.3802
Epoch 233: Starting validation phase...
  Epoch 233, Val Batch 1/1: Loading data...
  Epoch 233, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 233, Val Batch 1/1: Forward pass...
  Epoch 233, Val Batch 1/1: Calculating loss...
Epoch 233: Validation phase completed. Average Val Loss: 0.3012
Epoch 233 Summary ---> Train Loss: 0.3802 / Validation Loss: 0.3012
Epoch 233: Checking early stopping... (Current Best Loss: 0.3095, Epochs No Improve: 1)
  Epoch 233: Validation loss improved (0.3095 --> 0.3012). Saving model.
Epoch 233: Stepping scheduler...
--- Epoch 233 completed in 0.69 seconds ---

--- Starting Epoch 234/1000 ---
Epoch 234: Starting training phase (4 batches)
  Epoch 234, Batch 1/4: Loading data to device...
  Epoch 234, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 234, Batch 1/4: Zeroing gradients...
  Epoch 234, Batch 1/4: Forward pass...
  Epoch 234, Batch 1/4: Calculating loss...
  Epoch 234, Batch 1/4: Backward pass...
  Epoch 234, Batch 1/4: Clipping gradients...
  Epoch 234, Batch 1/4: Optimizer step...
  Epoch 234, Batch 1/4: Completed in 0.19s
  Epoch 234, Batch 2/4: Loading data to device...
  Epoch 234, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 234, Batch 2/4: Zeroing gradients...
  Epoch 234, Batch 2/4: Forward pass...
  Epoch 234, Batch 2/4: Calculating loss...
  Epoch 234, Batch 2/4: Backward pass...
  Epoch 234, Batch 2/4: Clipping gradients...
  Epoch 234, Batch 2/4: Optimizer step...
  Epoch 234, Batch 2/4: Completed in 0.19s
  Epoch 234, Batch 3/4: Loading data to device...
  Epoch 234, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 234, Batch 3/4: Zeroing gradients...
  Epoch 234, Batch 3/4: Forward pass...
  Epoch 234, Batch 3/4: Calculating loss...
  Epoch 234, Batch 3/4: Backward pass...
  Epoch 234, Batch 3/4: Clipping gradients...
  Epoch 234, Batch 3/4: Optimizer step...
  Epoch 234, Batch 3/4: Completed in 0.19s
  Epoch 234, Batch 4/4: Loading data to device...
  Epoch 234, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 234, Batch 4/4: Zeroing gradients...
  Epoch 234, Batch 4/4: Forward pass...
  Epoch 234, Batch 4/4: Calculating loss...
  Epoch 234, Batch 4/4: Backward pass...
  Epoch 234, Batch 4/4: Clipping gradients...
  Epoch 234, Batch 4/4: Optimizer step...
  Epoch 234, Batch 4/4: Completed in 0.03s
Epoch 234: Training phase completed. Average Train Loss: 0.3559
Epoch 234: Starting validation phase...
  Epoch 234, Val Batch 1/1: Loading data...
  Epoch 234, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 234, Val Batch 1/1: Forward pass...
  Epoch 234, Val Batch 1/1: Calculating loss...
Epoch 234: Validation phase completed. Average Val Loss: 0.3056
Epoch 234 Summary ---> Train Loss: 0.3559 / Validation Loss: 0.3056
Epoch 234: Checking early stopping... (Current Best Loss: 0.3012, Epochs No Improve: 0)
  Epoch 234: Validation loss did not improve. Epochs without improvement: 1
Epoch 234: Stepping scheduler...
--- Epoch 234 completed in 0.66 seconds ---

--- Starting Epoch 235/1000 ---
Epoch 235: Starting training phase (4 batches)
  Epoch 235, Batch 1/4: Loading data to device...
  Epoch 235, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 235, Batch 1/4: Zeroing gradients...
  Epoch 235, Batch 1/4: Forward pass...
  Epoch 235, Batch 1/4: Calculating loss...
  Epoch 235, Batch 1/4: Backward pass...
  Epoch 235, Batch 1/4: Clipping gradients...
  Epoch 235, Batch 1/4: Optimizer step...
  Epoch 235, Batch 1/4: Completed in 0.19s
  Epoch 235, Batch 2/4: Loading data to device...
  Epoch 235, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 235, Batch 2/4: Zeroing gradients...
  Epoch 235, Batch 2/4: Forward pass...
  Epoch 235, Batch 2/4: Calculating loss...
  Epoch 235, Batch 2/4: Backward pass...
  Epoch 235, Batch 2/4: Clipping gradients...
  Epoch 235, Batch 2/4: Optimizer step...
  Epoch 235, Batch 2/4: Completed in 0.20s
  Epoch 235, Batch 3/4: Loading data to device...
  Epoch 235, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 235, Batch 3/4: Zeroing gradients...
  Epoch 235, Batch 3/4: Forward pass...
  Epoch 235, Batch 3/4: Calculating loss...
  Epoch 235, Batch 3/4: Backward pass...
  Epoch 235, Batch 3/4: Clipping gradients...
  Epoch 235, Batch 3/4: Optimizer step...
  Epoch 235, Batch 3/4: Completed in 0.19s
  Epoch 235, Batch 4/4: Loading data to device...
  Epoch 235, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 235, Batch 4/4: Zeroing gradients...
  Epoch 235, Batch 4/4: Forward pass...
  Epoch 235, Batch 4/4: Calculating loss...
  Epoch 235, Batch 4/4: Backward pass...
  Epoch 235, Batch 4/4: Clipping gradients...
  Epoch 235, Batch 4/4: Optimizer step...
  Epoch 235, Batch 4/4: Completed in 0.03s
Epoch 235: Training phase completed. Average Train Loss: 0.3564
Epoch 235: Starting validation phase...
  Epoch 235, Val Batch 1/1: Loading data...
  Epoch 235, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 235, Val Batch 1/1: Forward pass...
  Epoch 235, Val Batch 1/1: Calculating loss...
Epoch 235: Validation phase completed. Average Val Loss: 0.3071
Epoch 235 Summary ---> Train Loss: 0.3564 / Validation Loss: 0.3071
Epoch 235: Checking early stopping... (Current Best Loss: 0.3012, Epochs No Improve: 1)
  Epoch 235: Validation loss did not improve. Epochs without improvement: 2
Epoch 235: Stepping scheduler...
--- Epoch 235 completed in 0.67 seconds ---

--- Starting Epoch 236/1000 ---
Epoch 236: Starting training phase (4 batches)
  Epoch 236, Batch 1/4: Loading data to device...
  Epoch 236, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 236, Batch 1/4: Zeroing gradients...
  Epoch 236, Batch 1/4: Forward pass...
  Epoch 236, Batch 1/4: Calculating loss...
  Epoch 236, Batch 1/4: Backward pass...
  Epoch 236, Batch 1/4: Clipping gradients...
  Epoch 236, Batch 1/4: Optimizer step...
  Epoch 236, Batch 1/4: Completed in 0.19s
  Epoch 236, Batch 2/4: Loading data to device...
  Epoch 236, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 236, Batch 2/4: Zeroing gradients...
  Epoch 236, Batch 2/4: Forward pass...
  Epoch 236, Batch 2/4: Calculating loss...
  Epoch 236, Batch 2/4: Backward pass...
  Epoch 236, Batch 2/4: Clipping gradients...
  Epoch 236, Batch 2/4: Optimizer step...
  Epoch 236, Batch 2/4: Completed in 0.19s
  Epoch 236, Batch 3/4: Loading data to device...
  Epoch 236, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 236, Batch 3/4: Zeroing gradients...
  Epoch 236, Batch 3/4: Forward pass...
  Epoch 236, Batch 3/4: Calculating loss...
  Epoch 236, Batch 3/4: Backward pass...
  Epoch 236, Batch 3/4: Clipping gradients...
  Epoch 236, Batch 3/4: Optimizer step...
  Epoch 236, Batch 3/4: Completed in 0.19s
  Epoch 236, Batch 4/4: Loading data to device...
  Epoch 236, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 236, Batch 4/4: Zeroing gradients...
  Epoch 236, Batch 4/4: Forward pass...
  Epoch 236, Batch 4/4: Calculating loss...
  Epoch 236, Batch 4/4: Backward pass...
  Epoch 236, Batch 4/4: Clipping gradients...
  Epoch 236, Batch 4/4: Optimizer step...
  Epoch 236, Batch 4/4: Completed in 0.03s
Epoch 236: Training phase completed. Average Train Loss: 0.3681
Epoch 236: Starting validation phase...
  Epoch 236, Val Batch 1/1: Loading data...
  Epoch 236, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 236, Val Batch 1/1: Forward pass...
  Epoch 236, Val Batch 1/1: Calculating loss...
Epoch 236: Validation phase completed. Average Val Loss: 0.3095
Epoch 236 Summary ---> Train Loss: 0.3681 / Validation Loss: 0.3095
Epoch 236: Checking early stopping... (Current Best Loss: 0.3012, Epochs No Improve: 2)
  Epoch 236: Validation loss did not improve. Epochs without improvement: 3
Epoch 236: Stepping scheduler...
--- Epoch 236 completed in 0.67 seconds ---

--- Starting Epoch 237/1000 ---
Epoch 237: Starting training phase (4 batches)
  Epoch 237, Batch 1/4: Loading data to device...
  Epoch 237, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 237, Batch 1/4: Zeroing gradients...
  Epoch 237, Batch 1/4: Forward pass...
  Epoch 237, Batch 1/4: Calculating loss...
  Epoch 237, Batch 1/4: Backward pass...
  Epoch 237, Batch 1/4: Clipping gradients...
  Epoch 237, Batch 1/4: Optimizer step...
  Epoch 237, Batch 1/4: Completed in 0.18s
  Epoch 237, Batch 2/4: Loading data to device...
  Epoch 237, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 237, Batch 2/4: Zeroing gradients...
  Epoch 237, Batch 2/4: Forward pass...
  Epoch 237, Batch 2/4: Calculating loss...
  Epoch 237, Batch 2/4: Backward pass...
  Epoch 237, Batch 2/4: Clipping gradients...
  Epoch 237, Batch 2/4: Optimizer step...
  Epoch 237, Batch 2/4: Completed in 0.19s
  Epoch 237, Batch 3/4: Loading data to device...
  Epoch 237, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 237, Batch 3/4: Zeroing gradients...
  Epoch 237, Batch 3/4: Forward pass...
  Epoch 237, Batch 3/4: Calculating loss...
  Epoch 237, Batch 3/4: Backward pass...
  Epoch 237, Batch 3/4: Clipping gradients...
  Epoch 237, Batch 3/4: Optimizer step...
  Epoch 237, Batch 3/4: Completed in 0.19s
  Epoch 237, Batch 4/4: Loading data to device...
  Epoch 237, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 237, Batch 4/4: Zeroing gradients...
  Epoch 237, Batch 4/4: Forward pass...
  Epoch 237, Batch 4/4: Calculating loss...
  Epoch 237, Batch 4/4: Backward pass...
  Epoch 237, Batch 4/4: Clipping gradients...
  Epoch 237, Batch 4/4: Optimizer step...
  Epoch 237, Batch 4/4: Completed in 0.03s
Epoch 237: Training phase completed. Average Train Loss: 0.4207
Epoch 237: Starting validation phase...
  Epoch 237, Val Batch 1/1: Loading data...
  Epoch 237, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 237, Val Batch 1/1: Forward pass...
  Epoch 237, Val Batch 1/1: Calculating loss...
Epoch 237: Validation phase completed. Average Val Loss: 0.3052
Epoch 237 Summary ---> Train Loss: 0.4207 / Validation Loss: 0.3052
Epoch 237: Checking early stopping... (Current Best Loss: 0.3012, Epochs No Improve: 3)
  Epoch 237: Validation loss did not improve. Epochs without improvement: 4
Epoch 237: Stepping scheduler...
--- Epoch 237 completed in 0.66 seconds ---

--- Starting Epoch 238/1000 ---
Epoch 238: Starting training phase (4 batches)
  Epoch 238, Batch 1/4: Loading data to device...
  Epoch 238, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 238, Batch 1/4: Zeroing gradients...
  Epoch 238, Batch 1/4: Forward pass...
  Epoch 238, Batch 1/4: Calculating loss...
  Epoch 238, Batch 1/4: Backward pass...
  Epoch 238, Batch 1/4: Clipping gradients...
  Epoch 238, Batch 1/4: Optimizer step...
  Epoch 238, Batch 1/4: Completed in 0.19s
  Epoch 238, Batch 2/4: Loading data to device...
  Epoch 238, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 238, Batch 2/4: Zeroing gradients...
  Epoch 238, Batch 2/4: Forward pass...
  Epoch 238, Batch 2/4: Calculating loss...
  Epoch 238, Batch 2/4: Backward pass...
  Epoch 238, Batch 2/4: Clipping gradients...
  Epoch 238, Batch 2/4: Optimizer step...
  Epoch 238, Batch 2/4: Completed in 0.19s
  Epoch 238, Batch 3/4: Loading data to device...
  Epoch 238, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 238, Batch 3/4: Zeroing gradients...
  Epoch 238, Batch 3/4: Forward pass...
  Epoch 238, Batch 3/4: Calculating loss...
  Epoch 238, Batch 3/4: Backward pass...
  Epoch 238, Batch 3/4: Clipping gradients...
  Epoch 238, Batch 3/4: Optimizer step...
  Epoch 238, Batch 3/4: Completed in 0.20s
  Epoch 238, Batch 4/4: Loading data to device...
  Epoch 238, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 238, Batch 4/4: Zeroing gradients...
  Epoch 238, Batch 4/4: Forward pass...
  Epoch 238, Batch 4/4: Calculating loss...
  Epoch 238, Batch 4/4: Backward pass...
  Epoch 238, Batch 4/4: Clipping gradients...
  Epoch 238, Batch 4/4: Optimizer step...
  Epoch 238, Batch 4/4: Completed in 0.03s
Epoch 238: Training phase completed. Average Train Loss: 0.3377
Epoch 238: Starting validation phase...
  Epoch 238, Val Batch 1/1: Loading data...
  Epoch 238, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 238, Val Batch 1/1: Forward pass...
  Epoch 238, Val Batch 1/1: Calculating loss...
Epoch 238: Validation phase completed. Average Val Loss: 0.3061
Epoch 238 Summary ---> Train Loss: 0.3377 / Validation Loss: 0.3061
Epoch 238: Checking early stopping... (Current Best Loss: 0.3012, Epochs No Improve: 4)
  Epoch 238: Validation loss did not improve. Epochs without improvement: 5
Epoch 238: Stepping scheduler...
--- Epoch 238 completed in 0.68 seconds ---

--- Starting Epoch 239/1000 ---
Epoch 239: Starting training phase (4 batches)
  Epoch 239, Batch 1/4: Loading data to device...
  Epoch 239, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 239, Batch 1/4: Zeroing gradients...
  Epoch 239, Batch 1/4: Forward pass...
  Epoch 239, Batch 1/4: Calculating loss...
  Epoch 239, Batch 1/4: Backward pass...
  Epoch 239, Batch 1/4: Clipping gradients...
  Epoch 239, Batch 1/4: Optimizer step...
  Epoch 239, Batch 1/4: Completed in 0.19s
  Epoch 239, Batch 2/4: Loading data to device...
  Epoch 239, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 239, Batch 2/4: Zeroing gradients...
  Epoch 239, Batch 2/4: Forward pass...
  Epoch 239, Batch 2/4: Calculating loss...
  Epoch 239, Batch 2/4: Backward pass...
  Epoch 239, Batch 2/4: Clipping gradients...
  Epoch 239, Batch 2/4: Optimizer step...
  Epoch 239, Batch 2/4: Completed in 0.19s
  Epoch 239, Batch 3/4: Loading data to device...
  Epoch 239, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 239, Batch 3/4: Zeroing gradients...
  Epoch 239, Batch 3/4: Forward pass...
  Epoch 239, Batch 3/4: Calculating loss...
  Epoch 239, Batch 3/4: Backward pass...
  Epoch 239, Batch 3/4: Clipping gradients...
  Epoch 239, Batch 3/4: Optimizer step...
  Epoch 239, Batch 3/4: Completed in 0.18s
  Epoch 239, Batch 4/4: Loading data to device...
  Epoch 239, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 239, Batch 4/4: Zeroing gradients...
  Epoch 239, Batch 4/4: Forward pass...
  Epoch 239, Batch 4/4: Calculating loss...
  Epoch 239, Batch 4/4: Backward pass...
  Epoch 239, Batch 4/4: Clipping gradients...
  Epoch 239, Batch 4/4: Optimizer step...
  Epoch 239, Batch 4/4: Completed in 0.03s
Epoch 239: Training phase completed. Average Train Loss: 0.3709
Epoch 239: Starting validation phase...
  Epoch 239, Val Batch 1/1: Loading data...
  Epoch 239, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 239, Val Batch 1/1: Forward pass...
  Epoch 239, Val Batch 1/1: Calculating loss...
Epoch 239: Validation phase completed. Average Val Loss: 0.3145
Epoch 239 Summary ---> Train Loss: 0.3709 / Validation Loss: 0.3145
Epoch 239: Checking early stopping... (Current Best Loss: 0.3012, Epochs No Improve: 5)
  Epoch 239: Validation loss did not improve. Epochs without improvement: 6
Epoch 239: Stepping scheduler...
--- Epoch 239 completed in 0.65 seconds ---

--- Starting Epoch 240/1000 ---
Epoch 240: Starting training phase (4 batches)
  Epoch 240, Batch 1/4: Loading data to device...
  Epoch 240, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 240, Batch 1/4: Zeroing gradients...
  Epoch 240, Batch 1/4: Forward pass...
  Epoch 240, Batch 1/4: Calculating loss...
  Epoch 240, Batch 1/4: Backward pass...
  Epoch 240, Batch 1/4: Clipping gradients...
  Epoch 240, Batch 1/4: Optimizer step...
  Epoch 240, Batch 1/4: Completed in 0.18s
  Epoch 240, Batch 2/4: Loading data to device...
  Epoch 240, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 240, Batch 2/4: Zeroing gradients...
  Epoch 240, Batch 2/4: Forward pass...
  Epoch 240, Batch 2/4: Calculating loss...
  Epoch 240, Batch 2/4: Backward pass...
  Epoch 240, Batch 2/4: Clipping gradients...
  Epoch 240, Batch 2/4: Optimizer step...
  Epoch 240, Batch 2/4: Completed in 0.19s
  Epoch 240, Batch 3/4: Loading data to device...
  Epoch 240, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 240, Batch 3/4: Zeroing gradients...
  Epoch 240, Batch 3/4: Forward pass...
  Epoch 240, Batch 3/4: Calculating loss...
  Epoch 240, Batch 3/4: Backward pass...
  Epoch 240, Batch 3/4: Clipping gradients...
  Epoch 240, Batch 3/4: Optimizer step...
  Epoch 240, Batch 3/4: Completed in 0.19s
  Epoch 240, Batch 4/4: Loading data to device...
  Epoch 240, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 240, Batch 4/4: Zeroing gradients...
  Epoch 240, Batch 4/4: Forward pass...
  Epoch 240, Batch 4/4: Calculating loss...
  Epoch 240, Batch 4/4: Backward pass...
  Epoch 240, Batch 4/4: Clipping gradients...
  Epoch 240, Batch 4/4: Optimizer step...
  Epoch 240, Batch 4/4: Completed in 0.03s
Epoch 240: Training phase completed. Average Train Loss: 0.4118
Epoch 240: Starting validation phase...
  Epoch 240, Val Batch 1/1: Loading data...
  Epoch 240, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 240, Val Batch 1/1: Forward pass...
  Epoch 240, Val Batch 1/1: Calculating loss...
Epoch 240: Validation phase completed. Average Val Loss: 0.3164
Epoch 240 Summary ---> Train Loss: 0.4118 / Validation Loss: 0.3164
Epoch 240: Checking early stopping... (Current Best Loss: 0.3012, Epochs No Improve: 6)
  Epoch 240: Validation loss did not improve. Epochs without improvement: 7
Epoch 240: Stepping scheduler...
--- Epoch 240 completed in 0.65 seconds ---

--- Starting Epoch 241/1000 ---
Epoch 241: Starting training phase (4 batches)
  Epoch 241, Batch 1/4: Loading data to device...
  Epoch 241, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 241, Batch 1/4: Zeroing gradients...
  Epoch 241, Batch 1/4: Forward pass...
  Epoch 241, Batch 1/4: Calculating loss...
  Epoch 241, Batch 1/4: Backward pass...
  Epoch 241, Batch 1/4: Clipping gradients...
  Epoch 241, Batch 1/4: Optimizer step...
  Epoch 241, Batch 1/4: Completed in 0.19s
  Epoch 241, Batch 2/4: Loading data to device...
  Epoch 241, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 241, Batch 2/4: Zeroing gradients...
  Epoch 241, Batch 2/4: Forward pass...
  Epoch 241, Batch 2/4: Calculating loss...
  Epoch 241, Batch 2/4: Backward pass...
  Epoch 241, Batch 2/4: Clipping gradients...
  Epoch 241, Batch 2/4: Optimizer step...
  Epoch 241, Batch 2/4: Completed in 0.18s
  Epoch 241, Batch 3/4: Loading data to device...
  Epoch 241, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 241, Batch 3/4: Zeroing gradients...
  Epoch 241, Batch 3/4: Forward pass...
  Epoch 241, Batch 3/4: Calculating loss...
  Epoch 241, Batch 3/4: Backward pass...
  Epoch 241, Batch 3/4: Clipping gradients...
  Epoch 241, Batch 3/4: Optimizer step...
  Epoch 241, Batch 3/4: Completed in 0.19s
  Epoch 241, Batch 4/4: Loading data to device...
  Epoch 241, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 241, Batch 4/4: Zeroing gradients...
  Epoch 241, Batch 4/4: Forward pass...
  Epoch 241, Batch 4/4: Calculating loss...
  Epoch 241, Batch 4/4: Backward pass...
  Epoch 241, Batch 4/4: Clipping gradients...
  Epoch 241, Batch 4/4: Optimizer step...
  Epoch 241, Batch 4/4: Completed in 0.03s
Epoch 241: Training phase completed. Average Train Loss: 0.3719
Epoch 241: Starting validation phase...
  Epoch 241, Val Batch 1/1: Loading data...
  Epoch 241, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 241, Val Batch 1/1: Forward pass...
  Epoch 241, Val Batch 1/1: Calculating loss...
Epoch 241: Validation phase completed. Average Val Loss: 0.3084
Epoch 241 Summary ---> Train Loss: 0.3719 / Validation Loss: 0.3084
Epoch 241: Checking early stopping... (Current Best Loss: 0.3012, Epochs No Improve: 7)
  Epoch 241: Validation loss did not improve. Epochs without improvement: 8
Epoch 241: Stepping scheduler...
--- Epoch 241 completed in 0.66 seconds ---

--- Starting Epoch 242/1000 ---
Epoch 242: Starting training phase (4 batches)
  Epoch 242, Batch 1/4: Loading data to device...
  Epoch 242, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 242, Batch 1/4: Zeroing gradients...
  Epoch 242, Batch 1/4: Forward pass...
  Epoch 242, Batch 1/4: Calculating loss...
  Epoch 242, Batch 1/4: Backward pass...
  Epoch 242, Batch 1/4: Clipping gradients...
  Epoch 242, Batch 1/4: Optimizer step...
  Epoch 242, Batch 1/4: Completed in 0.19s
  Epoch 242, Batch 2/4: Loading data to device...
  Epoch 242, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 242, Batch 2/4: Zeroing gradients...
  Epoch 242, Batch 2/4: Forward pass...
  Epoch 242, Batch 2/4: Calculating loss...
  Epoch 242, Batch 2/4: Backward pass...
  Epoch 242, Batch 2/4: Clipping gradients...
  Epoch 242, Batch 2/4: Optimizer step...
  Epoch 242, Batch 2/4: Completed in 0.19s
  Epoch 242, Batch 3/4: Loading data to device...
  Epoch 242, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 242, Batch 3/4: Zeroing gradients...
  Epoch 242, Batch 3/4: Forward pass...
  Epoch 242, Batch 3/4: Calculating loss...
  Epoch 242, Batch 3/4: Backward pass...
  Epoch 242, Batch 3/4: Clipping gradients...
  Epoch 242, Batch 3/4: Optimizer step...
  Epoch 242, Batch 3/4: Completed in 0.19s
  Epoch 242, Batch 4/4: Loading data to device...
  Epoch 242, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 242, Batch 4/4: Zeroing gradients...
  Epoch 242, Batch 4/4: Forward pass...
  Epoch 242, Batch 4/4: Calculating loss...
  Epoch 242, Batch 4/4: Backward pass...
  Epoch 242, Batch 4/4: Clipping gradients...
  Epoch 242, Batch 4/4: Optimizer step...
  Epoch 242, Batch 4/4: Completed in 0.03s
Epoch 242: Training phase completed. Average Train Loss: 0.3401
Epoch 242: Starting validation phase...
  Epoch 242, Val Batch 1/1: Loading data...
  Epoch 242, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 242, Val Batch 1/1: Forward pass...
  Epoch 242, Val Batch 1/1: Calculating loss...
Epoch 242: Validation phase completed. Average Val Loss: 0.3078
Epoch 242 Summary ---> Train Loss: 0.3401 / Validation Loss: 0.3078
Epoch 242: Checking early stopping... (Current Best Loss: 0.3012, Epochs No Improve: 8)
  Epoch 242: Validation loss did not improve. Epochs without improvement: 9
Epoch 242: Stepping scheduler...
--- Epoch 242 completed in 0.67 seconds ---

--- Starting Epoch 243/1000 ---
Epoch 243: Starting training phase (4 batches)
  Epoch 243, Batch 1/4: Loading data to device...
  Epoch 243, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 243, Batch 1/4: Zeroing gradients...
  Epoch 243, Batch 1/4: Forward pass...
  Epoch 243, Batch 1/4: Calculating loss...
  Epoch 243, Batch 1/4: Backward pass...
  Epoch 243, Batch 1/4: Clipping gradients...
  Epoch 243, Batch 1/4: Optimizer step...
  Epoch 243, Batch 1/4: Completed in 0.19s
  Epoch 243, Batch 2/4: Loading data to device...
  Epoch 243, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 243, Batch 2/4: Zeroing gradients...
  Epoch 243, Batch 2/4: Forward pass...
  Epoch 243, Batch 2/4: Calculating loss...
  Epoch 243, Batch 2/4: Backward pass...
  Epoch 243, Batch 2/4: Clipping gradients...
  Epoch 243, Batch 2/4: Optimizer step...
  Epoch 243, Batch 2/4: Completed in 0.19s
  Epoch 243, Batch 3/4: Loading data to device...
  Epoch 243, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 243, Batch 3/4: Zeroing gradients...
  Epoch 243, Batch 3/4: Forward pass...
  Epoch 243, Batch 3/4: Calculating loss...
  Epoch 243, Batch 3/4: Backward pass...
  Epoch 243, Batch 3/4: Clipping gradients...
  Epoch 243, Batch 3/4: Optimizer step...
  Epoch 243, Batch 3/4: Completed in 0.19s
  Epoch 243, Batch 4/4: Loading data to device...
  Epoch 243, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 243, Batch 4/4: Zeroing gradients...
  Epoch 243, Batch 4/4: Forward pass...
  Epoch 243, Batch 4/4: Calculating loss...
  Epoch 243, Batch 4/4: Backward pass...
  Epoch 243, Batch 4/4: Clipping gradients...
  Epoch 243, Batch 4/4: Optimizer step...
  Epoch 243, Batch 4/4: Completed in 0.03s
Epoch 243: Training phase completed. Average Train Loss: 0.3898
Epoch 243: Starting validation phase...
  Epoch 243, Val Batch 1/1: Loading data...
  Epoch 243, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 243, Val Batch 1/1: Forward pass...
  Epoch 243, Val Batch 1/1: Calculating loss...
Epoch 243: Validation phase completed. Average Val Loss: 0.3086
Epoch 243 Summary ---> Train Loss: 0.3898 / Validation Loss: 0.3086
Epoch 243: Checking early stopping... (Current Best Loss: 0.3012, Epochs No Improve: 9)
  Epoch 243: Validation loss did not improve. Epochs without improvement: 10
Epoch 243: Stepping scheduler...
--- Epoch 243 completed in 0.66 seconds ---

--- Starting Epoch 244/1000 ---
Epoch 244: Starting training phase (4 batches)
  Epoch 244, Batch 1/4: Loading data to device...
  Epoch 244, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 244, Batch 1/4: Zeroing gradients...
  Epoch 244, Batch 1/4: Forward pass...
  Epoch 244, Batch 1/4: Calculating loss...
  Epoch 244, Batch 1/4: Backward pass...
  Epoch 244, Batch 1/4: Clipping gradients...
  Epoch 244, Batch 1/4: Optimizer step...
  Epoch 244, Batch 1/4: Completed in 0.19s
  Epoch 244, Batch 2/4: Loading data to device...
  Epoch 244, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 244, Batch 2/4: Zeroing gradients...
  Epoch 244, Batch 2/4: Forward pass...
  Epoch 244, Batch 2/4: Calculating loss...
  Epoch 244, Batch 2/4: Backward pass...
  Epoch 244, Batch 2/4: Clipping gradients...
  Epoch 244, Batch 2/4: Optimizer step...
  Epoch 244, Batch 2/4: Completed in 0.18s
  Epoch 244, Batch 3/4: Loading data to device...
  Epoch 244, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 244, Batch 3/4: Zeroing gradients...
  Epoch 244, Batch 3/4: Forward pass...
  Epoch 244, Batch 3/4: Calculating loss...
  Epoch 244, Batch 3/4: Backward pass...
  Epoch 244, Batch 3/4: Clipping gradients...
  Epoch 244, Batch 3/4: Optimizer step...
  Epoch 244, Batch 3/4: Completed in 0.19s
  Epoch 244, Batch 4/4: Loading data to device...
  Epoch 244, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 244, Batch 4/4: Zeroing gradients...
  Epoch 244, Batch 4/4: Forward pass...
  Epoch 244, Batch 4/4: Calculating loss...
  Epoch 244, Batch 4/4: Backward pass...
  Epoch 244, Batch 4/4: Clipping gradients...
  Epoch 244, Batch 4/4: Optimizer step...
  Epoch 244, Batch 4/4: Completed in 0.03s
Epoch 244: Training phase completed. Average Train Loss: 0.3605
Epoch 244: Starting validation phase...
  Epoch 244, Val Batch 1/1: Loading data...
  Epoch 244, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 244, Val Batch 1/1: Forward pass...
  Epoch 244, Val Batch 1/1: Calculating loss...
Epoch 244: Validation phase completed. Average Val Loss: 0.3046
Epoch 244 Summary ---> Train Loss: 0.3605 / Validation Loss: 0.3046
Epoch 244: Checking early stopping... (Current Best Loss: 0.3012, Epochs No Improve: 10)
  Epoch 244: Validation loss did not improve. Epochs without improvement: 11
Epoch 244: Stepping scheduler...
--- Epoch 244 completed in 0.66 seconds ---

--- Starting Epoch 245/1000 ---
Epoch 245: Starting training phase (4 batches)
  Epoch 245, Batch 1/4: Loading data to device...
  Epoch 245, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 245, Batch 1/4: Zeroing gradients...
  Epoch 245, Batch 1/4: Forward pass...
  Epoch 245, Batch 1/4: Calculating loss...
  Epoch 245, Batch 1/4: Backward pass...
  Epoch 245, Batch 1/4: Clipping gradients...
  Epoch 245, Batch 1/4: Optimizer step...
  Epoch 245, Batch 1/4: Completed in 0.19s
  Epoch 245, Batch 2/4: Loading data to device...
  Epoch 245, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 245, Batch 2/4: Zeroing gradients...
  Epoch 245, Batch 2/4: Forward pass...
  Epoch 245, Batch 2/4: Calculating loss...
  Epoch 245, Batch 2/4: Backward pass...
  Epoch 245, Batch 2/4: Clipping gradients...
  Epoch 245, Batch 2/4: Optimizer step...
  Epoch 245, Batch 2/4: Completed in 0.18s
  Epoch 245, Batch 3/4: Loading data to device...
  Epoch 245, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 245, Batch 3/4: Zeroing gradients...
  Epoch 245, Batch 3/4: Forward pass...
  Epoch 245, Batch 3/4: Calculating loss...
  Epoch 245, Batch 3/4: Backward pass...
  Epoch 245, Batch 3/4: Clipping gradients...
  Epoch 245, Batch 3/4: Optimizer step...
  Epoch 245, Batch 3/4: Completed in 0.19s
  Epoch 245, Batch 4/4: Loading data to device...
  Epoch 245, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 245, Batch 4/4: Zeroing gradients...
  Epoch 245, Batch 4/4: Forward pass...
  Epoch 245, Batch 4/4: Calculating loss...
  Epoch 245, Batch 4/4: Backward pass...
  Epoch 245, Batch 4/4: Clipping gradients...
  Epoch 245, Batch 4/4: Optimizer step...
  Epoch 245, Batch 4/4: Completed in 0.03s
Epoch 245: Training phase completed. Average Train Loss: 0.3947
Epoch 245: Starting validation phase...
  Epoch 245, Val Batch 1/1: Loading data...
  Epoch 245, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 245, Val Batch 1/1: Forward pass...
  Epoch 245, Val Batch 1/1: Calculating loss...
Epoch 245: Validation phase completed. Average Val Loss: 0.2984
Epoch 245 Summary ---> Train Loss: 0.3947 / Validation Loss: 0.2984
Epoch 245: Checking early stopping... (Current Best Loss: 0.3012, Epochs No Improve: 11)
  Epoch 245: Validation loss improved (0.3012 --> 0.2984). Saving model.
Epoch 245: Stepping scheduler...
--- Epoch 245 completed in 0.66 seconds ---

--- Starting Epoch 246/1000 ---
Epoch 246: Starting training phase (4 batches)
  Epoch 246, Batch 1/4: Loading data to device...
  Epoch 246, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 246, Batch 1/4: Zeroing gradients...
  Epoch 246, Batch 1/4: Forward pass...
  Epoch 246, Batch 1/4: Calculating loss...
  Epoch 246, Batch 1/4: Backward pass...
  Epoch 246, Batch 1/4: Clipping gradients...
  Epoch 246, Batch 1/4: Optimizer step...
  Epoch 246, Batch 1/4: Completed in 0.19s
  Epoch 246, Batch 2/4: Loading data to device...
  Epoch 246, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 246, Batch 2/4: Zeroing gradients...
  Epoch 246, Batch 2/4: Forward pass...
  Epoch 246, Batch 2/4: Calculating loss...
  Epoch 246, Batch 2/4: Backward pass...
  Epoch 246, Batch 2/4: Clipping gradients...
  Epoch 246, Batch 2/4: Optimizer step...
  Epoch 246, Batch 2/4: Completed in 0.20s
  Epoch 246, Batch 3/4: Loading data to device...
  Epoch 246, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 246, Batch 3/4: Zeroing gradients...
  Epoch 246, Batch 3/4: Forward pass...
  Epoch 246, Batch 3/4: Calculating loss...
  Epoch 246, Batch 3/4: Backward pass...
  Epoch 246, Batch 3/4: Clipping gradients...
  Epoch 246, Batch 3/4: Optimizer step...
  Epoch 246, Batch 3/4: Completed in 0.21s
  Epoch 246, Batch 4/4: Loading data to device...
  Epoch 246, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 246, Batch 4/4: Zeroing gradients...
  Epoch 246, Batch 4/4: Forward pass...
  Epoch 246, Batch 4/4: Calculating loss...
  Epoch 246, Batch 4/4: Backward pass...
  Epoch 246, Batch 4/4: Clipping gradients...
  Epoch 246, Batch 4/4: Optimizer step...
  Epoch 246, Batch 4/4: Completed in 0.03s
Epoch 246: Training phase completed. Average Train Loss: 0.3895
Epoch 246: Starting validation phase...
  Epoch 246, Val Batch 1/1: Loading data...
  Epoch 246, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 246, Val Batch 1/1: Forward pass...
  Epoch 246, Val Batch 1/1: Calculating loss...
Epoch 246: Validation phase completed. Average Val Loss: 0.3031
Epoch 246 Summary ---> Train Loss: 0.3895 / Validation Loss: 0.3031
Epoch 246: Checking early stopping... (Current Best Loss: 0.2984, Epochs No Improve: 0)
  Epoch 246: Validation loss did not improve. Epochs without improvement: 1
Epoch 246: Stepping scheduler...
--- Epoch 246 completed in 0.71 seconds ---

--- Starting Epoch 247/1000 ---
Epoch 247: Starting training phase (4 batches)
  Epoch 247, Batch 1/4: Loading data to device...
  Epoch 247, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 247, Batch 1/4: Zeroing gradients...
  Epoch 247, Batch 1/4: Forward pass...
  Epoch 247, Batch 1/4: Calculating loss...
  Epoch 247, Batch 1/4: Backward pass...
  Epoch 247, Batch 1/4: Clipping gradients...
  Epoch 247, Batch 1/4: Optimizer step...
  Epoch 247, Batch 1/4: Completed in 0.20s
  Epoch 247, Batch 2/4: Loading data to device...
  Epoch 247, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 247, Batch 2/4: Zeroing gradients...
  Epoch 247, Batch 2/4: Forward pass...
  Epoch 247, Batch 2/4: Calculating loss...
  Epoch 247, Batch 2/4: Backward pass...
  Epoch 247, Batch 2/4: Clipping gradients...
  Epoch 247, Batch 2/4: Optimizer step...
  Epoch 247, Batch 2/4: Completed in 0.19s
  Epoch 247, Batch 3/4: Loading data to device...
  Epoch 247, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 247, Batch 3/4: Zeroing gradients...
  Epoch 247, Batch 3/4: Forward pass...
  Epoch 247, Batch 3/4: Calculating loss...
  Epoch 247, Batch 3/4: Backward pass...
  Epoch 247, Batch 3/4: Clipping gradients...
  Epoch 247, Batch 3/4: Optimizer step...
  Epoch 247, Batch 3/4: Completed in 0.19s
  Epoch 247, Batch 4/4: Loading data to device...
  Epoch 247, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 247, Batch 4/4: Zeroing gradients...
  Epoch 247, Batch 4/4: Forward pass...
  Epoch 247, Batch 4/4: Calculating loss...
  Epoch 247, Batch 4/4: Backward pass...
  Epoch 247, Batch 4/4: Clipping gradients...
  Epoch 247, Batch 4/4: Optimizer step...
  Epoch 247, Batch 4/4: Completed in 0.03s
Epoch 247: Training phase completed. Average Train Loss: 0.3873
Epoch 247: Starting validation phase...
  Epoch 247, Val Batch 1/1: Loading data...
  Epoch 247, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 247, Val Batch 1/1: Forward pass...
  Epoch 247, Val Batch 1/1: Calculating loss...
Epoch 247: Validation phase completed. Average Val Loss: 0.3021
Epoch 247 Summary ---> Train Loss: 0.3873 / Validation Loss: 0.3021
Epoch 247: Checking early stopping... (Current Best Loss: 0.2984, Epochs No Improve: 1)
  Epoch 247: Validation loss did not improve. Epochs without improvement: 2
Epoch 247: Stepping scheduler...
--- Epoch 247 completed in 0.68 seconds ---

--- Starting Epoch 248/1000 ---
Epoch 248: Starting training phase (4 batches)
  Epoch 248, Batch 1/4: Loading data to device...
  Epoch 248, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 248, Batch 1/4: Zeroing gradients...
  Epoch 248, Batch 1/4: Forward pass...
  Epoch 248, Batch 1/4: Calculating loss...
  Epoch 248, Batch 1/4: Backward pass...
  Epoch 248, Batch 1/4: Clipping gradients...
  Epoch 248, Batch 1/4: Optimizer step...
  Epoch 248, Batch 1/4: Completed in 0.20s
  Epoch 248, Batch 2/4: Loading data to device...
  Epoch 248, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 248, Batch 2/4: Zeroing gradients...
  Epoch 248, Batch 2/4: Forward pass...
  Epoch 248, Batch 2/4: Calculating loss...
  Epoch 248, Batch 2/4: Backward pass...
  Epoch 248, Batch 2/4: Clipping gradients...
  Epoch 248, Batch 2/4: Optimizer step...
  Epoch 248, Batch 2/4: Completed in 0.19s
  Epoch 248, Batch 3/4: Loading data to device...
  Epoch 248, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 248, Batch 3/4: Zeroing gradients...
  Epoch 248, Batch 3/4: Forward pass...
  Epoch 248, Batch 3/4: Calculating loss...
  Epoch 248, Batch 3/4: Backward pass...
  Epoch 248, Batch 3/4: Clipping gradients...
  Epoch 248, Batch 3/4: Optimizer step...
  Epoch 248, Batch 3/4: Completed in 0.19s
  Epoch 248, Batch 4/4: Loading data to device...
  Epoch 248, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 248, Batch 4/4: Zeroing gradients...
  Epoch 248, Batch 4/4: Forward pass...
  Epoch 248, Batch 4/4: Calculating loss...
  Epoch 248, Batch 4/4: Backward pass...
  Epoch 248, Batch 4/4: Clipping gradients...
  Epoch 248, Batch 4/4: Optimizer step...
  Epoch 248, Batch 4/4: Completed in 0.03s
Epoch 248: Training phase completed. Average Train Loss: 0.3280
Epoch 248: Starting validation phase...
  Epoch 248, Val Batch 1/1: Loading data...
  Epoch 248, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 248, Val Batch 1/1: Forward pass...
  Epoch 248, Val Batch 1/1: Calculating loss...
Epoch 248: Validation phase completed. Average Val Loss: 0.3083
Epoch 248 Summary ---> Train Loss: 0.3280 / Validation Loss: 0.3083
Epoch 248: Checking early stopping... (Current Best Loss: 0.2984, Epochs No Improve: 2)
  Epoch 248: Validation loss did not improve. Epochs without improvement: 3
Epoch 248: Stepping scheduler...
--- Epoch 248 completed in 0.67 seconds ---

--- Starting Epoch 249/1000 ---
Epoch 249: Starting training phase (4 batches)
  Epoch 249, Batch 1/4: Loading data to device...
  Epoch 249, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 249, Batch 1/4: Zeroing gradients...
  Epoch 249, Batch 1/4: Forward pass...
  Epoch 249, Batch 1/4: Calculating loss...
  Epoch 249, Batch 1/4: Backward pass...
  Epoch 249, Batch 1/4: Clipping gradients...
  Epoch 249, Batch 1/4: Optimizer step...
  Epoch 249, Batch 1/4: Completed in 0.20s
  Epoch 249, Batch 2/4: Loading data to device...
  Epoch 249, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 249, Batch 2/4: Zeroing gradients...
  Epoch 249, Batch 2/4: Forward pass...
  Epoch 249, Batch 2/4: Calculating loss...
  Epoch 249, Batch 2/4: Backward pass...
  Epoch 249, Batch 2/4: Clipping gradients...
  Epoch 249, Batch 2/4: Optimizer step...
  Epoch 249, Batch 2/4: Completed in 0.20s
  Epoch 249, Batch 3/4: Loading data to device...
  Epoch 249, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 249, Batch 3/4: Zeroing gradients...
  Epoch 249, Batch 3/4: Forward pass...
  Epoch 249, Batch 3/4: Calculating loss...
  Epoch 249, Batch 3/4: Backward pass...
  Epoch 249, Batch 3/4: Clipping gradients...
  Epoch 249, Batch 3/4: Optimizer step...
  Epoch 249, Batch 3/4: Completed in 0.19s
  Epoch 249, Batch 4/4: Loading data to device...
  Epoch 249, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 249, Batch 4/4: Zeroing gradients...
  Epoch 249, Batch 4/4: Forward pass...
  Epoch 249, Batch 4/4: Calculating loss...
  Epoch 249, Batch 4/4: Backward pass...
  Epoch 249, Batch 4/4: Clipping gradients...
  Epoch 249, Batch 4/4: Optimizer step...
  Epoch 249, Batch 4/4: Completed in 0.03s
Epoch 249: Training phase completed. Average Train Loss: 0.3906
Epoch 249: Starting validation phase...
  Epoch 249, Val Batch 1/1: Loading data...
  Epoch 249, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 249, Val Batch 1/1: Forward pass...
  Epoch 249, Val Batch 1/1: Calculating loss...
Epoch 249: Validation phase completed. Average Val Loss: 0.3035
Epoch 249 Summary ---> Train Loss: 0.3906 / Validation Loss: 0.3035
Epoch 249: Checking early stopping... (Current Best Loss: 0.2984, Epochs No Improve: 3)
  Epoch 249: Validation loss did not improve. Epochs without improvement: 4
Epoch 249: Stepping scheduler...
--- Epoch 249 completed in 0.68 seconds ---

--- Starting Epoch 250/1000 ---
Epoch 250: Starting training phase (4 batches)
  Epoch 250, Batch 1/4: Loading data to device...
  Epoch 250, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 250, Batch 1/4: Zeroing gradients...
  Epoch 250, Batch 1/4: Forward pass...
  Epoch 250, Batch 1/4: Calculating loss...
  Epoch 250, Batch 1/4: Backward pass...
  Epoch 250, Batch 1/4: Clipping gradients...
  Epoch 250, Batch 1/4: Optimizer step...
  Epoch 250, Batch 1/4: Completed in 0.19s
  Epoch 250, Batch 2/4: Loading data to device...
  Epoch 250, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 250, Batch 2/4: Zeroing gradients...
  Epoch 250, Batch 2/4: Forward pass...
  Epoch 250, Batch 2/4: Calculating loss...
  Epoch 250, Batch 2/4: Backward pass...
  Epoch 250, Batch 2/4: Clipping gradients...
  Epoch 250, Batch 2/4: Optimizer step...
  Epoch 250, Batch 2/4: Completed in 0.20s
  Epoch 250, Batch 3/4: Loading data to device...
  Epoch 250, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 250, Batch 3/4: Zeroing gradients...
  Epoch 250, Batch 3/4: Forward pass...
  Epoch 250, Batch 3/4: Calculating loss...
  Epoch 250, Batch 3/4: Backward pass...
  Epoch 250, Batch 3/4: Clipping gradients...
  Epoch 250, Batch 3/4: Optimizer step...
  Epoch 250, Batch 3/4: Completed in 0.19s
  Epoch 250, Batch 4/4: Loading data to device...
  Epoch 250, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 250, Batch 4/4: Zeroing gradients...
  Epoch 250, Batch 4/4: Forward pass...
  Epoch 250, Batch 4/4: Calculating loss...
  Epoch 250, Batch 4/4: Backward pass...
  Epoch 250, Batch 4/4: Clipping gradients...
  Epoch 250, Batch 4/4: Optimizer step...
  Epoch 250, Batch 4/4: Completed in 0.03s
Epoch 250: Training phase completed. Average Train Loss: 0.4417
Epoch 250: Starting validation phase...
  Epoch 250, Val Batch 1/1: Loading data...
  Epoch 250, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 250, Val Batch 1/1: Forward pass...
  Epoch 250, Val Batch 1/1: Calculating loss...
Epoch 250: Validation phase completed. Average Val Loss: 0.2967
Epoch 250 Summary ---> Train Loss: 0.4417 / Validation Loss: 0.2967
Epoch 250: Checking early stopping... (Current Best Loss: 0.2984, Epochs No Improve: 4)
  Epoch 250: Validation loss improved (0.2984 --> 0.2967). Saving model.
Epoch 250: Stepping scheduler...
--- Epoch 250 completed in 0.67 seconds ---

--- Starting Epoch 251/1000 ---
Epoch 251: Starting training phase (4 batches)
  Epoch 251, Batch 1/4: Loading data to device...
  Epoch 251, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 251, Batch 1/4: Zeroing gradients...
  Epoch 251, Batch 1/4: Forward pass...
  Epoch 251, Batch 1/4: Calculating loss...
  Epoch 251, Batch 1/4: Backward pass...
  Epoch 251, Batch 1/4: Clipping gradients...
  Epoch 251, Batch 1/4: Optimizer step...
  Epoch 251, Batch 1/4: Completed in 0.19s
  Epoch 251, Batch 2/4: Loading data to device...
  Epoch 251, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 251, Batch 2/4: Zeroing gradients...
  Epoch 251, Batch 2/4: Forward pass...
  Epoch 251, Batch 2/4: Calculating loss...
  Epoch 251, Batch 2/4: Backward pass...
  Epoch 251, Batch 2/4: Clipping gradients...
  Epoch 251, Batch 2/4: Optimizer step...
  Epoch 251, Batch 2/4: Completed in 0.19s
  Epoch 251, Batch 3/4: Loading data to device...
  Epoch 251, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 251, Batch 3/4: Zeroing gradients...
  Epoch 251, Batch 3/4: Forward pass...
  Epoch 251, Batch 3/4: Calculating loss...
  Epoch 251, Batch 3/4: Backward pass...
  Epoch 251, Batch 3/4: Clipping gradients...
  Epoch 251, Batch 3/4: Optimizer step...
  Epoch 251, Batch 3/4: Completed in 0.20s
  Epoch 251, Batch 4/4: Loading data to device...
  Epoch 251, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 251, Batch 4/4: Zeroing gradients...
  Epoch 251, Batch 4/4: Forward pass...
  Epoch 251, Batch 4/4: Calculating loss...
  Epoch 251, Batch 4/4: Backward pass...
  Epoch 251, Batch 4/4: Clipping gradients...
  Epoch 251, Batch 4/4: Optimizer step...
  Epoch 251, Batch 4/4: Completed in 0.03s
Epoch 251: Training phase completed. Average Train Loss: 0.3582
Epoch 251: Starting validation phase...
  Epoch 251, Val Batch 1/1: Loading data...
  Epoch 251, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 251, Val Batch 1/1: Forward pass...
  Epoch 251, Val Batch 1/1: Calculating loss...
Epoch 251: Validation phase completed. Average Val Loss: 0.3008
Epoch 251 Summary ---> Train Loss: 0.3582 / Validation Loss: 0.3008
Epoch 251: Checking early stopping... (Current Best Loss: 0.2967, Epochs No Improve: 0)
  Epoch 251: Validation loss did not improve. Epochs without improvement: 1
Epoch 251: Stepping scheduler...
--- Epoch 251 completed in 0.68 seconds ---

--- Starting Epoch 252/1000 ---
Epoch 252: Starting training phase (4 batches)
  Epoch 252, Batch 1/4: Loading data to device...
  Epoch 252, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 252, Batch 1/4: Zeroing gradients...
  Epoch 252, Batch 1/4: Forward pass...
  Epoch 252, Batch 1/4: Calculating loss...
  Epoch 252, Batch 1/4: Backward pass...
  Epoch 252, Batch 1/4: Clipping gradients...
  Epoch 252, Batch 1/4: Optimizer step...
  Epoch 252, Batch 1/4: Completed in 0.19s
  Epoch 252, Batch 2/4: Loading data to device...
  Epoch 252, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 252, Batch 2/4: Zeroing gradients...
  Epoch 252, Batch 2/4: Forward pass...
  Epoch 252, Batch 2/4: Calculating loss...
  Epoch 252, Batch 2/4: Backward pass...
  Epoch 252, Batch 2/4: Clipping gradients...
  Epoch 252, Batch 2/4: Optimizer step...
  Epoch 252, Batch 2/4: Completed in 0.19s
  Epoch 252, Batch 3/4: Loading data to device...
  Epoch 252, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 252, Batch 3/4: Zeroing gradients...
  Epoch 252, Batch 3/4: Forward pass...
  Epoch 252, Batch 3/4: Calculating loss...
  Epoch 252, Batch 3/4: Backward pass...
  Epoch 252, Batch 3/4: Clipping gradients...
  Epoch 252, Batch 3/4: Optimizer step...
  Epoch 252, Batch 3/4: Completed in 0.19s
  Epoch 252, Batch 4/4: Loading data to device...
  Epoch 252, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 252, Batch 4/4: Zeroing gradients...
  Epoch 252, Batch 4/4: Forward pass...
  Epoch 252, Batch 4/4: Calculating loss...
  Epoch 252, Batch 4/4: Backward pass...
  Epoch 252, Batch 4/4: Clipping gradients...
  Epoch 252, Batch 4/4: Optimizer step...
  Epoch 252, Batch 4/4: Completed in 0.03s
Epoch 252: Training phase completed. Average Train Loss: 0.3424
Epoch 252: Starting validation phase...
  Epoch 252, Val Batch 1/1: Loading data...
  Epoch 252, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 252, Val Batch 1/1: Forward pass...
  Epoch 252, Val Batch 1/1: Calculating loss...
Epoch 252: Validation phase completed. Average Val Loss: 0.3020
Epoch 252 Summary ---> Train Loss: 0.3424 / Validation Loss: 0.3020
Epoch 252: Checking early stopping... (Current Best Loss: 0.2967, Epochs No Improve: 1)
  Epoch 252: Validation loss did not improve. Epochs without improvement: 2
Epoch 252: Stepping scheduler...
--- Epoch 252 completed in 0.68 seconds ---

--- Starting Epoch 253/1000 ---
Epoch 253: Starting training phase (4 batches)
  Epoch 253, Batch 1/4: Loading data to device...
  Epoch 253, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 253, Batch 1/4: Zeroing gradients...
  Epoch 253, Batch 1/4: Forward pass...
  Epoch 253, Batch 1/4: Calculating loss...
  Epoch 253, Batch 1/4: Backward pass...
  Epoch 253, Batch 1/4: Clipping gradients...
  Epoch 253, Batch 1/4: Optimizer step...
  Epoch 253, Batch 1/4: Completed in 0.20s
  Epoch 253, Batch 2/4: Loading data to device...
  Epoch 253, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 253, Batch 2/4: Zeroing gradients...
  Epoch 253, Batch 2/4: Forward pass...
  Epoch 253, Batch 2/4: Calculating loss...
  Epoch 253, Batch 2/4: Backward pass...
  Epoch 253, Batch 2/4: Clipping gradients...
  Epoch 253, Batch 2/4: Optimizer step...
  Epoch 253, Batch 2/4: Completed in 0.20s
  Epoch 253, Batch 3/4: Loading data to device...
  Epoch 253, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 253, Batch 3/4: Zeroing gradients...
  Epoch 253, Batch 3/4: Forward pass...
  Epoch 253, Batch 3/4: Calculating loss...
  Epoch 253, Batch 3/4: Backward pass...
  Epoch 253, Batch 3/4: Clipping gradients...
  Epoch 253, Batch 3/4: Optimizer step...
  Epoch 253, Batch 3/4: Completed in 0.20s
  Epoch 253, Batch 4/4: Loading data to device...
  Epoch 253, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 253, Batch 4/4: Zeroing gradients...
  Epoch 253, Batch 4/4: Forward pass...
  Epoch 253, Batch 4/4: Calculating loss...
  Epoch 253, Batch 4/4: Backward pass...
  Epoch 253, Batch 4/4: Clipping gradients...
  Epoch 253, Batch 4/4: Optimizer step...
  Epoch 253, Batch 4/4: Completed in 0.03s
Epoch 253: Training phase completed. Average Train Loss: 0.3421
Epoch 253: Starting validation phase...
  Epoch 253, Val Batch 1/1: Loading data...
  Epoch 253, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 253, Val Batch 1/1: Forward pass...
  Epoch 253, Val Batch 1/1: Calculating loss...
Epoch 253: Validation phase completed. Average Val Loss: 0.3011
Epoch 253 Summary ---> Train Loss: 0.3421 / Validation Loss: 0.3011
Epoch 253: Checking early stopping... (Current Best Loss: 0.2967, Epochs No Improve: 2)
  Epoch 253: Validation loss did not improve. Epochs without improvement: 3
Epoch 253: Stepping scheduler...
--- Epoch 253 completed in 0.69 seconds ---

--- Starting Epoch 254/1000 ---
Epoch 254: Starting training phase (4 batches)
  Epoch 254, Batch 1/4: Loading data to device...
  Epoch 254, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 254, Batch 1/4: Zeroing gradients...
  Epoch 254, Batch 1/4: Forward pass...
  Epoch 254, Batch 1/4: Calculating loss...
  Epoch 254, Batch 1/4: Backward pass...
  Epoch 254, Batch 1/4: Clipping gradients...
  Epoch 254, Batch 1/4: Optimizer step...
  Epoch 254, Batch 1/4: Completed in 0.19s
  Epoch 254, Batch 2/4: Loading data to device...
  Epoch 254, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 254, Batch 2/4: Zeroing gradients...
  Epoch 254, Batch 2/4: Forward pass...
  Epoch 254, Batch 2/4: Calculating loss...
  Epoch 254, Batch 2/4: Backward pass...
  Epoch 254, Batch 2/4: Clipping gradients...
  Epoch 254, Batch 2/4: Optimizer step...
  Epoch 254, Batch 2/4: Completed in 0.19s
  Epoch 254, Batch 3/4: Loading data to device...
  Epoch 254, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 254, Batch 3/4: Zeroing gradients...
  Epoch 254, Batch 3/4: Forward pass...
  Epoch 254, Batch 3/4: Calculating loss...
  Epoch 254, Batch 3/4: Backward pass...
  Epoch 254, Batch 3/4: Clipping gradients...
  Epoch 254, Batch 3/4: Optimizer step...
  Epoch 254, Batch 3/4: Completed in 0.19s
  Epoch 254, Batch 4/4: Loading data to device...
  Epoch 254, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 254, Batch 4/4: Zeroing gradients...
  Epoch 254, Batch 4/4: Forward pass...
  Epoch 254, Batch 4/4: Calculating loss...
  Epoch 254, Batch 4/4: Backward pass...
  Epoch 254, Batch 4/4: Clipping gradients...
  Epoch 254, Batch 4/4: Optimizer step...
  Epoch 254, Batch 4/4: Completed in 0.03s
Epoch 254: Training phase completed. Average Train Loss: 0.3761
Epoch 254: Starting validation phase...
  Epoch 254, Val Batch 1/1: Loading data...
  Epoch 254, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 254, Val Batch 1/1: Forward pass...
  Epoch 254, Val Batch 1/1: Calculating loss...
Epoch 254: Validation phase completed. Average Val Loss: 0.2955
Epoch 254 Summary ---> Train Loss: 0.3761 / Validation Loss: 0.2955
Epoch 254: Checking early stopping... (Current Best Loss: 0.2967, Epochs No Improve: 3)
  Epoch 254: Validation loss improved (0.2967 --> 0.2955). Saving model.
Epoch 254: Stepping scheduler...
--- Epoch 254 completed in 0.67 seconds ---

--- Starting Epoch 255/1000 ---
Epoch 255: Starting training phase (4 batches)
  Epoch 255, Batch 1/4: Loading data to device...
  Epoch 255, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 255, Batch 1/4: Zeroing gradients...
  Epoch 255, Batch 1/4: Forward pass...
  Epoch 255, Batch 1/4: Calculating loss...
  Epoch 255, Batch 1/4: Backward pass...
  Epoch 255, Batch 1/4: Clipping gradients...
  Epoch 255, Batch 1/4: Optimizer step...
  Epoch 255, Batch 1/4: Completed in 0.19s
  Epoch 255, Batch 2/4: Loading data to device...
  Epoch 255, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 255, Batch 2/4: Zeroing gradients...
  Epoch 255, Batch 2/4: Forward pass...
  Epoch 255, Batch 2/4: Calculating loss...
  Epoch 255, Batch 2/4: Backward pass...
  Epoch 255, Batch 2/4: Clipping gradients...
  Epoch 255, Batch 2/4: Optimizer step...
  Epoch 255, Batch 2/4: Completed in 0.19s
  Epoch 255, Batch 3/4: Loading data to device...
  Epoch 255, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 255, Batch 3/4: Zeroing gradients...
  Epoch 255, Batch 3/4: Forward pass...
  Epoch 255, Batch 3/4: Calculating loss...
  Epoch 255, Batch 3/4: Backward pass...
  Epoch 255, Batch 3/4: Clipping gradients...
  Epoch 255, Batch 3/4: Optimizer step...
  Epoch 255, Batch 3/4: Completed in 0.19s
  Epoch 255, Batch 4/4: Loading data to device...
  Epoch 255, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 255, Batch 4/4: Zeroing gradients...
  Epoch 255, Batch 4/4: Forward pass...
  Epoch 255, Batch 4/4: Calculating loss...
  Epoch 255, Batch 4/4: Backward pass...
  Epoch 255, Batch 4/4: Clipping gradients...
  Epoch 255, Batch 4/4: Optimizer step...
  Epoch 255, Batch 4/4: Completed in 0.04s
Epoch 255: Training phase completed. Average Train Loss: 0.3540
Epoch 255: Starting validation phase...
  Epoch 255, Val Batch 1/1: Loading data...
  Epoch 255, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 255, Val Batch 1/1: Forward pass...
  Epoch 255, Val Batch 1/1: Calculating loss...
Epoch 255: Validation phase completed. Average Val Loss: 0.2964
Epoch 255 Summary ---> Train Loss: 0.3540 / Validation Loss: 0.2964
Epoch 255: Checking early stopping... (Current Best Loss: 0.2955, Epochs No Improve: 0)
  Epoch 255: Validation loss did not improve. Epochs without improvement: 1
Epoch 255: Stepping scheduler...
--- Epoch 255 completed in 0.68 seconds ---

--- Starting Epoch 256/1000 ---
Epoch 256: Starting training phase (4 batches)
  Epoch 256, Batch 1/4: Loading data to device...
  Epoch 256, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 256, Batch 1/4: Zeroing gradients...
  Epoch 256, Batch 1/4: Forward pass...
  Epoch 256, Batch 1/4: Calculating loss...
  Epoch 256, Batch 1/4: Backward pass...
  Epoch 256, Batch 1/4: Clipping gradients...
  Epoch 256, Batch 1/4: Optimizer step...
  Epoch 256, Batch 1/4: Completed in 0.20s
  Epoch 256, Batch 2/4: Loading data to device...
  Epoch 256, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 256, Batch 2/4: Zeroing gradients...
  Epoch 256, Batch 2/4: Forward pass...
  Epoch 256, Batch 2/4: Calculating loss...
  Epoch 256, Batch 2/4: Backward pass...
  Epoch 256, Batch 2/4: Clipping gradients...
  Epoch 256, Batch 2/4: Optimizer step...
  Epoch 256, Batch 2/4: Completed in 0.19s
  Epoch 256, Batch 3/4: Loading data to device...
  Epoch 256, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 256, Batch 3/4: Zeroing gradients...
  Epoch 256, Batch 3/4: Forward pass...
  Epoch 256, Batch 3/4: Calculating loss...
  Epoch 256, Batch 3/4: Backward pass...
  Epoch 256, Batch 3/4: Clipping gradients...
  Epoch 256, Batch 3/4: Optimizer step...
  Epoch 256, Batch 3/4: Completed in 0.19s
  Epoch 256, Batch 4/4: Loading data to device...
  Epoch 256, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 256, Batch 4/4: Zeroing gradients...
  Epoch 256, Batch 4/4: Forward pass...
  Epoch 256, Batch 4/4: Calculating loss...
  Epoch 256, Batch 4/4: Backward pass...
  Epoch 256, Batch 4/4: Clipping gradients...
  Epoch 256, Batch 4/4: Optimizer step...
  Epoch 256, Batch 4/4: Completed in 0.03s
Epoch 256: Training phase completed. Average Train Loss: 0.4250
Epoch 256: Starting validation phase...
  Epoch 256, Val Batch 1/1: Loading data...
  Epoch 256, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 256, Val Batch 1/1: Forward pass...
  Epoch 256, Val Batch 1/1: Calculating loss...
Epoch 256: Validation phase completed. Average Val Loss: 0.3011
Epoch 256 Summary ---> Train Loss: 0.4250 / Validation Loss: 0.3011
Epoch 256: Checking early stopping... (Current Best Loss: 0.2955, Epochs No Improve: 1)
  Epoch 256: Validation loss did not improve. Epochs without improvement: 2
Epoch 256: Stepping scheduler...
--- Epoch 256 completed in 0.68 seconds ---

--- Starting Epoch 257/1000 ---
Epoch 257: Starting training phase (4 batches)
  Epoch 257, Batch 1/4: Loading data to device...
  Epoch 257, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 257, Batch 1/4: Zeroing gradients...
  Epoch 257, Batch 1/4: Forward pass...
  Epoch 257, Batch 1/4: Calculating loss...
  Epoch 257, Batch 1/4: Backward pass...
  Epoch 257, Batch 1/4: Clipping gradients...
  Epoch 257, Batch 1/4: Optimizer step...
  Epoch 257, Batch 1/4: Completed in 0.19s
  Epoch 257, Batch 2/4: Loading data to device...
  Epoch 257, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 257, Batch 2/4: Zeroing gradients...
  Epoch 257, Batch 2/4: Forward pass...
  Epoch 257, Batch 2/4: Calculating loss...
  Epoch 257, Batch 2/4: Backward pass...
  Epoch 257, Batch 2/4: Clipping gradients...
  Epoch 257, Batch 2/4: Optimizer step...
  Epoch 257, Batch 2/4: Completed in 0.20s
  Epoch 257, Batch 3/4: Loading data to device...
  Epoch 257, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 257, Batch 3/4: Zeroing gradients...
  Epoch 257, Batch 3/4: Forward pass...
  Epoch 257, Batch 3/4: Calculating loss...
  Epoch 257, Batch 3/4: Backward pass...
  Epoch 257, Batch 3/4: Clipping gradients...
  Epoch 257, Batch 3/4: Optimizer step...
  Epoch 257, Batch 3/4: Completed in 0.19s
  Epoch 257, Batch 4/4: Loading data to device...
  Epoch 257, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 257, Batch 4/4: Zeroing gradients...
  Epoch 257, Batch 4/4: Forward pass...
  Epoch 257, Batch 4/4: Calculating loss...
  Epoch 257, Batch 4/4: Backward pass...
  Epoch 257, Batch 4/4: Clipping gradients...
  Epoch 257, Batch 4/4: Optimizer step...
  Epoch 257, Batch 4/4: Completed in 0.03s
Epoch 257: Training phase completed. Average Train Loss: 0.3413
Epoch 257: Starting validation phase...
  Epoch 257, Val Batch 1/1: Loading data...
  Epoch 257, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 257, Val Batch 1/1: Forward pass...
  Epoch 257, Val Batch 1/1: Calculating loss...
Epoch 257: Validation phase completed. Average Val Loss: 0.3012
Epoch 257 Summary ---> Train Loss: 0.3413 / Validation Loss: 0.3012
Epoch 257: Checking early stopping... (Current Best Loss: 0.2955, Epochs No Improve: 2)
  Epoch 257: Validation loss did not improve. Epochs without improvement: 3
Epoch 257: Stepping scheduler...
--- Epoch 257 completed in 0.68 seconds ---

--- Starting Epoch 258/1000 ---
Epoch 258: Starting training phase (4 batches)
  Epoch 258, Batch 1/4: Loading data to device...
  Epoch 258, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 258, Batch 1/4: Zeroing gradients...
  Epoch 258, Batch 1/4: Forward pass...
  Epoch 258, Batch 1/4: Calculating loss...
  Epoch 258, Batch 1/4: Backward pass...
  Epoch 258, Batch 1/4: Clipping gradients...
  Epoch 258, Batch 1/4: Optimizer step...
  Epoch 258, Batch 1/4: Completed in 0.19s
  Epoch 258, Batch 2/4: Loading data to device...
  Epoch 258, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 258, Batch 2/4: Zeroing gradients...
  Epoch 258, Batch 2/4: Forward pass...
  Epoch 258, Batch 2/4: Calculating loss...
  Epoch 258, Batch 2/4: Backward pass...
  Epoch 258, Batch 2/4: Clipping gradients...
  Epoch 258, Batch 2/4: Optimizer step...
  Epoch 258, Batch 2/4: Completed in 0.20s
  Epoch 258, Batch 3/4: Loading data to device...
  Epoch 258, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 258, Batch 3/4: Zeroing gradients...
  Epoch 258, Batch 3/4: Forward pass...
  Epoch 258, Batch 3/4: Calculating loss...
  Epoch 258, Batch 3/4: Backward pass...
  Epoch 258, Batch 3/4: Clipping gradients...
  Epoch 258, Batch 3/4: Optimizer step...
  Epoch 258, Batch 3/4: Completed in 0.19s
  Epoch 258, Batch 4/4: Loading data to device...
  Epoch 258, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 258, Batch 4/4: Zeroing gradients...
  Epoch 258, Batch 4/4: Forward pass...
  Epoch 258, Batch 4/4: Calculating loss...
  Epoch 258, Batch 4/4: Backward pass...
  Epoch 258, Batch 4/4: Clipping gradients...
  Epoch 258, Batch 4/4: Optimizer step...
  Epoch 258, Batch 4/4: Completed in 0.04s
Epoch 258: Training phase completed. Average Train Loss: 0.3396
Epoch 258: Starting validation phase...
  Epoch 258, Val Batch 1/1: Loading data...
  Epoch 258, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 258, Val Batch 1/1: Forward pass...
  Epoch 258, Val Batch 1/1: Calculating loss...
Epoch 258: Validation phase completed. Average Val Loss: 0.3009
Epoch 258 Summary ---> Train Loss: 0.3396 / Validation Loss: 0.3009
Epoch 258: Checking early stopping... (Current Best Loss: 0.2955, Epochs No Improve: 3)
  Epoch 258: Validation loss did not improve. Epochs without improvement: 4
Epoch 258: Stepping scheduler...
--- Epoch 258 completed in 0.69 seconds ---

--- Starting Epoch 259/1000 ---
Epoch 259: Starting training phase (4 batches)
  Epoch 259, Batch 1/4: Loading data to device...
  Epoch 259, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 259, Batch 1/4: Zeroing gradients...
  Epoch 259, Batch 1/4: Forward pass...
  Epoch 259, Batch 1/4: Calculating loss...
  Epoch 259, Batch 1/4: Backward pass...
  Epoch 259, Batch 1/4: Clipping gradients...
  Epoch 259, Batch 1/4: Optimizer step...
  Epoch 259, Batch 1/4: Completed in 0.19s
  Epoch 259, Batch 2/4: Loading data to device...
  Epoch 259, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 259, Batch 2/4: Zeroing gradients...
  Epoch 259, Batch 2/4: Forward pass...
  Epoch 259, Batch 2/4: Calculating loss...
  Epoch 259, Batch 2/4: Backward pass...
  Epoch 259, Batch 2/4: Clipping gradients...
  Epoch 259, Batch 2/4: Optimizer step...
  Epoch 259, Batch 2/4: Completed in 0.19s
  Epoch 259, Batch 3/4: Loading data to device...
  Epoch 259, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 259, Batch 3/4: Zeroing gradients...
  Epoch 259, Batch 3/4: Forward pass...
  Epoch 259, Batch 3/4: Calculating loss...
  Epoch 259, Batch 3/4: Backward pass...
  Epoch 259, Batch 3/4: Clipping gradients...
  Epoch 259, Batch 3/4: Optimizer step...
  Epoch 259, Batch 3/4: Completed in 0.19s
  Epoch 259, Batch 4/4: Loading data to device...
  Epoch 259, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 259, Batch 4/4: Zeroing gradients...
  Epoch 259, Batch 4/4: Forward pass...
  Epoch 259, Batch 4/4: Calculating loss...
  Epoch 259, Batch 4/4: Backward pass...
  Epoch 259, Batch 4/4: Clipping gradients...
  Epoch 259, Batch 4/4: Optimizer step...
  Epoch 259, Batch 4/4: Completed in 0.03s
Epoch 259: Training phase completed. Average Train Loss: 0.3499
Epoch 259: Starting validation phase...
  Epoch 259, Val Batch 1/1: Loading data...
  Epoch 259, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 259, Val Batch 1/1: Forward pass...
  Epoch 259, Val Batch 1/1: Calculating loss...
Epoch 259: Validation phase completed. Average Val Loss: 0.3024
Epoch 259 Summary ---> Train Loss: 0.3499 / Validation Loss: 0.3024
Epoch 259: Checking early stopping... (Current Best Loss: 0.2955, Epochs No Improve: 4)
  Epoch 259: Validation loss did not improve. Epochs without improvement: 5
Epoch 259: Stepping scheduler...
--- Epoch 259 completed in 0.68 seconds ---

--- Starting Epoch 260/1000 ---
Epoch 260: Starting training phase (4 batches)
  Epoch 260, Batch 1/4: Loading data to device...
  Epoch 260, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 260, Batch 1/4: Zeroing gradients...
  Epoch 260, Batch 1/4: Forward pass...
  Epoch 260, Batch 1/4: Calculating loss...
  Epoch 260, Batch 1/4: Backward pass...
  Epoch 260, Batch 1/4: Clipping gradients...
  Epoch 260, Batch 1/4: Optimizer step...
  Epoch 260, Batch 1/4: Completed in 0.19s
  Epoch 260, Batch 2/4: Loading data to device...
  Epoch 260, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 260, Batch 2/4: Zeroing gradients...
  Epoch 260, Batch 2/4: Forward pass...
  Epoch 260, Batch 2/4: Calculating loss...
  Epoch 260, Batch 2/4: Backward pass...
  Epoch 260, Batch 2/4: Clipping gradients...
  Epoch 260, Batch 2/4: Optimizer step...
  Epoch 260, Batch 2/4: Completed in 0.19s
  Epoch 260, Batch 3/4: Loading data to device...
  Epoch 260, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 260, Batch 3/4: Zeroing gradients...
  Epoch 260, Batch 3/4: Forward pass...
  Epoch 260, Batch 3/4: Calculating loss...
  Epoch 260, Batch 3/4: Backward pass...
  Epoch 260, Batch 3/4: Clipping gradients...
  Epoch 260, Batch 3/4: Optimizer step...
  Epoch 260, Batch 3/4: Completed in 0.19s
  Epoch 260, Batch 4/4: Loading data to device...
  Epoch 260, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 260, Batch 4/4: Zeroing gradients...
  Epoch 260, Batch 4/4: Forward pass...
  Epoch 260, Batch 4/4: Calculating loss...
  Epoch 260, Batch 4/4: Backward pass...
  Epoch 260, Batch 4/4: Clipping gradients...
  Epoch 260, Batch 4/4: Optimizer step...
  Epoch 260, Batch 4/4: Completed in 0.03s
Epoch 260: Training phase completed. Average Train Loss: 0.3160
Epoch 260: Starting validation phase...
  Epoch 260, Val Batch 1/1: Loading data...
  Epoch 260, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 260, Val Batch 1/1: Forward pass...
  Epoch 260, Val Batch 1/1: Calculating loss...
Epoch 260: Validation phase completed. Average Val Loss: 0.3050
Epoch 260 Summary ---> Train Loss: 0.3160 / Validation Loss: 0.3050
Epoch 260: Checking early stopping... (Current Best Loss: 0.2955, Epochs No Improve: 5)
  Epoch 260: Validation loss did not improve. Epochs without improvement: 6
Epoch 260: Stepping scheduler...
--- Epoch 260 completed in 0.68 seconds ---

--- Starting Epoch 261/1000 ---
Epoch 261: Starting training phase (4 batches)
  Epoch 261, Batch 1/4: Loading data to device...
  Epoch 261, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 261, Batch 1/4: Zeroing gradients...
  Epoch 261, Batch 1/4: Forward pass...
  Epoch 261, Batch 1/4: Calculating loss...
  Epoch 261, Batch 1/4: Backward pass...
  Epoch 261, Batch 1/4: Clipping gradients...
  Epoch 261, Batch 1/4: Optimizer step...
  Epoch 261, Batch 1/4: Completed in 0.20s
  Epoch 261, Batch 2/4: Loading data to device...
  Epoch 261, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 261, Batch 2/4: Zeroing gradients...
  Epoch 261, Batch 2/4: Forward pass...
  Epoch 261, Batch 2/4: Calculating loss...
  Epoch 261, Batch 2/4: Backward pass...
  Epoch 261, Batch 2/4: Clipping gradients...
  Epoch 261, Batch 2/4: Optimizer step...
  Epoch 261, Batch 2/4: Completed in 0.19s
  Epoch 261, Batch 3/4: Loading data to device...
  Epoch 261, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 261, Batch 3/4: Zeroing gradients...
  Epoch 261, Batch 3/4: Forward pass...
  Epoch 261, Batch 3/4: Calculating loss...
  Epoch 261, Batch 3/4: Backward pass...
  Epoch 261, Batch 3/4: Clipping gradients...
  Epoch 261, Batch 3/4: Optimizer step...
  Epoch 261, Batch 3/4: Completed in 0.19s
  Epoch 261, Batch 4/4: Loading data to device...
  Epoch 261, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 261, Batch 4/4: Zeroing gradients...
  Epoch 261, Batch 4/4: Forward pass...
  Epoch 261, Batch 4/4: Calculating loss...
  Epoch 261, Batch 4/4: Backward pass...
  Epoch 261, Batch 4/4: Clipping gradients...
  Epoch 261, Batch 4/4: Optimizer step...
  Epoch 261, Batch 4/4: Completed in 0.03s
Epoch 261: Training phase completed. Average Train Loss: 0.3326
Epoch 261: Starting validation phase...
  Epoch 261, Val Batch 1/1: Loading data...
  Epoch 261, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 261, Val Batch 1/1: Forward pass...
  Epoch 261, Val Batch 1/1: Calculating loss...
Epoch 261: Validation phase completed. Average Val Loss: 0.3047
Epoch 261 Summary ---> Train Loss: 0.3326 / Validation Loss: 0.3047
Epoch 261: Checking early stopping... (Current Best Loss: 0.2955, Epochs No Improve: 6)
  Epoch 261: Validation loss did not improve. Epochs without improvement: 7
Epoch 261: Stepping scheduler...
--- Epoch 261 completed in 0.68 seconds ---

--- Starting Epoch 262/1000 ---
Epoch 262: Starting training phase (4 batches)
  Epoch 262, Batch 1/4: Loading data to device...
  Epoch 262, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 262, Batch 1/4: Zeroing gradients...
  Epoch 262, Batch 1/4: Forward pass...
  Epoch 262, Batch 1/4: Calculating loss...
  Epoch 262, Batch 1/4: Backward pass...
  Epoch 262, Batch 1/4: Clipping gradients...
  Epoch 262, Batch 1/4: Optimizer step...
  Epoch 262, Batch 1/4: Completed in 0.20s
  Epoch 262, Batch 2/4: Loading data to device...
  Epoch 262, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 262, Batch 2/4: Zeroing gradients...
  Epoch 262, Batch 2/4: Forward pass...
  Epoch 262, Batch 2/4: Calculating loss...
  Epoch 262, Batch 2/4: Backward pass...
  Epoch 262, Batch 2/4: Clipping gradients...
  Epoch 262, Batch 2/4: Optimizer step...
  Epoch 262, Batch 2/4: Completed in 0.20s
  Epoch 262, Batch 3/4: Loading data to device...
  Epoch 262, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 262, Batch 3/4: Zeroing gradients...
  Epoch 262, Batch 3/4: Forward pass...
  Epoch 262, Batch 3/4: Calculating loss...
  Epoch 262, Batch 3/4: Backward pass...
  Epoch 262, Batch 3/4: Clipping gradients...
  Epoch 262, Batch 3/4: Optimizer step...
  Epoch 262, Batch 3/4: Completed in 0.20s
  Epoch 262, Batch 4/4: Loading data to device...
  Epoch 262, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 262, Batch 4/4: Zeroing gradients...
  Epoch 262, Batch 4/4: Forward pass...
  Epoch 262, Batch 4/4: Calculating loss...
  Epoch 262, Batch 4/4: Backward pass...
  Epoch 262, Batch 4/4: Clipping gradients...
  Epoch 262, Batch 4/4: Optimizer step...
  Epoch 262, Batch 4/4: Completed in 0.03s
Epoch 262: Training phase completed. Average Train Loss: 0.3212
Epoch 262: Starting validation phase...
  Epoch 262, Val Batch 1/1: Loading data...
  Epoch 262, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 262, Val Batch 1/1: Forward pass...
  Epoch 262, Val Batch 1/1: Calculating loss...
Epoch 262: Validation phase completed. Average Val Loss: 0.2995
Epoch 262 Summary ---> Train Loss: 0.3212 / Validation Loss: 0.2995
Epoch 262: Checking early stopping... (Current Best Loss: 0.2955, Epochs No Improve: 7)
  Epoch 262: Validation loss did not improve. Epochs without improvement: 8
Epoch 262: Stepping scheduler...
--- Epoch 262 completed in 0.69 seconds ---

--- Starting Epoch 263/1000 ---
Epoch 263: Starting training phase (4 batches)
  Epoch 263, Batch 1/4: Loading data to device...
  Epoch 263, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 263, Batch 1/4: Zeroing gradients...
  Epoch 263, Batch 1/4: Forward pass...
  Epoch 263, Batch 1/4: Calculating loss...
  Epoch 263, Batch 1/4: Backward pass...
  Epoch 263, Batch 1/4: Clipping gradients...
  Epoch 263, Batch 1/4: Optimizer step...
  Epoch 263, Batch 1/4: Completed in 0.19s
  Epoch 263, Batch 2/4: Loading data to device...
  Epoch 263, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 263, Batch 2/4: Zeroing gradients...
  Epoch 263, Batch 2/4: Forward pass...
  Epoch 263, Batch 2/4: Calculating loss...
  Epoch 263, Batch 2/4: Backward pass...
  Epoch 263, Batch 2/4: Clipping gradients...
  Epoch 263, Batch 2/4: Optimizer step...
  Epoch 263, Batch 2/4: Completed in 0.19s
  Epoch 263, Batch 3/4: Loading data to device...
  Epoch 263, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 263, Batch 3/4: Zeroing gradients...
  Epoch 263, Batch 3/4: Forward pass...
  Epoch 263, Batch 3/4: Calculating loss...
  Epoch 263, Batch 3/4: Backward pass...
  Epoch 263, Batch 3/4: Clipping gradients...
  Epoch 263, Batch 3/4: Optimizer step...
  Epoch 263, Batch 3/4: Completed in 0.19s
  Epoch 263, Batch 4/4: Loading data to device...
  Epoch 263, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 263, Batch 4/4: Zeroing gradients...
  Epoch 263, Batch 4/4: Forward pass...
  Epoch 263, Batch 4/4: Calculating loss...
  Epoch 263, Batch 4/4: Backward pass...
  Epoch 263, Batch 4/4: Clipping gradients...
  Epoch 263, Batch 4/4: Optimizer step...
  Epoch 263, Batch 4/4: Completed in 0.03s
Epoch 263: Training phase completed. Average Train Loss: 0.3492
Epoch 263: Starting validation phase...
  Epoch 263, Val Batch 1/1: Loading data...
  Epoch 263, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 263, Val Batch 1/1: Forward pass...
  Epoch 263, Val Batch 1/1: Calculating loss...
Epoch 263: Validation phase completed. Average Val Loss: 0.2993
Epoch 263 Summary ---> Train Loss: 0.3492 / Validation Loss: 0.2993
Epoch 263: Checking early stopping... (Current Best Loss: 0.2955, Epochs No Improve: 8)
  Epoch 263: Validation loss did not improve. Epochs without improvement: 9
Epoch 263: Stepping scheduler...
--- Epoch 263 completed in 0.68 seconds ---

--- Starting Epoch 264/1000 ---
Epoch 264: Starting training phase (4 batches)
  Epoch 264, Batch 1/4: Loading data to device...
  Epoch 264, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 264, Batch 1/4: Zeroing gradients...
  Epoch 264, Batch 1/4: Forward pass...
  Epoch 264, Batch 1/4: Calculating loss...
  Epoch 264, Batch 1/4: Backward pass...
  Epoch 264, Batch 1/4: Clipping gradients...
  Epoch 264, Batch 1/4: Optimizer step...
  Epoch 264, Batch 1/4: Completed in 0.19s
  Epoch 264, Batch 2/4: Loading data to device...
  Epoch 264, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 264, Batch 2/4: Zeroing gradients...
  Epoch 264, Batch 2/4: Forward pass...
  Epoch 264, Batch 2/4: Calculating loss...
  Epoch 264, Batch 2/4: Backward pass...
  Epoch 264, Batch 2/4: Clipping gradients...
  Epoch 264, Batch 2/4: Optimizer step...
  Epoch 264, Batch 2/4: Completed in 0.19s
  Epoch 264, Batch 3/4: Loading data to device...
  Epoch 264, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 264, Batch 3/4: Zeroing gradients...
  Epoch 264, Batch 3/4: Forward pass...
  Epoch 264, Batch 3/4: Calculating loss...
  Epoch 264, Batch 3/4: Backward pass...
  Epoch 264, Batch 3/4: Clipping gradients...
  Epoch 264, Batch 3/4: Optimizer step...
  Epoch 264, Batch 3/4: Completed in 0.19s
  Epoch 264, Batch 4/4: Loading data to device...
  Epoch 264, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 264, Batch 4/4: Zeroing gradients...
  Epoch 264, Batch 4/4: Forward pass...
  Epoch 264, Batch 4/4: Calculating loss...
  Epoch 264, Batch 4/4: Backward pass...
  Epoch 264, Batch 4/4: Clipping gradients...
  Epoch 264, Batch 4/4: Optimizer step...
  Epoch 264, Batch 4/4: Completed in 0.03s
Epoch 264: Training phase completed. Average Train Loss: 0.3605
Epoch 264: Starting validation phase...
  Epoch 264, Val Batch 1/1: Loading data...
  Epoch 264, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 264, Val Batch 1/1: Forward pass...
  Epoch 264, Val Batch 1/1: Calculating loss...
Epoch 264: Validation phase completed. Average Val Loss: 0.2947
Epoch 264 Summary ---> Train Loss: 0.3605 / Validation Loss: 0.2947
Epoch 264: Checking early stopping... (Current Best Loss: 0.2955, Epochs No Improve: 9)
  Epoch 264: Validation loss improved (0.2955 --> 0.2947). Saving model.
Epoch 264: Stepping scheduler...
--- Epoch 264 completed in 0.68 seconds ---

--- Starting Epoch 265/1000 ---
Epoch 265: Starting training phase (4 batches)
  Epoch 265, Batch 1/4: Loading data to device...
  Epoch 265, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 265, Batch 1/4: Zeroing gradients...
  Epoch 265, Batch 1/4: Forward pass...
  Epoch 265, Batch 1/4: Calculating loss...
  Epoch 265, Batch 1/4: Backward pass...
  Epoch 265, Batch 1/4: Clipping gradients...
  Epoch 265, Batch 1/4: Optimizer step...
  Epoch 265, Batch 1/4: Completed in 0.19s
  Epoch 265, Batch 2/4: Loading data to device...
  Epoch 265, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 265, Batch 2/4: Zeroing gradients...
  Epoch 265, Batch 2/4: Forward pass...
  Epoch 265, Batch 2/4: Calculating loss...
  Epoch 265, Batch 2/4: Backward pass...
  Epoch 265, Batch 2/4: Clipping gradients...
  Epoch 265, Batch 2/4: Optimizer step...
  Epoch 265, Batch 2/4: Completed in 0.19s
  Epoch 265, Batch 3/4: Loading data to device...
  Epoch 265, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 265, Batch 3/4: Zeroing gradients...
  Epoch 265, Batch 3/4: Forward pass...
  Epoch 265, Batch 3/4: Calculating loss...
  Epoch 265, Batch 3/4: Backward pass...
  Epoch 265, Batch 3/4: Clipping gradients...
  Epoch 265, Batch 3/4: Optimizer step...
  Epoch 265, Batch 3/4: Completed in 0.19s
  Epoch 265, Batch 4/4: Loading data to device...
  Epoch 265, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 265, Batch 4/4: Zeroing gradients...
  Epoch 265, Batch 4/4: Forward pass...
  Epoch 265, Batch 4/4: Calculating loss...
  Epoch 265, Batch 4/4: Backward pass...
  Epoch 265, Batch 4/4: Clipping gradients...
  Epoch 265, Batch 4/4: Optimizer step...
  Epoch 265, Batch 4/4: Completed in 0.03s
Epoch 265: Training phase completed. Average Train Loss: 0.3565
Epoch 265: Starting validation phase...
  Epoch 265, Val Batch 1/1: Loading data...
  Epoch 265, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 265, Val Batch 1/1: Forward pass...
  Epoch 265, Val Batch 1/1: Calculating loss...
Epoch 265: Validation phase completed. Average Val Loss: 0.2931
Epoch 265 Summary ---> Train Loss: 0.3565 / Validation Loss: 0.2931
Epoch 265: Checking early stopping... (Current Best Loss: 0.2947, Epochs No Improve: 0)
  Epoch 265: Validation loss improved (0.2947 --> 0.2931). Saving model.
Epoch 265: Stepping scheduler...
--- Epoch 265 completed in 0.68 seconds ---

--- Starting Epoch 266/1000 ---
Epoch 266: Starting training phase (4 batches)
  Epoch 266, Batch 1/4: Loading data to device...
  Epoch 266, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 266, Batch 1/4: Zeroing gradients...
  Epoch 266, Batch 1/4: Forward pass...
  Epoch 266, Batch 1/4: Calculating loss...
  Epoch 266, Batch 1/4: Backward pass...
  Epoch 266, Batch 1/4: Clipping gradients...
  Epoch 266, Batch 1/4: Optimizer step...
  Epoch 266, Batch 1/4: Completed in 0.19s
  Epoch 266, Batch 2/4: Loading data to device...
  Epoch 266, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 266, Batch 2/4: Zeroing gradients...
  Epoch 266, Batch 2/4: Forward pass...
  Epoch 266, Batch 2/4: Calculating loss...
  Epoch 266, Batch 2/4: Backward pass...
  Epoch 266, Batch 2/4: Clipping gradients...
  Epoch 266, Batch 2/4: Optimizer step...
  Epoch 266, Batch 2/4: Completed in 0.20s
  Epoch 266, Batch 3/4: Loading data to device...
  Epoch 266, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 266, Batch 3/4: Zeroing gradients...
  Epoch 266, Batch 3/4: Forward pass...
  Epoch 266, Batch 3/4: Calculating loss...
  Epoch 266, Batch 3/4: Backward pass...
  Epoch 266, Batch 3/4: Clipping gradients...
  Epoch 266, Batch 3/4: Optimizer step...
  Epoch 266, Batch 3/4: Completed in 0.19s
  Epoch 266, Batch 4/4: Loading data to device...
  Epoch 266, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 266, Batch 4/4: Zeroing gradients...
  Epoch 266, Batch 4/4: Forward pass...
  Epoch 266, Batch 4/4: Calculating loss...
  Epoch 266, Batch 4/4: Backward pass...
  Epoch 266, Batch 4/4: Clipping gradients...
  Epoch 266, Batch 4/4: Optimizer step...
  Epoch 266, Batch 4/4: Completed in 0.03s
Epoch 266: Training phase completed. Average Train Loss: 0.3878
Epoch 266: Starting validation phase...
  Epoch 266, Val Batch 1/1: Loading data...
  Epoch 266, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 266, Val Batch 1/1: Forward pass...
  Epoch 266, Val Batch 1/1: Calculating loss...
Epoch 266: Validation phase completed. Average Val Loss: 0.2920
Epoch 266 Summary ---> Train Loss: 0.3878 / Validation Loss: 0.2920
Epoch 266: Checking early stopping... (Current Best Loss: 0.2931, Epochs No Improve: 0)
  Epoch 266: Validation loss improved (0.2931 --> 0.2920). Saving model.
Epoch 266: Stepping scheduler...
--- Epoch 266 completed in 0.68 seconds ---

--- Starting Epoch 267/1000 ---
Epoch 267: Starting training phase (4 batches)
  Epoch 267, Batch 1/4: Loading data to device...
  Epoch 267, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 267, Batch 1/4: Zeroing gradients...
  Epoch 267, Batch 1/4: Forward pass...
  Epoch 267, Batch 1/4: Calculating loss...
  Epoch 267, Batch 1/4: Backward pass...
  Epoch 267, Batch 1/4: Clipping gradients...
  Epoch 267, Batch 1/4: Optimizer step...
  Epoch 267, Batch 1/4: Completed in 0.19s
  Epoch 267, Batch 2/4: Loading data to device...
  Epoch 267, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 267, Batch 2/4: Zeroing gradients...
  Epoch 267, Batch 2/4: Forward pass...
  Epoch 267, Batch 2/4: Calculating loss...
  Epoch 267, Batch 2/4: Backward pass...
  Epoch 267, Batch 2/4: Clipping gradients...
  Epoch 267, Batch 2/4: Optimizer step...
  Epoch 267, Batch 2/4: Completed in 0.19s
  Epoch 267, Batch 3/4: Loading data to device...
  Epoch 267, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 267, Batch 3/4: Zeroing gradients...
  Epoch 267, Batch 3/4: Forward pass...
  Epoch 267, Batch 3/4: Calculating loss...
  Epoch 267, Batch 3/4: Backward pass...
  Epoch 267, Batch 3/4: Clipping gradients...
  Epoch 267, Batch 3/4: Optimizer step...
  Epoch 267, Batch 3/4: Completed in 0.20s
  Epoch 267, Batch 4/4: Loading data to device...
  Epoch 267, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 267, Batch 4/4: Zeroing gradients...
  Epoch 267, Batch 4/4: Forward pass...
  Epoch 267, Batch 4/4: Calculating loss...
  Epoch 267, Batch 4/4: Backward pass...
  Epoch 267, Batch 4/4: Clipping gradients...
  Epoch 267, Batch 4/4: Optimizer step...
  Epoch 267, Batch 4/4: Completed in 0.03s
Epoch 267: Training phase completed. Average Train Loss: 0.3819
Epoch 267: Starting validation phase...
  Epoch 267, Val Batch 1/1: Loading data...
  Epoch 267, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 267, Val Batch 1/1: Forward pass...
  Epoch 267, Val Batch 1/1: Calculating loss...
Epoch 267: Validation phase completed. Average Val Loss: 0.2915
Epoch 267 Summary ---> Train Loss: 0.3819 / Validation Loss: 0.2915
Epoch 267: Checking early stopping... (Current Best Loss: 0.2920, Epochs No Improve: 0)
  Epoch 267: Validation loss improved (0.2920 --> 0.2915). Saving model.
Epoch 267: Stepping scheduler...
--- Epoch 267 completed in 0.67 seconds ---

--- Starting Epoch 268/1000 ---
Epoch 268: Starting training phase (4 batches)
  Epoch 268, Batch 1/4: Loading data to device...
  Epoch 268, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 268, Batch 1/4: Zeroing gradients...
  Epoch 268, Batch 1/4: Forward pass...
  Epoch 268, Batch 1/4: Calculating loss...
  Epoch 268, Batch 1/4: Backward pass...
  Epoch 268, Batch 1/4: Clipping gradients...
  Epoch 268, Batch 1/4: Optimizer step...
  Epoch 268, Batch 1/4: Completed in 0.20s
  Epoch 268, Batch 2/4: Loading data to device...
  Epoch 268, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 268, Batch 2/4: Zeroing gradients...
  Epoch 268, Batch 2/4: Forward pass...
  Epoch 268, Batch 2/4: Calculating loss...
  Epoch 268, Batch 2/4: Backward pass...
  Epoch 268, Batch 2/4: Clipping gradients...
  Epoch 268, Batch 2/4: Optimizer step...
  Epoch 268, Batch 2/4: Completed in 0.19s
  Epoch 268, Batch 3/4: Loading data to device...
  Epoch 268, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 268, Batch 3/4: Zeroing gradients...
  Epoch 268, Batch 3/4: Forward pass...
  Epoch 268, Batch 3/4: Calculating loss...
  Epoch 268, Batch 3/4: Backward pass...
  Epoch 268, Batch 3/4: Clipping gradients...
  Epoch 268, Batch 3/4: Optimizer step...
  Epoch 268, Batch 3/4: Completed in 0.20s
  Epoch 268, Batch 4/4: Loading data to device...
  Epoch 268, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 268, Batch 4/4: Zeroing gradients...
  Epoch 268, Batch 4/4: Forward pass...
  Epoch 268, Batch 4/4: Calculating loss...
  Epoch 268, Batch 4/4: Backward pass...
  Epoch 268, Batch 4/4: Clipping gradients...
  Epoch 268, Batch 4/4: Optimizer step...
  Epoch 268, Batch 4/4: Completed in 0.03s
Epoch 268: Training phase completed. Average Train Loss: 0.3361
Epoch 268: Starting validation phase...
  Epoch 268, Val Batch 1/1: Loading data...
  Epoch 268, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 268, Val Batch 1/1: Forward pass...
  Epoch 268, Val Batch 1/1: Calculating loss...
Epoch 268: Validation phase completed. Average Val Loss: 0.2948
Epoch 268 Summary ---> Train Loss: 0.3361 / Validation Loss: 0.2948
Epoch 268: Checking early stopping... (Current Best Loss: 0.2915, Epochs No Improve: 0)
  Epoch 268: Validation loss did not improve. Epochs without improvement: 1
Epoch 268: Stepping scheduler...
--- Epoch 268 completed in 0.69 seconds ---

--- Starting Epoch 269/1000 ---
Epoch 269: Starting training phase (4 batches)
  Epoch 269, Batch 1/4: Loading data to device...
  Epoch 269, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 269, Batch 1/4: Zeroing gradients...
  Epoch 269, Batch 1/4: Forward pass...
  Epoch 269, Batch 1/4: Calculating loss...
  Epoch 269, Batch 1/4: Backward pass...
  Epoch 269, Batch 1/4: Clipping gradients...
  Epoch 269, Batch 1/4: Optimizer step...
  Epoch 269, Batch 1/4: Completed in 0.19s
  Epoch 269, Batch 2/4: Loading data to device...
  Epoch 269, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 269, Batch 2/4: Zeroing gradients...
  Epoch 269, Batch 2/4: Forward pass...
  Epoch 269, Batch 2/4: Calculating loss...
  Epoch 269, Batch 2/4: Backward pass...
  Epoch 269, Batch 2/4: Clipping gradients...
  Epoch 269, Batch 2/4: Optimizer step...
  Epoch 269, Batch 2/4: Completed in 0.19s
  Epoch 269, Batch 3/4: Loading data to device...
  Epoch 269, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 269, Batch 3/4: Zeroing gradients...
  Epoch 269, Batch 3/4: Forward pass...
  Epoch 269, Batch 3/4: Calculating loss...
  Epoch 269, Batch 3/4: Backward pass...
  Epoch 269, Batch 3/4: Clipping gradients...
  Epoch 269, Batch 3/4: Optimizer step...
  Epoch 269, Batch 3/4: Completed in 0.19s
  Epoch 269, Batch 4/4: Loading data to device...
  Epoch 269, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 269, Batch 4/4: Zeroing gradients...
  Epoch 269, Batch 4/4: Forward pass...
  Epoch 269, Batch 4/4: Calculating loss...
  Epoch 269, Batch 4/4: Backward pass...
  Epoch 269, Batch 4/4: Clipping gradients...
  Epoch 269, Batch 4/4: Optimizer step...
  Epoch 269, Batch 4/4: Completed in 0.03s
Epoch 269: Training phase completed. Average Train Loss: 0.3255
Epoch 269: Starting validation phase...
  Epoch 269, Val Batch 1/1: Loading data...
  Epoch 269, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 269, Val Batch 1/1: Forward pass...
  Epoch 269, Val Batch 1/1: Calculating loss...
Epoch 269: Validation phase completed. Average Val Loss: 0.2924
Epoch 269 Summary ---> Train Loss: 0.3255 / Validation Loss: 0.2924
Epoch 269: Checking early stopping... (Current Best Loss: 0.2915, Epochs No Improve: 1)
  Epoch 269: Validation loss did not improve. Epochs without improvement: 2
Epoch 269: Stepping scheduler...
--- Epoch 269 completed in 0.67 seconds ---

--- Starting Epoch 270/1000 ---
Epoch 270: Starting training phase (4 batches)
  Epoch 270, Batch 1/4: Loading data to device...
  Epoch 270, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 270, Batch 1/4: Zeroing gradients...
  Epoch 270, Batch 1/4: Forward pass...
  Epoch 270, Batch 1/4: Calculating loss...
  Epoch 270, Batch 1/4: Backward pass...
  Epoch 270, Batch 1/4: Clipping gradients...
  Epoch 270, Batch 1/4: Optimizer step...
  Epoch 270, Batch 1/4: Completed in 0.19s
  Epoch 270, Batch 2/4: Loading data to device...
  Epoch 270, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 270, Batch 2/4: Zeroing gradients...
  Epoch 270, Batch 2/4: Forward pass...
  Epoch 270, Batch 2/4: Calculating loss...
  Epoch 270, Batch 2/4: Backward pass...
  Epoch 270, Batch 2/4: Clipping gradients...
  Epoch 270, Batch 2/4: Optimizer step...
  Epoch 270, Batch 2/4: Completed in 0.19s
  Epoch 270, Batch 3/4: Loading data to device...
  Epoch 270, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 270, Batch 3/4: Zeroing gradients...
  Epoch 270, Batch 3/4: Forward pass...
  Epoch 270, Batch 3/4: Calculating loss...
  Epoch 270, Batch 3/4: Backward pass...
  Epoch 270, Batch 3/4: Clipping gradients...
  Epoch 270, Batch 3/4: Optimizer step...
  Epoch 270, Batch 3/4: Completed in 0.19s
  Epoch 270, Batch 4/4: Loading data to device...
  Epoch 270, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 270, Batch 4/4: Zeroing gradients...
  Epoch 270, Batch 4/4: Forward pass...
  Epoch 270, Batch 4/4: Calculating loss...
  Epoch 270, Batch 4/4: Backward pass...
  Epoch 270, Batch 4/4: Clipping gradients...
  Epoch 270, Batch 4/4: Optimizer step...
  Epoch 270, Batch 4/4: Completed in 0.03s
Epoch 270: Training phase completed. Average Train Loss: 0.3440
Epoch 270: Starting validation phase...
  Epoch 270, Val Batch 1/1: Loading data...
  Epoch 270, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 270, Val Batch 1/1: Forward pass...
  Epoch 270, Val Batch 1/1: Calculating loss...
Epoch 270: Validation phase completed. Average Val Loss: 0.2929
Epoch 270 Summary ---> Train Loss: 0.3440 / Validation Loss: 0.2929
Epoch 270: Checking early stopping... (Current Best Loss: 0.2915, Epochs No Improve: 2)
  Epoch 270: Validation loss did not improve. Epochs without improvement: 3
Epoch 270: Stepping scheduler...
--- Epoch 270 completed in 0.67 seconds ---

--- Starting Epoch 271/1000 ---
Epoch 271: Starting training phase (4 batches)
  Epoch 271, Batch 1/4: Loading data to device...
  Epoch 271, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 271, Batch 1/4: Zeroing gradients...
  Epoch 271, Batch 1/4: Forward pass...
  Epoch 271, Batch 1/4: Calculating loss...
  Epoch 271, Batch 1/4: Backward pass...
  Epoch 271, Batch 1/4: Clipping gradients...
  Epoch 271, Batch 1/4: Optimizer step...
  Epoch 271, Batch 1/4: Completed in 0.19s
  Epoch 271, Batch 2/4: Loading data to device...
  Epoch 271, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 271, Batch 2/4: Zeroing gradients...
  Epoch 271, Batch 2/4: Forward pass...
  Epoch 271, Batch 2/4: Calculating loss...
  Epoch 271, Batch 2/4: Backward pass...
  Epoch 271, Batch 2/4: Clipping gradients...
  Epoch 271, Batch 2/4: Optimizer step...
  Epoch 271, Batch 2/4: Completed in 0.19s
  Epoch 271, Batch 3/4: Loading data to device...
  Epoch 271, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 271, Batch 3/4: Zeroing gradients...
  Epoch 271, Batch 3/4: Forward pass...
  Epoch 271, Batch 3/4: Calculating loss...
  Epoch 271, Batch 3/4: Backward pass...
  Epoch 271, Batch 3/4: Clipping gradients...
  Epoch 271, Batch 3/4: Optimizer step...
  Epoch 271, Batch 3/4: Completed in 0.19s
  Epoch 271, Batch 4/4: Loading data to device...
  Epoch 271, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 271, Batch 4/4: Zeroing gradients...
  Epoch 271, Batch 4/4: Forward pass...
  Epoch 271, Batch 4/4: Calculating loss...
  Epoch 271, Batch 4/4: Backward pass...
  Epoch 271, Batch 4/4: Clipping gradients...
  Epoch 271, Batch 4/4: Optimizer step...
  Epoch 271, Batch 4/4: Completed in 0.03s
Epoch 271: Training phase completed. Average Train Loss: 0.3850
Epoch 271: Starting validation phase...
  Epoch 271, Val Batch 1/1: Loading data...
  Epoch 271, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 271, Val Batch 1/1: Forward pass...
  Epoch 271, Val Batch 1/1: Calculating loss...
Epoch 271: Validation phase completed. Average Val Loss: 0.2916
Epoch 271 Summary ---> Train Loss: 0.3850 / Validation Loss: 0.2916
Epoch 271: Checking early stopping... (Current Best Loss: 0.2915, Epochs No Improve: 3)
  Epoch 271: Validation loss did not improve. Epochs without improvement: 4
Epoch 271: Stepping scheduler...
--- Epoch 271 completed in 0.67 seconds ---

--- Starting Epoch 272/1000 ---
Epoch 272: Starting training phase (4 batches)
  Epoch 272, Batch 1/4: Loading data to device...
  Epoch 272, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 272, Batch 1/4: Zeroing gradients...
  Epoch 272, Batch 1/4: Forward pass...
  Epoch 272, Batch 1/4: Calculating loss...
  Epoch 272, Batch 1/4: Backward pass...
  Epoch 272, Batch 1/4: Clipping gradients...
  Epoch 272, Batch 1/4: Optimizer step...
  Epoch 272, Batch 1/4: Completed in 0.19s
  Epoch 272, Batch 2/4: Loading data to device...
  Epoch 272, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 272, Batch 2/4: Zeroing gradients...
  Epoch 272, Batch 2/4: Forward pass...
  Epoch 272, Batch 2/4: Calculating loss...
  Epoch 272, Batch 2/4: Backward pass...
  Epoch 272, Batch 2/4: Clipping gradients...
  Epoch 272, Batch 2/4: Optimizer step...
  Epoch 272, Batch 2/4: Completed in 0.19s
  Epoch 272, Batch 3/4: Loading data to device...
  Epoch 272, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 272, Batch 3/4: Zeroing gradients...
  Epoch 272, Batch 3/4: Forward pass...
  Epoch 272, Batch 3/4: Calculating loss...
  Epoch 272, Batch 3/4: Backward pass...
  Epoch 272, Batch 3/4: Clipping gradients...
  Epoch 272, Batch 3/4: Optimizer step...
  Epoch 272, Batch 3/4: Completed in 0.19s
  Epoch 272, Batch 4/4: Loading data to device...
  Epoch 272, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 272, Batch 4/4: Zeroing gradients...
  Epoch 272, Batch 4/4: Forward pass...
  Epoch 272, Batch 4/4: Calculating loss...
  Epoch 272, Batch 4/4: Backward pass...
  Epoch 272, Batch 4/4: Clipping gradients...
  Epoch 272, Batch 4/4: Optimizer step...
  Epoch 272, Batch 4/4: Completed in 0.03s
Epoch 272: Training phase completed. Average Train Loss: 0.4070
Epoch 272: Starting validation phase...
  Epoch 272, Val Batch 1/1: Loading data...
  Epoch 272, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 272, Val Batch 1/1: Forward pass...
  Epoch 272, Val Batch 1/1: Calculating loss...
Epoch 272: Validation phase completed. Average Val Loss: 0.2871
Epoch 272 Summary ---> Train Loss: 0.4070 / Validation Loss: 0.2871
Epoch 272: Checking early stopping... (Current Best Loss: 0.2915, Epochs No Improve: 4)
  Epoch 272: Validation loss improved (0.2915 --> 0.2871). Saving model.
Epoch 272: Stepping scheduler...
--- Epoch 272 completed in 0.68 seconds ---

--- Starting Epoch 273/1000 ---
Epoch 273: Starting training phase (4 batches)
  Epoch 273, Batch 1/4: Loading data to device...
  Epoch 273, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 273, Batch 1/4: Zeroing gradients...
  Epoch 273, Batch 1/4: Forward pass...
  Epoch 273, Batch 1/4: Calculating loss...
  Epoch 273, Batch 1/4: Backward pass...
  Epoch 273, Batch 1/4: Clipping gradients...
  Epoch 273, Batch 1/4: Optimizer step...
  Epoch 273, Batch 1/4: Completed in 0.19s
  Epoch 273, Batch 2/4: Loading data to device...
  Epoch 273, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 273, Batch 2/4: Zeroing gradients...
  Epoch 273, Batch 2/4: Forward pass...
  Epoch 273, Batch 2/4: Calculating loss...
  Epoch 273, Batch 2/4: Backward pass...
  Epoch 273, Batch 2/4: Clipping gradients...
  Epoch 273, Batch 2/4: Optimizer step...
  Epoch 273, Batch 2/4: Completed in 0.18s
  Epoch 273, Batch 3/4: Loading data to device...
  Epoch 273, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 273, Batch 3/4: Zeroing gradients...
  Epoch 273, Batch 3/4: Forward pass...
  Epoch 273, Batch 3/4: Calculating loss...
  Epoch 273, Batch 3/4: Backward pass...
  Epoch 273, Batch 3/4: Clipping gradients...
  Epoch 273, Batch 3/4: Optimizer step...
  Epoch 273, Batch 3/4: Completed in 0.19s
  Epoch 273, Batch 4/4: Loading data to device...
  Epoch 273, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 273, Batch 4/4: Zeroing gradients...
  Epoch 273, Batch 4/4: Forward pass...
  Epoch 273, Batch 4/4: Calculating loss...
  Epoch 273, Batch 4/4: Backward pass...
  Epoch 273, Batch 4/4: Clipping gradients...
  Epoch 273, Batch 4/4: Optimizer step...
  Epoch 273, Batch 4/4: Completed in 0.03s
Epoch 273: Training phase completed. Average Train Loss: 0.3822
Epoch 273: Starting validation phase...
  Epoch 273, Val Batch 1/1: Loading data...
  Epoch 273, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 273, Val Batch 1/1: Forward pass...
  Epoch 273, Val Batch 1/1: Calculating loss...
Epoch 273: Validation phase completed. Average Val Loss: 0.2889
Epoch 273 Summary ---> Train Loss: 0.3822 / Validation Loss: 0.2889
Epoch 273: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 0)
  Epoch 273: Validation loss did not improve. Epochs without improvement: 1
Epoch 273: Stepping scheduler...
--- Epoch 273 completed in 0.66 seconds ---

--- Starting Epoch 274/1000 ---
Epoch 274: Starting training phase (4 batches)
  Epoch 274, Batch 1/4: Loading data to device...
  Epoch 274, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 274, Batch 1/4: Zeroing gradients...
  Epoch 274, Batch 1/4: Forward pass...
  Epoch 274, Batch 1/4: Calculating loss...
  Epoch 274, Batch 1/4: Backward pass...
  Epoch 274, Batch 1/4: Clipping gradients...
  Epoch 274, Batch 1/4: Optimizer step...
  Epoch 274, Batch 1/4: Completed in 0.19s
  Epoch 274, Batch 2/4: Loading data to device...
  Epoch 274, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 274, Batch 2/4: Zeroing gradients...
  Epoch 274, Batch 2/4: Forward pass...
  Epoch 274, Batch 2/4: Calculating loss...
  Epoch 274, Batch 2/4: Backward pass...
  Epoch 274, Batch 2/4: Clipping gradients...
  Epoch 274, Batch 2/4: Optimizer step...
  Epoch 274, Batch 2/4: Completed in 0.19s
  Epoch 274, Batch 3/4: Loading data to device...
  Epoch 274, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 274, Batch 3/4: Zeroing gradients...
  Epoch 274, Batch 3/4: Forward pass...
  Epoch 274, Batch 3/4: Calculating loss...
  Epoch 274, Batch 3/4: Backward pass...
  Epoch 274, Batch 3/4: Clipping gradients...
  Epoch 274, Batch 3/4: Optimizer step...
  Epoch 274, Batch 3/4: Completed in 0.19s
  Epoch 274, Batch 4/4: Loading data to device...
  Epoch 274, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 274, Batch 4/4: Zeroing gradients...
  Epoch 274, Batch 4/4: Forward pass...
  Epoch 274, Batch 4/4: Calculating loss...
  Epoch 274, Batch 4/4: Backward pass...
  Epoch 274, Batch 4/4: Clipping gradients...
  Epoch 274, Batch 4/4: Optimizer step...
  Epoch 274, Batch 4/4: Completed in 0.03s
Epoch 274: Training phase completed. Average Train Loss: 0.3438
Epoch 274: Starting validation phase...
  Epoch 274, Val Batch 1/1: Loading data...
  Epoch 274, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 274, Val Batch 1/1: Forward pass...
  Epoch 274, Val Batch 1/1: Calculating loss...
Epoch 274: Validation phase completed. Average Val Loss: 0.2905
Epoch 274 Summary ---> Train Loss: 0.3438 / Validation Loss: 0.2905
Epoch 274: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 1)
  Epoch 274: Validation loss did not improve. Epochs without improvement: 2
Epoch 274: Stepping scheduler...
--- Epoch 274 completed in 0.67 seconds ---

--- Starting Epoch 275/1000 ---
Epoch 275: Starting training phase (4 batches)
  Epoch 275, Batch 1/4: Loading data to device...
  Epoch 275, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 275, Batch 1/4: Zeroing gradients...
  Epoch 275, Batch 1/4: Forward pass...
  Epoch 275, Batch 1/4: Calculating loss...
  Epoch 275, Batch 1/4: Backward pass...
  Epoch 275, Batch 1/4: Clipping gradients...
  Epoch 275, Batch 1/4: Optimizer step...
  Epoch 275, Batch 1/4: Completed in 0.20s
  Epoch 275, Batch 2/4: Loading data to device...
  Epoch 275, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 275, Batch 2/4: Zeroing gradients...
  Epoch 275, Batch 2/4: Forward pass...
  Epoch 275, Batch 2/4: Calculating loss...
  Epoch 275, Batch 2/4: Backward pass...
  Epoch 275, Batch 2/4: Clipping gradients...
  Epoch 275, Batch 2/4: Optimizer step...
  Epoch 275, Batch 2/4: Completed in 0.20s
  Epoch 275, Batch 3/4: Loading data to device...
  Epoch 275, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 275, Batch 3/4: Zeroing gradients...
  Epoch 275, Batch 3/4: Forward pass...
  Epoch 275, Batch 3/4: Calculating loss...
  Epoch 275, Batch 3/4: Backward pass...
  Epoch 275, Batch 3/4: Clipping gradients...
  Epoch 275, Batch 3/4: Optimizer step...
  Epoch 275, Batch 3/4: Completed in 0.20s
  Epoch 275, Batch 4/4: Loading data to device...
  Epoch 275, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 275, Batch 4/4: Zeroing gradients...
  Epoch 275, Batch 4/4: Forward pass...
  Epoch 275, Batch 4/4: Calculating loss...
  Epoch 275, Batch 4/4: Backward pass...
  Epoch 275, Batch 4/4: Clipping gradients...
  Epoch 275, Batch 4/4: Optimizer step...
  Epoch 275, Batch 4/4: Completed in 0.03s
Epoch 275: Training phase completed. Average Train Loss: 0.3328
Epoch 275: Starting validation phase...
  Epoch 275, Val Batch 1/1: Loading data...
  Epoch 275, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 275, Val Batch 1/1: Forward pass...
  Epoch 275, Val Batch 1/1: Calculating loss...
Epoch 275: Validation phase completed. Average Val Loss: 0.2925
Epoch 275 Summary ---> Train Loss: 0.3328 / Validation Loss: 0.2925
Epoch 275: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 2)
  Epoch 275: Validation loss did not improve. Epochs without improvement: 3
Epoch 275: Stepping scheduler...
--- Epoch 275 completed in 0.69 seconds ---

--- Starting Epoch 276/1000 ---
Epoch 276: Starting training phase (4 batches)
  Epoch 276, Batch 1/4: Loading data to device...
  Epoch 276, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 276, Batch 1/4: Zeroing gradients...
  Epoch 276, Batch 1/4: Forward pass...
  Epoch 276, Batch 1/4: Calculating loss...
  Epoch 276, Batch 1/4: Backward pass...
  Epoch 276, Batch 1/4: Clipping gradients...
  Epoch 276, Batch 1/4: Optimizer step...
  Epoch 276, Batch 1/4: Completed in 0.20s
  Epoch 276, Batch 2/4: Loading data to device...
  Epoch 276, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 276, Batch 2/4: Zeroing gradients...
  Epoch 276, Batch 2/4: Forward pass...
  Epoch 276, Batch 2/4: Calculating loss...
  Epoch 276, Batch 2/4: Backward pass...
  Epoch 276, Batch 2/4: Clipping gradients...
  Epoch 276, Batch 2/4: Optimizer step...
  Epoch 276, Batch 2/4: Completed in 0.19s
  Epoch 276, Batch 3/4: Loading data to device...
  Epoch 276, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 276, Batch 3/4: Zeroing gradients...
  Epoch 276, Batch 3/4: Forward pass...
  Epoch 276, Batch 3/4: Calculating loss...
  Epoch 276, Batch 3/4: Backward pass...
  Epoch 276, Batch 3/4: Clipping gradients...
  Epoch 276, Batch 3/4: Optimizer step...
  Epoch 276, Batch 3/4: Completed in 0.19s
  Epoch 276, Batch 4/4: Loading data to device...
  Epoch 276, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 276, Batch 4/4: Zeroing gradients...
  Epoch 276, Batch 4/4: Forward pass...
  Epoch 276, Batch 4/4: Calculating loss...
  Epoch 276, Batch 4/4: Backward pass...
  Epoch 276, Batch 4/4: Clipping gradients...
  Epoch 276, Batch 4/4: Optimizer step...
  Epoch 276, Batch 4/4: Completed in 0.04s
Epoch 276: Training phase completed. Average Train Loss: 0.3943
Epoch 276: Starting validation phase...
  Epoch 276, Val Batch 1/1: Loading data...
  Epoch 276, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 276, Val Batch 1/1: Forward pass...
  Epoch 276, Val Batch 1/1: Calculating loss...
Epoch 276: Validation phase completed. Average Val Loss: 0.2920
Epoch 276 Summary ---> Train Loss: 0.3943 / Validation Loss: 0.2920
Epoch 276: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 3)
  Epoch 276: Validation loss did not improve. Epochs without improvement: 4
Epoch 276: Stepping scheduler...
--- Epoch 276 completed in 0.69 seconds ---

--- Starting Epoch 277/1000 ---
Epoch 277: Starting training phase (4 batches)
  Epoch 277, Batch 1/4: Loading data to device...
  Epoch 277, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 277, Batch 1/4: Zeroing gradients...
  Epoch 277, Batch 1/4: Forward pass...
  Epoch 277, Batch 1/4: Calculating loss...
  Epoch 277, Batch 1/4: Backward pass...
  Epoch 277, Batch 1/4: Clipping gradients...
  Epoch 277, Batch 1/4: Optimizer step...
  Epoch 277, Batch 1/4: Completed in 0.19s
  Epoch 277, Batch 2/4: Loading data to device...
  Epoch 277, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 277, Batch 2/4: Zeroing gradients...
  Epoch 277, Batch 2/4: Forward pass...
  Epoch 277, Batch 2/4: Calculating loss...
  Epoch 277, Batch 2/4: Backward pass...
  Epoch 277, Batch 2/4: Clipping gradients...
  Epoch 277, Batch 2/4: Optimizer step...
  Epoch 277, Batch 2/4: Completed in 0.19s
  Epoch 277, Batch 3/4: Loading data to device...
  Epoch 277, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 277, Batch 3/4: Zeroing gradients...
  Epoch 277, Batch 3/4: Forward pass...
  Epoch 277, Batch 3/4: Calculating loss...
  Epoch 277, Batch 3/4: Backward pass...
  Epoch 277, Batch 3/4: Clipping gradients...
  Epoch 277, Batch 3/4: Optimizer step...
  Epoch 277, Batch 3/4: Completed in 0.19s
  Epoch 277, Batch 4/4: Loading data to device...
  Epoch 277, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 277, Batch 4/4: Zeroing gradients...
  Epoch 277, Batch 4/4: Forward pass...
  Epoch 277, Batch 4/4: Calculating loss...
  Epoch 277, Batch 4/4: Backward pass...
  Epoch 277, Batch 4/4: Clipping gradients...
  Epoch 277, Batch 4/4: Optimizer step...
  Epoch 277, Batch 4/4: Completed in 0.03s
Epoch 277: Training phase completed. Average Train Loss: 0.3742
Epoch 277: Starting validation phase...
  Epoch 277, Val Batch 1/1: Loading data...
  Epoch 277, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 277, Val Batch 1/1: Forward pass...
  Epoch 277, Val Batch 1/1: Calculating loss...
Epoch 277: Validation phase completed. Average Val Loss: 0.2890
Epoch 277 Summary ---> Train Loss: 0.3742 / Validation Loss: 0.2890
Epoch 277: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 4)
  Epoch 277: Validation loss did not improve. Epochs without improvement: 5
Epoch 277: Stepping scheduler...
--- Epoch 277 completed in 0.66 seconds ---

--- Starting Epoch 278/1000 ---
Epoch 278: Starting training phase (4 batches)
  Epoch 278, Batch 1/4: Loading data to device...
  Epoch 278, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 278, Batch 1/4: Zeroing gradients...
  Epoch 278, Batch 1/4: Forward pass...
  Epoch 278, Batch 1/4: Calculating loss...
  Epoch 278, Batch 1/4: Backward pass...
  Epoch 278, Batch 1/4: Clipping gradients...
  Epoch 278, Batch 1/4: Optimizer step...
  Epoch 278, Batch 1/4: Completed in 0.19s
  Epoch 278, Batch 2/4: Loading data to device...
  Epoch 278, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 278, Batch 2/4: Zeroing gradients...
  Epoch 278, Batch 2/4: Forward pass...
  Epoch 278, Batch 2/4: Calculating loss...
  Epoch 278, Batch 2/4: Backward pass...
  Epoch 278, Batch 2/4: Clipping gradients...
  Epoch 278, Batch 2/4: Optimizer step...
  Epoch 278, Batch 2/4: Completed in 0.20s
  Epoch 278, Batch 3/4: Loading data to device...
  Epoch 278, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 278, Batch 3/4: Zeroing gradients...
  Epoch 278, Batch 3/4: Forward pass...
  Epoch 278, Batch 3/4: Calculating loss...
  Epoch 278, Batch 3/4: Backward pass...
  Epoch 278, Batch 3/4: Clipping gradients...
  Epoch 278, Batch 3/4: Optimizer step...
  Epoch 278, Batch 3/4: Completed in 0.19s
  Epoch 278, Batch 4/4: Loading data to device...
  Epoch 278, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 278, Batch 4/4: Zeroing gradients...
  Epoch 278, Batch 4/4: Forward pass...
  Epoch 278, Batch 4/4: Calculating loss...
  Epoch 278, Batch 4/4: Backward pass...
  Epoch 278, Batch 4/4: Clipping gradients...
  Epoch 278, Batch 4/4: Optimizer step...
  Epoch 278, Batch 4/4: Completed in 0.03s
Epoch 278: Training phase completed. Average Train Loss: 0.3636
Epoch 278: Starting validation phase...
  Epoch 278, Val Batch 1/1: Loading data...
  Epoch 278, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 278, Val Batch 1/1: Forward pass...
  Epoch 278, Val Batch 1/1: Calculating loss...
Epoch 278: Validation phase completed. Average Val Loss: 0.2894
Epoch 278 Summary ---> Train Loss: 0.3636 / Validation Loss: 0.2894
Epoch 278: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 5)
  Epoch 278: Validation loss did not improve. Epochs without improvement: 6
Epoch 278: Stepping scheduler...
--- Epoch 278 completed in 0.68 seconds ---

--- Starting Epoch 279/1000 ---
Epoch 279: Starting training phase (4 batches)
  Epoch 279, Batch 1/4: Loading data to device...
  Epoch 279, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 279, Batch 1/4: Zeroing gradients...
  Epoch 279, Batch 1/4: Forward pass...
  Epoch 279, Batch 1/4: Calculating loss...
  Epoch 279, Batch 1/4: Backward pass...
  Epoch 279, Batch 1/4: Clipping gradients...
  Epoch 279, Batch 1/4: Optimizer step...
  Epoch 279, Batch 1/4: Completed in 0.19s
  Epoch 279, Batch 2/4: Loading data to device...
  Epoch 279, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 279, Batch 2/4: Zeroing gradients...
  Epoch 279, Batch 2/4: Forward pass...
  Epoch 279, Batch 2/4: Calculating loss...
  Epoch 279, Batch 2/4: Backward pass...
  Epoch 279, Batch 2/4: Clipping gradients...
  Epoch 279, Batch 2/4: Optimizer step...
  Epoch 279, Batch 2/4: Completed in 0.19s
  Epoch 279, Batch 3/4: Loading data to device...
  Epoch 279, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 279, Batch 3/4: Zeroing gradients...
  Epoch 279, Batch 3/4: Forward pass...
  Epoch 279, Batch 3/4: Calculating loss...
  Epoch 279, Batch 3/4: Backward pass...
  Epoch 279, Batch 3/4: Clipping gradients...
  Epoch 279, Batch 3/4: Optimizer step...
  Epoch 279, Batch 3/4: Completed in 0.19s
  Epoch 279, Batch 4/4: Loading data to device...
  Epoch 279, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 279, Batch 4/4: Zeroing gradients...
  Epoch 279, Batch 4/4: Forward pass...
  Epoch 279, Batch 4/4: Calculating loss...
  Epoch 279, Batch 4/4: Backward pass...
  Epoch 279, Batch 4/4: Clipping gradients...
  Epoch 279, Batch 4/4: Optimizer step...
  Epoch 279, Batch 4/4: Completed in 0.03s
Epoch 279: Training phase completed. Average Train Loss: 0.3445
Epoch 279: Starting validation phase...
  Epoch 279, Val Batch 1/1: Loading data...
  Epoch 279, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 279, Val Batch 1/1: Forward pass...
  Epoch 279, Val Batch 1/1: Calculating loss...
Epoch 279: Validation phase completed. Average Val Loss: 0.2886
Epoch 279 Summary ---> Train Loss: 0.3445 / Validation Loss: 0.2886
Epoch 279: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 6)
  Epoch 279: Validation loss did not improve. Epochs without improvement: 7
Epoch 279: Stepping scheduler...
--- Epoch 279 completed in 0.68 seconds ---

--- Starting Epoch 280/1000 ---
Epoch 280: Starting training phase (4 batches)
  Epoch 280, Batch 1/4: Loading data to device...
  Epoch 280, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 280, Batch 1/4: Zeroing gradients...
  Epoch 280, Batch 1/4: Forward pass...
  Epoch 280, Batch 1/4: Calculating loss...
  Epoch 280, Batch 1/4: Backward pass...
  Epoch 280, Batch 1/4: Clipping gradients...
  Epoch 280, Batch 1/4: Optimizer step...
  Epoch 280, Batch 1/4: Completed in 0.20s
  Epoch 280, Batch 2/4: Loading data to device...
  Epoch 280, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 280, Batch 2/4: Zeroing gradients...
  Epoch 280, Batch 2/4: Forward pass...
  Epoch 280, Batch 2/4: Calculating loss...
  Epoch 280, Batch 2/4: Backward pass...
  Epoch 280, Batch 2/4: Clipping gradients...
  Epoch 280, Batch 2/4: Optimizer step...
  Epoch 280, Batch 2/4: Completed in 0.20s
  Epoch 280, Batch 3/4: Loading data to device...
  Epoch 280, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 280, Batch 3/4: Zeroing gradients...
  Epoch 280, Batch 3/4: Forward pass...
  Epoch 280, Batch 3/4: Calculating loss...
  Epoch 280, Batch 3/4: Backward pass...
  Epoch 280, Batch 3/4: Clipping gradients...
  Epoch 280, Batch 3/4: Optimizer step...
  Epoch 280, Batch 3/4: Completed in 0.19s
  Epoch 280, Batch 4/4: Loading data to device...
  Epoch 280, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 280, Batch 4/4: Zeroing gradients...
  Epoch 280, Batch 4/4: Forward pass...
  Epoch 280, Batch 4/4: Calculating loss...
  Epoch 280, Batch 4/4: Backward pass...
  Epoch 280, Batch 4/4: Clipping gradients...
  Epoch 280, Batch 4/4: Optimizer step...
  Epoch 280, Batch 4/4: Completed in 0.03s
Epoch 280: Training phase completed. Average Train Loss: 0.3287
Epoch 280: Starting validation phase...
  Epoch 280, Val Batch 1/1: Loading data...
  Epoch 280, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 280, Val Batch 1/1: Forward pass...
  Epoch 280, Val Batch 1/1: Calculating loss...
Epoch 280: Validation phase completed. Average Val Loss: 0.2892
Epoch 280 Summary ---> Train Loss: 0.3287 / Validation Loss: 0.2892
Epoch 280: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 7)
  Epoch 280: Validation loss did not improve. Epochs without improvement: 8
Epoch 280: Stepping scheduler...
--- Epoch 280 completed in 0.69 seconds ---

--- Starting Epoch 281/1000 ---
Epoch 281: Starting training phase (4 batches)
  Epoch 281, Batch 1/4: Loading data to device...
  Epoch 281, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 281, Batch 1/4: Zeroing gradients...
  Epoch 281, Batch 1/4: Forward pass...
  Epoch 281, Batch 1/4: Calculating loss...
  Epoch 281, Batch 1/4: Backward pass...
  Epoch 281, Batch 1/4: Clipping gradients...
  Epoch 281, Batch 1/4: Optimizer step...
  Epoch 281, Batch 1/4: Completed in 0.19s
  Epoch 281, Batch 2/4: Loading data to device...
  Epoch 281, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 281, Batch 2/4: Zeroing gradients...
  Epoch 281, Batch 2/4: Forward pass...
  Epoch 281, Batch 2/4: Calculating loss...
  Epoch 281, Batch 2/4: Backward pass...
  Epoch 281, Batch 2/4: Clipping gradients...
  Epoch 281, Batch 2/4: Optimizer step...
  Epoch 281, Batch 2/4: Completed in 0.19s
  Epoch 281, Batch 3/4: Loading data to device...
  Epoch 281, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 281, Batch 3/4: Zeroing gradients...
  Epoch 281, Batch 3/4: Forward pass...
  Epoch 281, Batch 3/4: Calculating loss...
  Epoch 281, Batch 3/4: Backward pass...
  Epoch 281, Batch 3/4: Clipping gradients...
  Epoch 281, Batch 3/4: Optimizer step...
  Epoch 281, Batch 3/4: Completed in 0.20s
  Epoch 281, Batch 4/4: Loading data to device...
  Epoch 281, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 281, Batch 4/4: Zeroing gradients...
  Epoch 281, Batch 4/4: Forward pass...
  Epoch 281, Batch 4/4: Calculating loss...
  Epoch 281, Batch 4/4: Backward pass...
  Epoch 281, Batch 4/4: Clipping gradients...
  Epoch 281, Batch 4/4: Optimizer step...
  Epoch 281, Batch 4/4: Completed in 0.03s
Epoch 281: Training phase completed. Average Train Loss: 0.3432
Epoch 281: Starting validation phase...
  Epoch 281, Val Batch 1/1: Loading data...
  Epoch 281, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 281, Val Batch 1/1: Forward pass...
  Epoch 281, Val Batch 1/1: Calculating loss...
Epoch 281: Validation phase completed. Average Val Loss: 0.2918
Epoch 281 Summary ---> Train Loss: 0.3432 / Validation Loss: 0.2918
Epoch 281: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 8)
  Epoch 281: Validation loss did not improve. Epochs without improvement: 9
Epoch 281: Stepping scheduler...
--- Epoch 281 completed in 0.68 seconds ---

--- Starting Epoch 282/1000 ---
Epoch 282: Starting training phase (4 batches)
  Epoch 282, Batch 1/4: Loading data to device...
  Epoch 282, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 282, Batch 1/4: Zeroing gradients...
  Epoch 282, Batch 1/4: Forward pass...
  Epoch 282, Batch 1/4: Calculating loss...
  Epoch 282, Batch 1/4: Backward pass...
  Epoch 282, Batch 1/4: Clipping gradients...
  Epoch 282, Batch 1/4: Optimizer step...
  Epoch 282, Batch 1/4: Completed in 0.20s
  Epoch 282, Batch 2/4: Loading data to device...
  Epoch 282, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 282, Batch 2/4: Zeroing gradients...
  Epoch 282, Batch 2/4: Forward pass...
  Epoch 282, Batch 2/4: Calculating loss...
  Epoch 282, Batch 2/4: Backward pass...
  Epoch 282, Batch 2/4: Clipping gradients...
  Epoch 282, Batch 2/4: Optimizer step...
  Epoch 282, Batch 2/4: Completed in 0.20s
  Epoch 282, Batch 3/4: Loading data to device...
  Epoch 282, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 282, Batch 3/4: Zeroing gradients...
  Epoch 282, Batch 3/4: Forward pass...
  Epoch 282, Batch 3/4: Calculating loss...
  Epoch 282, Batch 3/4: Backward pass...
  Epoch 282, Batch 3/4: Clipping gradients...
  Epoch 282, Batch 3/4: Optimizer step...
  Epoch 282, Batch 3/4: Completed in 0.20s
  Epoch 282, Batch 4/4: Loading data to device...
  Epoch 282, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 282, Batch 4/4: Zeroing gradients...
  Epoch 282, Batch 4/4: Forward pass...
  Epoch 282, Batch 4/4: Calculating loss...
  Epoch 282, Batch 4/4: Backward pass...
  Epoch 282, Batch 4/4: Clipping gradients...
  Epoch 282, Batch 4/4: Optimizer step...
  Epoch 282, Batch 4/4: Completed in 0.03s
Epoch 282: Training phase completed. Average Train Loss: 0.3347
Epoch 282: Starting validation phase...
  Epoch 282, Val Batch 1/1: Loading data...
  Epoch 282, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 282, Val Batch 1/1: Forward pass...
  Epoch 282, Val Batch 1/1: Calculating loss...
Epoch 282: Validation phase completed. Average Val Loss: 0.2949
Epoch 282 Summary ---> Train Loss: 0.3347 / Validation Loss: 0.2949
Epoch 282: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 9)
  Epoch 282: Validation loss did not improve. Epochs without improvement: 10
Epoch 282: Stepping scheduler...
--- Epoch 282 completed in 0.69 seconds ---

--- Starting Epoch 283/1000 ---
Epoch 283: Starting training phase (4 batches)
  Epoch 283, Batch 1/4: Loading data to device...
  Epoch 283, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 283, Batch 1/4: Zeroing gradients...
  Epoch 283, Batch 1/4: Forward pass...
  Epoch 283, Batch 1/4: Calculating loss...
  Epoch 283, Batch 1/4: Backward pass...
  Epoch 283, Batch 1/4: Clipping gradients...
  Epoch 283, Batch 1/4: Optimizer step...
  Epoch 283, Batch 1/4: Completed in 0.19s
  Epoch 283, Batch 2/4: Loading data to device...
  Epoch 283, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 283, Batch 2/4: Zeroing gradients...
  Epoch 283, Batch 2/4: Forward pass...
  Epoch 283, Batch 2/4: Calculating loss...
  Epoch 283, Batch 2/4: Backward pass...
  Epoch 283, Batch 2/4: Clipping gradients...
  Epoch 283, Batch 2/4: Optimizer step...
  Epoch 283, Batch 2/4: Completed in 0.19s
  Epoch 283, Batch 3/4: Loading data to device...
  Epoch 283, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 283, Batch 3/4: Zeroing gradients...
  Epoch 283, Batch 3/4: Forward pass...
  Epoch 283, Batch 3/4: Calculating loss...
  Epoch 283, Batch 3/4: Backward pass...
  Epoch 283, Batch 3/4: Clipping gradients...
  Epoch 283, Batch 3/4: Optimizer step...
  Epoch 283, Batch 3/4: Completed in 0.19s
  Epoch 283, Batch 4/4: Loading data to device...
  Epoch 283, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 283, Batch 4/4: Zeroing gradients...
  Epoch 283, Batch 4/4: Forward pass...
  Epoch 283, Batch 4/4: Calculating loss...
  Epoch 283, Batch 4/4: Backward pass...
  Epoch 283, Batch 4/4: Clipping gradients...
  Epoch 283, Batch 4/4: Optimizer step...
  Epoch 283, Batch 4/4: Completed in 0.03s
Epoch 283: Training phase completed. Average Train Loss: 0.3689
Epoch 283: Starting validation phase...
  Epoch 283, Val Batch 1/1: Loading data...
  Epoch 283, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 283, Val Batch 1/1: Forward pass...
  Epoch 283, Val Batch 1/1: Calculating loss...
Epoch 283: Validation phase completed. Average Val Loss: 0.2953
Epoch 283 Summary ---> Train Loss: 0.3689 / Validation Loss: 0.2953
Epoch 283: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 10)
  Epoch 283: Validation loss did not improve. Epochs without improvement: 11
Epoch 283: Stepping scheduler...
--- Epoch 283 completed in 0.68 seconds ---

--- Starting Epoch 284/1000 ---
Epoch 284: Starting training phase (4 batches)
  Epoch 284, Batch 1/4: Loading data to device...
  Epoch 284, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 284, Batch 1/4: Zeroing gradients...
  Epoch 284, Batch 1/4: Forward pass...
  Epoch 284, Batch 1/4: Calculating loss...
  Epoch 284, Batch 1/4: Backward pass...
  Epoch 284, Batch 1/4: Clipping gradients...
  Epoch 284, Batch 1/4: Optimizer step...
  Epoch 284, Batch 1/4: Completed in 0.19s
  Epoch 284, Batch 2/4: Loading data to device...
  Epoch 284, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 284, Batch 2/4: Zeroing gradients...
  Epoch 284, Batch 2/4: Forward pass...
  Epoch 284, Batch 2/4: Calculating loss...
  Epoch 284, Batch 2/4: Backward pass...
  Epoch 284, Batch 2/4: Clipping gradients...
  Epoch 284, Batch 2/4: Optimizer step...
  Epoch 284, Batch 2/4: Completed in 0.19s
  Epoch 284, Batch 3/4: Loading data to device...
  Epoch 284, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 284, Batch 3/4: Zeroing gradients...
  Epoch 284, Batch 3/4: Forward pass...
  Epoch 284, Batch 3/4: Calculating loss...
  Epoch 284, Batch 3/4: Backward pass...
  Epoch 284, Batch 3/4: Clipping gradients...
  Epoch 284, Batch 3/4: Optimizer step...
  Epoch 284, Batch 3/4: Completed in 0.19s
  Epoch 284, Batch 4/4: Loading data to device...
  Epoch 284, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 284, Batch 4/4: Zeroing gradients...
  Epoch 284, Batch 4/4: Forward pass...
  Epoch 284, Batch 4/4: Calculating loss...
  Epoch 284, Batch 4/4: Backward pass...
  Epoch 284, Batch 4/4: Clipping gradients...
  Epoch 284, Batch 4/4: Optimizer step...
  Epoch 284, Batch 4/4: Completed in 0.03s
Epoch 284: Training phase completed. Average Train Loss: 0.3387
Epoch 284: Starting validation phase...
  Epoch 284, Val Batch 1/1: Loading data...
  Epoch 284, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 284, Val Batch 1/1: Forward pass...
  Epoch 284, Val Batch 1/1: Calculating loss...
Epoch 284: Validation phase completed. Average Val Loss: 0.2875
Epoch 284 Summary ---> Train Loss: 0.3387 / Validation Loss: 0.2875
Epoch 284: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 11)
  Epoch 284: Validation loss did not improve. Epochs without improvement: 12
Epoch 284: Stepping scheduler...
--- Epoch 284 completed in 0.66 seconds ---

--- Starting Epoch 285/1000 ---
Epoch 285: Starting training phase (4 batches)
  Epoch 285, Batch 1/4: Loading data to device...
  Epoch 285, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 285, Batch 1/4: Zeroing gradients...
  Epoch 285, Batch 1/4: Forward pass...
  Epoch 285, Batch 1/4: Calculating loss...
  Epoch 285, Batch 1/4: Backward pass...
  Epoch 285, Batch 1/4: Clipping gradients...
  Epoch 285, Batch 1/4: Optimizer step...
  Epoch 285, Batch 1/4: Completed in 0.19s
  Epoch 285, Batch 2/4: Loading data to device...
  Epoch 285, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 285, Batch 2/4: Zeroing gradients...
  Epoch 285, Batch 2/4: Forward pass...
  Epoch 285, Batch 2/4: Calculating loss...
  Epoch 285, Batch 2/4: Backward pass...
  Epoch 285, Batch 2/4: Clipping gradients...
  Epoch 285, Batch 2/4: Optimizer step...
  Epoch 285, Batch 2/4: Completed in 0.19s
  Epoch 285, Batch 3/4: Loading data to device...
  Epoch 285, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 285, Batch 3/4: Zeroing gradients...
  Epoch 285, Batch 3/4: Forward pass...
  Epoch 285, Batch 3/4: Calculating loss...
  Epoch 285, Batch 3/4: Backward pass...
  Epoch 285, Batch 3/4: Clipping gradients...
  Epoch 285, Batch 3/4: Optimizer step...
  Epoch 285, Batch 3/4: Completed in 0.19s
  Epoch 285, Batch 4/4: Loading data to device...
  Epoch 285, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 285, Batch 4/4: Zeroing gradients...
  Epoch 285, Batch 4/4: Forward pass...
  Epoch 285, Batch 4/4: Calculating loss...
  Epoch 285, Batch 4/4: Backward pass...
  Epoch 285, Batch 4/4: Clipping gradients...
  Epoch 285, Batch 4/4: Optimizer step...
  Epoch 285, Batch 4/4: Completed in 0.03s
Epoch 285: Training phase completed. Average Train Loss: 0.3369
Epoch 285: Starting validation phase...
  Epoch 285, Val Batch 1/1: Loading data...
  Epoch 285, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 285, Val Batch 1/1: Forward pass...
  Epoch 285, Val Batch 1/1: Calculating loss...
Epoch 285: Validation phase completed. Average Val Loss: 0.2961
Epoch 285 Summary ---> Train Loss: 0.3369 / Validation Loss: 0.2961
Epoch 285: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 12)
  Epoch 285: Validation loss did not improve. Epochs without improvement: 13
Epoch 285: Stepping scheduler...
--- Epoch 285 completed in 0.67 seconds ---

--- Starting Epoch 286/1000 ---
Epoch 286: Starting training phase (4 batches)
  Epoch 286, Batch 1/4: Loading data to device...
  Epoch 286, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 286, Batch 1/4: Zeroing gradients...
  Epoch 286, Batch 1/4: Forward pass...
  Epoch 286, Batch 1/4: Calculating loss...
  Epoch 286, Batch 1/4: Backward pass...
  Epoch 286, Batch 1/4: Clipping gradients...
  Epoch 286, Batch 1/4: Optimizer step...
  Epoch 286, Batch 1/4: Completed in 0.19s
  Epoch 286, Batch 2/4: Loading data to device...
  Epoch 286, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 286, Batch 2/4: Zeroing gradients...
  Epoch 286, Batch 2/4: Forward pass...
  Epoch 286, Batch 2/4: Calculating loss...
  Epoch 286, Batch 2/4: Backward pass...
  Epoch 286, Batch 2/4: Clipping gradients...
  Epoch 286, Batch 2/4: Optimizer step...
  Epoch 286, Batch 2/4: Completed in 0.20s
  Epoch 286, Batch 3/4: Loading data to device...
  Epoch 286, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 286, Batch 3/4: Zeroing gradients...
  Epoch 286, Batch 3/4: Forward pass...
  Epoch 286, Batch 3/4: Calculating loss...
  Epoch 286, Batch 3/4: Backward pass...
  Epoch 286, Batch 3/4: Clipping gradients...
  Epoch 286, Batch 3/4: Optimizer step...
  Epoch 286, Batch 3/4: Completed in 0.20s
  Epoch 286, Batch 4/4: Loading data to device...
  Epoch 286, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 286, Batch 4/4: Zeroing gradients...
  Epoch 286, Batch 4/4: Forward pass...
  Epoch 286, Batch 4/4: Calculating loss...
  Epoch 286, Batch 4/4: Backward pass...
  Epoch 286, Batch 4/4: Clipping gradients...
  Epoch 286, Batch 4/4: Optimizer step...
  Epoch 286, Batch 4/4: Completed in 0.03s
Epoch 286: Training phase completed. Average Train Loss: 0.3732
Epoch 286: Starting validation phase...
  Epoch 286, Val Batch 1/1: Loading data...
  Epoch 286, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 286, Val Batch 1/1: Forward pass...
  Epoch 286, Val Batch 1/1: Calculating loss...
Epoch 286: Validation phase completed. Average Val Loss: 0.2906
Epoch 286 Summary ---> Train Loss: 0.3732 / Validation Loss: 0.2906
Epoch 286: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 13)
  Epoch 286: Validation loss did not improve. Epochs without improvement: 14
Epoch 286: Stepping scheduler...
--- Epoch 286 completed in 0.68 seconds ---

--- Starting Epoch 287/1000 ---
Epoch 287: Starting training phase (4 batches)
  Epoch 287, Batch 1/4: Loading data to device...
  Epoch 287, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 287, Batch 1/4: Zeroing gradients...
  Epoch 287, Batch 1/4: Forward pass...
  Epoch 287, Batch 1/4: Calculating loss...
  Epoch 287, Batch 1/4: Backward pass...
  Epoch 287, Batch 1/4: Clipping gradients...
  Epoch 287, Batch 1/4: Optimizer step...
  Epoch 287, Batch 1/4: Completed in 0.19s
  Epoch 287, Batch 2/4: Loading data to device...
  Epoch 287, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 287, Batch 2/4: Zeroing gradients...
  Epoch 287, Batch 2/4: Forward pass...
  Epoch 287, Batch 2/4: Calculating loss...
  Epoch 287, Batch 2/4: Backward pass...
  Epoch 287, Batch 2/4: Clipping gradients...
  Epoch 287, Batch 2/4: Optimizer step...
  Epoch 287, Batch 2/4: Completed in 0.20s
  Epoch 287, Batch 3/4: Loading data to device...
  Epoch 287, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 287, Batch 3/4: Zeroing gradients...
  Epoch 287, Batch 3/4: Forward pass...
  Epoch 287, Batch 3/4: Calculating loss...
  Epoch 287, Batch 3/4: Backward pass...
  Epoch 287, Batch 3/4: Clipping gradients...
  Epoch 287, Batch 3/4: Optimizer step...
  Epoch 287, Batch 3/4: Completed in 0.19s
  Epoch 287, Batch 4/4: Loading data to device...
  Epoch 287, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 287, Batch 4/4: Zeroing gradients...
  Epoch 287, Batch 4/4: Forward pass...
  Epoch 287, Batch 4/4: Calculating loss...
  Epoch 287, Batch 4/4: Backward pass...
  Epoch 287, Batch 4/4: Clipping gradients...
  Epoch 287, Batch 4/4: Optimizer step...
  Epoch 287, Batch 4/4: Completed in 0.04s
Epoch 287: Training phase completed. Average Train Loss: 0.3402
Epoch 287: Starting validation phase...
  Epoch 287, Val Batch 1/1: Loading data...
  Epoch 287, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 287, Val Batch 1/1: Forward pass...
  Epoch 287, Val Batch 1/1: Calculating loss...
Epoch 287: Validation phase completed. Average Val Loss: 0.2965
Epoch 287 Summary ---> Train Loss: 0.3402 / Validation Loss: 0.2965
Epoch 287: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 14)
  Epoch 287: Validation loss did not improve. Epochs without improvement: 15
Epoch 287: Stepping scheduler...
--- Epoch 287 completed in 0.67 seconds ---

--- Starting Epoch 288/1000 ---
Epoch 288: Starting training phase (4 batches)
  Epoch 288, Batch 1/4: Loading data to device...
  Epoch 288, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 288, Batch 1/4: Zeroing gradients...
  Epoch 288, Batch 1/4: Forward pass...
  Epoch 288, Batch 1/4: Calculating loss...
  Epoch 288, Batch 1/4: Backward pass...
  Epoch 288, Batch 1/4: Clipping gradients...
  Epoch 288, Batch 1/4: Optimizer step...
  Epoch 288, Batch 1/4: Completed in 0.19s
  Epoch 288, Batch 2/4: Loading data to device...
  Epoch 288, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 288, Batch 2/4: Zeroing gradients...
  Epoch 288, Batch 2/4: Forward pass...
  Epoch 288, Batch 2/4: Calculating loss...
  Epoch 288, Batch 2/4: Backward pass...
  Epoch 288, Batch 2/4: Clipping gradients...
  Epoch 288, Batch 2/4: Optimizer step...
  Epoch 288, Batch 2/4: Completed in 0.19s
  Epoch 288, Batch 3/4: Loading data to device...
  Epoch 288, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 288, Batch 3/4: Zeroing gradients...
  Epoch 288, Batch 3/4: Forward pass...
  Epoch 288, Batch 3/4: Calculating loss...
  Epoch 288, Batch 3/4: Backward pass...
  Epoch 288, Batch 3/4: Clipping gradients...
  Epoch 288, Batch 3/4: Optimizer step...
  Epoch 288, Batch 3/4: Completed in 0.19s
  Epoch 288, Batch 4/4: Loading data to device...
  Epoch 288, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 288, Batch 4/4: Zeroing gradients...
  Epoch 288, Batch 4/4: Forward pass...
  Epoch 288, Batch 4/4: Calculating loss...
  Epoch 288, Batch 4/4: Backward pass...
  Epoch 288, Batch 4/4: Clipping gradients...
  Epoch 288, Batch 4/4: Optimizer step...
  Epoch 288, Batch 4/4: Completed in 0.03s
Epoch 288: Training phase completed. Average Train Loss: 0.3403
Epoch 288: Starting validation phase...
  Epoch 288, Val Batch 1/1: Loading data...
  Epoch 288, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 288, Val Batch 1/1: Forward pass...
  Epoch 288, Val Batch 1/1: Calculating loss...
Epoch 288: Validation phase completed. Average Val Loss: 0.2880
Epoch 288 Summary ---> Train Loss: 0.3403 / Validation Loss: 0.2880
Epoch 288: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 15)
  Epoch 288: Validation loss did not improve. Epochs without improvement: 16
Epoch 288: Stepping scheduler...
--- Epoch 288 completed in 0.67 seconds ---

--- Starting Epoch 289/1000 ---
Epoch 289: Starting training phase (4 batches)
  Epoch 289, Batch 1/4: Loading data to device...
  Epoch 289, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 289, Batch 1/4: Zeroing gradients...
  Epoch 289, Batch 1/4: Forward pass...
  Epoch 289, Batch 1/4: Calculating loss...
  Epoch 289, Batch 1/4: Backward pass...
  Epoch 289, Batch 1/4: Clipping gradients...
  Epoch 289, Batch 1/4: Optimizer step...
  Epoch 289, Batch 1/4: Completed in 0.19s
  Epoch 289, Batch 2/4: Loading data to device...
  Epoch 289, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 289, Batch 2/4: Zeroing gradients...
  Epoch 289, Batch 2/4: Forward pass...
  Epoch 289, Batch 2/4: Calculating loss...
  Epoch 289, Batch 2/4: Backward pass...
  Epoch 289, Batch 2/4: Clipping gradients...
  Epoch 289, Batch 2/4: Optimizer step...
  Epoch 289, Batch 2/4: Completed in 0.19s
  Epoch 289, Batch 3/4: Loading data to device...
  Epoch 289, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 289, Batch 3/4: Zeroing gradients...
  Epoch 289, Batch 3/4: Forward pass...
  Epoch 289, Batch 3/4: Calculating loss...
  Epoch 289, Batch 3/4: Backward pass...
  Epoch 289, Batch 3/4: Clipping gradients...
  Epoch 289, Batch 3/4: Optimizer step...
  Epoch 289, Batch 3/4: Completed in 0.19s
  Epoch 289, Batch 4/4: Loading data to device...
  Epoch 289, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 289, Batch 4/4: Zeroing gradients...
  Epoch 289, Batch 4/4: Forward pass...
  Epoch 289, Batch 4/4: Calculating loss...
  Epoch 289, Batch 4/4: Backward pass...
  Epoch 289, Batch 4/4: Clipping gradients...
  Epoch 289, Batch 4/4: Optimizer step...
  Epoch 289, Batch 4/4: Completed in 0.03s
Epoch 289: Training phase completed. Average Train Loss: 0.3600
Epoch 289: Starting validation phase...
  Epoch 289, Val Batch 1/1: Loading data...
  Epoch 289, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 289, Val Batch 1/1: Forward pass...
  Epoch 289, Val Batch 1/1: Calculating loss...
Epoch 289: Validation phase completed. Average Val Loss: 0.2872
Epoch 289 Summary ---> Train Loss: 0.3600 / Validation Loss: 0.2872
Epoch 289: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 16)
  Epoch 289: Validation loss did not improve. Epochs without improvement: 17
Epoch 289: Stepping scheduler...
--- Epoch 289 completed in 0.67 seconds ---

--- Starting Epoch 290/1000 ---
Epoch 290: Starting training phase (4 batches)
  Epoch 290, Batch 1/4: Loading data to device...
  Epoch 290, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 290, Batch 1/4: Zeroing gradients...
  Epoch 290, Batch 1/4: Forward pass...
  Epoch 290, Batch 1/4: Calculating loss...
  Epoch 290, Batch 1/4: Backward pass...
  Epoch 290, Batch 1/4: Clipping gradients...
  Epoch 290, Batch 1/4: Optimizer step...
  Epoch 290, Batch 1/4: Completed in 0.19s
  Epoch 290, Batch 2/4: Loading data to device...
  Epoch 290, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 290, Batch 2/4: Zeroing gradients...
  Epoch 290, Batch 2/4: Forward pass...
  Epoch 290, Batch 2/4: Calculating loss...
  Epoch 290, Batch 2/4: Backward pass...
  Epoch 290, Batch 2/4: Clipping gradients...
  Epoch 290, Batch 2/4: Optimizer step...
  Epoch 290, Batch 2/4: Completed in 0.19s
  Epoch 290, Batch 3/4: Loading data to device...
  Epoch 290, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 290, Batch 3/4: Zeroing gradients...
  Epoch 290, Batch 3/4: Forward pass...
  Epoch 290, Batch 3/4: Calculating loss...
  Epoch 290, Batch 3/4: Backward pass...
  Epoch 290, Batch 3/4: Clipping gradients...
  Epoch 290, Batch 3/4: Optimizer step...
  Epoch 290, Batch 3/4: Completed in 0.20s
  Epoch 290, Batch 4/4: Loading data to device...
  Epoch 290, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 290, Batch 4/4: Zeroing gradients...
  Epoch 290, Batch 4/4: Forward pass...
  Epoch 290, Batch 4/4: Calculating loss...
  Epoch 290, Batch 4/4: Backward pass...
  Epoch 290, Batch 4/4: Clipping gradients...
  Epoch 290, Batch 4/4: Optimizer step...
  Epoch 290, Batch 4/4: Completed in 0.03s
Epoch 290: Training phase completed. Average Train Loss: 0.3420
Epoch 290: Starting validation phase...
  Epoch 290, Val Batch 1/1: Loading data...
  Epoch 290, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 290, Val Batch 1/1: Forward pass...
  Epoch 290, Val Batch 1/1: Calculating loss...
Epoch 290: Validation phase completed. Average Val Loss: 0.2860
Epoch 290 Summary ---> Train Loss: 0.3420 / Validation Loss: 0.2860
Epoch 290: Checking early stopping... (Current Best Loss: 0.2871, Epochs No Improve: 17)
  Epoch 290: Validation loss improved (0.2871 --> 0.2860). Saving model.
Epoch 290: Stepping scheduler...
--- Epoch 290 completed in 0.67 seconds ---

--- Starting Epoch 291/1000 ---
Epoch 291: Starting training phase (4 batches)
  Epoch 291, Batch 1/4: Loading data to device...
  Epoch 291, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 291, Batch 1/4: Zeroing gradients...
  Epoch 291, Batch 1/4: Forward pass...
  Epoch 291, Batch 1/4: Calculating loss...
  Epoch 291, Batch 1/4: Backward pass...
  Epoch 291, Batch 1/4: Clipping gradients...
  Epoch 291, Batch 1/4: Optimizer step...
  Epoch 291, Batch 1/4: Completed in 0.19s
  Epoch 291, Batch 2/4: Loading data to device...
  Epoch 291, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 291, Batch 2/4: Zeroing gradients...
  Epoch 291, Batch 2/4: Forward pass...
  Epoch 291, Batch 2/4: Calculating loss...
  Epoch 291, Batch 2/4: Backward pass...
  Epoch 291, Batch 2/4: Clipping gradients...
  Epoch 291, Batch 2/4: Optimizer step...
  Epoch 291, Batch 2/4: Completed in 0.19s
  Epoch 291, Batch 3/4: Loading data to device...
  Epoch 291, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 291, Batch 3/4: Zeroing gradients...
  Epoch 291, Batch 3/4: Forward pass...
  Epoch 291, Batch 3/4: Calculating loss...
  Epoch 291, Batch 3/4: Backward pass...
  Epoch 291, Batch 3/4: Clipping gradients...
  Epoch 291, Batch 3/4: Optimizer step...
  Epoch 291, Batch 3/4: Completed in 0.19s
  Epoch 291, Batch 4/4: Loading data to device...
  Epoch 291, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 291, Batch 4/4: Zeroing gradients...
  Epoch 291, Batch 4/4: Forward pass...
  Epoch 291, Batch 4/4: Calculating loss...
  Epoch 291, Batch 4/4: Backward pass...
  Epoch 291, Batch 4/4: Clipping gradients...
  Epoch 291, Batch 4/4: Optimizer step...
  Epoch 291, Batch 4/4: Completed in 0.03s
Epoch 291: Training phase completed. Average Train Loss: 0.3258
Epoch 291: Starting validation phase...
  Epoch 291, Val Batch 1/1: Loading data...
  Epoch 291, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 291, Val Batch 1/1: Forward pass...
  Epoch 291, Val Batch 1/1: Calculating loss...
Epoch 291: Validation phase completed. Average Val Loss: 0.2812
Epoch 291 Summary ---> Train Loss: 0.3258 / Validation Loss: 0.2812
Epoch 291: Checking early stopping... (Current Best Loss: 0.2860, Epochs No Improve: 0)
  Epoch 291: Validation loss improved (0.2860 --> 0.2812). Saving model.
Epoch 291: Stepping scheduler...
--- Epoch 291 completed in 0.67 seconds ---

--- Starting Epoch 292/1000 ---
Epoch 292: Starting training phase (4 batches)
  Epoch 292, Batch 1/4: Loading data to device...
  Epoch 292, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 292, Batch 1/4: Zeroing gradients...
  Epoch 292, Batch 1/4: Forward pass...
  Epoch 292, Batch 1/4: Calculating loss...
  Epoch 292, Batch 1/4: Backward pass...
  Epoch 292, Batch 1/4: Clipping gradients...
  Epoch 292, Batch 1/4: Optimizer step...
  Epoch 292, Batch 1/4: Completed in 0.19s
  Epoch 292, Batch 2/4: Loading data to device...
  Epoch 292, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 292, Batch 2/4: Zeroing gradients...
  Epoch 292, Batch 2/4: Forward pass...
  Epoch 292, Batch 2/4: Calculating loss...
  Epoch 292, Batch 2/4: Backward pass...
  Epoch 292, Batch 2/4: Clipping gradients...
  Epoch 292, Batch 2/4: Optimizer step...
  Epoch 292, Batch 2/4: Completed in 0.18s
  Epoch 292, Batch 3/4: Loading data to device...
  Epoch 292, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 292, Batch 3/4: Zeroing gradients...
  Epoch 292, Batch 3/4: Forward pass...
  Epoch 292, Batch 3/4: Calculating loss...
  Epoch 292, Batch 3/4: Backward pass...
  Epoch 292, Batch 3/4: Clipping gradients...
  Epoch 292, Batch 3/4: Optimizer step...
  Epoch 292, Batch 3/4: Completed in 0.19s
  Epoch 292, Batch 4/4: Loading data to device...
  Epoch 292, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 292, Batch 4/4: Zeroing gradients...
  Epoch 292, Batch 4/4: Forward pass...
  Epoch 292, Batch 4/4: Calculating loss...
  Epoch 292, Batch 4/4: Backward pass...
  Epoch 292, Batch 4/4: Clipping gradients...
  Epoch 292, Batch 4/4: Optimizer step...
  Epoch 292, Batch 4/4: Completed in 0.04s
Epoch 292: Training phase completed. Average Train Loss: 0.3273
Epoch 292: Starting validation phase...
  Epoch 292, Val Batch 1/1: Loading data...
  Epoch 292, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 292, Val Batch 1/1: Forward pass...
  Epoch 292, Val Batch 1/1: Calculating loss...
Epoch 292: Validation phase completed. Average Val Loss: 0.2799
Epoch 292 Summary ---> Train Loss: 0.3273 / Validation Loss: 0.2799
Epoch 292: Checking early stopping... (Current Best Loss: 0.2812, Epochs No Improve: 0)
  Epoch 292: Validation loss improved (0.2812 --> 0.2799). Saving model.
Epoch 292: Stepping scheduler...
--- Epoch 292 completed in 0.66 seconds ---

--- Starting Epoch 293/1000 ---
Epoch 293: Starting training phase (4 batches)
  Epoch 293, Batch 1/4: Loading data to device...
  Epoch 293, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 293, Batch 1/4: Zeroing gradients...
  Epoch 293, Batch 1/4: Forward pass...
  Epoch 293, Batch 1/4: Calculating loss...
  Epoch 293, Batch 1/4: Backward pass...
  Epoch 293, Batch 1/4: Clipping gradients...
  Epoch 293, Batch 1/4: Optimizer step...
  Epoch 293, Batch 1/4: Completed in 0.19s
  Epoch 293, Batch 2/4: Loading data to device...
  Epoch 293, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 293, Batch 2/4: Zeroing gradients...
  Epoch 293, Batch 2/4: Forward pass...
  Epoch 293, Batch 2/4: Calculating loss...
  Epoch 293, Batch 2/4: Backward pass...
  Epoch 293, Batch 2/4: Clipping gradients...
  Epoch 293, Batch 2/4: Optimizer step...
  Epoch 293, Batch 2/4: Completed in 0.19s
  Epoch 293, Batch 3/4: Loading data to device...
  Epoch 293, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 293, Batch 3/4: Zeroing gradients...
  Epoch 293, Batch 3/4: Forward pass...
  Epoch 293, Batch 3/4: Calculating loss...
  Epoch 293, Batch 3/4: Backward pass...
  Epoch 293, Batch 3/4: Clipping gradients...
  Epoch 293, Batch 3/4: Optimizer step...
  Epoch 293, Batch 3/4: Completed in 0.19s
  Epoch 293, Batch 4/4: Loading data to device...
  Epoch 293, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 293, Batch 4/4: Zeroing gradients...
  Epoch 293, Batch 4/4: Forward pass...
  Epoch 293, Batch 4/4: Calculating loss...
  Epoch 293, Batch 4/4: Backward pass...
  Epoch 293, Batch 4/4: Clipping gradients...
  Epoch 293, Batch 4/4: Optimizer step...
  Epoch 293, Batch 4/4: Completed in 0.03s
Epoch 293: Training phase completed. Average Train Loss: 0.3562
Epoch 293: Starting validation phase...
  Epoch 293, Val Batch 1/1: Loading data...
  Epoch 293, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 293, Val Batch 1/1: Forward pass...
  Epoch 293, Val Batch 1/1: Calculating loss...
Epoch 293: Validation phase completed. Average Val Loss: 0.2826
Epoch 293 Summary ---> Train Loss: 0.3562 / Validation Loss: 0.2826
Epoch 293: Checking early stopping... (Current Best Loss: 0.2799, Epochs No Improve: 0)
  Epoch 293: Validation loss did not improve. Epochs without improvement: 1
Epoch 293: Stepping scheduler...
--- Epoch 293 completed in 0.66 seconds ---

--- Starting Epoch 294/1000 ---
Epoch 294: Starting training phase (4 batches)
  Epoch 294, Batch 1/4: Loading data to device...
  Epoch 294, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 294, Batch 1/4: Zeroing gradients...
  Epoch 294, Batch 1/4: Forward pass...
  Epoch 294, Batch 1/4: Calculating loss...
  Epoch 294, Batch 1/4: Backward pass...
  Epoch 294, Batch 1/4: Clipping gradients...
  Epoch 294, Batch 1/4: Optimizer step...
  Epoch 294, Batch 1/4: Completed in 0.19s
  Epoch 294, Batch 2/4: Loading data to device...
  Epoch 294, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 294, Batch 2/4: Zeroing gradients...
  Epoch 294, Batch 2/4: Forward pass...
  Epoch 294, Batch 2/4: Calculating loss...
  Epoch 294, Batch 2/4: Backward pass...
  Epoch 294, Batch 2/4: Clipping gradients...
  Epoch 294, Batch 2/4: Optimizer step...
  Epoch 294, Batch 2/4: Completed in 0.20s
  Epoch 294, Batch 3/4: Loading data to device...
  Epoch 294, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 294, Batch 3/4: Zeroing gradients...
  Epoch 294, Batch 3/4: Forward pass...
  Epoch 294, Batch 3/4: Calculating loss...
  Epoch 294, Batch 3/4: Backward pass...
  Epoch 294, Batch 3/4: Clipping gradients...
  Epoch 294, Batch 3/4: Optimizer step...
  Epoch 294, Batch 3/4: Completed in 0.19s
  Epoch 294, Batch 4/4: Loading data to device...
  Epoch 294, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 294, Batch 4/4: Zeroing gradients...
  Epoch 294, Batch 4/4: Forward pass...
  Epoch 294, Batch 4/4: Calculating loss...
  Epoch 294, Batch 4/4: Backward pass...
  Epoch 294, Batch 4/4: Clipping gradients...
  Epoch 294, Batch 4/4: Optimizer step...
  Epoch 294, Batch 4/4: Completed in 0.03s
Epoch 294: Training phase completed. Average Train Loss: 0.3264
Epoch 294: Starting validation phase...
  Epoch 294, Val Batch 1/1: Loading data...
  Epoch 294, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 294, Val Batch 1/1: Forward pass...
  Epoch 294, Val Batch 1/1: Calculating loss...
Epoch 294: Validation phase completed. Average Val Loss: 0.2871
Epoch 294 Summary ---> Train Loss: 0.3264 / Validation Loss: 0.2871
Epoch 294: Checking early stopping... (Current Best Loss: 0.2799, Epochs No Improve: 1)
  Epoch 294: Validation loss did not improve. Epochs without improvement: 2
Epoch 294: Stepping scheduler...
--- Epoch 294 completed in 0.67 seconds ---

--- Starting Epoch 295/1000 ---
Epoch 295: Starting training phase (4 batches)
  Epoch 295, Batch 1/4: Loading data to device...
  Epoch 295, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 295, Batch 1/4: Zeroing gradients...
  Epoch 295, Batch 1/4: Forward pass...
  Epoch 295, Batch 1/4: Calculating loss...
  Epoch 295, Batch 1/4: Backward pass...
  Epoch 295, Batch 1/4: Clipping gradients...
  Epoch 295, Batch 1/4: Optimizer step...
  Epoch 295, Batch 1/4: Completed in 0.19s
  Epoch 295, Batch 2/4: Loading data to device...
  Epoch 295, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 295, Batch 2/4: Zeroing gradients...
  Epoch 295, Batch 2/4: Forward pass...
  Epoch 295, Batch 2/4: Calculating loss...
  Epoch 295, Batch 2/4: Backward pass...
  Epoch 295, Batch 2/4: Clipping gradients...
  Epoch 295, Batch 2/4: Optimizer step...
  Epoch 295, Batch 2/4: Completed in 0.19s
  Epoch 295, Batch 3/4: Loading data to device...
  Epoch 295, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 295, Batch 3/4: Zeroing gradients...
  Epoch 295, Batch 3/4: Forward pass...
  Epoch 295, Batch 3/4: Calculating loss...
  Epoch 295, Batch 3/4: Backward pass...
  Epoch 295, Batch 3/4: Clipping gradients...
  Epoch 295, Batch 3/4: Optimizer step...
  Epoch 295, Batch 3/4: Completed in 0.19s
  Epoch 295, Batch 4/4: Loading data to device...
  Epoch 295, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 295, Batch 4/4: Zeroing gradients...
  Epoch 295, Batch 4/4: Forward pass...
  Epoch 295, Batch 4/4: Calculating loss...
  Epoch 295, Batch 4/4: Backward pass...
  Epoch 295, Batch 4/4: Clipping gradients...
  Epoch 295, Batch 4/4: Optimizer step...
  Epoch 295, Batch 4/4: Completed in 0.03s
Epoch 295: Training phase completed. Average Train Loss: 0.3387
Epoch 295: Starting validation phase...
  Epoch 295, Val Batch 1/1: Loading data...
  Epoch 295, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 295, Val Batch 1/1: Forward pass...
  Epoch 295, Val Batch 1/1: Calculating loss...
Epoch 295: Validation phase completed. Average Val Loss: 0.2848
Epoch 295 Summary ---> Train Loss: 0.3387 / Validation Loss: 0.2848
Epoch 295: Checking early stopping... (Current Best Loss: 0.2799, Epochs No Improve: 2)
  Epoch 295: Validation loss did not improve. Epochs without improvement: 3
Epoch 295: Stepping scheduler...
--- Epoch 295 completed in 0.67 seconds ---

--- Starting Epoch 296/1000 ---
Epoch 296: Starting training phase (4 batches)
  Epoch 296, Batch 1/4: Loading data to device...
  Epoch 296, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 296, Batch 1/4: Zeroing gradients...
  Epoch 296, Batch 1/4: Forward pass...
  Epoch 296, Batch 1/4: Calculating loss...
  Epoch 296, Batch 1/4: Backward pass...
  Epoch 296, Batch 1/4: Clipping gradients...
  Epoch 296, Batch 1/4: Optimizer step...
  Epoch 296, Batch 1/4: Completed in 0.19s
  Epoch 296, Batch 2/4: Loading data to device...
  Epoch 296, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 296, Batch 2/4: Zeroing gradients...
  Epoch 296, Batch 2/4: Forward pass...
  Epoch 296, Batch 2/4: Calculating loss...
  Epoch 296, Batch 2/4: Backward pass...
  Epoch 296, Batch 2/4: Clipping gradients...
  Epoch 296, Batch 2/4: Optimizer step...
  Epoch 296, Batch 2/4: Completed in 0.19s
  Epoch 296, Batch 3/4: Loading data to device...
  Epoch 296, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 296, Batch 3/4: Zeroing gradients...
  Epoch 296, Batch 3/4: Forward pass...
  Epoch 296, Batch 3/4: Calculating loss...
  Epoch 296, Batch 3/4: Backward pass...
  Epoch 296, Batch 3/4: Clipping gradients...
  Epoch 296, Batch 3/4: Optimizer step...
  Epoch 296, Batch 3/4: Completed in 0.19s
  Epoch 296, Batch 4/4: Loading data to device...
  Epoch 296, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 296, Batch 4/4: Zeroing gradients...
  Epoch 296, Batch 4/4: Forward pass...
  Epoch 296, Batch 4/4: Calculating loss...
  Epoch 296, Batch 4/4: Backward pass...
  Epoch 296, Batch 4/4: Clipping gradients...
  Epoch 296, Batch 4/4: Optimizer step...
  Epoch 296, Batch 4/4: Completed in 0.03s
Epoch 296: Training phase completed. Average Train Loss: 0.3457
Epoch 296: Starting validation phase...
  Epoch 296, Val Batch 1/1: Loading data...
  Epoch 296, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 296, Val Batch 1/1: Forward pass...
  Epoch 296, Val Batch 1/1: Calculating loss...
Epoch 296: Validation phase completed. Average Val Loss: 0.2827
Epoch 296 Summary ---> Train Loss: 0.3457 / Validation Loss: 0.2827
Epoch 296: Checking early stopping... (Current Best Loss: 0.2799, Epochs No Improve: 3)
  Epoch 296: Validation loss did not improve. Epochs without improvement: 4
Epoch 296: Stepping scheduler...
--- Epoch 296 completed in 0.67 seconds ---

--- Starting Epoch 297/1000 ---
Epoch 297: Starting training phase (4 batches)
  Epoch 297, Batch 1/4: Loading data to device...
  Epoch 297, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 297, Batch 1/4: Zeroing gradients...
  Epoch 297, Batch 1/4: Forward pass...
  Epoch 297, Batch 1/4: Calculating loss...
  Epoch 297, Batch 1/4: Backward pass...
  Epoch 297, Batch 1/4: Clipping gradients...
  Epoch 297, Batch 1/4: Optimizer step...
  Epoch 297, Batch 1/4: Completed in 0.20s
  Epoch 297, Batch 2/4: Loading data to device...
  Epoch 297, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 297, Batch 2/4: Zeroing gradients...
  Epoch 297, Batch 2/4: Forward pass...
  Epoch 297, Batch 2/4: Calculating loss...
  Epoch 297, Batch 2/4: Backward pass...
  Epoch 297, Batch 2/4: Clipping gradients...
  Epoch 297, Batch 2/4: Optimizer step...
  Epoch 297, Batch 2/4: Completed in 0.19s
  Epoch 297, Batch 3/4: Loading data to device...
  Epoch 297, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 297, Batch 3/4: Zeroing gradients...
  Epoch 297, Batch 3/4: Forward pass...
  Epoch 297, Batch 3/4: Calculating loss...
  Epoch 297, Batch 3/4: Backward pass...
  Epoch 297, Batch 3/4: Clipping gradients...
  Epoch 297, Batch 3/4: Optimizer step...
  Epoch 297, Batch 3/4: Completed in 0.20s
  Epoch 297, Batch 4/4: Loading data to device...
  Epoch 297, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 297, Batch 4/4: Zeroing gradients...
  Epoch 297, Batch 4/4: Forward pass...
  Epoch 297, Batch 4/4: Calculating loss...
  Epoch 297, Batch 4/4: Backward pass...
  Epoch 297, Batch 4/4: Clipping gradients...
  Epoch 297, Batch 4/4: Optimizer step...
  Epoch 297, Batch 4/4: Completed in 0.03s
Epoch 297: Training phase completed. Average Train Loss: 0.3168
Epoch 297: Starting validation phase...
  Epoch 297, Val Batch 1/1: Loading data...
  Epoch 297, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 297, Val Batch 1/1: Forward pass...
  Epoch 297, Val Batch 1/1: Calculating loss...
Epoch 297: Validation phase completed. Average Val Loss: 0.2862
Epoch 297 Summary ---> Train Loss: 0.3168 / Validation Loss: 0.2862
Epoch 297: Checking early stopping... (Current Best Loss: 0.2799, Epochs No Improve: 4)
  Epoch 297: Validation loss did not improve. Epochs without improvement: 5
Epoch 297: Stepping scheduler...
--- Epoch 297 completed in 0.69 seconds ---

--- Starting Epoch 298/1000 ---
Epoch 298: Starting training phase (4 batches)
  Epoch 298, Batch 1/4: Loading data to device...
  Epoch 298, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 298, Batch 1/4: Zeroing gradients...
  Epoch 298, Batch 1/4: Forward pass...
  Epoch 298, Batch 1/4: Calculating loss...
  Epoch 298, Batch 1/4: Backward pass...
  Epoch 298, Batch 1/4: Clipping gradients...
  Epoch 298, Batch 1/4: Optimizer step...
  Epoch 298, Batch 1/4: Completed in 0.20s
  Epoch 298, Batch 2/4: Loading data to device...
  Epoch 298, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 298, Batch 2/4: Zeroing gradients...
  Epoch 298, Batch 2/4: Forward pass...
  Epoch 298, Batch 2/4: Calculating loss...
  Epoch 298, Batch 2/4: Backward pass...
  Epoch 298, Batch 2/4: Clipping gradients...
  Epoch 298, Batch 2/4: Optimizer step...
  Epoch 298, Batch 2/4: Completed in 0.19s
  Epoch 298, Batch 3/4: Loading data to device...
  Epoch 298, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 298, Batch 3/4: Zeroing gradients...
  Epoch 298, Batch 3/4: Forward pass...
  Epoch 298, Batch 3/4: Calculating loss...
  Epoch 298, Batch 3/4: Backward pass...
  Epoch 298, Batch 3/4: Clipping gradients...
  Epoch 298, Batch 3/4: Optimizer step...
  Epoch 298, Batch 3/4: Completed in 0.19s
  Epoch 298, Batch 4/4: Loading data to device...
  Epoch 298, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 298, Batch 4/4: Zeroing gradients...
  Epoch 298, Batch 4/4: Forward pass...
  Epoch 298, Batch 4/4: Calculating loss...
  Epoch 298, Batch 4/4: Backward pass...
  Epoch 298, Batch 4/4: Clipping gradients...
  Epoch 298, Batch 4/4: Optimizer step...
  Epoch 298, Batch 4/4: Completed in 0.03s
Epoch 298: Training phase completed. Average Train Loss: 0.3818
Epoch 298: Starting validation phase...
  Epoch 298, Val Batch 1/1: Loading data...
  Epoch 298, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 298, Val Batch 1/1: Forward pass...
  Epoch 298, Val Batch 1/1: Calculating loss...
Epoch 298: Validation phase completed. Average Val Loss: 0.2856
Epoch 298 Summary ---> Train Loss: 0.3818 / Validation Loss: 0.2856
Epoch 298: Checking early stopping... (Current Best Loss: 0.2799, Epochs No Improve: 5)
  Epoch 298: Validation loss did not improve. Epochs without improvement: 6
Epoch 298: Stepping scheduler...
--- Epoch 298 completed in 0.68 seconds ---

--- Starting Epoch 299/1000 ---
Epoch 299: Starting training phase (4 batches)
  Epoch 299, Batch 1/4: Loading data to device...
  Epoch 299, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 299, Batch 1/4: Zeroing gradients...
  Epoch 299, Batch 1/4: Forward pass...
  Epoch 299, Batch 1/4: Calculating loss...
  Epoch 299, Batch 1/4: Backward pass...
  Epoch 299, Batch 1/4: Clipping gradients...
  Epoch 299, Batch 1/4: Optimizer step...
  Epoch 299, Batch 1/4: Completed in 0.20s
  Epoch 299, Batch 2/4: Loading data to device...
  Epoch 299, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 299, Batch 2/4: Zeroing gradients...
  Epoch 299, Batch 2/4: Forward pass...
  Epoch 299, Batch 2/4: Calculating loss...
  Epoch 299, Batch 2/4: Backward pass...
  Epoch 299, Batch 2/4: Clipping gradients...
  Epoch 299, Batch 2/4: Optimizer step...
  Epoch 299, Batch 2/4: Completed in 0.19s
  Epoch 299, Batch 3/4: Loading data to device...
  Epoch 299, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 299, Batch 3/4: Zeroing gradients...
  Epoch 299, Batch 3/4: Forward pass...
  Epoch 299, Batch 3/4: Calculating loss...
  Epoch 299, Batch 3/4: Backward pass...
  Epoch 299, Batch 3/4: Clipping gradients...
  Epoch 299, Batch 3/4: Optimizer step...
  Epoch 299, Batch 3/4: Completed in 0.19s
  Epoch 299, Batch 4/4: Loading data to device...
  Epoch 299, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 299, Batch 4/4: Zeroing gradients...
  Epoch 299, Batch 4/4: Forward pass...
  Epoch 299, Batch 4/4: Calculating loss...
  Epoch 299, Batch 4/4: Backward pass...
  Epoch 299, Batch 4/4: Clipping gradients...
  Epoch 299, Batch 4/4: Optimizer step...
  Epoch 299, Batch 4/4: Completed in 0.03s
Epoch 299: Training phase completed. Average Train Loss: 0.3242
Epoch 299: Starting validation phase...
  Epoch 299, Val Batch 1/1: Loading data...
  Epoch 299, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 299, Val Batch 1/1: Forward pass...
  Epoch 299, Val Batch 1/1: Calculating loss...
Epoch 299: Validation phase completed. Average Val Loss: 0.2812
Epoch 299 Summary ---> Train Loss: 0.3242 / Validation Loss: 0.2812
Epoch 299: Checking early stopping... (Current Best Loss: 0.2799, Epochs No Improve: 6)
  Epoch 299: Validation loss did not improve. Epochs without improvement: 7
Epoch 299: Stepping scheduler...
--- Epoch 299 completed in 0.68 seconds ---

--- Starting Epoch 300/1000 ---
Epoch 300: Starting training phase (4 batches)
  Epoch 300, Batch 1/4: Loading data to device...
  Epoch 300, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 300, Batch 1/4: Zeroing gradients...
  Epoch 300, Batch 1/4: Forward pass...
  Epoch 300, Batch 1/4: Calculating loss...
  Epoch 300, Batch 1/4: Backward pass...
  Epoch 300, Batch 1/4: Clipping gradients...
  Epoch 300, Batch 1/4: Optimizer step...
  Epoch 300, Batch 1/4: Completed in 0.19s
  Epoch 300, Batch 2/4: Loading data to device...
  Epoch 300, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 300, Batch 2/4: Zeroing gradients...
  Epoch 300, Batch 2/4: Forward pass...
  Epoch 300, Batch 2/4: Calculating loss...
  Epoch 300, Batch 2/4: Backward pass...
  Epoch 300, Batch 2/4: Clipping gradients...
  Epoch 300, Batch 2/4: Optimizer step...
  Epoch 300, Batch 2/4: Completed in 0.19s
  Epoch 300, Batch 3/4: Loading data to device...
  Epoch 300, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 300, Batch 3/4: Zeroing gradients...
  Epoch 300, Batch 3/4: Forward pass...
  Epoch 300, Batch 3/4: Calculating loss...
  Epoch 300, Batch 3/4: Backward pass...
  Epoch 300, Batch 3/4: Clipping gradients...
  Epoch 300, Batch 3/4: Optimizer step...
  Epoch 300, Batch 3/4: Completed in 0.19s
  Epoch 300, Batch 4/4: Loading data to device...
  Epoch 300, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 300, Batch 4/4: Zeroing gradients...
  Epoch 300, Batch 4/4: Forward pass...
  Epoch 300, Batch 4/4: Calculating loss...
  Epoch 300, Batch 4/4: Backward pass...
  Epoch 300, Batch 4/4: Clipping gradients...
  Epoch 300, Batch 4/4: Optimizer step...
  Epoch 300, Batch 4/4: Completed in 0.03s
Epoch 300: Training phase completed. Average Train Loss: 0.3555
Epoch 300: Starting validation phase...
  Epoch 300, Val Batch 1/1: Loading data...
  Epoch 300, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 300, Val Batch 1/1: Forward pass...
  Epoch 300, Val Batch 1/1: Calculating loss...
Epoch 300: Validation phase completed. Average Val Loss: 0.2866
Epoch 300 Summary ---> Train Loss: 0.3555 / Validation Loss: 0.2866
Epoch 300: Checking early stopping... (Current Best Loss: 0.2799, Epochs No Improve: 7)
  Epoch 300: Validation loss did not improve. Epochs without improvement: 8
Epoch 300: Stepping scheduler...
--- Epoch 300 completed in 0.66 seconds ---

--- Starting Epoch 301/1000 ---
Epoch 301: Starting training phase (4 batches)
  Epoch 301, Batch 1/4: Loading data to device...
  Epoch 301, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 301, Batch 1/4: Zeroing gradients...
  Epoch 301, Batch 1/4: Forward pass...
  Epoch 301, Batch 1/4: Calculating loss...
  Epoch 301, Batch 1/4: Backward pass...
  Epoch 301, Batch 1/4: Clipping gradients...
  Epoch 301, Batch 1/4: Optimizer step...
  Epoch 301, Batch 1/4: Completed in 0.19s
  Epoch 301, Batch 2/4: Loading data to device...
  Epoch 301, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 301, Batch 2/4: Zeroing gradients...
  Epoch 301, Batch 2/4: Forward pass...
  Epoch 301, Batch 2/4: Calculating loss...
  Epoch 301, Batch 2/4: Backward pass...
  Epoch 301, Batch 2/4: Clipping gradients...
  Epoch 301, Batch 2/4: Optimizer step...
  Epoch 301, Batch 2/4: Completed in 0.19s
  Epoch 301, Batch 3/4: Loading data to device...
  Epoch 301, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 301, Batch 3/4: Zeroing gradients...
  Epoch 301, Batch 3/4: Forward pass...
  Epoch 301, Batch 3/4: Calculating loss...
  Epoch 301, Batch 3/4: Backward pass...
  Epoch 301, Batch 3/4: Clipping gradients...
  Epoch 301, Batch 3/4: Optimizer step...
  Epoch 301, Batch 3/4: Completed in 0.18s
  Epoch 301, Batch 4/4: Loading data to device...
  Epoch 301, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 301, Batch 4/4: Zeroing gradients...
  Epoch 301, Batch 4/4: Forward pass...
  Epoch 301, Batch 4/4: Calculating loss...
  Epoch 301, Batch 4/4: Backward pass...
  Epoch 301, Batch 4/4: Clipping gradients...
  Epoch 301, Batch 4/4: Optimizer step...
  Epoch 301, Batch 4/4: Completed in 0.03s
Epoch 301: Training phase completed. Average Train Loss: 0.3130
Epoch 301: Starting validation phase...
  Epoch 301, Val Batch 1/1: Loading data...
  Epoch 301, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 301, Val Batch 1/1: Forward pass...
  Epoch 301, Val Batch 1/1: Calculating loss...
Epoch 301: Validation phase completed. Average Val Loss: 0.2819
Epoch 301 Summary ---> Train Loss: 0.3130 / Validation Loss: 0.2819
Epoch 301: Checking early stopping... (Current Best Loss: 0.2799, Epochs No Improve: 8)
  Epoch 301: Validation loss did not improve. Epochs without improvement: 9
Epoch 301: Stepping scheduler...
--- Epoch 301 completed in 0.65 seconds ---

--- Starting Epoch 302/1000 ---
Epoch 302: Starting training phase (4 batches)
  Epoch 302, Batch 1/4: Loading data to device...
  Epoch 302, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 302, Batch 1/4: Zeroing gradients...
  Epoch 302, Batch 1/4: Forward pass...
  Epoch 302, Batch 1/4: Calculating loss...
  Epoch 302, Batch 1/4: Backward pass...
  Epoch 302, Batch 1/4: Clipping gradients...
  Epoch 302, Batch 1/4: Optimizer step...
  Epoch 302, Batch 1/4: Completed in 0.19s
  Epoch 302, Batch 2/4: Loading data to device...
  Epoch 302, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 302, Batch 2/4: Zeroing gradients...
  Epoch 302, Batch 2/4: Forward pass...
  Epoch 302, Batch 2/4: Calculating loss...
  Epoch 302, Batch 2/4: Backward pass...
  Epoch 302, Batch 2/4: Clipping gradients...
  Epoch 302, Batch 2/4: Optimizer step...
  Epoch 302, Batch 2/4: Completed in 0.18s
  Epoch 302, Batch 3/4: Loading data to device...
  Epoch 302, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 302, Batch 3/4: Zeroing gradients...
  Epoch 302, Batch 3/4: Forward pass...
  Epoch 302, Batch 3/4: Calculating loss...
  Epoch 302, Batch 3/4: Backward pass...
  Epoch 302, Batch 3/4: Clipping gradients...
  Epoch 302, Batch 3/4: Optimizer step...
  Epoch 302, Batch 3/4: Completed in 0.18s
  Epoch 302, Batch 4/4: Loading data to device...
  Epoch 302, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 302, Batch 4/4: Zeroing gradients...
  Epoch 302, Batch 4/4: Forward pass...
  Epoch 302, Batch 4/4: Calculating loss...
  Epoch 302, Batch 4/4: Backward pass...
  Epoch 302, Batch 4/4: Clipping gradients...
  Epoch 302, Batch 4/4: Optimizer step...
  Epoch 302, Batch 4/4: Completed in 0.03s
Epoch 302: Training phase completed. Average Train Loss: 0.3541
Epoch 302: Starting validation phase...
  Epoch 302, Val Batch 1/1: Loading data...
  Epoch 302, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 302, Val Batch 1/1: Forward pass...
  Epoch 302, Val Batch 1/1: Calculating loss...
Epoch 302: Validation phase completed. Average Val Loss: 0.2777
Epoch 302 Summary ---> Train Loss: 0.3541 / Validation Loss: 0.2777
Epoch 302: Checking early stopping... (Current Best Loss: 0.2799, Epochs No Improve: 9)
  Epoch 302: Validation loss improved (0.2799 --> 0.2777). Saving model.
Epoch 302: Stepping scheduler...
--- Epoch 302 completed in 0.66 seconds ---

--- Starting Epoch 303/1000 ---
Epoch 303: Starting training phase (4 batches)
  Epoch 303, Batch 1/4: Loading data to device...
  Epoch 303, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 303, Batch 1/4: Zeroing gradients...
  Epoch 303, Batch 1/4: Forward pass...
  Epoch 303, Batch 1/4: Calculating loss...
  Epoch 303, Batch 1/4: Backward pass...
  Epoch 303, Batch 1/4: Clipping gradients...
  Epoch 303, Batch 1/4: Optimizer step...
  Epoch 303, Batch 1/4: Completed in 0.19s
  Epoch 303, Batch 2/4: Loading data to device...
  Epoch 303, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 303, Batch 2/4: Zeroing gradients...
  Epoch 303, Batch 2/4: Forward pass...
  Epoch 303, Batch 2/4: Calculating loss...
  Epoch 303, Batch 2/4: Backward pass...
  Epoch 303, Batch 2/4: Clipping gradients...
  Epoch 303, Batch 2/4: Optimizer step...
  Epoch 303, Batch 2/4: Completed in 0.19s
  Epoch 303, Batch 3/4: Loading data to device...
  Epoch 303, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 303, Batch 3/4: Zeroing gradients...
  Epoch 303, Batch 3/4: Forward pass...
  Epoch 303, Batch 3/4: Calculating loss...
  Epoch 303, Batch 3/4: Backward pass...
  Epoch 303, Batch 3/4: Clipping gradients...
  Epoch 303, Batch 3/4: Optimizer step...
  Epoch 303, Batch 3/4: Completed in 0.19s
  Epoch 303, Batch 4/4: Loading data to device...
  Epoch 303, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 303, Batch 4/4: Zeroing gradients...
  Epoch 303, Batch 4/4: Forward pass...
  Epoch 303, Batch 4/4: Calculating loss...
  Epoch 303, Batch 4/4: Backward pass...
  Epoch 303, Batch 4/4: Clipping gradients...
  Epoch 303, Batch 4/4: Optimizer step...
  Epoch 303, Batch 4/4: Completed in 0.03s
Epoch 303: Training phase completed. Average Train Loss: 0.3278
Epoch 303: Starting validation phase...
  Epoch 303, Val Batch 1/1: Loading data...
  Epoch 303, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 303, Val Batch 1/1: Forward pass...
  Epoch 303, Val Batch 1/1: Calculating loss...
Epoch 303: Validation phase completed. Average Val Loss: 0.2824
Epoch 303 Summary ---> Train Loss: 0.3278 / Validation Loss: 0.2824
Epoch 303: Checking early stopping... (Current Best Loss: 0.2777, Epochs No Improve: 0)
  Epoch 303: Validation loss did not improve. Epochs without improvement: 1
Epoch 303: Stepping scheduler...
--- Epoch 303 completed in 0.65 seconds ---

--- Starting Epoch 304/1000 ---
Epoch 304: Starting training phase (4 batches)
  Epoch 304, Batch 1/4: Loading data to device...
  Epoch 304, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 304, Batch 1/4: Zeroing gradients...
  Epoch 304, Batch 1/4: Forward pass...
  Epoch 304, Batch 1/4: Calculating loss...
  Epoch 304, Batch 1/4: Backward pass...
  Epoch 304, Batch 1/4: Clipping gradients...
  Epoch 304, Batch 1/4: Optimizer step...
  Epoch 304, Batch 1/4: Completed in 0.19s
  Epoch 304, Batch 2/4: Loading data to device...
  Epoch 304, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 304, Batch 2/4: Zeroing gradients...
  Epoch 304, Batch 2/4: Forward pass...
  Epoch 304, Batch 2/4: Calculating loss...
  Epoch 304, Batch 2/4: Backward pass...
  Epoch 304, Batch 2/4: Clipping gradients...
  Epoch 304, Batch 2/4: Optimizer step...
  Epoch 304, Batch 2/4: Completed in 0.19s
  Epoch 304, Batch 3/4: Loading data to device...
  Epoch 304, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 304, Batch 3/4: Zeroing gradients...
  Epoch 304, Batch 3/4: Forward pass...
  Epoch 304, Batch 3/4: Calculating loss...
  Epoch 304, Batch 3/4: Backward pass...
  Epoch 304, Batch 3/4: Clipping gradients...
  Epoch 304, Batch 3/4: Optimizer step...
  Epoch 304, Batch 3/4: Completed in 0.19s
  Epoch 304, Batch 4/4: Loading data to device...
  Epoch 304, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 304, Batch 4/4: Zeroing gradients...
  Epoch 304, Batch 4/4: Forward pass...
  Epoch 304, Batch 4/4: Calculating loss...
  Epoch 304, Batch 4/4: Backward pass...
  Epoch 304, Batch 4/4: Clipping gradients...
  Epoch 304, Batch 4/4: Optimizer step...
  Epoch 304, Batch 4/4: Completed in 0.04s
Epoch 304: Training phase completed. Average Train Loss: 0.3124
Epoch 304: Starting validation phase...
  Epoch 304, Val Batch 1/1: Loading data...
  Epoch 304, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 304, Val Batch 1/1: Forward pass...
  Epoch 304, Val Batch 1/1: Calculating loss...
Epoch 304: Validation phase completed. Average Val Loss: 0.2802
Epoch 304 Summary ---> Train Loss: 0.3124 / Validation Loss: 0.2802
Epoch 304: Checking early stopping... (Current Best Loss: 0.2777, Epochs No Improve: 1)
  Epoch 304: Validation loss did not improve. Epochs without improvement: 2
Epoch 304: Stepping scheduler...
--- Epoch 304 completed in 0.67 seconds ---

--- Starting Epoch 305/1000 ---
Epoch 305: Starting training phase (4 batches)
  Epoch 305, Batch 1/4: Loading data to device...
  Epoch 305, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 305, Batch 1/4: Zeroing gradients...
  Epoch 305, Batch 1/4: Forward pass...
  Epoch 305, Batch 1/4: Calculating loss...
  Epoch 305, Batch 1/4: Backward pass...
  Epoch 305, Batch 1/4: Clipping gradients...
  Epoch 305, Batch 1/4: Optimizer step...
  Epoch 305, Batch 1/4: Completed in 0.19s
  Epoch 305, Batch 2/4: Loading data to device...
  Epoch 305, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 305, Batch 2/4: Zeroing gradients...
  Epoch 305, Batch 2/4: Forward pass...
  Epoch 305, Batch 2/4: Calculating loss...
  Epoch 305, Batch 2/4: Backward pass...
  Epoch 305, Batch 2/4: Clipping gradients...
  Epoch 305, Batch 2/4: Optimizer step...
  Epoch 305, Batch 2/4: Completed in 0.18s
  Epoch 305, Batch 3/4: Loading data to device...
  Epoch 305, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 305, Batch 3/4: Zeroing gradients...
  Epoch 305, Batch 3/4: Forward pass...
  Epoch 305, Batch 3/4: Calculating loss...
  Epoch 305, Batch 3/4: Backward pass...
  Epoch 305, Batch 3/4: Clipping gradients...
  Epoch 305, Batch 3/4: Optimizer step...
  Epoch 305, Batch 3/4: Completed in 0.19s
  Epoch 305, Batch 4/4: Loading data to device...
  Epoch 305, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 305, Batch 4/4: Zeroing gradients...
  Epoch 305, Batch 4/4: Forward pass...
  Epoch 305, Batch 4/4: Calculating loss...
  Epoch 305, Batch 4/4: Backward pass...
  Epoch 305, Batch 4/4: Clipping gradients...
  Epoch 305, Batch 4/4: Optimizer step...
  Epoch 305, Batch 4/4: Completed in 0.03s
Epoch 305: Training phase completed. Average Train Loss: 0.3042
Epoch 305: Starting validation phase...
  Epoch 305, Val Batch 1/1: Loading data...
  Epoch 305, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 305, Val Batch 1/1: Forward pass...
  Epoch 305, Val Batch 1/1: Calculating loss...
Epoch 305: Validation phase completed. Average Val Loss: 0.2822
Epoch 305 Summary ---> Train Loss: 0.3042 / Validation Loss: 0.2822
Epoch 305: Checking early stopping... (Current Best Loss: 0.2777, Epochs No Improve: 2)
  Epoch 305: Validation loss did not improve. Epochs without improvement: 3
Epoch 305: Stepping scheduler...
--- Epoch 305 completed in 0.66 seconds ---

--- Starting Epoch 306/1000 ---
Epoch 306: Starting training phase (4 batches)
  Epoch 306, Batch 1/4: Loading data to device...
  Epoch 306, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 306, Batch 1/4: Zeroing gradients...
  Epoch 306, Batch 1/4: Forward pass...
  Epoch 306, Batch 1/4: Calculating loss...
  Epoch 306, Batch 1/4: Backward pass...
  Epoch 306, Batch 1/4: Clipping gradients...
  Epoch 306, Batch 1/4: Optimizer step...
  Epoch 306, Batch 1/4: Completed in 0.19s
  Epoch 306, Batch 2/4: Loading data to device...
  Epoch 306, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 306, Batch 2/4: Zeroing gradients...
  Epoch 306, Batch 2/4: Forward pass...
  Epoch 306, Batch 2/4: Calculating loss...
  Epoch 306, Batch 2/4: Backward pass...
  Epoch 306, Batch 2/4: Clipping gradients...
  Epoch 306, Batch 2/4: Optimizer step...
  Epoch 306, Batch 2/4: Completed in 0.20s
  Epoch 306, Batch 3/4: Loading data to device...
  Epoch 306, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 306, Batch 3/4: Zeroing gradients...
  Epoch 306, Batch 3/4: Forward pass...
  Epoch 306, Batch 3/4: Calculating loss...
  Epoch 306, Batch 3/4: Backward pass...
  Epoch 306, Batch 3/4: Clipping gradients...
  Epoch 306, Batch 3/4: Optimizer step...
  Epoch 306, Batch 3/4: Completed in 0.20s
  Epoch 306, Batch 4/4: Loading data to device...
  Epoch 306, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 306, Batch 4/4: Zeroing gradients...
  Epoch 306, Batch 4/4: Forward pass...
  Epoch 306, Batch 4/4: Calculating loss...
  Epoch 306, Batch 4/4: Backward pass...
  Epoch 306, Batch 4/4: Clipping gradients...
  Epoch 306, Batch 4/4: Optimizer step...
  Epoch 306, Batch 4/4: Completed in 0.03s
Epoch 306: Training phase completed. Average Train Loss: 0.4119
Epoch 306: Starting validation phase...
  Epoch 306, Val Batch 1/1: Loading data...
  Epoch 306, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 306, Val Batch 1/1: Forward pass...
  Epoch 306, Val Batch 1/1: Calculating loss...
Epoch 306: Validation phase completed. Average Val Loss: 0.2803
Epoch 306 Summary ---> Train Loss: 0.4119 / Validation Loss: 0.2803
Epoch 306: Checking early stopping... (Current Best Loss: 0.2777, Epochs No Improve: 3)
  Epoch 306: Validation loss did not improve. Epochs without improvement: 4
Epoch 306: Stepping scheduler...
--- Epoch 306 completed in 0.69 seconds ---

--- Starting Epoch 307/1000 ---
Epoch 307: Starting training phase (4 batches)
  Epoch 307, Batch 1/4: Loading data to device...
  Epoch 307, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 307, Batch 1/4: Zeroing gradients...
  Epoch 307, Batch 1/4: Forward pass...
  Epoch 307, Batch 1/4: Calculating loss...
  Epoch 307, Batch 1/4: Backward pass...
  Epoch 307, Batch 1/4: Clipping gradients...
  Epoch 307, Batch 1/4: Optimizer step...
  Epoch 307, Batch 1/4: Completed in 0.19s
  Epoch 307, Batch 2/4: Loading data to device...
  Epoch 307, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 307, Batch 2/4: Zeroing gradients...
  Epoch 307, Batch 2/4: Forward pass...
  Epoch 307, Batch 2/4: Calculating loss...
  Epoch 307, Batch 2/4: Backward pass...
  Epoch 307, Batch 2/4: Clipping gradients...
  Epoch 307, Batch 2/4: Optimizer step...
  Epoch 307, Batch 2/4: Completed in 0.19s
  Epoch 307, Batch 3/4: Loading data to device...
  Epoch 307, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 307, Batch 3/4: Zeroing gradients...
  Epoch 307, Batch 3/4: Forward pass...
  Epoch 307, Batch 3/4: Calculating loss...
  Epoch 307, Batch 3/4: Backward pass...
  Epoch 307, Batch 3/4: Clipping gradients...
  Epoch 307, Batch 3/4: Optimizer step...
  Epoch 307, Batch 3/4: Completed in 0.19s
  Epoch 307, Batch 4/4: Loading data to device...
  Epoch 307, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 307, Batch 4/4: Zeroing gradients...
  Epoch 307, Batch 4/4: Forward pass...
  Epoch 307, Batch 4/4: Calculating loss...
  Epoch 307, Batch 4/4: Backward pass...
  Epoch 307, Batch 4/4: Clipping gradients...
  Epoch 307, Batch 4/4: Optimizer step...
  Epoch 307, Batch 4/4: Completed in 0.03s
Epoch 307: Training phase completed. Average Train Loss: 0.3211
Epoch 307: Starting validation phase...
  Epoch 307, Val Batch 1/1: Loading data...
  Epoch 307, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 307, Val Batch 1/1: Forward pass...
  Epoch 307, Val Batch 1/1: Calculating loss...
Epoch 307: Validation phase completed. Average Val Loss: 0.2792
Epoch 307 Summary ---> Train Loss: 0.3211 / Validation Loss: 0.2792
Epoch 307: Checking early stopping... (Current Best Loss: 0.2777, Epochs No Improve: 4)
  Epoch 307: Validation loss did not improve. Epochs without improvement: 5
Epoch 307: Stepping scheduler...
--- Epoch 307 completed in 0.68 seconds ---

--- Starting Epoch 308/1000 ---
Epoch 308: Starting training phase (4 batches)
  Epoch 308, Batch 1/4: Loading data to device...
  Epoch 308, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 308, Batch 1/4: Zeroing gradients...
  Epoch 308, Batch 1/4: Forward pass...
  Epoch 308, Batch 1/4: Calculating loss...
  Epoch 308, Batch 1/4: Backward pass...
  Epoch 308, Batch 1/4: Clipping gradients...
  Epoch 308, Batch 1/4: Optimizer step...
  Epoch 308, Batch 1/4: Completed in 0.19s
  Epoch 308, Batch 2/4: Loading data to device...
  Epoch 308, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 308, Batch 2/4: Zeroing gradients...
  Epoch 308, Batch 2/4: Forward pass...
  Epoch 308, Batch 2/4: Calculating loss...
  Epoch 308, Batch 2/4: Backward pass...
  Epoch 308, Batch 2/4: Clipping gradients...
  Epoch 308, Batch 2/4: Optimizer step...
  Epoch 308, Batch 2/4: Completed in 0.20s
  Epoch 308, Batch 3/4: Loading data to device...
  Epoch 308, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 308, Batch 3/4: Zeroing gradients...
  Epoch 308, Batch 3/4: Forward pass...
  Epoch 308, Batch 3/4: Calculating loss...
  Epoch 308, Batch 3/4: Backward pass...
  Epoch 308, Batch 3/4: Clipping gradients...
  Epoch 308, Batch 3/4: Optimizer step...
  Epoch 308, Batch 3/4: Completed in 0.20s
  Epoch 308, Batch 4/4: Loading data to device...
  Epoch 308, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 308, Batch 4/4: Zeroing gradients...
  Epoch 308, Batch 4/4: Forward pass...
  Epoch 308, Batch 4/4: Calculating loss...
  Epoch 308, Batch 4/4: Backward pass...
  Epoch 308, Batch 4/4: Clipping gradients...
  Epoch 308, Batch 4/4: Optimizer step...
  Epoch 308, Batch 4/4: Completed in 0.03s
Epoch 308: Training phase completed. Average Train Loss: 0.4002
Epoch 308: Starting validation phase...
  Epoch 308, Val Batch 1/1: Loading data...
  Epoch 308, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 308, Val Batch 1/1: Forward pass...
  Epoch 308, Val Batch 1/1: Calculating loss...
Epoch 308: Validation phase completed. Average Val Loss: 0.2718
Epoch 308 Summary ---> Train Loss: 0.4002 / Validation Loss: 0.2718
Epoch 308: Checking early stopping... (Current Best Loss: 0.2777, Epochs No Improve: 5)
  Epoch 308: Validation loss improved (0.2777 --> 0.2718). Saving model.
Epoch 308: Stepping scheduler...
--- Epoch 308 completed in 0.69 seconds ---

--- Starting Epoch 309/1000 ---
Epoch 309: Starting training phase (4 batches)
  Epoch 309, Batch 1/4: Loading data to device...
  Epoch 309, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 309, Batch 1/4: Zeroing gradients...
  Epoch 309, Batch 1/4: Forward pass...
  Epoch 309, Batch 1/4: Calculating loss...
  Epoch 309, Batch 1/4: Backward pass...
  Epoch 309, Batch 1/4: Clipping gradients...
  Epoch 309, Batch 1/4: Optimizer step...
  Epoch 309, Batch 1/4: Completed in 0.19s
  Epoch 309, Batch 2/4: Loading data to device...
  Epoch 309, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 309, Batch 2/4: Zeroing gradients...
  Epoch 309, Batch 2/4: Forward pass...
  Epoch 309, Batch 2/4: Calculating loss...
  Epoch 309, Batch 2/4: Backward pass...
  Epoch 309, Batch 2/4: Clipping gradients...
  Epoch 309, Batch 2/4: Optimizer step...
  Epoch 309, Batch 2/4: Completed in 0.18s
  Epoch 309, Batch 3/4: Loading data to device...
  Epoch 309, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 309, Batch 3/4: Zeroing gradients...
  Epoch 309, Batch 3/4: Forward pass...
  Epoch 309, Batch 3/4: Calculating loss...
  Epoch 309, Batch 3/4: Backward pass...
  Epoch 309, Batch 3/4: Clipping gradients...
  Epoch 309, Batch 3/4: Optimizer step...
  Epoch 309, Batch 3/4: Completed in 0.19s
  Epoch 309, Batch 4/4: Loading data to device...
  Epoch 309, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 309, Batch 4/4: Zeroing gradients...
  Epoch 309, Batch 4/4: Forward pass...
  Epoch 309, Batch 4/4: Calculating loss...
  Epoch 309, Batch 4/4: Backward pass...
  Epoch 309, Batch 4/4: Clipping gradients...
  Epoch 309, Batch 4/4: Optimizer step...
  Epoch 309, Batch 4/4: Completed in 0.03s
Epoch 309: Training phase completed. Average Train Loss: 0.3492
Epoch 309: Starting validation phase...
  Epoch 309, Val Batch 1/1: Loading data...
  Epoch 309, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 309, Val Batch 1/1: Forward pass...
  Epoch 309, Val Batch 1/1: Calculating loss...
Epoch 309: Validation phase completed. Average Val Loss: 0.2774
Epoch 309 Summary ---> Train Loss: 0.3492 / Validation Loss: 0.2774
Epoch 309: Checking early stopping... (Current Best Loss: 0.2718, Epochs No Improve: 0)
  Epoch 309: Validation loss did not improve. Epochs without improvement: 1
Epoch 309: Stepping scheduler...
--- Epoch 309 completed in 0.66 seconds ---

--- Starting Epoch 310/1000 ---
Epoch 310: Starting training phase (4 batches)
  Epoch 310, Batch 1/4: Loading data to device...
  Epoch 310, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 310, Batch 1/4: Zeroing gradients...
  Epoch 310, Batch 1/4: Forward pass...
  Epoch 310, Batch 1/4: Calculating loss...
  Epoch 310, Batch 1/4: Backward pass...
  Epoch 310, Batch 1/4: Clipping gradients...
  Epoch 310, Batch 1/4: Optimizer step...
  Epoch 310, Batch 1/4: Completed in 0.19s
  Epoch 310, Batch 2/4: Loading data to device...
  Epoch 310, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 310, Batch 2/4: Zeroing gradients...
  Epoch 310, Batch 2/4: Forward pass...
  Epoch 310, Batch 2/4: Calculating loss...
  Epoch 310, Batch 2/4: Backward pass...
  Epoch 310, Batch 2/4: Clipping gradients...
  Epoch 310, Batch 2/4: Optimizer step...
  Epoch 310, Batch 2/4: Completed in 0.19s
  Epoch 310, Batch 3/4: Loading data to device...
  Epoch 310, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 310, Batch 3/4: Zeroing gradients...
  Epoch 310, Batch 3/4: Forward pass...
  Epoch 310, Batch 3/4: Calculating loss...
  Epoch 310, Batch 3/4: Backward pass...
  Epoch 310, Batch 3/4: Clipping gradients...
  Epoch 310, Batch 3/4: Optimizer step...
  Epoch 310, Batch 3/4: Completed in 0.19s
  Epoch 310, Batch 4/4: Loading data to device...
  Epoch 310, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 310, Batch 4/4: Zeroing gradients...
  Epoch 310, Batch 4/4: Forward pass...
  Epoch 310, Batch 4/4: Calculating loss...
  Epoch 310, Batch 4/4: Backward pass...
  Epoch 310, Batch 4/4: Clipping gradients...
  Epoch 310, Batch 4/4: Optimizer step...
  Epoch 310, Batch 4/4: Completed in 0.03s
Epoch 310: Training phase completed. Average Train Loss: 0.3597
Epoch 310: Starting validation phase...
  Epoch 310, Val Batch 1/1: Loading data...
  Epoch 310, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 310, Val Batch 1/1: Forward pass...
  Epoch 310, Val Batch 1/1: Calculating loss...
Epoch 310: Validation phase completed. Average Val Loss: 0.2822
Epoch 310 Summary ---> Train Loss: 0.3597 / Validation Loss: 0.2822
Epoch 310: Checking early stopping... (Current Best Loss: 0.2718, Epochs No Improve: 1)
  Epoch 310: Validation loss did not improve. Epochs without improvement: 2
Epoch 310: Stepping scheduler...
--- Epoch 310 completed in 0.67 seconds ---

--- Starting Epoch 311/1000 ---
Epoch 311: Starting training phase (4 batches)
  Epoch 311, Batch 1/4: Loading data to device...
  Epoch 311, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 311, Batch 1/4: Zeroing gradients...
  Epoch 311, Batch 1/4: Forward pass...
  Epoch 311, Batch 1/4: Calculating loss...
  Epoch 311, Batch 1/4: Backward pass...
  Epoch 311, Batch 1/4: Clipping gradients...
  Epoch 311, Batch 1/4: Optimizer step...
  Epoch 311, Batch 1/4: Completed in 0.19s
  Epoch 311, Batch 2/4: Loading data to device...
  Epoch 311, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 311, Batch 2/4: Zeroing gradients...
  Epoch 311, Batch 2/4: Forward pass...
  Epoch 311, Batch 2/4: Calculating loss...
  Epoch 311, Batch 2/4: Backward pass...
  Epoch 311, Batch 2/4: Clipping gradients...
  Epoch 311, Batch 2/4: Optimizer step...
  Epoch 311, Batch 2/4: Completed in 0.19s
  Epoch 311, Batch 3/4: Loading data to device...
  Epoch 311, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 311, Batch 3/4: Zeroing gradients...
  Epoch 311, Batch 3/4: Forward pass...
  Epoch 311, Batch 3/4: Calculating loss...
  Epoch 311, Batch 3/4: Backward pass...
  Epoch 311, Batch 3/4: Clipping gradients...
  Epoch 311, Batch 3/4: Optimizer step...
  Epoch 311, Batch 3/4: Completed in 0.19s
  Epoch 311, Batch 4/4: Loading data to device...
  Epoch 311, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 311, Batch 4/4: Zeroing gradients...
  Epoch 311, Batch 4/4: Forward pass...
  Epoch 311, Batch 4/4: Calculating loss...
  Epoch 311, Batch 4/4: Backward pass...
  Epoch 311, Batch 4/4: Clipping gradients...
  Epoch 311, Batch 4/4: Optimizer step...
  Epoch 311, Batch 4/4: Completed in 0.03s
Epoch 311: Training phase completed. Average Train Loss: 0.3280
Epoch 311: Starting validation phase...
  Epoch 311, Val Batch 1/1: Loading data...
  Epoch 311, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 311, Val Batch 1/1: Forward pass...
  Epoch 311, Val Batch 1/1: Calculating loss...
Epoch 311: Validation phase completed. Average Val Loss: 0.2825
Epoch 311 Summary ---> Train Loss: 0.3280 / Validation Loss: 0.2825
Epoch 311: Checking early stopping... (Current Best Loss: 0.2718, Epochs No Improve: 2)
  Epoch 311: Validation loss did not improve. Epochs without improvement: 3
Epoch 311: Stepping scheduler...
--- Epoch 311 completed in 0.68 seconds ---

--- Starting Epoch 312/1000 ---
Epoch 312: Starting training phase (4 batches)
  Epoch 312, Batch 1/4: Loading data to device...
  Epoch 312, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 312, Batch 1/4: Zeroing gradients...
  Epoch 312, Batch 1/4: Forward pass...
  Epoch 312, Batch 1/4: Calculating loss...
  Epoch 312, Batch 1/4: Backward pass...
  Epoch 312, Batch 1/4: Clipping gradients...
  Epoch 312, Batch 1/4: Optimizer step...
  Epoch 312, Batch 1/4: Completed in 0.20s
  Epoch 312, Batch 2/4: Loading data to device...
  Epoch 312, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 312, Batch 2/4: Zeroing gradients...
  Epoch 312, Batch 2/4: Forward pass...
  Epoch 312, Batch 2/4: Calculating loss...
  Epoch 312, Batch 2/4: Backward pass...
  Epoch 312, Batch 2/4: Clipping gradients...
  Epoch 312, Batch 2/4: Optimizer step...
  Epoch 312, Batch 2/4: Completed in 0.19s
  Epoch 312, Batch 3/4: Loading data to device...
  Epoch 312, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 312, Batch 3/4: Zeroing gradients...
  Epoch 312, Batch 3/4: Forward pass...
  Epoch 312, Batch 3/4: Calculating loss...
  Epoch 312, Batch 3/4: Backward pass...
  Epoch 312, Batch 3/4: Clipping gradients...
  Epoch 312, Batch 3/4: Optimizer step...
  Epoch 312, Batch 3/4: Completed in 0.19s
  Epoch 312, Batch 4/4: Loading data to device...
  Epoch 312, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 312, Batch 4/4: Zeroing gradients...
  Epoch 312, Batch 4/4: Forward pass...
  Epoch 312, Batch 4/4: Calculating loss...
  Epoch 312, Batch 4/4: Backward pass...
  Epoch 312, Batch 4/4: Clipping gradients...
  Epoch 312, Batch 4/4: Optimizer step...
  Epoch 312, Batch 4/4: Completed in 0.03s
Epoch 312: Training phase completed. Average Train Loss: 0.3706
Epoch 312: Starting validation phase...
  Epoch 312, Val Batch 1/1: Loading data...
  Epoch 312, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 312, Val Batch 1/1: Forward pass...
  Epoch 312, Val Batch 1/1: Calculating loss...
Epoch 312: Validation phase completed. Average Val Loss: 0.2805
Epoch 312 Summary ---> Train Loss: 0.3706 / Validation Loss: 0.2805
Epoch 312: Checking early stopping... (Current Best Loss: 0.2718, Epochs No Improve: 3)
  Epoch 312: Validation loss did not improve. Epochs without improvement: 4
Epoch 312: Stepping scheduler...
--- Epoch 312 completed in 0.67 seconds ---

--- Starting Epoch 313/1000 ---
Epoch 313: Starting training phase (4 batches)
  Epoch 313, Batch 1/4: Loading data to device...
  Epoch 313, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 313, Batch 1/4: Zeroing gradients...
  Epoch 313, Batch 1/4: Forward pass...
  Epoch 313, Batch 1/4: Calculating loss...
  Epoch 313, Batch 1/4: Backward pass...
  Epoch 313, Batch 1/4: Clipping gradients...
  Epoch 313, Batch 1/4: Optimizer step...
  Epoch 313, Batch 1/4: Completed in 0.19s
  Epoch 313, Batch 2/4: Loading data to device...
  Epoch 313, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 313, Batch 2/4: Zeroing gradients...
  Epoch 313, Batch 2/4: Forward pass...
  Epoch 313, Batch 2/4: Calculating loss...
  Epoch 313, Batch 2/4: Backward pass...
  Epoch 313, Batch 2/4: Clipping gradients...
  Epoch 313, Batch 2/4: Optimizer step...
  Epoch 313, Batch 2/4: Completed in 0.19s
  Epoch 313, Batch 3/4: Loading data to device...
  Epoch 313, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 313, Batch 3/4: Zeroing gradients...
  Epoch 313, Batch 3/4: Forward pass...
  Epoch 313, Batch 3/4: Calculating loss...
  Epoch 313, Batch 3/4: Backward pass...
  Epoch 313, Batch 3/4: Clipping gradients...
  Epoch 313, Batch 3/4: Optimizer step...
  Epoch 313, Batch 3/4: Completed in 0.19s
  Epoch 313, Batch 4/4: Loading data to device...
  Epoch 313, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 313, Batch 4/4: Zeroing gradients...
  Epoch 313, Batch 4/4: Forward pass...
  Epoch 313, Batch 4/4: Calculating loss...
  Epoch 313, Batch 4/4: Backward pass...
  Epoch 313, Batch 4/4: Clipping gradients...
  Epoch 313, Batch 4/4: Optimizer step...
  Epoch 313, Batch 4/4: Completed in 0.03s
Epoch 313: Training phase completed. Average Train Loss: 0.3196
Epoch 313: Starting validation phase...
  Epoch 313, Val Batch 1/1: Loading data...
  Epoch 313, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 313, Val Batch 1/1: Forward pass...
  Epoch 313, Val Batch 1/1: Calculating loss...
Epoch 313: Validation phase completed. Average Val Loss: 0.2774
Epoch 313 Summary ---> Train Loss: 0.3196 / Validation Loss: 0.2774
Epoch 313: Checking early stopping... (Current Best Loss: 0.2718, Epochs No Improve: 4)
  Epoch 313: Validation loss did not improve. Epochs without improvement: 5
Epoch 313: Stepping scheduler...
--- Epoch 313 completed in 0.67 seconds ---

--- Starting Epoch 314/1000 ---
Epoch 314: Starting training phase (4 batches)
  Epoch 314, Batch 1/4: Loading data to device...
  Epoch 314, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 314, Batch 1/4: Zeroing gradients...
  Epoch 314, Batch 1/4: Forward pass...
  Epoch 314, Batch 1/4: Calculating loss...
  Epoch 314, Batch 1/4: Backward pass...
  Epoch 314, Batch 1/4: Clipping gradients...
  Epoch 314, Batch 1/4: Optimizer step...
  Epoch 314, Batch 1/4: Completed in 0.19s
  Epoch 314, Batch 2/4: Loading data to device...
  Epoch 314, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 314, Batch 2/4: Zeroing gradients...
  Epoch 314, Batch 2/4: Forward pass...
  Epoch 314, Batch 2/4: Calculating loss...
  Epoch 314, Batch 2/4: Backward pass...
  Epoch 314, Batch 2/4: Clipping gradients...
  Epoch 314, Batch 2/4: Optimizer step...
  Epoch 314, Batch 2/4: Completed in 0.19s
  Epoch 314, Batch 3/4: Loading data to device...
  Epoch 314, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 314, Batch 3/4: Zeroing gradients...
  Epoch 314, Batch 3/4: Forward pass...
  Epoch 314, Batch 3/4: Calculating loss...
  Epoch 314, Batch 3/4: Backward pass...
  Epoch 314, Batch 3/4: Clipping gradients...
  Epoch 314, Batch 3/4: Optimizer step...
  Epoch 314, Batch 3/4: Completed in 0.18s
  Epoch 314, Batch 4/4: Loading data to device...
  Epoch 314, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 314, Batch 4/4: Zeroing gradients...
  Epoch 314, Batch 4/4: Forward pass...
  Epoch 314, Batch 4/4: Calculating loss...
  Epoch 314, Batch 4/4: Backward pass...
  Epoch 314, Batch 4/4: Clipping gradients...
  Epoch 314, Batch 4/4: Optimizer step...
  Epoch 314, Batch 4/4: Completed in 0.03s
Epoch 314: Training phase completed. Average Train Loss: 0.3569
Epoch 314: Starting validation phase...
  Epoch 314, Val Batch 1/1: Loading data...
  Epoch 314, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 314, Val Batch 1/1: Forward pass...
  Epoch 314, Val Batch 1/1: Calculating loss...
Epoch 314: Validation phase completed. Average Val Loss: 0.2657
Epoch 314 Summary ---> Train Loss: 0.3569 / Validation Loss: 0.2657
Epoch 314: Checking early stopping... (Current Best Loss: 0.2718, Epochs No Improve: 5)
  Epoch 314: Validation loss improved (0.2718 --> 0.2657). Saving model.
Epoch 314: Stepping scheduler...
--- Epoch 314 completed in 0.66 seconds ---

--- Starting Epoch 315/1000 ---
Epoch 315: Starting training phase (4 batches)
  Epoch 315, Batch 1/4: Loading data to device...
  Epoch 315, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 315, Batch 1/4: Zeroing gradients...
  Epoch 315, Batch 1/4: Forward pass...
  Epoch 315, Batch 1/4: Calculating loss...
  Epoch 315, Batch 1/4: Backward pass...
  Epoch 315, Batch 1/4: Clipping gradients...
  Epoch 315, Batch 1/4: Optimizer step...
  Epoch 315, Batch 1/4: Completed in 0.19s
  Epoch 315, Batch 2/4: Loading data to device...
  Epoch 315, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 315, Batch 2/4: Zeroing gradients...
  Epoch 315, Batch 2/4: Forward pass...
  Epoch 315, Batch 2/4: Calculating loss...
  Epoch 315, Batch 2/4: Backward pass...
  Epoch 315, Batch 2/4: Clipping gradients...
  Epoch 315, Batch 2/4: Optimizer step...
  Epoch 315, Batch 2/4: Completed in 0.18s
  Epoch 315, Batch 3/4: Loading data to device...
  Epoch 315, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 315, Batch 3/4: Zeroing gradients...
  Epoch 315, Batch 3/4: Forward pass...
  Epoch 315, Batch 3/4: Calculating loss...
  Epoch 315, Batch 3/4: Backward pass...
  Epoch 315, Batch 3/4: Clipping gradients...
  Epoch 315, Batch 3/4: Optimizer step...
  Epoch 315, Batch 3/4: Completed in 0.19s
  Epoch 315, Batch 4/4: Loading data to device...
  Epoch 315, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 315, Batch 4/4: Zeroing gradients...
  Epoch 315, Batch 4/4: Forward pass...
  Epoch 315, Batch 4/4: Calculating loss...
  Epoch 315, Batch 4/4: Backward pass...
  Epoch 315, Batch 4/4: Clipping gradients...
  Epoch 315, Batch 4/4: Optimizer step...
  Epoch 315, Batch 4/4: Completed in 0.04s
Epoch 315: Training phase completed. Average Train Loss: 0.4576
Epoch 315: Starting validation phase...
  Epoch 315, Val Batch 1/1: Loading data...
  Epoch 315, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 315, Val Batch 1/1: Forward pass...
  Epoch 315, Val Batch 1/1: Calculating loss...
Epoch 315: Validation phase completed. Average Val Loss: 0.2667
Epoch 315 Summary ---> Train Loss: 0.4576 / Validation Loss: 0.2667
Epoch 315: Checking early stopping... (Current Best Loss: 0.2657, Epochs No Improve: 0)
  Epoch 315: Validation loss did not improve. Epochs without improvement: 1
Epoch 315: Stepping scheduler...
--- Epoch 315 completed in 0.66 seconds ---

--- Starting Epoch 316/1000 ---
Epoch 316: Starting training phase (4 batches)
  Epoch 316, Batch 1/4: Loading data to device...
  Epoch 316, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 316, Batch 1/4: Zeroing gradients...
  Epoch 316, Batch 1/4: Forward pass...
  Epoch 316, Batch 1/4: Calculating loss...
  Epoch 316, Batch 1/4: Backward pass...
  Epoch 316, Batch 1/4: Clipping gradients...
  Epoch 316, Batch 1/4: Optimizer step...
  Epoch 316, Batch 1/4: Completed in 0.19s
  Epoch 316, Batch 2/4: Loading data to device...
  Epoch 316, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 316, Batch 2/4: Zeroing gradients...
  Epoch 316, Batch 2/4: Forward pass...
  Epoch 316, Batch 2/4: Calculating loss...
  Epoch 316, Batch 2/4: Backward pass...
  Epoch 316, Batch 2/4: Clipping gradients...
  Epoch 316, Batch 2/4: Optimizer step...
  Epoch 316, Batch 2/4: Completed in 0.19s
  Epoch 316, Batch 3/4: Loading data to device...
  Epoch 316, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 316, Batch 3/4: Zeroing gradients...
  Epoch 316, Batch 3/4: Forward pass...
  Epoch 316, Batch 3/4: Calculating loss...
  Epoch 316, Batch 3/4: Backward pass...
  Epoch 316, Batch 3/4: Clipping gradients...
  Epoch 316, Batch 3/4: Optimizer step...
  Epoch 316, Batch 3/4: Completed in 0.20s
  Epoch 316, Batch 4/4: Loading data to device...
  Epoch 316, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 316, Batch 4/4: Zeroing gradients...
  Epoch 316, Batch 4/4: Forward pass...
  Epoch 316, Batch 4/4: Calculating loss...
  Epoch 316, Batch 4/4: Backward pass...
  Epoch 316, Batch 4/4: Clipping gradients...
  Epoch 316, Batch 4/4: Optimizer step...
  Epoch 316, Batch 4/4: Completed in 0.03s
Epoch 316: Training phase completed. Average Train Loss: 0.3790
Epoch 316: Starting validation phase...
  Epoch 316, Val Batch 1/1: Loading data...
  Epoch 316, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 316, Val Batch 1/1: Forward pass...
  Epoch 316, Val Batch 1/1: Calculating loss...
Epoch 316: Validation phase completed. Average Val Loss: 0.2590
Epoch 316 Summary ---> Train Loss: 0.3790 / Validation Loss: 0.2590
Epoch 316: Checking early stopping... (Current Best Loss: 0.2657, Epochs No Improve: 1)
  Epoch 316: Validation loss improved (0.2657 --> 0.2590). Saving model.
Epoch 316: Stepping scheduler...
--- Epoch 316 completed in 0.68 seconds ---

--- Starting Epoch 317/1000 ---
Epoch 317: Starting training phase (4 batches)
  Epoch 317, Batch 1/4: Loading data to device...
  Epoch 317, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 317, Batch 1/4: Zeroing gradients...
  Epoch 317, Batch 1/4: Forward pass...
  Epoch 317, Batch 1/4: Calculating loss...
  Epoch 317, Batch 1/4: Backward pass...
  Epoch 317, Batch 1/4: Clipping gradients...
  Epoch 317, Batch 1/4: Optimizer step...
  Epoch 317, Batch 1/4: Completed in 0.20s
  Epoch 317, Batch 2/4: Loading data to device...
  Epoch 317, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 317, Batch 2/4: Zeroing gradients...
  Epoch 317, Batch 2/4: Forward pass...
  Epoch 317, Batch 2/4: Calculating loss...
  Epoch 317, Batch 2/4: Backward pass...
  Epoch 317, Batch 2/4: Clipping gradients...
  Epoch 317, Batch 2/4: Optimizer step...
  Epoch 317, Batch 2/4: Completed in 0.19s
  Epoch 317, Batch 3/4: Loading data to device...
  Epoch 317, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 317, Batch 3/4: Zeroing gradients...
  Epoch 317, Batch 3/4: Forward pass...
  Epoch 317, Batch 3/4: Calculating loss...
  Epoch 317, Batch 3/4: Backward pass...
  Epoch 317, Batch 3/4: Clipping gradients...
  Epoch 317, Batch 3/4: Optimizer step...
  Epoch 317, Batch 3/4: Completed in 0.19s
  Epoch 317, Batch 4/4: Loading data to device...
  Epoch 317, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 317, Batch 4/4: Zeroing gradients...
  Epoch 317, Batch 4/4: Forward pass...
  Epoch 317, Batch 4/4: Calculating loss...
  Epoch 317, Batch 4/4: Backward pass...
  Epoch 317, Batch 4/4: Clipping gradients...
  Epoch 317, Batch 4/4: Optimizer step...
  Epoch 317, Batch 4/4: Completed in 0.03s
Epoch 317: Training phase completed. Average Train Loss: 0.3161
Epoch 317: Starting validation phase...
  Epoch 317, Val Batch 1/1: Loading data...
  Epoch 317, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 317, Val Batch 1/1: Forward pass...
  Epoch 317, Val Batch 1/1: Calculating loss...
Epoch 317: Validation phase completed. Average Val Loss: 0.2588
Epoch 317 Summary ---> Train Loss: 0.3161 / Validation Loss: 0.2588
Epoch 317: Checking early stopping... (Current Best Loss: 0.2590, Epochs No Improve: 0)
  Epoch 317: Validation loss improved (0.2590 --> 0.2588). Saving model.
Epoch 317: Stepping scheduler...
--- Epoch 317 completed in 0.68 seconds ---

--- Starting Epoch 318/1000 ---
Epoch 318: Starting training phase (4 batches)
  Epoch 318, Batch 1/4: Loading data to device...
  Epoch 318, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 318, Batch 1/4: Zeroing gradients...
  Epoch 318, Batch 1/4: Forward pass...
  Epoch 318, Batch 1/4: Calculating loss...
  Epoch 318, Batch 1/4: Backward pass...
  Epoch 318, Batch 1/4: Clipping gradients...
  Epoch 318, Batch 1/4: Optimizer step...
  Epoch 318, Batch 1/4: Completed in 0.19s
  Epoch 318, Batch 2/4: Loading data to device...
  Epoch 318, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 318, Batch 2/4: Zeroing gradients...
  Epoch 318, Batch 2/4: Forward pass...
  Epoch 318, Batch 2/4: Calculating loss...
  Epoch 318, Batch 2/4: Backward pass...
  Epoch 318, Batch 2/4: Clipping gradients...
  Epoch 318, Batch 2/4: Optimizer step...
  Epoch 318, Batch 2/4: Completed in 0.19s
  Epoch 318, Batch 3/4: Loading data to device...
  Epoch 318, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 318, Batch 3/4: Zeroing gradients...
  Epoch 318, Batch 3/4: Forward pass...
  Epoch 318, Batch 3/4: Calculating loss...
  Epoch 318, Batch 3/4: Backward pass...
  Epoch 318, Batch 3/4: Clipping gradients...
  Epoch 318, Batch 3/4: Optimizer step...
  Epoch 318, Batch 3/4: Completed in 0.19s
  Epoch 318, Batch 4/4: Loading data to device...
  Epoch 318, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 318, Batch 4/4: Zeroing gradients...
  Epoch 318, Batch 4/4: Forward pass...
  Epoch 318, Batch 4/4: Calculating loss...
  Epoch 318, Batch 4/4: Backward pass...
  Epoch 318, Batch 4/4: Clipping gradients...
  Epoch 318, Batch 4/4: Optimizer step...
  Epoch 318, Batch 4/4: Completed in 0.03s
Epoch 318: Training phase completed. Average Train Loss: 0.3830
Epoch 318: Starting validation phase...
  Epoch 318, Val Batch 1/1: Loading data...
  Epoch 318, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 318, Val Batch 1/1: Forward pass...
  Epoch 318, Val Batch 1/1: Calculating loss...
Epoch 318: Validation phase completed. Average Val Loss: 0.2548
Epoch 318 Summary ---> Train Loss: 0.3830 / Validation Loss: 0.2548
Epoch 318: Checking early stopping... (Current Best Loss: 0.2588, Epochs No Improve: 0)
  Epoch 318: Validation loss improved (0.2588 --> 0.2548). Saving model.
Epoch 318: Stepping scheduler...
--- Epoch 318 completed in 0.68 seconds ---

--- Starting Epoch 319/1000 ---
Epoch 319: Starting training phase (4 batches)
  Epoch 319, Batch 1/4: Loading data to device...
  Epoch 319, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 319, Batch 1/4: Zeroing gradients...
  Epoch 319, Batch 1/4: Forward pass...
  Epoch 319, Batch 1/4: Calculating loss...
  Epoch 319, Batch 1/4: Backward pass...
  Epoch 319, Batch 1/4: Clipping gradients...
  Epoch 319, Batch 1/4: Optimizer step...
  Epoch 319, Batch 1/4: Completed in 0.19s
  Epoch 319, Batch 2/4: Loading data to device...
  Epoch 319, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 319, Batch 2/4: Zeroing gradients...
  Epoch 319, Batch 2/4: Forward pass...
  Epoch 319, Batch 2/4: Calculating loss...
  Epoch 319, Batch 2/4: Backward pass...
  Epoch 319, Batch 2/4: Clipping gradients...
  Epoch 319, Batch 2/4: Optimizer step...
  Epoch 319, Batch 2/4: Completed in 0.20s
  Epoch 319, Batch 3/4: Loading data to device...
  Epoch 319, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 319, Batch 3/4: Zeroing gradients...
  Epoch 319, Batch 3/4: Forward pass...
  Epoch 319, Batch 3/4: Calculating loss...
  Epoch 319, Batch 3/4: Backward pass...
  Epoch 319, Batch 3/4: Clipping gradients...
  Epoch 319, Batch 3/4: Optimizer step...
  Epoch 319, Batch 3/4: Completed in 0.19s
  Epoch 319, Batch 4/4: Loading data to device...
  Epoch 319, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 319, Batch 4/4: Zeroing gradients...
  Epoch 319, Batch 4/4: Forward pass...
  Epoch 319, Batch 4/4: Calculating loss...
  Epoch 319, Batch 4/4: Backward pass...
  Epoch 319, Batch 4/4: Clipping gradients...
  Epoch 319, Batch 4/4: Optimizer step...
  Epoch 319, Batch 4/4: Completed in 0.03s
Epoch 319: Training phase completed. Average Train Loss: 0.4033
Epoch 319: Starting validation phase...
  Epoch 319, Val Batch 1/1: Loading data...
  Epoch 319, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 319, Val Batch 1/1: Forward pass...
  Epoch 319, Val Batch 1/1: Calculating loss...
Epoch 319: Validation phase completed. Average Val Loss: 0.2576
Epoch 319 Summary ---> Train Loss: 0.4033 / Validation Loss: 0.2576
Epoch 319: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 0)
  Epoch 319: Validation loss did not improve. Epochs without improvement: 1
Epoch 319: Stepping scheduler...
--- Epoch 319 completed in 0.68 seconds ---

--- Starting Epoch 320/1000 ---
Epoch 320: Starting training phase (4 batches)
  Epoch 320, Batch 1/4: Loading data to device...
  Epoch 320, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 320, Batch 1/4: Zeroing gradients...
  Epoch 320, Batch 1/4: Forward pass...
  Epoch 320, Batch 1/4: Calculating loss...
  Epoch 320, Batch 1/4: Backward pass...
  Epoch 320, Batch 1/4: Clipping gradients...
  Epoch 320, Batch 1/4: Optimizer step...
  Epoch 320, Batch 1/4: Completed in 0.19s
  Epoch 320, Batch 2/4: Loading data to device...
  Epoch 320, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 320, Batch 2/4: Zeroing gradients...
  Epoch 320, Batch 2/4: Forward pass...
  Epoch 320, Batch 2/4: Calculating loss...
  Epoch 320, Batch 2/4: Backward pass...
  Epoch 320, Batch 2/4: Clipping gradients...
  Epoch 320, Batch 2/4: Optimizer step...
  Epoch 320, Batch 2/4: Completed in 0.19s
  Epoch 320, Batch 3/4: Loading data to device...
  Epoch 320, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 320, Batch 3/4: Zeroing gradients...
  Epoch 320, Batch 3/4: Forward pass...
  Epoch 320, Batch 3/4: Calculating loss...
  Epoch 320, Batch 3/4: Backward pass...
  Epoch 320, Batch 3/4: Clipping gradients...
  Epoch 320, Batch 3/4: Optimizer step...
  Epoch 320, Batch 3/4: Completed in 0.19s
  Epoch 320, Batch 4/4: Loading data to device...
  Epoch 320, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 320, Batch 4/4: Zeroing gradients...
  Epoch 320, Batch 4/4: Forward pass...
  Epoch 320, Batch 4/4: Calculating loss...
  Epoch 320, Batch 4/4: Backward pass...
  Epoch 320, Batch 4/4: Clipping gradients...
  Epoch 320, Batch 4/4: Optimizer step...
  Epoch 320, Batch 4/4: Completed in 0.03s
Epoch 320: Training phase completed. Average Train Loss: 0.3382
Epoch 320: Starting validation phase...
  Epoch 320, Val Batch 1/1: Loading data...
  Epoch 320, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 320, Val Batch 1/1: Forward pass...
  Epoch 320, Val Batch 1/1: Calculating loss...
Epoch 320: Validation phase completed. Average Val Loss: 0.2567
Epoch 320 Summary ---> Train Loss: 0.3382 / Validation Loss: 0.2567
Epoch 320: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 1)
  Epoch 320: Validation loss did not improve. Epochs without improvement: 2
Epoch 320: Stepping scheduler...
--- Epoch 320 completed in 0.66 seconds ---

--- Starting Epoch 321/1000 ---
Epoch 321: Starting training phase (4 batches)
  Epoch 321, Batch 1/4: Loading data to device...
  Epoch 321, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 321, Batch 1/4: Zeroing gradients...
  Epoch 321, Batch 1/4: Forward pass...
  Epoch 321, Batch 1/4: Calculating loss...
  Epoch 321, Batch 1/4: Backward pass...
  Epoch 321, Batch 1/4: Clipping gradients...
  Epoch 321, Batch 1/4: Optimizer step...
  Epoch 321, Batch 1/4: Completed in 0.19s
  Epoch 321, Batch 2/4: Loading data to device...
  Epoch 321, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 321, Batch 2/4: Zeroing gradients...
  Epoch 321, Batch 2/4: Forward pass...
  Epoch 321, Batch 2/4: Calculating loss...
  Epoch 321, Batch 2/4: Backward pass...
  Epoch 321, Batch 2/4: Clipping gradients...
  Epoch 321, Batch 2/4: Optimizer step...
  Epoch 321, Batch 2/4: Completed in 0.19s
  Epoch 321, Batch 3/4: Loading data to device...
  Epoch 321, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 321, Batch 3/4: Zeroing gradients...
  Epoch 321, Batch 3/4: Forward pass...
  Epoch 321, Batch 3/4: Calculating loss...
  Epoch 321, Batch 3/4: Backward pass...
  Epoch 321, Batch 3/4: Clipping gradients...
  Epoch 321, Batch 3/4: Optimizer step...
  Epoch 321, Batch 3/4: Completed in 0.19s
  Epoch 321, Batch 4/4: Loading data to device...
  Epoch 321, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 321, Batch 4/4: Zeroing gradients...
  Epoch 321, Batch 4/4: Forward pass...
  Epoch 321, Batch 4/4: Calculating loss...
  Epoch 321, Batch 4/4: Backward pass...
  Epoch 321, Batch 4/4: Clipping gradients...
  Epoch 321, Batch 4/4: Optimizer step...
  Epoch 321, Batch 4/4: Completed in 0.04s
Epoch 321: Training phase completed. Average Train Loss: 0.3356
Epoch 321: Starting validation phase...
  Epoch 321, Val Batch 1/1: Loading data...
  Epoch 321, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 321, Val Batch 1/1: Forward pass...
  Epoch 321, Val Batch 1/1: Calculating loss...
Epoch 321: Validation phase completed. Average Val Loss: 0.2619
Epoch 321 Summary ---> Train Loss: 0.3356 / Validation Loss: 0.2619
Epoch 321: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 2)
  Epoch 321: Validation loss did not improve. Epochs without improvement: 3
Epoch 321: Stepping scheduler...
--- Epoch 321 completed in 0.68 seconds ---

--- Starting Epoch 322/1000 ---
Epoch 322: Starting training phase (4 batches)
  Epoch 322, Batch 1/4: Loading data to device...
  Epoch 322, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 322, Batch 1/4: Zeroing gradients...
  Epoch 322, Batch 1/4: Forward pass...
  Epoch 322, Batch 1/4: Calculating loss...
  Epoch 322, Batch 1/4: Backward pass...
  Epoch 322, Batch 1/4: Clipping gradients...
  Epoch 322, Batch 1/4: Optimizer step...
  Epoch 322, Batch 1/4: Completed in 0.20s
  Epoch 322, Batch 2/4: Loading data to device...
  Epoch 322, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 322, Batch 2/4: Zeroing gradients...
  Epoch 322, Batch 2/4: Forward pass...
  Epoch 322, Batch 2/4: Calculating loss...
  Epoch 322, Batch 2/4: Backward pass...
  Epoch 322, Batch 2/4: Clipping gradients...
  Epoch 322, Batch 2/4: Optimizer step...
  Epoch 322, Batch 2/4: Completed in 0.19s
  Epoch 322, Batch 3/4: Loading data to device...
  Epoch 322, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 322, Batch 3/4: Zeroing gradients...
  Epoch 322, Batch 3/4: Forward pass...
  Epoch 322, Batch 3/4: Calculating loss...
  Epoch 322, Batch 3/4: Backward pass...
  Epoch 322, Batch 3/4: Clipping gradients...
  Epoch 322, Batch 3/4: Optimizer step...
  Epoch 322, Batch 3/4: Completed in 0.20s
  Epoch 322, Batch 4/4: Loading data to device...
  Epoch 322, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 322, Batch 4/4: Zeroing gradients...
  Epoch 322, Batch 4/4: Forward pass...
  Epoch 322, Batch 4/4: Calculating loss...
  Epoch 322, Batch 4/4: Backward pass...
  Epoch 322, Batch 4/4: Clipping gradients...
  Epoch 322, Batch 4/4: Optimizer step...
  Epoch 322, Batch 4/4: Completed in 0.03s
Epoch 322: Training phase completed. Average Train Loss: 0.3384
Epoch 322: Starting validation phase...
  Epoch 322, Val Batch 1/1: Loading data...
  Epoch 322, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 322, Val Batch 1/1: Forward pass...
  Epoch 322, Val Batch 1/1: Calculating loss...
Epoch 322: Validation phase completed. Average Val Loss: 0.2696
Epoch 322 Summary ---> Train Loss: 0.3384 / Validation Loss: 0.2696
Epoch 322: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 3)
  Epoch 322: Validation loss did not improve. Epochs without improvement: 4
Epoch 322: Stepping scheduler...
--- Epoch 322 completed in 0.69 seconds ---

--- Starting Epoch 323/1000 ---
Epoch 323: Starting training phase (4 batches)
  Epoch 323, Batch 1/4: Loading data to device...
  Epoch 323, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 323, Batch 1/4: Zeroing gradients...
  Epoch 323, Batch 1/4: Forward pass...
  Epoch 323, Batch 1/4: Calculating loss...
  Epoch 323, Batch 1/4: Backward pass...
  Epoch 323, Batch 1/4: Clipping gradients...
  Epoch 323, Batch 1/4: Optimizer step...
  Epoch 323, Batch 1/4: Completed in 0.19s
  Epoch 323, Batch 2/4: Loading data to device...
  Epoch 323, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 323, Batch 2/4: Zeroing gradients...
  Epoch 323, Batch 2/4: Forward pass...
  Epoch 323, Batch 2/4: Calculating loss...
  Epoch 323, Batch 2/4: Backward pass...
  Epoch 323, Batch 2/4: Clipping gradients...
  Epoch 323, Batch 2/4: Optimizer step...
  Epoch 323, Batch 2/4: Completed in 0.20s
  Epoch 323, Batch 3/4: Loading data to device...
  Epoch 323, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 323, Batch 3/4: Zeroing gradients...
  Epoch 323, Batch 3/4: Forward pass...
  Epoch 323, Batch 3/4: Calculating loss...
  Epoch 323, Batch 3/4: Backward pass...
  Epoch 323, Batch 3/4: Clipping gradients...
  Epoch 323, Batch 3/4: Optimizer step...
  Epoch 323, Batch 3/4: Completed in 0.20s
  Epoch 323, Batch 4/4: Loading data to device...
  Epoch 323, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 323, Batch 4/4: Zeroing gradients...
  Epoch 323, Batch 4/4: Forward pass...
  Epoch 323, Batch 4/4: Calculating loss...
  Epoch 323, Batch 4/4: Backward pass...
  Epoch 323, Batch 4/4: Clipping gradients...
  Epoch 323, Batch 4/4: Optimizer step...
  Epoch 323, Batch 4/4: Completed in 0.03s
Epoch 323: Training phase completed. Average Train Loss: 0.3159
Epoch 323: Starting validation phase...
  Epoch 323, Val Batch 1/1: Loading data...
  Epoch 323, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 323, Val Batch 1/1: Forward pass...
  Epoch 323, Val Batch 1/1: Calculating loss...
Epoch 323: Validation phase completed. Average Val Loss: 0.2713
Epoch 323 Summary ---> Train Loss: 0.3159 / Validation Loss: 0.2713
Epoch 323: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 4)
  Epoch 323: Validation loss did not improve. Epochs without improvement: 5
Epoch 323: Stepping scheduler...
--- Epoch 323 completed in 0.68 seconds ---

--- Starting Epoch 324/1000 ---
Epoch 324: Starting training phase (4 batches)
  Epoch 324, Batch 1/4: Loading data to device...
  Epoch 324, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 324, Batch 1/4: Zeroing gradients...
  Epoch 324, Batch 1/4: Forward pass...
  Epoch 324, Batch 1/4: Calculating loss...
  Epoch 324, Batch 1/4: Backward pass...
  Epoch 324, Batch 1/4: Clipping gradients...
  Epoch 324, Batch 1/4: Optimizer step...
  Epoch 324, Batch 1/4: Completed in 0.20s
  Epoch 324, Batch 2/4: Loading data to device...
  Epoch 324, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 324, Batch 2/4: Zeroing gradients...
  Epoch 324, Batch 2/4: Forward pass...
  Epoch 324, Batch 2/4: Calculating loss...
  Epoch 324, Batch 2/4: Backward pass...
  Epoch 324, Batch 2/4: Clipping gradients...
  Epoch 324, Batch 2/4: Optimizer step...
  Epoch 324, Batch 2/4: Completed in 0.20s
  Epoch 324, Batch 3/4: Loading data to device...
  Epoch 324, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 324, Batch 3/4: Zeroing gradients...
  Epoch 324, Batch 3/4: Forward pass...
  Epoch 324, Batch 3/4: Calculating loss...
  Epoch 324, Batch 3/4: Backward pass...
  Epoch 324, Batch 3/4: Clipping gradients...
  Epoch 324, Batch 3/4: Optimizer step...
  Epoch 324, Batch 3/4: Completed in 0.19s
  Epoch 324, Batch 4/4: Loading data to device...
  Epoch 324, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 324, Batch 4/4: Zeroing gradients...
  Epoch 324, Batch 4/4: Forward pass...
  Epoch 324, Batch 4/4: Calculating loss...
  Epoch 324, Batch 4/4: Backward pass...
  Epoch 324, Batch 4/4: Clipping gradients...
  Epoch 324, Batch 4/4: Optimizer step...
  Epoch 324, Batch 4/4: Completed in 0.03s
Epoch 324: Training phase completed. Average Train Loss: 0.4519
Epoch 324: Starting validation phase...
  Epoch 324, Val Batch 1/1: Loading data...
  Epoch 324, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 324, Val Batch 1/1: Forward pass...
  Epoch 324, Val Batch 1/1: Calculating loss...
Epoch 324: Validation phase completed. Average Val Loss: 0.2742
Epoch 324 Summary ---> Train Loss: 0.4519 / Validation Loss: 0.2742
Epoch 324: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 5)
  Epoch 324: Validation loss did not improve. Epochs without improvement: 6
Epoch 324: Stepping scheduler...
--- Epoch 324 completed in 0.68 seconds ---

--- Starting Epoch 325/1000 ---
Epoch 325: Starting training phase (4 batches)
  Epoch 325, Batch 1/4: Loading data to device...
  Epoch 325, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 325, Batch 1/4: Zeroing gradients...
  Epoch 325, Batch 1/4: Forward pass...
  Epoch 325, Batch 1/4: Calculating loss...
  Epoch 325, Batch 1/4: Backward pass...
  Epoch 325, Batch 1/4: Clipping gradients...
  Epoch 325, Batch 1/4: Optimizer step...
  Epoch 325, Batch 1/4: Completed in 0.20s
  Epoch 325, Batch 2/4: Loading data to device...
  Epoch 325, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 325, Batch 2/4: Zeroing gradients...
  Epoch 325, Batch 2/4: Forward pass...
  Epoch 325, Batch 2/4: Calculating loss...
  Epoch 325, Batch 2/4: Backward pass...
  Epoch 325, Batch 2/4: Clipping gradients...
  Epoch 325, Batch 2/4: Optimizer step...
  Epoch 325, Batch 2/4: Completed in 0.20s
  Epoch 325, Batch 3/4: Loading data to device...
  Epoch 325, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 325, Batch 3/4: Zeroing gradients...
  Epoch 325, Batch 3/4: Forward pass...
  Epoch 325, Batch 3/4: Calculating loss...
  Epoch 325, Batch 3/4: Backward pass...
  Epoch 325, Batch 3/4: Clipping gradients...
  Epoch 325, Batch 3/4: Optimizer step...
  Epoch 325, Batch 3/4: Completed in 0.20s
  Epoch 325, Batch 4/4: Loading data to device...
  Epoch 325, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 325, Batch 4/4: Zeroing gradients...
  Epoch 325, Batch 4/4: Forward pass...
  Epoch 325, Batch 4/4: Calculating loss...
  Epoch 325, Batch 4/4: Backward pass...
  Epoch 325, Batch 4/4: Clipping gradients...
  Epoch 325, Batch 4/4: Optimizer step...
  Epoch 325, Batch 4/4: Completed in 0.03s
Epoch 325: Training phase completed. Average Train Loss: 0.3245
Epoch 325: Starting validation phase...
  Epoch 325, Val Batch 1/1: Loading data...
  Epoch 325, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 325, Val Batch 1/1: Forward pass...
  Epoch 325, Val Batch 1/1: Calculating loss...
Epoch 325: Validation phase completed. Average Val Loss: 0.2724
Epoch 325 Summary ---> Train Loss: 0.3245 / Validation Loss: 0.2724
Epoch 325: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 6)
  Epoch 325: Validation loss did not improve. Epochs without improvement: 7
Epoch 325: Stepping scheduler...
--- Epoch 325 completed in 0.69 seconds ---

--- Starting Epoch 326/1000 ---
Epoch 326: Starting training phase (4 batches)
  Epoch 326, Batch 1/4: Loading data to device...
  Epoch 326, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 326, Batch 1/4: Zeroing gradients...
  Epoch 326, Batch 1/4: Forward pass...
  Epoch 326, Batch 1/4: Calculating loss...
  Epoch 326, Batch 1/4: Backward pass...
  Epoch 326, Batch 1/4: Clipping gradients...
  Epoch 326, Batch 1/4: Optimizer step...
  Epoch 326, Batch 1/4: Completed in 0.20s
  Epoch 326, Batch 2/4: Loading data to device...
  Epoch 326, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 326, Batch 2/4: Zeroing gradients...
  Epoch 326, Batch 2/4: Forward pass...
  Epoch 326, Batch 2/4: Calculating loss...
  Epoch 326, Batch 2/4: Backward pass...
  Epoch 326, Batch 2/4: Clipping gradients...
  Epoch 326, Batch 2/4: Optimizer step...
  Epoch 326, Batch 2/4: Completed in 0.20s
  Epoch 326, Batch 3/4: Loading data to device...
  Epoch 326, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 326, Batch 3/4: Zeroing gradients...
  Epoch 326, Batch 3/4: Forward pass...
  Epoch 326, Batch 3/4: Calculating loss...
  Epoch 326, Batch 3/4: Backward pass...
  Epoch 326, Batch 3/4: Clipping gradients...
  Epoch 326, Batch 3/4: Optimizer step...
  Epoch 326, Batch 3/4: Completed in 0.20s
  Epoch 326, Batch 4/4: Loading data to device...
  Epoch 326, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 326, Batch 4/4: Zeroing gradients...
  Epoch 326, Batch 4/4: Forward pass...
  Epoch 326, Batch 4/4: Calculating loss...
  Epoch 326, Batch 4/4: Backward pass...
  Epoch 326, Batch 4/4: Clipping gradients...
  Epoch 326, Batch 4/4: Optimizer step...
  Epoch 326, Batch 4/4: Completed in 0.03s
Epoch 326: Training phase completed. Average Train Loss: 0.3278
Epoch 326: Starting validation phase...
  Epoch 326, Val Batch 1/1: Loading data...
  Epoch 326, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 326, Val Batch 1/1: Forward pass...
  Epoch 326, Val Batch 1/1: Calculating loss...
Epoch 326: Validation phase completed. Average Val Loss: 0.2703
Epoch 326 Summary ---> Train Loss: 0.3278 / Validation Loss: 0.2703
Epoch 326: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 7)
  Epoch 326: Validation loss did not improve. Epochs without improvement: 8
Epoch 326: Stepping scheduler...
--- Epoch 326 completed in 0.69 seconds ---

--- Starting Epoch 327/1000 ---
Epoch 327: Starting training phase (4 batches)
  Epoch 327, Batch 1/4: Loading data to device...
  Epoch 327, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 327, Batch 1/4: Zeroing gradients...
  Epoch 327, Batch 1/4: Forward pass...
  Epoch 327, Batch 1/4: Calculating loss...
  Epoch 327, Batch 1/4: Backward pass...
  Epoch 327, Batch 1/4: Clipping gradients...
  Epoch 327, Batch 1/4: Optimizer step...
  Epoch 327, Batch 1/4: Completed in 0.19s
  Epoch 327, Batch 2/4: Loading data to device...
  Epoch 327, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 327, Batch 2/4: Zeroing gradients...
  Epoch 327, Batch 2/4: Forward pass...
  Epoch 327, Batch 2/4: Calculating loss...
  Epoch 327, Batch 2/4: Backward pass...
  Epoch 327, Batch 2/4: Clipping gradients...
  Epoch 327, Batch 2/4: Optimizer step...
  Epoch 327, Batch 2/4: Completed in 0.20s
  Epoch 327, Batch 3/4: Loading data to device...
  Epoch 327, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 327, Batch 3/4: Zeroing gradients...
  Epoch 327, Batch 3/4: Forward pass...
  Epoch 327, Batch 3/4: Calculating loss...
  Epoch 327, Batch 3/4: Backward pass...
  Epoch 327, Batch 3/4: Clipping gradients...
  Epoch 327, Batch 3/4: Optimizer step...
  Epoch 327, Batch 3/4: Completed in 0.19s
  Epoch 327, Batch 4/4: Loading data to device...
  Epoch 327, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 327, Batch 4/4: Zeroing gradients...
  Epoch 327, Batch 4/4: Forward pass...
  Epoch 327, Batch 4/4: Calculating loss...
  Epoch 327, Batch 4/4: Backward pass...
  Epoch 327, Batch 4/4: Clipping gradients...
  Epoch 327, Batch 4/4: Optimizer step...
  Epoch 327, Batch 4/4: Completed in 0.03s
Epoch 327: Training phase completed. Average Train Loss: 0.3095
Epoch 327: Starting validation phase...
  Epoch 327, Val Batch 1/1: Loading data...
  Epoch 327, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 327, Val Batch 1/1: Forward pass...
  Epoch 327, Val Batch 1/1: Calculating loss...
Epoch 327: Validation phase completed. Average Val Loss: 0.2696
Epoch 327 Summary ---> Train Loss: 0.3095 / Validation Loss: 0.2696
Epoch 327: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 8)
  Epoch 327: Validation loss did not improve. Epochs without improvement: 9
Epoch 327: Stepping scheduler...
--- Epoch 327 completed in 0.68 seconds ---

--- Starting Epoch 328/1000 ---
Epoch 328: Starting training phase (4 batches)
  Epoch 328, Batch 1/4: Loading data to device...
  Epoch 328, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 328, Batch 1/4: Zeroing gradients...
  Epoch 328, Batch 1/4: Forward pass...
  Epoch 328, Batch 1/4: Calculating loss...
  Epoch 328, Batch 1/4: Backward pass...
  Epoch 328, Batch 1/4: Clipping gradients...
  Epoch 328, Batch 1/4: Optimizer step...
  Epoch 328, Batch 1/4: Completed in 0.20s
  Epoch 328, Batch 2/4: Loading data to device...
  Epoch 328, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 328, Batch 2/4: Zeroing gradients...
  Epoch 328, Batch 2/4: Forward pass...
  Epoch 328, Batch 2/4: Calculating loss...
  Epoch 328, Batch 2/4: Backward pass...
  Epoch 328, Batch 2/4: Clipping gradients...
  Epoch 328, Batch 2/4: Optimizer step...
  Epoch 328, Batch 2/4: Completed in 0.20s
  Epoch 328, Batch 3/4: Loading data to device...
  Epoch 328, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 328, Batch 3/4: Zeroing gradients...
  Epoch 328, Batch 3/4: Forward pass...
  Epoch 328, Batch 3/4: Calculating loss...
  Epoch 328, Batch 3/4: Backward pass...
  Epoch 328, Batch 3/4: Clipping gradients...
  Epoch 328, Batch 3/4: Optimizer step...
  Epoch 328, Batch 3/4: Completed in 0.19s
  Epoch 328, Batch 4/4: Loading data to device...
  Epoch 328, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 328, Batch 4/4: Zeroing gradients...
  Epoch 328, Batch 4/4: Forward pass...
  Epoch 328, Batch 4/4: Calculating loss...
  Epoch 328, Batch 4/4: Backward pass...
  Epoch 328, Batch 4/4: Clipping gradients...
  Epoch 328, Batch 4/4: Optimizer step...
  Epoch 328, Batch 4/4: Completed in 0.03s
Epoch 328: Training phase completed. Average Train Loss: 0.3184
Epoch 328: Starting validation phase...
  Epoch 328, Val Batch 1/1: Loading data...
  Epoch 328, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 328, Val Batch 1/1: Forward pass...
  Epoch 328, Val Batch 1/1: Calculating loss...
Epoch 328: Validation phase completed. Average Val Loss: 0.2731
Epoch 328 Summary ---> Train Loss: 0.3184 / Validation Loss: 0.2731
Epoch 328: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 9)
  Epoch 328: Validation loss did not improve. Epochs without improvement: 10
Epoch 328: Stepping scheduler...
--- Epoch 328 completed in 0.69 seconds ---

--- Starting Epoch 329/1000 ---
Epoch 329: Starting training phase (4 batches)
  Epoch 329, Batch 1/4: Loading data to device...
  Epoch 329, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 329, Batch 1/4: Zeroing gradients...
  Epoch 329, Batch 1/4: Forward pass...
  Epoch 329, Batch 1/4: Calculating loss...
  Epoch 329, Batch 1/4: Backward pass...
  Epoch 329, Batch 1/4: Clipping gradients...
  Epoch 329, Batch 1/4: Optimizer step...
  Epoch 329, Batch 1/4: Completed in 0.20s
  Epoch 329, Batch 2/4: Loading data to device...
  Epoch 329, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 329, Batch 2/4: Zeroing gradients...
  Epoch 329, Batch 2/4: Forward pass...
  Epoch 329, Batch 2/4: Calculating loss...
  Epoch 329, Batch 2/4: Backward pass...
  Epoch 329, Batch 2/4: Clipping gradients...
  Epoch 329, Batch 2/4: Optimizer step...
  Epoch 329, Batch 2/4: Completed in 0.20s
  Epoch 329, Batch 3/4: Loading data to device...
  Epoch 329, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 329, Batch 3/4: Zeroing gradients...
  Epoch 329, Batch 3/4: Forward pass...
  Epoch 329, Batch 3/4: Calculating loss...
  Epoch 329, Batch 3/4: Backward pass...
  Epoch 329, Batch 3/4: Clipping gradients...
  Epoch 329, Batch 3/4: Optimizer step...
  Epoch 329, Batch 3/4: Completed in 0.20s
  Epoch 329, Batch 4/4: Loading data to device...
  Epoch 329, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 329, Batch 4/4: Zeroing gradients...
  Epoch 329, Batch 4/4: Forward pass...
  Epoch 329, Batch 4/4: Calculating loss...
  Epoch 329, Batch 4/4: Backward pass...
  Epoch 329, Batch 4/4: Clipping gradients...
  Epoch 329, Batch 4/4: Optimizer step...
  Epoch 329, Batch 4/4: Completed in 0.03s
Epoch 329: Training phase completed. Average Train Loss: 0.3655
Epoch 329: Starting validation phase...
  Epoch 329, Val Batch 1/1: Loading data...
  Epoch 329, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 329, Val Batch 1/1: Forward pass...
  Epoch 329, Val Batch 1/1: Calculating loss...
Epoch 329: Validation phase completed. Average Val Loss: 0.2760
Epoch 329 Summary ---> Train Loss: 0.3655 / Validation Loss: 0.2760
Epoch 329: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 10)
  Epoch 329: Validation loss did not improve. Epochs without improvement: 11
Epoch 329: Stepping scheduler...
--- Epoch 329 completed in 0.70 seconds ---

--- Starting Epoch 330/1000 ---
Epoch 330: Starting training phase (4 batches)
  Epoch 330, Batch 1/4: Loading data to device...
  Epoch 330, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 330, Batch 1/4: Zeroing gradients...
  Epoch 330, Batch 1/4: Forward pass...
  Epoch 330, Batch 1/4: Calculating loss...
  Epoch 330, Batch 1/4: Backward pass...
  Epoch 330, Batch 1/4: Clipping gradients...
  Epoch 330, Batch 1/4: Optimizer step...
  Epoch 330, Batch 1/4: Completed in 0.20s
  Epoch 330, Batch 2/4: Loading data to device...
  Epoch 330, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 330, Batch 2/4: Zeroing gradients...
  Epoch 330, Batch 2/4: Forward pass...
  Epoch 330, Batch 2/4: Calculating loss...
  Epoch 330, Batch 2/4: Backward pass...
  Epoch 330, Batch 2/4: Clipping gradients...
  Epoch 330, Batch 2/4: Optimizer step...
  Epoch 330, Batch 2/4: Completed in 0.20s
  Epoch 330, Batch 3/4: Loading data to device...
  Epoch 330, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 330, Batch 3/4: Zeroing gradients...
  Epoch 330, Batch 3/4: Forward pass...
  Epoch 330, Batch 3/4: Calculating loss...
  Epoch 330, Batch 3/4: Backward pass...
  Epoch 330, Batch 3/4: Clipping gradients...
  Epoch 330, Batch 3/4: Optimizer step...
  Epoch 330, Batch 3/4: Completed in 0.20s
  Epoch 330, Batch 4/4: Loading data to device...
  Epoch 330, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 330, Batch 4/4: Zeroing gradients...
  Epoch 330, Batch 4/4: Forward pass...
  Epoch 330, Batch 4/4: Calculating loss...
  Epoch 330, Batch 4/4: Backward pass...
  Epoch 330, Batch 4/4: Clipping gradients...
  Epoch 330, Batch 4/4: Optimizer step...
  Epoch 330, Batch 4/4: Completed in 0.03s
Epoch 330: Training phase completed. Average Train Loss: 0.3244
Epoch 330: Starting validation phase...
  Epoch 330, Val Batch 1/1: Loading data...
  Epoch 330, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 330, Val Batch 1/1: Forward pass...
  Epoch 330, Val Batch 1/1: Calculating loss...
Epoch 330: Validation phase completed. Average Val Loss: 0.2705
Epoch 330 Summary ---> Train Loss: 0.3244 / Validation Loss: 0.2705
Epoch 330: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 11)
  Epoch 330: Validation loss did not improve. Epochs without improvement: 12
Epoch 330: Stepping scheduler...
--- Epoch 330 completed in 0.69 seconds ---

--- Starting Epoch 331/1000 ---
Epoch 331: Starting training phase (4 batches)
  Epoch 331, Batch 1/4: Loading data to device...
  Epoch 331, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 331, Batch 1/4: Zeroing gradients...
  Epoch 331, Batch 1/4: Forward pass...
  Epoch 331, Batch 1/4: Calculating loss...
  Epoch 331, Batch 1/4: Backward pass...
  Epoch 331, Batch 1/4: Clipping gradients...
  Epoch 331, Batch 1/4: Optimizer step...
  Epoch 331, Batch 1/4: Completed in 0.19s
  Epoch 331, Batch 2/4: Loading data to device...
  Epoch 331, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 331, Batch 2/4: Zeroing gradients...
  Epoch 331, Batch 2/4: Forward pass...
  Epoch 331, Batch 2/4: Calculating loss...
  Epoch 331, Batch 2/4: Backward pass...
  Epoch 331, Batch 2/4: Clipping gradients...
  Epoch 331, Batch 2/4: Optimizer step...
  Epoch 331, Batch 2/4: Completed in 0.20s
  Epoch 331, Batch 3/4: Loading data to device...
  Epoch 331, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 331, Batch 3/4: Zeroing gradients...
  Epoch 331, Batch 3/4: Forward pass...
  Epoch 331, Batch 3/4: Calculating loss...
  Epoch 331, Batch 3/4: Backward pass...
  Epoch 331, Batch 3/4: Clipping gradients...
  Epoch 331, Batch 3/4: Optimizer step...
  Epoch 331, Batch 3/4: Completed in 0.19s
  Epoch 331, Batch 4/4: Loading data to device...
  Epoch 331, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 331, Batch 4/4: Zeroing gradients...
  Epoch 331, Batch 4/4: Forward pass...
  Epoch 331, Batch 4/4: Calculating loss...
  Epoch 331, Batch 4/4: Backward pass...
  Epoch 331, Batch 4/4: Clipping gradients...
  Epoch 331, Batch 4/4: Optimizer step...
  Epoch 331, Batch 4/4: Completed in 0.03s
Epoch 331: Training phase completed. Average Train Loss: 0.3120
Epoch 331: Starting validation phase...
  Epoch 331, Val Batch 1/1: Loading data...
  Epoch 331, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 331, Val Batch 1/1: Forward pass...
  Epoch 331, Val Batch 1/1: Calculating loss...
Epoch 331: Validation phase completed. Average Val Loss: 0.2701
Epoch 331 Summary ---> Train Loss: 0.3120 / Validation Loss: 0.2701
Epoch 331: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 12)
  Epoch 331: Validation loss did not improve. Epochs without improvement: 13
Epoch 331: Stepping scheduler...
--- Epoch 331 completed in 0.68 seconds ---

--- Starting Epoch 332/1000 ---
Epoch 332: Starting training phase (4 batches)
  Epoch 332, Batch 1/4: Loading data to device...
  Epoch 332, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 332, Batch 1/4: Zeroing gradients...
  Epoch 332, Batch 1/4: Forward pass...
  Epoch 332, Batch 1/4: Calculating loss...
  Epoch 332, Batch 1/4: Backward pass...
  Epoch 332, Batch 1/4: Clipping gradients...
  Epoch 332, Batch 1/4: Optimizer step...
  Epoch 332, Batch 1/4: Completed in 0.20s
  Epoch 332, Batch 2/4: Loading data to device...
  Epoch 332, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 332, Batch 2/4: Zeroing gradients...
  Epoch 332, Batch 2/4: Forward pass...
  Epoch 332, Batch 2/4: Calculating loss...
  Epoch 332, Batch 2/4: Backward pass...
  Epoch 332, Batch 2/4: Clipping gradients...
  Epoch 332, Batch 2/4: Optimizer step...
  Epoch 332, Batch 2/4: Completed in 0.19s
  Epoch 332, Batch 3/4: Loading data to device...
  Epoch 332, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 332, Batch 3/4: Zeroing gradients...
  Epoch 332, Batch 3/4: Forward pass...
  Epoch 332, Batch 3/4: Calculating loss...
  Epoch 332, Batch 3/4: Backward pass...
  Epoch 332, Batch 3/4: Clipping gradients...
  Epoch 332, Batch 3/4: Optimizer step...
  Epoch 332, Batch 3/4: Completed in 0.19s
  Epoch 332, Batch 4/4: Loading data to device...
  Epoch 332, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 332, Batch 4/4: Zeroing gradients...
  Epoch 332, Batch 4/4: Forward pass...
  Epoch 332, Batch 4/4: Calculating loss...
  Epoch 332, Batch 4/4: Backward pass...
  Epoch 332, Batch 4/4: Clipping gradients...
  Epoch 332, Batch 4/4: Optimizer step...
  Epoch 332, Batch 4/4: Completed in 0.03s
Epoch 332: Training phase completed. Average Train Loss: 0.3004
Epoch 332: Starting validation phase...
  Epoch 332, Val Batch 1/1: Loading data...
  Epoch 332, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 332, Val Batch 1/1: Forward pass...
  Epoch 332, Val Batch 1/1: Calculating loss...
Epoch 332: Validation phase completed. Average Val Loss: 0.2724
Epoch 332 Summary ---> Train Loss: 0.3004 / Validation Loss: 0.2724
Epoch 332: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 13)
  Epoch 332: Validation loss did not improve. Epochs without improvement: 14
Epoch 332: Stepping scheduler...
--- Epoch 332 completed in 0.69 seconds ---

--- Starting Epoch 333/1000 ---
Epoch 333: Starting training phase (4 batches)
  Epoch 333, Batch 1/4: Loading data to device...
  Epoch 333, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 333, Batch 1/4: Zeroing gradients...
  Epoch 333, Batch 1/4: Forward pass...
  Epoch 333, Batch 1/4: Calculating loss...
  Epoch 333, Batch 1/4: Backward pass...
  Epoch 333, Batch 1/4: Clipping gradients...
  Epoch 333, Batch 1/4: Optimizer step...
  Epoch 333, Batch 1/4: Completed in 0.19s
  Epoch 333, Batch 2/4: Loading data to device...
  Epoch 333, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 333, Batch 2/4: Zeroing gradients...
  Epoch 333, Batch 2/4: Forward pass...
  Epoch 333, Batch 2/4: Calculating loss...
  Epoch 333, Batch 2/4: Backward pass...
  Epoch 333, Batch 2/4: Clipping gradients...
  Epoch 333, Batch 2/4: Optimizer step...
  Epoch 333, Batch 2/4: Completed in 0.20s
  Epoch 333, Batch 3/4: Loading data to device...
  Epoch 333, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 333, Batch 3/4: Zeroing gradients...
  Epoch 333, Batch 3/4: Forward pass...
  Epoch 333, Batch 3/4: Calculating loss...
  Epoch 333, Batch 3/4: Backward pass...
  Epoch 333, Batch 3/4: Clipping gradients...
  Epoch 333, Batch 3/4: Optimizer step...
  Epoch 333, Batch 3/4: Completed in 0.20s
  Epoch 333, Batch 4/4: Loading data to device...
  Epoch 333, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 333, Batch 4/4: Zeroing gradients...
  Epoch 333, Batch 4/4: Forward pass...
  Epoch 333, Batch 4/4: Calculating loss...
  Epoch 333, Batch 4/4: Backward pass...
  Epoch 333, Batch 4/4: Clipping gradients...
  Epoch 333, Batch 4/4: Optimizer step...
  Epoch 333, Batch 4/4: Completed in 0.03s
Epoch 333: Training phase completed. Average Train Loss: 0.3544
Epoch 333: Starting validation phase...
  Epoch 333, Val Batch 1/1: Loading data...
  Epoch 333, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 333, Val Batch 1/1: Forward pass...
  Epoch 333, Val Batch 1/1: Calculating loss...
Epoch 333: Validation phase completed. Average Val Loss: 0.2699
Epoch 333 Summary ---> Train Loss: 0.3544 / Validation Loss: 0.2699
Epoch 333: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 14)
  Epoch 333: Validation loss did not improve. Epochs without improvement: 15
Epoch 333: Stepping scheduler...
--- Epoch 333 completed in 0.68 seconds ---

--- Starting Epoch 334/1000 ---
Epoch 334: Starting training phase (4 batches)
  Epoch 334, Batch 1/4: Loading data to device...
  Epoch 334, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 334, Batch 1/4: Zeroing gradients...
  Epoch 334, Batch 1/4: Forward pass...
  Epoch 334, Batch 1/4: Calculating loss...
  Epoch 334, Batch 1/4: Backward pass...
  Epoch 334, Batch 1/4: Clipping gradients...
  Epoch 334, Batch 1/4: Optimizer step...
  Epoch 334, Batch 1/4: Completed in 0.19s
  Epoch 334, Batch 2/4: Loading data to device...
  Epoch 334, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 334, Batch 2/4: Zeroing gradients...
  Epoch 334, Batch 2/4: Forward pass...
  Epoch 334, Batch 2/4: Calculating loss...
  Epoch 334, Batch 2/4: Backward pass...
  Epoch 334, Batch 2/4: Clipping gradients...
  Epoch 334, Batch 2/4: Optimizer step...
  Epoch 334, Batch 2/4: Completed in 0.20s
  Epoch 334, Batch 3/4: Loading data to device...
  Epoch 334, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 334, Batch 3/4: Zeroing gradients...
  Epoch 334, Batch 3/4: Forward pass...
  Epoch 334, Batch 3/4: Calculating loss...
  Epoch 334, Batch 3/4: Backward pass...
  Epoch 334, Batch 3/4: Clipping gradients...
  Epoch 334, Batch 3/4: Optimizer step...
  Epoch 334, Batch 3/4: Completed in 0.20s
  Epoch 334, Batch 4/4: Loading data to device...
  Epoch 334, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 334, Batch 4/4: Zeroing gradients...
  Epoch 334, Batch 4/4: Forward pass...
  Epoch 334, Batch 4/4: Calculating loss...
  Epoch 334, Batch 4/4: Backward pass...
  Epoch 334, Batch 4/4: Clipping gradients...
  Epoch 334, Batch 4/4: Optimizer step...
  Epoch 334, Batch 4/4: Completed in 0.03s
Epoch 334: Training phase completed. Average Train Loss: 0.3040
Epoch 334: Starting validation phase...
  Epoch 334, Val Batch 1/1: Loading data...
  Epoch 334, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 334, Val Batch 1/1: Forward pass...
  Epoch 334, Val Batch 1/1: Calculating loss...
Epoch 334: Validation phase completed. Average Val Loss: 0.2734
Epoch 334 Summary ---> Train Loss: 0.3040 / Validation Loss: 0.2734
Epoch 334: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 15)
  Epoch 334: Validation loss did not improve. Epochs without improvement: 16
Epoch 334: Stepping scheduler...
--- Epoch 334 completed in 0.68 seconds ---

--- Starting Epoch 335/1000 ---
Epoch 335: Starting training phase (4 batches)
  Epoch 335, Batch 1/4: Loading data to device...
  Epoch 335, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 335, Batch 1/4: Zeroing gradients...
  Epoch 335, Batch 1/4: Forward pass...
  Epoch 335, Batch 1/4: Calculating loss...
  Epoch 335, Batch 1/4: Backward pass...
  Epoch 335, Batch 1/4: Clipping gradients...
  Epoch 335, Batch 1/4: Optimizer step...
  Epoch 335, Batch 1/4: Completed in 0.20s
  Epoch 335, Batch 2/4: Loading data to device...
  Epoch 335, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 335, Batch 2/4: Zeroing gradients...
  Epoch 335, Batch 2/4: Forward pass...
  Epoch 335, Batch 2/4: Calculating loss...
  Epoch 335, Batch 2/4: Backward pass...
  Epoch 335, Batch 2/4: Clipping gradients...
  Epoch 335, Batch 2/4: Optimizer step...
  Epoch 335, Batch 2/4: Completed in 0.20s
  Epoch 335, Batch 3/4: Loading data to device...
  Epoch 335, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 335, Batch 3/4: Zeroing gradients...
  Epoch 335, Batch 3/4: Forward pass...
  Epoch 335, Batch 3/4: Calculating loss...
  Epoch 335, Batch 3/4: Backward pass...
  Epoch 335, Batch 3/4: Clipping gradients...
  Epoch 335, Batch 3/4: Optimizer step...
  Epoch 335, Batch 3/4: Completed in 0.19s
  Epoch 335, Batch 4/4: Loading data to device...
  Epoch 335, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 335, Batch 4/4: Zeroing gradients...
  Epoch 335, Batch 4/4: Forward pass...
  Epoch 335, Batch 4/4: Calculating loss...
  Epoch 335, Batch 4/4: Backward pass...
  Epoch 335, Batch 4/4: Clipping gradients...
  Epoch 335, Batch 4/4: Optimizer step...
  Epoch 335, Batch 4/4: Completed in 0.04s
Epoch 335: Training phase completed. Average Train Loss: 0.3051
Epoch 335: Starting validation phase...
  Epoch 335, Val Batch 1/1: Loading data...
  Epoch 335, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 335, Val Batch 1/1: Forward pass...
  Epoch 335, Val Batch 1/1: Calculating loss...
Epoch 335: Validation phase completed. Average Val Loss: 0.2740
Epoch 335 Summary ---> Train Loss: 0.3051 / Validation Loss: 0.2740
Epoch 335: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 16)
  Epoch 335: Validation loss did not improve. Epochs without improvement: 17
Epoch 335: Stepping scheduler...
--- Epoch 335 completed in 0.69 seconds ---

--- Starting Epoch 336/1000 ---
Epoch 336: Starting training phase (4 batches)
  Epoch 336, Batch 1/4: Loading data to device...
  Epoch 336, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 336, Batch 1/4: Zeroing gradients...
  Epoch 336, Batch 1/4: Forward pass...
  Epoch 336, Batch 1/4: Calculating loss...
  Epoch 336, Batch 1/4: Backward pass...
  Epoch 336, Batch 1/4: Clipping gradients...
  Epoch 336, Batch 1/4: Optimizer step...
  Epoch 336, Batch 1/4: Completed in 0.19s
  Epoch 336, Batch 2/4: Loading data to device...
  Epoch 336, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 336, Batch 2/4: Zeroing gradients...
  Epoch 336, Batch 2/4: Forward pass...
  Epoch 336, Batch 2/4: Calculating loss...
  Epoch 336, Batch 2/4: Backward pass...
  Epoch 336, Batch 2/4: Clipping gradients...
  Epoch 336, Batch 2/4: Optimizer step...
  Epoch 336, Batch 2/4: Completed in 0.20s
  Epoch 336, Batch 3/4: Loading data to device...
  Epoch 336, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 336, Batch 3/4: Zeroing gradients...
  Epoch 336, Batch 3/4: Forward pass...
  Epoch 336, Batch 3/4: Calculating loss...
  Epoch 336, Batch 3/4: Backward pass...
  Epoch 336, Batch 3/4: Clipping gradients...
  Epoch 336, Batch 3/4: Optimizer step...
  Epoch 336, Batch 3/4: Completed in 0.20s
  Epoch 336, Batch 4/4: Loading data to device...
  Epoch 336, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 336, Batch 4/4: Zeroing gradients...
  Epoch 336, Batch 4/4: Forward pass...
  Epoch 336, Batch 4/4: Calculating loss...
  Epoch 336, Batch 4/4: Backward pass...
  Epoch 336, Batch 4/4: Clipping gradients...
  Epoch 336, Batch 4/4: Optimizer step...
  Epoch 336, Batch 4/4: Completed in 0.03s
Epoch 336: Training phase completed. Average Train Loss: 0.3088
Epoch 336: Starting validation phase...
  Epoch 336, Val Batch 1/1: Loading data...
  Epoch 336, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 336, Val Batch 1/1: Forward pass...
  Epoch 336, Val Batch 1/1: Calculating loss...
Epoch 336: Validation phase completed. Average Val Loss: 0.2725
Epoch 336 Summary ---> Train Loss: 0.3088 / Validation Loss: 0.2725
Epoch 336: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 17)
  Epoch 336: Validation loss did not improve. Epochs without improvement: 18
Epoch 336: Stepping scheduler...
--- Epoch 336 completed in 0.69 seconds ---

--- Starting Epoch 337/1000 ---
Epoch 337: Starting training phase (4 batches)
  Epoch 337, Batch 1/4: Loading data to device...
  Epoch 337, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 337, Batch 1/4: Zeroing gradients...
  Epoch 337, Batch 1/4: Forward pass...
  Epoch 337, Batch 1/4: Calculating loss...
  Epoch 337, Batch 1/4: Backward pass...
  Epoch 337, Batch 1/4: Clipping gradients...
  Epoch 337, Batch 1/4: Optimizer step...
  Epoch 337, Batch 1/4: Completed in 0.20s
  Epoch 337, Batch 2/4: Loading data to device...
  Epoch 337, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 337, Batch 2/4: Zeroing gradients...
  Epoch 337, Batch 2/4: Forward pass...
  Epoch 337, Batch 2/4: Calculating loss...
  Epoch 337, Batch 2/4: Backward pass...
  Epoch 337, Batch 2/4: Clipping gradients...
  Epoch 337, Batch 2/4: Optimizer step...
  Epoch 337, Batch 2/4: Completed in 0.19s
  Epoch 337, Batch 3/4: Loading data to device...
  Epoch 337, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 337, Batch 3/4: Zeroing gradients...
  Epoch 337, Batch 3/4: Forward pass...
  Epoch 337, Batch 3/4: Calculating loss...
  Epoch 337, Batch 3/4: Backward pass...
  Epoch 337, Batch 3/4: Clipping gradients...
  Epoch 337, Batch 3/4: Optimizer step...
  Epoch 337, Batch 3/4: Completed in 0.19s
  Epoch 337, Batch 4/4: Loading data to device...
  Epoch 337, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 337, Batch 4/4: Zeroing gradients...
  Epoch 337, Batch 4/4: Forward pass...
  Epoch 337, Batch 4/4: Calculating loss...
  Epoch 337, Batch 4/4: Backward pass...
  Epoch 337, Batch 4/4: Clipping gradients...
  Epoch 337, Batch 4/4: Optimizer step...
  Epoch 337, Batch 4/4: Completed in 0.03s
Epoch 337: Training phase completed. Average Train Loss: 0.3212
Epoch 337: Starting validation phase...
  Epoch 337, Val Batch 1/1: Loading data...
  Epoch 337, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 337, Val Batch 1/1: Forward pass...
  Epoch 337, Val Batch 1/1: Calculating loss...
Epoch 337: Validation phase completed. Average Val Loss: 0.2688
Epoch 337 Summary ---> Train Loss: 0.3212 / Validation Loss: 0.2688
Epoch 337: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 18)
  Epoch 337: Validation loss did not improve. Epochs without improvement: 19
Epoch 337: Stepping scheduler...
--- Epoch 337 completed in 0.67 seconds ---

--- Starting Epoch 338/1000 ---
Epoch 338: Starting training phase (4 batches)
  Epoch 338, Batch 1/4: Loading data to device...
  Epoch 338, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 338, Batch 1/4: Zeroing gradients...
  Epoch 338, Batch 1/4: Forward pass...
  Epoch 338, Batch 1/4: Calculating loss...
  Epoch 338, Batch 1/4: Backward pass...
  Epoch 338, Batch 1/4: Clipping gradients...
  Epoch 338, Batch 1/4: Optimizer step...
  Epoch 338, Batch 1/4: Completed in 0.19s
  Epoch 338, Batch 2/4: Loading data to device...
  Epoch 338, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 338, Batch 2/4: Zeroing gradients...
  Epoch 338, Batch 2/4: Forward pass...
  Epoch 338, Batch 2/4: Calculating loss...
  Epoch 338, Batch 2/4: Backward pass...
  Epoch 338, Batch 2/4: Clipping gradients...
  Epoch 338, Batch 2/4: Optimizer step...
  Epoch 338, Batch 2/4: Completed in 0.19s
  Epoch 338, Batch 3/4: Loading data to device...
  Epoch 338, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 338, Batch 3/4: Zeroing gradients...
  Epoch 338, Batch 3/4: Forward pass...
  Epoch 338, Batch 3/4: Calculating loss...
  Epoch 338, Batch 3/4: Backward pass...
  Epoch 338, Batch 3/4: Clipping gradients...
  Epoch 338, Batch 3/4: Optimizer step...
  Epoch 338, Batch 3/4: Completed in 0.19s
  Epoch 338, Batch 4/4: Loading data to device...
  Epoch 338, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 338, Batch 4/4: Zeroing gradients...
  Epoch 338, Batch 4/4: Forward pass...
  Epoch 338, Batch 4/4: Calculating loss...
  Epoch 338, Batch 4/4: Backward pass...
  Epoch 338, Batch 4/4: Clipping gradients...
  Epoch 338, Batch 4/4: Optimizer step...
  Epoch 338, Batch 4/4: Completed in 0.03s
Epoch 338: Training phase completed. Average Train Loss: 0.3272
Epoch 338: Starting validation phase...
  Epoch 338, Val Batch 1/1: Loading data...
  Epoch 338, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 338, Val Batch 1/1: Forward pass...
  Epoch 338, Val Batch 1/1: Calculating loss...
Epoch 338: Validation phase completed. Average Val Loss: 0.2662
Epoch 338 Summary ---> Train Loss: 0.3272 / Validation Loss: 0.2662
Epoch 338: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 19)
  Epoch 338: Validation loss did not improve. Epochs without improvement: 20
Epoch 338: Stepping scheduler...
--- Epoch 338 completed in 0.67 seconds ---

--- Starting Epoch 339/1000 ---
Epoch 339: Starting training phase (4 batches)
  Epoch 339, Batch 1/4: Loading data to device...
  Epoch 339, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 339, Batch 1/4: Zeroing gradients...
  Epoch 339, Batch 1/4: Forward pass...
  Epoch 339, Batch 1/4: Calculating loss...
  Epoch 339, Batch 1/4: Backward pass...
  Epoch 339, Batch 1/4: Clipping gradients...
  Epoch 339, Batch 1/4: Optimizer step...
  Epoch 339, Batch 1/4: Completed in 0.19s
  Epoch 339, Batch 2/4: Loading data to device...
  Epoch 339, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 339, Batch 2/4: Zeroing gradients...
  Epoch 339, Batch 2/4: Forward pass...
  Epoch 339, Batch 2/4: Calculating loss...
  Epoch 339, Batch 2/4: Backward pass...
  Epoch 339, Batch 2/4: Clipping gradients...
  Epoch 339, Batch 2/4: Optimizer step...
  Epoch 339, Batch 2/4: Completed in 0.19s
  Epoch 339, Batch 3/4: Loading data to device...
  Epoch 339, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 339, Batch 3/4: Zeroing gradients...
  Epoch 339, Batch 3/4: Forward pass...
  Epoch 339, Batch 3/4: Calculating loss...
  Epoch 339, Batch 3/4: Backward pass...
  Epoch 339, Batch 3/4: Clipping gradients...
  Epoch 339, Batch 3/4: Optimizer step...
  Epoch 339, Batch 3/4: Completed in 0.19s
  Epoch 339, Batch 4/4: Loading data to device...
  Epoch 339, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 339, Batch 4/4: Zeroing gradients...
  Epoch 339, Batch 4/4: Forward pass...
  Epoch 339, Batch 4/4: Calculating loss...
  Epoch 339, Batch 4/4: Backward pass...
  Epoch 339, Batch 4/4: Clipping gradients...
  Epoch 339, Batch 4/4: Optimizer step...
  Epoch 339, Batch 4/4: Completed in 0.03s
Epoch 339: Training phase completed. Average Train Loss: 0.3872
Epoch 339: Starting validation phase...
  Epoch 339, Val Batch 1/1: Loading data...
  Epoch 339, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 339, Val Batch 1/1: Forward pass...
  Epoch 339, Val Batch 1/1: Calculating loss...
Epoch 339: Validation phase completed. Average Val Loss: 0.2617
Epoch 339 Summary ---> Train Loss: 0.3872 / Validation Loss: 0.2617
Epoch 339: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 20)
  Epoch 339: Validation loss did not improve. Epochs without improvement: 21
Epoch 339: Stepping scheduler...
--- Epoch 339 completed in 0.67 seconds ---

--- Starting Epoch 340/1000 ---
Epoch 340: Starting training phase (4 batches)
  Epoch 340, Batch 1/4: Loading data to device...
  Epoch 340, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 340, Batch 1/4: Zeroing gradients...
  Epoch 340, Batch 1/4: Forward pass...
  Epoch 340, Batch 1/4: Calculating loss...
  Epoch 340, Batch 1/4: Backward pass...
  Epoch 340, Batch 1/4: Clipping gradients...
  Epoch 340, Batch 1/4: Optimizer step...
  Epoch 340, Batch 1/4: Completed in 0.19s
  Epoch 340, Batch 2/4: Loading data to device...
  Epoch 340, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 340, Batch 2/4: Zeroing gradients...
  Epoch 340, Batch 2/4: Forward pass...
  Epoch 340, Batch 2/4: Calculating loss...
  Epoch 340, Batch 2/4: Backward pass...
  Epoch 340, Batch 2/4: Clipping gradients...
  Epoch 340, Batch 2/4: Optimizer step...
  Epoch 340, Batch 2/4: Completed in 0.19s
  Epoch 340, Batch 3/4: Loading data to device...
  Epoch 340, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 340, Batch 3/4: Zeroing gradients...
  Epoch 340, Batch 3/4: Forward pass...
  Epoch 340, Batch 3/4: Calculating loss...
  Epoch 340, Batch 3/4: Backward pass...
  Epoch 340, Batch 3/4: Clipping gradients...
  Epoch 340, Batch 3/4: Optimizer step...
  Epoch 340, Batch 3/4: Completed in 0.19s
  Epoch 340, Batch 4/4: Loading data to device...
  Epoch 340, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 340, Batch 4/4: Zeroing gradients...
  Epoch 340, Batch 4/4: Forward pass...
  Epoch 340, Batch 4/4: Calculating loss...
  Epoch 340, Batch 4/4: Backward pass...
  Epoch 340, Batch 4/4: Clipping gradients...
  Epoch 340, Batch 4/4: Optimizer step...
  Epoch 340, Batch 4/4: Completed in 0.03s
Epoch 340: Training phase completed. Average Train Loss: 0.3223
Epoch 340: Starting validation phase...
  Epoch 340, Val Batch 1/1: Loading data...
  Epoch 340, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 340, Val Batch 1/1: Forward pass...
  Epoch 340, Val Batch 1/1: Calculating loss...
Epoch 340: Validation phase completed. Average Val Loss: 0.2646
Epoch 340 Summary ---> Train Loss: 0.3223 / Validation Loss: 0.2646
Epoch 340: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 21)
  Epoch 340: Validation loss did not improve. Epochs without improvement: 22
Epoch 340: Stepping scheduler...
--- Epoch 340 completed in 0.67 seconds ---

--- Starting Epoch 341/1000 ---
Epoch 341: Starting training phase (4 batches)
  Epoch 341, Batch 1/4: Loading data to device...
  Epoch 341, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 341, Batch 1/4: Zeroing gradients...
  Epoch 341, Batch 1/4: Forward pass...
  Epoch 341, Batch 1/4: Calculating loss...
  Epoch 341, Batch 1/4: Backward pass...
  Epoch 341, Batch 1/4: Clipping gradients...
  Epoch 341, Batch 1/4: Optimizer step...
  Epoch 341, Batch 1/4: Completed in 0.20s
  Epoch 341, Batch 2/4: Loading data to device...
  Epoch 341, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 341, Batch 2/4: Zeroing gradients...
  Epoch 341, Batch 2/4: Forward pass...
  Epoch 341, Batch 2/4: Calculating loss...
  Epoch 341, Batch 2/4: Backward pass...
  Epoch 341, Batch 2/4: Clipping gradients...
  Epoch 341, Batch 2/4: Optimizer step...
  Epoch 341, Batch 2/4: Completed in 0.19s
  Epoch 341, Batch 3/4: Loading data to device...
  Epoch 341, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 341, Batch 3/4: Zeroing gradients...
  Epoch 341, Batch 3/4: Forward pass...
  Epoch 341, Batch 3/4: Calculating loss...
  Epoch 341, Batch 3/4: Backward pass...
  Epoch 341, Batch 3/4: Clipping gradients...
  Epoch 341, Batch 3/4: Optimizer step...
  Epoch 341, Batch 3/4: Completed in 0.19s
  Epoch 341, Batch 4/4: Loading data to device...
  Epoch 341, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 341, Batch 4/4: Zeroing gradients...
  Epoch 341, Batch 4/4: Forward pass...
  Epoch 341, Batch 4/4: Calculating loss...
  Epoch 341, Batch 4/4: Backward pass...
  Epoch 341, Batch 4/4: Clipping gradients...
  Epoch 341, Batch 4/4: Optimizer step...
  Epoch 341, Batch 4/4: Completed in 0.03s
Epoch 341: Training phase completed. Average Train Loss: 0.3281
Epoch 341: Starting validation phase...
  Epoch 341, Val Batch 1/1: Loading data...
  Epoch 341, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 341, Val Batch 1/1: Forward pass...
  Epoch 341, Val Batch 1/1: Calculating loss...
Epoch 341: Validation phase completed. Average Val Loss: 0.2645
Epoch 341 Summary ---> Train Loss: 0.3281 / Validation Loss: 0.2645
Epoch 341: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 22)
  Epoch 341: Validation loss did not improve. Epochs without improvement: 23
Epoch 341: Stepping scheduler...
--- Epoch 341 completed in 0.69 seconds ---

--- Starting Epoch 342/1000 ---
Epoch 342: Starting training phase (4 batches)
  Epoch 342, Batch 1/4: Loading data to device...
  Epoch 342, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 342, Batch 1/4: Zeroing gradients...
  Epoch 342, Batch 1/4: Forward pass...
  Epoch 342, Batch 1/4: Calculating loss...
  Epoch 342, Batch 1/4: Backward pass...
  Epoch 342, Batch 1/4: Clipping gradients...
  Epoch 342, Batch 1/4: Optimizer step...
  Epoch 342, Batch 1/4: Completed in 0.20s
  Epoch 342, Batch 2/4: Loading data to device...
  Epoch 342, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 342, Batch 2/4: Zeroing gradients...
  Epoch 342, Batch 2/4: Forward pass...
  Epoch 342, Batch 2/4: Calculating loss...
  Epoch 342, Batch 2/4: Backward pass...
  Epoch 342, Batch 2/4: Clipping gradients...
  Epoch 342, Batch 2/4: Optimizer step...
  Epoch 342, Batch 2/4: Completed in 0.19s
  Epoch 342, Batch 3/4: Loading data to device...
  Epoch 342, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 342, Batch 3/4: Zeroing gradients...
  Epoch 342, Batch 3/4: Forward pass...
  Epoch 342, Batch 3/4: Calculating loss...
  Epoch 342, Batch 3/4: Backward pass...
  Epoch 342, Batch 3/4: Clipping gradients...
  Epoch 342, Batch 3/4: Optimizer step...
  Epoch 342, Batch 3/4: Completed in 0.20s
  Epoch 342, Batch 4/4: Loading data to device...
  Epoch 342, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 342, Batch 4/4: Zeroing gradients...
  Epoch 342, Batch 4/4: Forward pass...
  Epoch 342, Batch 4/4: Calculating loss...
  Epoch 342, Batch 4/4: Backward pass...
  Epoch 342, Batch 4/4: Clipping gradients...
  Epoch 342, Batch 4/4: Optimizer step...
  Epoch 342, Batch 4/4: Completed in 0.03s
Epoch 342: Training phase completed. Average Train Loss: 0.3453
Epoch 342: Starting validation phase...
  Epoch 342, Val Batch 1/1: Loading data...
  Epoch 342, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 342, Val Batch 1/1: Forward pass...
  Epoch 342, Val Batch 1/1: Calculating loss...
Epoch 342: Validation phase completed. Average Val Loss: 0.2561
Epoch 342 Summary ---> Train Loss: 0.3453 / Validation Loss: 0.2561
Epoch 342: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 23)
  Epoch 342: Validation loss did not improve. Epochs without improvement: 24
Epoch 342: Stepping scheduler...
--- Epoch 342 completed in 0.69 seconds ---

--- Starting Epoch 343/1000 ---
Epoch 343: Starting training phase (4 batches)
  Epoch 343, Batch 1/4: Loading data to device...
  Epoch 343, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 343, Batch 1/4: Zeroing gradients...
  Epoch 343, Batch 1/4: Forward pass...
  Epoch 343, Batch 1/4: Calculating loss...
  Epoch 343, Batch 1/4: Backward pass...
  Epoch 343, Batch 1/4: Clipping gradients...
  Epoch 343, Batch 1/4: Optimizer step...
  Epoch 343, Batch 1/4: Completed in 0.19s
  Epoch 343, Batch 2/4: Loading data to device...
  Epoch 343, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 343, Batch 2/4: Zeroing gradients...
  Epoch 343, Batch 2/4: Forward pass...
  Epoch 343, Batch 2/4: Calculating loss...
  Epoch 343, Batch 2/4: Backward pass...
  Epoch 343, Batch 2/4: Clipping gradients...
  Epoch 343, Batch 2/4: Optimizer step...
  Epoch 343, Batch 2/4: Completed in 0.20s
  Epoch 343, Batch 3/4: Loading data to device...
  Epoch 343, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 343, Batch 3/4: Zeroing gradients...
  Epoch 343, Batch 3/4: Forward pass...
  Epoch 343, Batch 3/4: Calculating loss...
  Epoch 343, Batch 3/4: Backward pass...
  Epoch 343, Batch 3/4: Clipping gradients...
  Epoch 343, Batch 3/4: Optimizer step...
  Epoch 343, Batch 3/4: Completed in 0.20s
  Epoch 343, Batch 4/4: Loading data to device...
  Epoch 343, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 343, Batch 4/4: Zeroing gradients...
  Epoch 343, Batch 4/4: Forward pass...
  Epoch 343, Batch 4/4: Calculating loss...
  Epoch 343, Batch 4/4: Backward pass...
  Epoch 343, Batch 4/4: Clipping gradients...
  Epoch 343, Batch 4/4: Optimizer step...
  Epoch 343, Batch 4/4: Completed in 0.03s
Epoch 343: Training phase completed. Average Train Loss: 0.3382
Epoch 343: Starting validation phase...
  Epoch 343, Val Batch 1/1: Loading data...
  Epoch 343, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 343, Val Batch 1/1: Forward pass...
  Epoch 343, Val Batch 1/1: Calculating loss...
Epoch 343: Validation phase completed. Average Val Loss: 0.2581
Epoch 343 Summary ---> Train Loss: 0.3382 / Validation Loss: 0.2581
Epoch 343: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 24)
  Epoch 343: Validation loss did not improve. Epochs without improvement: 25
Epoch 343: Stepping scheduler...
--- Epoch 343 completed in 0.69 seconds ---

--- Starting Epoch 344/1000 ---
Epoch 344: Starting training phase (4 batches)
  Epoch 344, Batch 1/4: Loading data to device...
  Epoch 344, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 344, Batch 1/4: Zeroing gradients...
  Epoch 344, Batch 1/4: Forward pass...
  Epoch 344, Batch 1/4: Calculating loss...
  Epoch 344, Batch 1/4: Backward pass...
  Epoch 344, Batch 1/4: Clipping gradients...
  Epoch 344, Batch 1/4: Optimizer step...
  Epoch 344, Batch 1/4: Completed in 0.20s
  Epoch 344, Batch 2/4: Loading data to device...
  Epoch 344, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 344, Batch 2/4: Zeroing gradients...
  Epoch 344, Batch 2/4: Forward pass...
  Epoch 344, Batch 2/4: Calculating loss...
  Epoch 344, Batch 2/4: Backward pass...
  Epoch 344, Batch 2/4: Clipping gradients...
  Epoch 344, Batch 2/4: Optimizer step...
  Epoch 344, Batch 2/4: Completed in 0.20s
  Epoch 344, Batch 3/4: Loading data to device...
  Epoch 344, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 344, Batch 3/4: Zeroing gradients...
  Epoch 344, Batch 3/4: Forward pass...
  Epoch 344, Batch 3/4: Calculating loss...
  Epoch 344, Batch 3/4: Backward pass...
  Epoch 344, Batch 3/4: Clipping gradients...
  Epoch 344, Batch 3/4: Optimizer step...
  Epoch 344, Batch 3/4: Completed in 0.19s
  Epoch 344, Batch 4/4: Loading data to device...
  Epoch 344, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 344, Batch 4/4: Zeroing gradients...
  Epoch 344, Batch 4/4: Forward pass...
  Epoch 344, Batch 4/4: Calculating loss...
  Epoch 344, Batch 4/4: Backward pass...
  Epoch 344, Batch 4/4: Clipping gradients...
  Epoch 344, Batch 4/4: Optimizer step...
  Epoch 344, Batch 4/4: Completed in 0.03s
Epoch 344: Training phase completed. Average Train Loss: 0.4095
Epoch 344: Starting validation phase...
  Epoch 344, Val Batch 1/1: Loading data...
  Epoch 344, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 344, Val Batch 1/1: Forward pass...
  Epoch 344, Val Batch 1/1: Calculating loss...
Epoch 344: Validation phase completed. Average Val Loss: 0.2566
Epoch 344 Summary ---> Train Loss: 0.4095 / Validation Loss: 0.2566
Epoch 344: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 25)
  Epoch 344: Validation loss did not improve. Epochs without improvement: 26
Epoch 344: Stepping scheduler...
--- Epoch 344 completed in 0.69 seconds ---

--- Starting Epoch 345/1000 ---
Epoch 345: Starting training phase (4 batches)
  Epoch 345, Batch 1/4: Loading data to device...
  Epoch 345, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 345, Batch 1/4: Zeroing gradients...
  Epoch 345, Batch 1/4: Forward pass...
  Epoch 345, Batch 1/4: Calculating loss...
  Epoch 345, Batch 1/4: Backward pass...
  Epoch 345, Batch 1/4: Clipping gradients...
  Epoch 345, Batch 1/4: Optimizer step...
  Epoch 345, Batch 1/4: Completed in 0.19s
  Epoch 345, Batch 2/4: Loading data to device...
  Epoch 345, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 345, Batch 2/4: Zeroing gradients...
  Epoch 345, Batch 2/4: Forward pass...
  Epoch 345, Batch 2/4: Calculating loss...
  Epoch 345, Batch 2/4: Backward pass...
  Epoch 345, Batch 2/4: Clipping gradients...
  Epoch 345, Batch 2/4: Optimizer step...
  Epoch 345, Batch 2/4: Completed in 0.19s
  Epoch 345, Batch 3/4: Loading data to device...
  Epoch 345, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 345, Batch 3/4: Zeroing gradients...
  Epoch 345, Batch 3/4: Forward pass...
  Epoch 345, Batch 3/4: Calculating loss...
  Epoch 345, Batch 3/4: Backward pass...
  Epoch 345, Batch 3/4: Clipping gradients...
  Epoch 345, Batch 3/4: Optimizer step...
  Epoch 345, Batch 3/4: Completed in 0.19s
  Epoch 345, Batch 4/4: Loading data to device...
  Epoch 345, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 345, Batch 4/4: Zeroing gradients...
  Epoch 345, Batch 4/4: Forward pass...
  Epoch 345, Batch 4/4: Calculating loss...
  Epoch 345, Batch 4/4: Backward pass...
  Epoch 345, Batch 4/4: Clipping gradients...
  Epoch 345, Batch 4/4: Optimizer step...
  Epoch 345, Batch 4/4: Completed in 0.03s
Epoch 345: Training phase completed. Average Train Loss: 0.3395
Epoch 345: Starting validation phase...
  Epoch 345, Val Batch 1/1: Loading data...
  Epoch 345, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 345, Val Batch 1/1: Forward pass...
  Epoch 345, Val Batch 1/1: Calculating loss...
Epoch 345: Validation phase completed. Average Val Loss: 0.2569
Epoch 345 Summary ---> Train Loss: 0.3395 / Validation Loss: 0.2569
Epoch 345: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 26)
  Epoch 345: Validation loss did not improve. Epochs without improvement: 27
Epoch 345: Stepping scheduler...
--- Epoch 345 completed in 0.67 seconds ---

--- Starting Epoch 346/1000 ---
Epoch 346: Starting training phase (4 batches)
  Epoch 346, Batch 1/4: Loading data to device...
  Epoch 346, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 346, Batch 1/4: Zeroing gradients...
  Epoch 346, Batch 1/4: Forward pass...
  Epoch 346, Batch 1/4: Calculating loss...
  Epoch 346, Batch 1/4: Backward pass...
  Epoch 346, Batch 1/4: Clipping gradients...
  Epoch 346, Batch 1/4: Optimizer step...
  Epoch 346, Batch 1/4: Completed in 0.20s
  Epoch 346, Batch 2/4: Loading data to device...
  Epoch 346, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 346, Batch 2/4: Zeroing gradients...
  Epoch 346, Batch 2/4: Forward pass...
  Epoch 346, Batch 2/4: Calculating loss...
  Epoch 346, Batch 2/4: Backward pass...
  Epoch 346, Batch 2/4: Clipping gradients...
  Epoch 346, Batch 2/4: Optimizer step...
  Epoch 346, Batch 2/4: Completed in 0.19s
  Epoch 346, Batch 3/4: Loading data to device...
  Epoch 346, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 346, Batch 3/4: Zeroing gradients...
  Epoch 346, Batch 3/4: Forward pass...
  Epoch 346, Batch 3/4: Calculating loss...
  Epoch 346, Batch 3/4: Backward pass...
  Epoch 346, Batch 3/4: Clipping gradients...
  Epoch 346, Batch 3/4: Optimizer step...
  Epoch 346, Batch 3/4: Completed in 0.19s
  Epoch 346, Batch 4/4: Loading data to device...
  Epoch 346, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 346, Batch 4/4: Zeroing gradients...
  Epoch 346, Batch 4/4: Forward pass...
  Epoch 346, Batch 4/4: Calculating loss...
  Epoch 346, Batch 4/4: Backward pass...
  Epoch 346, Batch 4/4: Clipping gradients...
  Epoch 346, Batch 4/4: Optimizer step...
  Epoch 346, Batch 4/4: Completed in 0.03s
Epoch 346: Training phase completed. Average Train Loss: 0.3040
Epoch 346: Starting validation phase...
  Epoch 346, Val Batch 1/1: Loading data...
  Epoch 346, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 346, Val Batch 1/1: Forward pass...
  Epoch 346, Val Batch 1/1: Calculating loss...
Epoch 346: Validation phase completed. Average Val Loss: 0.2570
Epoch 346 Summary ---> Train Loss: 0.3040 / Validation Loss: 0.2570
Epoch 346: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 27)
  Epoch 346: Validation loss did not improve. Epochs without improvement: 28
Epoch 346: Stepping scheduler...
--- Epoch 346 completed in 0.68 seconds ---

--- Starting Epoch 347/1000 ---
Epoch 347: Starting training phase (4 batches)
  Epoch 347, Batch 1/4: Loading data to device...
  Epoch 347, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 347, Batch 1/4: Zeroing gradients...
  Epoch 347, Batch 1/4: Forward pass...
  Epoch 347, Batch 1/4: Calculating loss...
  Epoch 347, Batch 1/4: Backward pass...
  Epoch 347, Batch 1/4: Clipping gradients...
  Epoch 347, Batch 1/4: Optimizer step...
  Epoch 347, Batch 1/4: Completed in 0.19s
  Epoch 347, Batch 2/4: Loading data to device...
  Epoch 347, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 347, Batch 2/4: Zeroing gradients...
  Epoch 347, Batch 2/4: Forward pass...
  Epoch 347, Batch 2/4: Calculating loss...
  Epoch 347, Batch 2/4: Backward pass...
  Epoch 347, Batch 2/4: Clipping gradients...
  Epoch 347, Batch 2/4: Optimizer step...
  Epoch 347, Batch 2/4: Completed in 0.19s
  Epoch 347, Batch 3/4: Loading data to device...
  Epoch 347, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 347, Batch 3/4: Zeroing gradients...
  Epoch 347, Batch 3/4: Forward pass...
  Epoch 347, Batch 3/4: Calculating loss...
  Epoch 347, Batch 3/4: Backward pass...
  Epoch 347, Batch 3/4: Clipping gradients...
  Epoch 347, Batch 3/4: Optimizer step...
  Epoch 347, Batch 3/4: Completed in 0.19s
  Epoch 347, Batch 4/4: Loading data to device...
  Epoch 347, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 347, Batch 4/4: Zeroing gradients...
  Epoch 347, Batch 4/4: Forward pass...
  Epoch 347, Batch 4/4: Calculating loss...
  Epoch 347, Batch 4/4: Backward pass...
  Epoch 347, Batch 4/4: Clipping gradients...
  Epoch 347, Batch 4/4: Optimizer step...
  Epoch 347, Batch 4/4: Completed in 0.03s
Epoch 347: Training phase completed. Average Train Loss: 0.3575
Epoch 347: Starting validation phase...
  Epoch 347, Val Batch 1/1: Loading data...
  Epoch 347, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 347, Val Batch 1/1: Forward pass...
  Epoch 347, Val Batch 1/1: Calculating loss...
Epoch 347: Validation phase completed. Average Val Loss: 0.2524
Epoch 347 Summary ---> Train Loss: 0.3575 / Validation Loss: 0.2524
Epoch 347: Checking early stopping... (Current Best Loss: 0.2548, Epochs No Improve: 28)
  Epoch 347: Validation loss improved (0.2548 --> 0.2524). Saving model.
Epoch 347: Stepping scheduler...
--- Epoch 347 completed in 0.67 seconds ---

--- Starting Epoch 348/1000 ---
Epoch 348: Starting training phase (4 batches)
  Epoch 348, Batch 1/4: Loading data to device...
  Epoch 348, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 348, Batch 1/4: Zeroing gradients...
  Epoch 348, Batch 1/4: Forward pass...
  Epoch 348, Batch 1/4: Calculating loss...
  Epoch 348, Batch 1/4: Backward pass...
  Epoch 348, Batch 1/4: Clipping gradients...
  Epoch 348, Batch 1/4: Optimizer step...
  Epoch 348, Batch 1/4: Completed in 0.20s
  Epoch 348, Batch 2/4: Loading data to device...
  Epoch 348, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 348, Batch 2/4: Zeroing gradients...
  Epoch 348, Batch 2/4: Forward pass...
  Epoch 348, Batch 2/4: Calculating loss...
  Epoch 348, Batch 2/4: Backward pass...
  Epoch 348, Batch 2/4: Clipping gradients...
  Epoch 348, Batch 2/4: Optimizer step...
  Epoch 348, Batch 2/4: Completed in 0.19s
  Epoch 348, Batch 3/4: Loading data to device...
  Epoch 348, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 348, Batch 3/4: Zeroing gradients...
  Epoch 348, Batch 3/4: Forward pass...
  Epoch 348, Batch 3/4: Calculating loss...
  Epoch 348, Batch 3/4: Backward pass...
  Epoch 348, Batch 3/4: Clipping gradients...
  Epoch 348, Batch 3/4: Optimizer step...
  Epoch 348, Batch 3/4: Completed in 0.19s
  Epoch 348, Batch 4/4: Loading data to device...
  Epoch 348, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 348, Batch 4/4: Zeroing gradients...
  Epoch 348, Batch 4/4: Forward pass...
  Epoch 348, Batch 4/4: Calculating loss...
  Epoch 348, Batch 4/4: Backward pass...
  Epoch 348, Batch 4/4: Clipping gradients...
  Epoch 348, Batch 4/4: Optimizer step...
  Epoch 348, Batch 4/4: Completed in 0.03s
Epoch 348: Training phase completed. Average Train Loss: 0.2966
Epoch 348: Starting validation phase...
  Epoch 348, Val Batch 1/1: Loading data...
  Epoch 348, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 348, Val Batch 1/1: Forward pass...
  Epoch 348, Val Batch 1/1: Calculating loss...
Epoch 348: Validation phase completed. Average Val Loss: 0.2498
Epoch 348 Summary ---> Train Loss: 0.2966 / Validation Loss: 0.2498
Epoch 348: Checking early stopping... (Current Best Loss: 0.2524, Epochs No Improve: 0)
  Epoch 348: Validation loss improved (0.2524 --> 0.2498). Saving model.
Epoch 348: Stepping scheduler...
--- Epoch 348 completed in 0.67 seconds ---

--- Starting Epoch 349/1000 ---
Epoch 349: Starting training phase (4 batches)
  Epoch 349, Batch 1/4: Loading data to device...
  Epoch 349, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 349, Batch 1/4: Zeroing gradients...
  Epoch 349, Batch 1/4: Forward pass...
  Epoch 349, Batch 1/4: Calculating loss...
  Epoch 349, Batch 1/4: Backward pass...
  Epoch 349, Batch 1/4: Clipping gradients...
  Epoch 349, Batch 1/4: Optimizer step...
  Epoch 349, Batch 1/4: Completed in 0.19s
  Epoch 349, Batch 2/4: Loading data to device...
  Epoch 349, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 349, Batch 2/4: Zeroing gradients...
  Epoch 349, Batch 2/4: Forward pass...
  Epoch 349, Batch 2/4: Calculating loss...
  Epoch 349, Batch 2/4: Backward pass...
  Epoch 349, Batch 2/4: Clipping gradients...
  Epoch 349, Batch 2/4: Optimizer step...
  Epoch 349, Batch 2/4: Completed in 0.20s
  Epoch 349, Batch 3/4: Loading data to device...
  Epoch 349, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 349, Batch 3/4: Zeroing gradients...
  Epoch 349, Batch 3/4: Forward pass...
  Epoch 349, Batch 3/4: Calculating loss...
  Epoch 349, Batch 3/4: Backward pass...
  Epoch 349, Batch 3/4: Clipping gradients...
  Epoch 349, Batch 3/4: Optimizer step...
  Epoch 349, Batch 3/4: Completed in 0.20s
  Epoch 349, Batch 4/4: Loading data to device...
  Epoch 349, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 349, Batch 4/4: Zeroing gradients...
  Epoch 349, Batch 4/4: Forward pass...
  Epoch 349, Batch 4/4: Calculating loss...
  Epoch 349, Batch 4/4: Backward pass...
  Epoch 349, Batch 4/4: Clipping gradients...
  Epoch 349, Batch 4/4: Optimizer step...
  Epoch 349, Batch 4/4: Completed in 0.03s
Epoch 349: Training phase completed. Average Train Loss: 0.3292
Epoch 349: Starting validation phase...
  Epoch 349, Val Batch 1/1: Loading data...
  Epoch 349, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 349, Val Batch 1/1: Forward pass...
  Epoch 349, Val Batch 1/1: Calculating loss...
Epoch 349: Validation phase completed. Average Val Loss: 0.2560
Epoch 349 Summary ---> Train Loss: 0.3292 / Validation Loss: 0.2560
Epoch 349: Checking early stopping... (Current Best Loss: 0.2498, Epochs No Improve: 0)
  Epoch 349: Validation loss did not improve. Epochs without improvement: 1
Epoch 349: Stepping scheduler...
--- Epoch 349 completed in 0.69 seconds ---

--- Starting Epoch 350/1000 ---
Epoch 350: Starting training phase (4 batches)
  Epoch 350, Batch 1/4: Loading data to device...
  Epoch 350, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 350, Batch 1/4: Zeroing gradients...
  Epoch 350, Batch 1/4: Forward pass...
  Epoch 350, Batch 1/4: Calculating loss...
  Epoch 350, Batch 1/4: Backward pass...
  Epoch 350, Batch 1/4: Clipping gradients...
  Epoch 350, Batch 1/4: Optimizer step...
  Epoch 350, Batch 1/4: Completed in 0.19s
  Epoch 350, Batch 2/4: Loading data to device...
  Epoch 350, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 350, Batch 2/4: Zeroing gradients...
  Epoch 350, Batch 2/4: Forward pass...
  Epoch 350, Batch 2/4: Calculating loss...
  Epoch 350, Batch 2/4: Backward pass...
  Epoch 350, Batch 2/4: Clipping gradients...
  Epoch 350, Batch 2/4: Optimizer step...
  Epoch 350, Batch 2/4: Completed in 0.20s
  Epoch 350, Batch 3/4: Loading data to device...
  Epoch 350, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 350, Batch 3/4: Zeroing gradients...
  Epoch 350, Batch 3/4: Forward pass...
  Epoch 350, Batch 3/4: Calculating loss...
  Epoch 350, Batch 3/4: Backward pass...
  Epoch 350, Batch 3/4: Clipping gradients...
  Epoch 350, Batch 3/4: Optimizer step...
  Epoch 350, Batch 3/4: Completed in 0.20s
  Epoch 350, Batch 4/4: Loading data to device...
  Epoch 350, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 350, Batch 4/4: Zeroing gradients...
  Epoch 350, Batch 4/4: Forward pass...
  Epoch 350, Batch 4/4: Calculating loss...
  Epoch 350, Batch 4/4: Backward pass...
  Epoch 350, Batch 4/4: Clipping gradients...
  Epoch 350, Batch 4/4: Optimizer step...
  Epoch 350, Batch 4/4: Completed in 0.03s
Epoch 350: Training phase completed. Average Train Loss: 0.3080
Epoch 350: Starting validation phase...
  Epoch 350, Val Batch 1/1: Loading data...
  Epoch 350, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 350, Val Batch 1/1: Forward pass...
  Epoch 350, Val Batch 1/1: Calculating loss...
Epoch 350: Validation phase completed. Average Val Loss: 0.2575
Epoch 350 Summary ---> Train Loss: 0.3080 / Validation Loss: 0.2575
Epoch 350: Checking early stopping... (Current Best Loss: 0.2498, Epochs No Improve: 1)
  Epoch 350: Validation loss did not improve. Epochs without improvement: 2
Epoch 350: Stepping scheduler...
--- Epoch 350 completed in 0.69 seconds ---

--- Starting Epoch 351/1000 ---
Epoch 351: Starting training phase (4 batches)
  Epoch 351, Batch 1/4: Loading data to device...
  Epoch 351, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 351, Batch 1/4: Zeroing gradients...
  Epoch 351, Batch 1/4: Forward pass...
  Epoch 351, Batch 1/4: Calculating loss...
  Epoch 351, Batch 1/4: Backward pass...
  Epoch 351, Batch 1/4: Clipping gradients...
  Epoch 351, Batch 1/4: Optimizer step...
  Epoch 351, Batch 1/4: Completed in 0.19s
  Epoch 351, Batch 2/4: Loading data to device...
  Epoch 351, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 351, Batch 2/4: Zeroing gradients...
  Epoch 351, Batch 2/4: Forward pass...
  Epoch 351, Batch 2/4: Calculating loss...
  Epoch 351, Batch 2/4: Backward pass...
  Epoch 351, Batch 2/4: Clipping gradients...
  Epoch 351, Batch 2/4: Optimizer step...
  Epoch 351, Batch 2/4: Completed in 0.20s
  Epoch 351, Batch 3/4: Loading data to device...
  Epoch 351, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 351, Batch 3/4: Zeroing gradients...
  Epoch 351, Batch 3/4: Forward pass...
  Epoch 351, Batch 3/4: Calculating loss...
  Epoch 351, Batch 3/4: Backward pass...
  Epoch 351, Batch 3/4: Clipping gradients...
  Epoch 351, Batch 3/4: Optimizer step...
  Epoch 351, Batch 3/4: Completed in 0.19s
  Epoch 351, Batch 4/4: Loading data to device...
  Epoch 351, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 351, Batch 4/4: Zeroing gradients...
  Epoch 351, Batch 4/4: Forward pass...
  Epoch 351, Batch 4/4: Calculating loss...
  Epoch 351, Batch 4/4: Backward pass...
  Epoch 351, Batch 4/4: Clipping gradients...
  Epoch 351, Batch 4/4: Optimizer step...
  Epoch 351, Batch 4/4: Completed in 0.03s
Epoch 351: Training phase completed. Average Train Loss: 0.3098
Epoch 351: Starting validation phase...
  Epoch 351, Val Batch 1/1: Loading data...
  Epoch 351, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 351, Val Batch 1/1: Forward pass...
  Epoch 351, Val Batch 1/1: Calculating loss...
Epoch 351: Validation phase completed. Average Val Loss: 0.2602
Epoch 351 Summary ---> Train Loss: 0.3098 / Validation Loss: 0.2602
Epoch 351: Checking early stopping... (Current Best Loss: 0.2498, Epochs No Improve: 2)
  Epoch 351: Validation loss did not improve. Epochs without improvement: 3
Epoch 351: Stepping scheduler...
--- Epoch 351 completed in 0.68 seconds ---

--- Starting Epoch 352/1000 ---
Epoch 352: Starting training phase (4 batches)
  Epoch 352, Batch 1/4: Loading data to device...
  Epoch 352, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 352, Batch 1/4: Zeroing gradients...
  Epoch 352, Batch 1/4: Forward pass...
  Epoch 352, Batch 1/4: Calculating loss...
  Epoch 352, Batch 1/4: Backward pass...
  Epoch 352, Batch 1/4: Clipping gradients...
  Epoch 352, Batch 1/4: Optimizer step...
  Epoch 352, Batch 1/4: Completed in 0.19s
  Epoch 352, Batch 2/4: Loading data to device...
  Epoch 352, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 352, Batch 2/4: Zeroing gradients...
  Epoch 352, Batch 2/4: Forward pass...
  Epoch 352, Batch 2/4: Calculating loss...
  Epoch 352, Batch 2/4: Backward pass...
  Epoch 352, Batch 2/4: Clipping gradients...
  Epoch 352, Batch 2/4: Optimizer step...
  Epoch 352, Batch 2/4: Completed in 0.19s
  Epoch 352, Batch 3/4: Loading data to device...
  Epoch 352, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 352, Batch 3/4: Zeroing gradients...
  Epoch 352, Batch 3/4: Forward pass...
  Epoch 352, Batch 3/4: Calculating loss...
  Epoch 352, Batch 3/4: Backward pass...
  Epoch 352, Batch 3/4: Clipping gradients...
  Epoch 352, Batch 3/4: Optimizer step...
  Epoch 352, Batch 3/4: Completed in 0.20s
  Epoch 352, Batch 4/4: Loading data to device...
  Epoch 352, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 352, Batch 4/4: Zeroing gradients...
  Epoch 352, Batch 4/4: Forward pass...
  Epoch 352, Batch 4/4: Calculating loss...
  Epoch 352, Batch 4/4: Backward pass...
  Epoch 352, Batch 4/4: Clipping gradients...
  Epoch 352, Batch 4/4: Optimizer step...
  Epoch 352, Batch 4/4: Completed in 0.03s
Epoch 352: Training phase completed. Average Train Loss: 0.3062
Epoch 352: Starting validation phase...
  Epoch 352, Val Batch 1/1: Loading data...
  Epoch 352, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 352, Val Batch 1/1: Forward pass...
  Epoch 352, Val Batch 1/1: Calculating loss...
Epoch 352: Validation phase completed. Average Val Loss: 0.2592
Epoch 352 Summary ---> Train Loss: 0.3062 / Validation Loss: 0.2592
Epoch 352: Checking early stopping... (Current Best Loss: 0.2498, Epochs No Improve: 3)
  Epoch 352: Validation loss did not improve. Epochs without improvement: 4
Epoch 352: Stepping scheduler...
--- Epoch 352 completed in 0.68 seconds ---

--- Starting Epoch 353/1000 ---
Epoch 353: Starting training phase (4 batches)
  Epoch 353, Batch 1/4: Loading data to device...
  Epoch 353, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 353, Batch 1/4: Zeroing gradients...
  Epoch 353, Batch 1/4: Forward pass...
  Epoch 353, Batch 1/4: Calculating loss...
  Epoch 353, Batch 1/4: Backward pass...
  Epoch 353, Batch 1/4: Clipping gradients...
  Epoch 353, Batch 1/4: Optimizer step...
  Epoch 353, Batch 1/4: Completed in 0.19s
  Epoch 353, Batch 2/4: Loading data to device...
  Epoch 353, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 353, Batch 2/4: Zeroing gradients...
  Epoch 353, Batch 2/4: Forward pass...
  Epoch 353, Batch 2/4: Calculating loss...
  Epoch 353, Batch 2/4: Backward pass...
  Epoch 353, Batch 2/4: Clipping gradients...
  Epoch 353, Batch 2/4: Optimizer step...
  Epoch 353, Batch 2/4: Completed in 0.20s
  Epoch 353, Batch 3/4: Loading data to device...
  Epoch 353, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 353, Batch 3/4: Zeroing gradients...
  Epoch 353, Batch 3/4: Forward pass...
  Epoch 353, Batch 3/4: Calculating loss...
  Epoch 353, Batch 3/4: Backward pass...
  Epoch 353, Batch 3/4: Clipping gradients...
  Epoch 353, Batch 3/4: Optimizer step...
  Epoch 353, Batch 3/4: Completed in 0.20s
  Epoch 353, Batch 4/4: Loading data to device...
  Epoch 353, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 353, Batch 4/4: Zeroing gradients...
  Epoch 353, Batch 4/4: Forward pass...
  Epoch 353, Batch 4/4: Calculating loss...
  Epoch 353, Batch 4/4: Backward pass...
  Epoch 353, Batch 4/4: Clipping gradients...
  Epoch 353, Batch 4/4: Optimizer step...
  Epoch 353, Batch 4/4: Completed in 0.03s
Epoch 353: Training phase completed. Average Train Loss: 0.3741
Epoch 353: Starting validation phase...
  Epoch 353, Val Batch 1/1: Loading data...
  Epoch 353, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 353, Val Batch 1/1: Forward pass...
  Epoch 353, Val Batch 1/1: Calculating loss...
Epoch 353: Validation phase completed. Average Val Loss: 0.2518
Epoch 353 Summary ---> Train Loss: 0.3741 / Validation Loss: 0.2518
Epoch 353: Checking early stopping... (Current Best Loss: 0.2498, Epochs No Improve: 4)
  Epoch 353: Validation loss did not improve. Epochs without improvement: 5
Epoch 353: Stepping scheduler...
--- Epoch 353 completed in 0.69 seconds ---

--- Starting Epoch 354/1000 ---
Epoch 354: Starting training phase (4 batches)
  Epoch 354, Batch 1/4: Loading data to device...
  Epoch 354, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 354, Batch 1/4: Zeroing gradients...
  Epoch 354, Batch 1/4: Forward pass...
  Epoch 354, Batch 1/4: Calculating loss...
  Epoch 354, Batch 1/4: Backward pass...
  Epoch 354, Batch 1/4: Clipping gradients...
  Epoch 354, Batch 1/4: Optimizer step...
  Epoch 354, Batch 1/4: Completed in 0.19s
  Epoch 354, Batch 2/4: Loading data to device...
  Epoch 354, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 354, Batch 2/4: Zeroing gradients...
  Epoch 354, Batch 2/4: Forward pass...
  Epoch 354, Batch 2/4: Calculating loss...
  Epoch 354, Batch 2/4: Backward pass...
  Epoch 354, Batch 2/4: Clipping gradients...
  Epoch 354, Batch 2/4: Optimizer step...
  Epoch 354, Batch 2/4: Completed in 0.20s
  Epoch 354, Batch 3/4: Loading data to device...
  Epoch 354, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 354, Batch 3/4: Zeroing gradients...
  Epoch 354, Batch 3/4: Forward pass...
  Epoch 354, Batch 3/4: Calculating loss...
  Epoch 354, Batch 3/4: Backward pass...
  Epoch 354, Batch 3/4: Clipping gradients...
  Epoch 354, Batch 3/4: Optimizer step...
  Epoch 354, Batch 3/4: Completed in 0.19s
  Epoch 354, Batch 4/4: Loading data to device...
  Epoch 354, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 354, Batch 4/4: Zeroing gradients...
  Epoch 354, Batch 4/4: Forward pass...
  Epoch 354, Batch 4/4: Calculating loss...
  Epoch 354, Batch 4/4: Backward pass...
  Epoch 354, Batch 4/4: Clipping gradients...
  Epoch 354, Batch 4/4: Optimizer step...
  Epoch 354, Batch 4/4: Completed in 0.03s
Epoch 354: Training phase completed. Average Train Loss: 0.3722
Epoch 354: Starting validation phase...
  Epoch 354, Val Batch 1/1: Loading data...
  Epoch 354, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 354, Val Batch 1/1: Forward pass...
  Epoch 354, Val Batch 1/1: Calculating loss...
Epoch 354: Validation phase completed. Average Val Loss: 0.2533
Epoch 354 Summary ---> Train Loss: 0.3722 / Validation Loss: 0.2533
Epoch 354: Checking early stopping... (Current Best Loss: 0.2498, Epochs No Improve: 5)
  Epoch 354: Validation loss did not improve. Epochs without improvement: 6
Epoch 354: Stepping scheduler...
--- Epoch 354 completed in 0.68 seconds ---

--- Starting Epoch 355/1000 ---
Epoch 355: Starting training phase (4 batches)
  Epoch 355, Batch 1/4: Loading data to device...
  Epoch 355, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 355, Batch 1/4: Zeroing gradients...
  Epoch 355, Batch 1/4: Forward pass...
  Epoch 355, Batch 1/4: Calculating loss...
  Epoch 355, Batch 1/4: Backward pass...
  Epoch 355, Batch 1/4: Clipping gradients...
  Epoch 355, Batch 1/4: Optimizer step...
  Epoch 355, Batch 1/4: Completed in 0.19s
  Epoch 355, Batch 2/4: Loading data to device...
  Epoch 355, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 355, Batch 2/4: Zeroing gradients...
  Epoch 355, Batch 2/4: Forward pass...
  Epoch 355, Batch 2/4: Calculating loss...
  Epoch 355, Batch 2/4: Backward pass...
  Epoch 355, Batch 2/4: Clipping gradients...
  Epoch 355, Batch 2/4: Optimizer step...
  Epoch 355, Batch 2/4: Completed in 0.19s
  Epoch 355, Batch 3/4: Loading data to device...
  Epoch 355, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 355, Batch 3/4: Zeroing gradients...
  Epoch 355, Batch 3/4: Forward pass...
  Epoch 355, Batch 3/4: Calculating loss...
  Epoch 355, Batch 3/4: Backward pass...
  Epoch 355, Batch 3/4: Clipping gradients...
  Epoch 355, Batch 3/4: Optimizer step...
  Epoch 355, Batch 3/4: Completed in 0.19s
  Epoch 355, Batch 4/4: Loading data to device...
  Epoch 355, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 355, Batch 4/4: Zeroing gradients...
  Epoch 355, Batch 4/4: Forward pass...
  Epoch 355, Batch 4/4: Calculating loss...
  Epoch 355, Batch 4/4: Backward pass...
  Epoch 355, Batch 4/4: Clipping gradients...
  Epoch 355, Batch 4/4: Optimizer step...
  Epoch 355, Batch 4/4: Completed in 0.03s
Epoch 355: Training phase completed. Average Train Loss: 0.3922
Epoch 355: Starting validation phase...
  Epoch 355, Val Batch 1/1: Loading data...
  Epoch 355, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 355, Val Batch 1/1: Forward pass...
  Epoch 355, Val Batch 1/1: Calculating loss...
Epoch 355: Validation phase completed. Average Val Loss: 0.2526
Epoch 355 Summary ---> Train Loss: 0.3922 / Validation Loss: 0.2526
Epoch 355: Checking early stopping... (Current Best Loss: 0.2498, Epochs No Improve: 6)
  Epoch 355: Validation loss did not improve. Epochs without improvement: 7
Epoch 355: Stepping scheduler...
--- Epoch 355 completed in 0.67 seconds ---

--- Starting Epoch 356/1000 ---
Epoch 356: Starting training phase (4 batches)
  Epoch 356, Batch 1/4: Loading data to device...
  Epoch 356, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 356, Batch 1/4: Zeroing gradients...
  Epoch 356, Batch 1/4: Forward pass...
  Epoch 356, Batch 1/4: Calculating loss...
  Epoch 356, Batch 1/4: Backward pass...
  Epoch 356, Batch 1/4: Clipping gradients...
  Epoch 356, Batch 1/4: Optimizer step...
  Epoch 356, Batch 1/4: Completed in 0.19s
  Epoch 356, Batch 2/4: Loading data to device...
  Epoch 356, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 356, Batch 2/4: Zeroing gradients...
  Epoch 356, Batch 2/4: Forward pass...
  Epoch 356, Batch 2/4: Calculating loss...
  Epoch 356, Batch 2/4: Backward pass...
  Epoch 356, Batch 2/4: Clipping gradients...
  Epoch 356, Batch 2/4: Optimizer step...
  Epoch 356, Batch 2/4: Completed in 0.20s
  Epoch 356, Batch 3/4: Loading data to device...
  Epoch 356, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 356, Batch 3/4: Zeroing gradients...
  Epoch 356, Batch 3/4: Forward pass...
  Epoch 356, Batch 3/4: Calculating loss...
  Epoch 356, Batch 3/4: Backward pass...
  Epoch 356, Batch 3/4: Clipping gradients...
  Epoch 356, Batch 3/4: Optimizer step...
  Epoch 356, Batch 3/4: Completed in 0.20s
  Epoch 356, Batch 4/4: Loading data to device...
  Epoch 356, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 356, Batch 4/4: Zeroing gradients...
  Epoch 356, Batch 4/4: Forward pass...
  Epoch 356, Batch 4/4: Calculating loss...
  Epoch 356, Batch 4/4: Backward pass...
  Epoch 356, Batch 4/4: Clipping gradients...
  Epoch 356, Batch 4/4: Optimizer step...
  Epoch 356, Batch 4/4: Completed in 0.03s
Epoch 356: Training phase completed. Average Train Loss: 0.3297
Epoch 356: Starting validation phase...
  Epoch 356, Val Batch 1/1: Loading data...
  Epoch 356, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 356, Val Batch 1/1: Forward pass...
  Epoch 356, Val Batch 1/1: Calculating loss...
Epoch 356: Validation phase completed. Average Val Loss: 0.2525
Epoch 356 Summary ---> Train Loss: 0.3297 / Validation Loss: 0.2525
Epoch 356: Checking early stopping... (Current Best Loss: 0.2498, Epochs No Improve: 7)
  Epoch 356: Validation loss did not improve. Epochs without improvement: 8
Epoch 356: Stepping scheduler...
--- Epoch 356 completed in 0.68 seconds ---

--- Starting Epoch 357/1000 ---
Epoch 357: Starting training phase (4 batches)
  Epoch 357, Batch 1/4: Loading data to device...
  Epoch 357, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 357, Batch 1/4: Zeroing gradients...
  Epoch 357, Batch 1/4: Forward pass...
  Epoch 357, Batch 1/4: Calculating loss...
  Epoch 357, Batch 1/4: Backward pass...
  Epoch 357, Batch 1/4: Clipping gradients...
  Epoch 357, Batch 1/4: Optimizer step...
  Epoch 357, Batch 1/4: Completed in 0.20s
  Epoch 357, Batch 2/4: Loading data to device...
  Epoch 357, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 357, Batch 2/4: Zeroing gradients...
  Epoch 357, Batch 2/4: Forward pass...
  Epoch 357, Batch 2/4: Calculating loss...
  Epoch 357, Batch 2/4: Backward pass...
  Epoch 357, Batch 2/4: Clipping gradients...
  Epoch 357, Batch 2/4: Optimizer step...
  Epoch 357, Batch 2/4: Completed in 0.20s
  Epoch 357, Batch 3/4: Loading data to device...
  Epoch 357, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 357, Batch 3/4: Zeroing gradients...
  Epoch 357, Batch 3/4: Forward pass...
  Epoch 357, Batch 3/4: Calculating loss...
  Epoch 357, Batch 3/4: Backward pass...
  Epoch 357, Batch 3/4: Clipping gradients...
  Epoch 357, Batch 3/4: Optimizer step...
  Epoch 357, Batch 3/4: Completed in 0.19s
  Epoch 357, Batch 4/4: Loading data to device...
  Epoch 357, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 357, Batch 4/4: Zeroing gradients...
  Epoch 357, Batch 4/4: Forward pass...
  Epoch 357, Batch 4/4: Calculating loss...
  Epoch 357, Batch 4/4: Backward pass...
  Epoch 357, Batch 4/4: Clipping gradients...
  Epoch 357, Batch 4/4: Optimizer step...
  Epoch 357, Batch 4/4: Completed in 0.03s
Epoch 357: Training phase completed. Average Train Loss: 0.3124
Epoch 357: Starting validation phase...
  Epoch 357, Val Batch 1/1: Loading data...
  Epoch 357, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 357, Val Batch 1/1: Forward pass...
  Epoch 357, Val Batch 1/1: Calculating loss...
Epoch 357: Validation phase completed. Average Val Loss: 0.2506
Epoch 357 Summary ---> Train Loss: 0.3124 / Validation Loss: 0.2506
Epoch 357: Checking early stopping... (Current Best Loss: 0.2498, Epochs No Improve: 8)
  Epoch 357: Validation loss did not improve. Epochs without improvement: 9
Epoch 357: Stepping scheduler...
--- Epoch 357 completed in 0.68 seconds ---

--- Starting Epoch 358/1000 ---
Epoch 358: Starting training phase (4 batches)
  Epoch 358, Batch 1/4: Loading data to device...
  Epoch 358, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 358, Batch 1/4: Zeroing gradients...
  Epoch 358, Batch 1/4: Forward pass...
  Epoch 358, Batch 1/4: Calculating loss...
  Epoch 358, Batch 1/4: Backward pass...
  Epoch 358, Batch 1/4: Clipping gradients...
  Epoch 358, Batch 1/4: Optimizer step...
  Epoch 358, Batch 1/4: Completed in 0.19s
  Epoch 358, Batch 2/4: Loading data to device...
  Epoch 358, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 358, Batch 2/4: Zeroing gradients...
  Epoch 358, Batch 2/4: Forward pass...
  Epoch 358, Batch 2/4: Calculating loss...
  Epoch 358, Batch 2/4: Backward pass...
  Epoch 358, Batch 2/4: Clipping gradients...
  Epoch 358, Batch 2/4: Optimizer step...
  Epoch 358, Batch 2/4: Completed in 0.19s
  Epoch 358, Batch 3/4: Loading data to device...
  Epoch 358, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 358, Batch 3/4: Zeroing gradients...
  Epoch 358, Batch 3/4: Forward pass...
  Epoch 358, Batch 3/4: Calculating loss...
  Epoch 358, Batch 3/4: Backward pass...
  Epoch 358, Batch 3/4: Clipping gradients...
  Epoch 358, Batch 3/4: Optimizer step...
  Epoch 358, Batch 3/4: Completed in 0.19s
  Epoch 358, Batch 4/4: Loading data to device...
  Epoch 358, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 358, Batch 4/4: Zeroing gradients...
  Epoch 358, Batch 4/4: Forward pass...
  Epoch 358, Batch 4/4: Calculating loss...
  Epoch 358, Batch 4/4: Backward pass...
  Epoch 358, Batch 4/4: Clipping gradients...
  Epoch 358, Batch 4/4: Optimizer step...
  Epoch 358, Batch 4/4: Completed in 0.04s
Epoch 358: Training phase completed. Average Train Loss: 0.2952
Epoch 358: Starting validation phase...
  Epoch 358, Val Batch 1/1: Loading data...
  Epoch 358, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 358, Val Batch 1/1: Forward pass...
  Epoch 358, Val Batch 1/1: Calculating loss...
Epoch 358: Validation phase completed. Average Val Loss: 0.2543
Epoch 358 Summary ---> Train Loss: 0.2952 / Validation Loss: 0.2543
Epoch 358: Checking early stopping... (Current Best Loss: 0.2498, Epochs No Improve: 9)
  Epoch 358: Validation loss did not improve. Epochs without improvement: 10
Epoch 358: Stepping scheduler...
--- Epoch 358 completed in 0.69 seconds ---

--- Starting Epoch 359/1000 ---
Epoch 359: Starting training phase (4 batches)
  Epoch 359, Batch 1/4: Loading data to device...
  Epoch 359, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 359, Batch 1/4: Zeroing gradients...
  Epoch 359, Batch 1/4: Forward pass...
  Epoch 359, Batch 1/4: Calculating loss...
  Epoch 359, Batch 1/4: Backward pass...
  Epoch 359, Batch 1/4: Clipping gradients...
  Epoch 359, Batch 1/4: Optimizer step...
  Epoch 359, Batch 1/4: Completed in 0.19s
  Epoch 359, Batch 2/4: Loading data to device...
  Epoch 359, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 359, Batch 2/4: Zeroing gradients...
  Epoch 359, Batch 2/4: Forward pass...
  Epoch 359, Batch 2/4: Calculating loss...
  Epoch 359, Batch 2/4: Backward pass...
  Epoch 359, Batch 2/4: Clipping gradients...
  Epoch 359, Batch 2/4: Optimizer step...
  Epoch 359, Batch 2/4: Completed in 0.20s
  Epoch 359, Batch 3/4: Loading data to device...
  Epoch 359, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 359, Batch 3/4: Zeroing gradients...
  Epoch 359, Batch 3/4: Forward pass...
  Epoch 359, Batch 3/4: Calculating loss...
  Epoch 359, Batch 3/4: Backward pass...
  Epoch 359, Batch 3/4: Clipping gradients...
  Epoch 359, Batch 3/4: Optimizer step...
  Epoch 359, Batch 3/4: Completed in 0.20s
  Epoch 359, Batch 4/4: Loading data to device...
  Epoch 359, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 359, Batch 4/4: Zeroing gradients...
  Epoch 359, Batch 4/4: Forward pass...
  Epoch 359, Batch 4/4: Calculating loss...
  Epoch 359, Batch 4/4: Backward pass...
  Epoch 359, Batch 4/4: Clipping gradients...
  Epoch 359, Batch 4/4: Optimizer step...
  Epoch 359, Batch 4/4: Completed in 0.03s
Epoch 359: Training phase completed. Average Train Loss: 0.3644
Epoch 359: Starting validation phase...
  Epoch 359, Val Batch 1/1: Loading data...
  Epoch 359, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 359, Val Batch 1/1: Forward pass...
  Epoch 359, Val Batch 1/1: Calculating loss...
Epoch 359: Validation phase completed. Average Val Loss: 0.2491
Epoch 359 Summary ---> Train Loss: 0.3644 / Validation Loss: 0.2491
Epoch 359: Checking early stopping... (Current Best Loss: 0.2498, Epochs No Improve: 10)
  Epoch 359: Validation loss improved (0.2498 --> 0.2491). Saving model.
Epoch 359: Stepping scheduler...
--- Epoch 359 completed in 0.69 seconds ---

--- Starting Epoch 360/1000 ---
Epoch 360: Starting training phase (4 batches)
  Epoch 360, Batch 1/4: Loading data to device...
  Epoch 360, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 360, Batch 1/4: Zeroing gradients...
  Epoch 360, Batch 1/4: Forward pass...
  Epoch 360, Batch 1/4: Calculating loss...
  Epoch 360, Batch 1/4: Backward pass...
  Epoch 360, Batch 1/4: Clipping gradients...
  Epoch 360, Batch 1/4: Optimizer step...
  Epoch 360, Batch 1/4: Completed in 0.19s
  Epoch 360, Batch 2/4: Loading data to device...
  Epoch 360, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 360, Batch 2/4: Zeroing gradients...
  Epoch 360, Batch 2/4: Forward pass...
  Epoch 360, Batch 2/4: Calculating loss...
  Epoch 360, Batch 2/4: Backward pass...
  Epoch 360, Batch 2/4: Clipping gradients...
  Epoch 360, Batch 2/4: Optimizer step...
  Epoch 360, Batch 2/4: Completed in 0.20s
  Epoch 360, Batch 3/4: Loading data to device...
  Epoch 360, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 360, Batch 3/4: Zeroing gradients...
  Epoch 360, Batch 3/4: Forward pass...
  Epoch 360, Batch 3/4: Calculating loss...
  Epoch 360, Batch 3/4: Backward pass...
  Epoch 360, Batch 3/4: Clipping gradients...
  Epoch 360, Batch 3/4: Optimizer step...
  Epoch 360, Batch 3/4: Completed in 0.19s
  Epoch 360, Batch 4/4: Loading data to device...
  Epoch 360, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 360, Batch 4/4: Zeroing gradients...
  Epoch 360, Batch 4/4: Forward pass...
  Epoch 360, Batch 4/4: Calculating loss...
  Epoch 360, Batch 4/4: Backward pass...
  Epoch 360, Batch 4/4: Clipping gradients...
  Epoch 360, Batch 4/4: Optimizer step...
  Epoch 360, Batch 4/4: Completed in 0.03s
Epoch 360: Training phase completed. Average Train Loss: 0.3349
Epoch 360: Starting validation phase...
  Epoch 360, Val Batch 1/1: Loading data...
  Epoch 360, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 360, Val Batch 1/1: Forward pass...
  Epoch 360, Val Batch 1/1: Calculating loss...
Epoch 360: Validation phase completed. Average Val Loss: 0.2532
Epoch 360 Summary ---> Train Loss: 0.3349 / Validation Loss: 0.2532
Epoch 360: Checking early stopping... (Current Best Loss: 0.2491, Epochs No Improve: 0)
  Epoch 360: Validation loss did not improve. Epochs without improvement: 1
Epoch 360: Stepping scheduler...
--- Epoch 360 completed in 0.68 seconds ---

--- Starting Epoch 361/1000 ---
Epoch 361: Starting training phase (4 batches)
  Epoch 361, Batch 1/4: Loading data to device...
  Epoch 361, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 361, Batch 1/4: Zeroing gradients...
  Epoch 361, Batch 1/4: Forward pass...
  Epoch 361, Batch 1/4: Calculating loss...
  Epoch 361, Batch 1/4: Backward pass...
  Epoch 361, Batch 1/4: Clipping gradients...
  Epoch 361, Batch 1/4: Optimizer step...
  Epoch 361, Batch 1/4: Completed in 0.19s
  Epoch 361, Batch 2/4: Loading data to device...
  Epoch 361, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 361, Batch 2/4: Zeroing gradients...
  Epoch 361, Batch 2/4: Forward pass...
  Epoch 361, Batch 2/4: Calculating loss...
  Epoch 361, Batch 2/4: Backward pass...
  Epoch 361, Batch 2/4: Clipping gradients...
  Epoch 361, Batch 2/4: Optimizer step...
  Epoch 361, Batch 2/4: Completed in 0.19s
  Epoch 361, Batch 3/4: Loading data to device...
  Epoch 361, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 361, Batch 3/4: Zeroing gradients...
  Epoch 361, Batch 3/4: Forward pass...
  Epoch 361, Batch 3/4: Calculating loss...
  Epoch 361, Batch 3/4: Backward pass...
  Epoch 361, Batch 3/4: Clipping gradients...
  Epoch 361, Batch 3/4: Optimizer step...
  Epoch 361, Batch 3/4: Completed in 0.19s
  Epoch 361, Batch 4/4: Loading data to device...
  Epoch 361, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 361, Batch 4/4: Zeroing gradients...
  Epoch 361, Batch 4/4: Forward pass...
  Epoch 361, Batch 4/4: Calculating loss...
  Epoch 361, Batch 4/4: Backward pass...
  Epoch 361, Batch 4/4: Clipping gradients...
  Epoch 361, Batch 4/4: Optimizer step...
  Epoch 361, Batch 4/4: Completed in 0.04s
Epoch 361: Training phase completed. Average Train Loss: 0.3101
Epoch 361: Starting validation phase...
  Epoch 361, Val Batch 1/1: Loading data...
  Epoch 361, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 361, Val Batch 1/1: Forward pass...
  Epoch 361, Val Batch 1/1: Calculating loss...
Epoch 361: Validation phase completed. Average Val Loss: 0.2544
Epoch 361 Summary ---> Train Loss: 0.3101 / Validation Loss: 0.2544
Epoch 361: Checking early stopping... (Current Best Loss: 0.2491, Epochs No Improve: 1)
  Epoch 361: Validation loss did not improve. Epochs without improvement: 2
Epoch 361: Stepping scheduler...
--- Epoch 361 completed in 0.68 seconds ---

--- Starting Epoch 362/1000 ---
Epoch 362: Starting training phase (4 batches)
  Epoch 362, Batch 1/4: Loading data to device...
  Epoch 362, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 362, Batch 1/4: Zeroing gradients...
  Epoch 362, Batch 1/4: Forward pass...
  Epoch 362, Batch 1/4: Calculating loss...
  Epoch 362, Batch 1/4: Backward pass...
  Epoch 362, Batch 1/4: Clipping gradients...
  Epoch 362, Batch 1/4: Optimizer step...
  Epoch 362, Batch 1/4: Completed in 0.20s
  Epoch 362, Batch 2/4: Loading data to device...
  Epoch 362, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 362, Batch 2/4: Zeroing gradients...
  Epoch 362, Batch 2/4: Forward pass...
  Epoch 362, Batch 2/4: Calculating loss...
  Epoch 362, Batch 2/4: Backward pass...
  Epoch 362, Batch 2/4: Clipping gradients...
  Epoch 362, Batch 2/4: Optimizer step...
  Epoch 362, Batch 2/4: Completed in 0.19s
  Epoch 362, Batch 3/4: Loading data to device...
  Epoch 362, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 362, Batch 3/4: Zeroing gradients...
  Epoch 362, Batch 3/4: Forward pass...
  Epoch 362, Batch 3/4: Calculating loss...
  Epoch 362, Batch 3/4: Backward pass...
  Epoch 362, Batch 3/4: Clipping gradients...
  Epoch 362, Batch 3/4: Optimizer step...
  Epoch 362, Batch 3/4: Completed in 0.20s
  Epoch 362, Batch 4/4: Loading data to device...
  Epoch 362, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 362, Batch 4/4: Zeroing gradients...
  Epoch 362, Batch 4/4: Forward pass...
  Epoch 362, Batch 4/4: Calculating loss...
  Epoch 362, Batch 4/4: Backward pass...
  Epoch 362, Batch 4/4: Clipping gradients...
  Epoch 362, Batch 4/4: Optimizer step...
  Epoch 362, Batch 4/4: Completed in 0.03s
Epoch 362: Training phase completed. Average Train Loss: 0.3120
Epoch 362: Starting validation phase...
  Epoch 362, Val Batch 1/1: Loading data...
  Epoch 362, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 362, Val Batch 1/1: Forward pass...
  Epoch 362, Val Batch 1/1: Calculating loss...
Epoch 362: Validation phase completed. Average Val Loss: 0.2575
Epoch 362 Summary ---> Train Loss: 0.3120 / Validation Loss: 0.2575
Epoch 362: Checking early stopping... (Current Best Loss: 0.2491, Epochs No Improve: 2)
  Epoch 362: Validation loss did not improve. Epochs without improvement: 3
Epoch 362: Stepping scheduler...
--- Epoch 362 completed in 0.68 seconds ---

--- Starting Epoch 363/1000 ---
Epoch 363: Starting training phase (4 batches)
  Epoch 363, Batch 1/4: Loading data to device...
  Epoch 363, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 363, Batch 1/4: Zeroing gradients...
  Epoch 363, Batch 1/4: Forward pass...
  Epoch 363, Batch 1/4: Calculating loss...
  Epoch 363, Batch 1/4: Backward pass...
  Epoch 363, Batch 1/4: Clipping gradients...
  Epoch 363, Batch 1/4: Optimizer step...
  Epoch 363, Batch 1/4: Completed in 0.20s
  Epoch 363, Batch 2/4: Loading data to device...
  Epoch 363, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 363, Batch 2/4: Zeroing gradients...
  Epoch 363, Batch 2/4: Forward pass...
  Epoch 363, Batch 2/4: Calculating loss...
  Epoch 363, Batch 2/4: Backward pass...
  Epoch 363, Batch 2/4: Clipping gradients...
  Epoch 363, Batch 2/4: Optimizer step...
  Epoch 363, Batch 2/4: Completed in 0.19s
  Epoch 363, Batch 3/4: Loading data to device...
  Epoch 363, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 363, Batch 3/4: Zeroing gradients...
  Epoch 363, Batch 3/4: Forward pass...
  Epoch 363, Batch 3/4: Calculating loss...
  Epoch 363, Batch 3/4: Backward pass...
  Epoch 363, Batch 3/4: Clipping gradients...
  Epoch 363, Batch 3/4: Optimizer step...
  Epoch 363, Batch 3/4: Completed in 0.19s
  Epoch 363, Batch 4/4: Loading data to device...
  Epoch 363, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 363, Batch 4/4: Zeroing gradients...
  Epoch 363, Batch 4/4: Forward pass...
  Epoch 363, Batch 4/4: Calculating loss...
  Epoch 363, Batch 4/4: Backward pass...
  Epoch 363, Batch 4/4: Clipping gradients...
  Epoch 363, Batch 4/4: Optimizer step...
  Epoch 363, Batch 4/4: Completed in 0.03s
Epoch 363: Training phase completed. Average Train Loss: 0.3990
Epoch 363: Starting validation phase...
  Epoch 363, Val Batch 1/1: Loading data...
  Epoch 363, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 363, Val Batch 1/1: Forward pass...
  Epoch 363, Val Batch 1/1: Calculating loss...
Epoch 363: Validation phase completed. Average Val Loss: 0.2562
Epoch 363 Summary ---> Train Loss: 0.3990 / Validation Loss: 0.2562
Epoch 363: Checking early stopping... (Current Best Loss: 0.2491, Epochs No Improve: 3)
  Epoch 363: Validation loss did not improve. Epochs without improvement: 4
Epoch 363: Stepping scheduler...
--- Epoch 363 completed in 0.67 seconds ---

--- Starting Epoch 364/1000 ---
Epoch 364: Starting training phase (4 batches)
  Epoch 364, Batch 1/4: Loading data to device...
  Epoch 364, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 364, Batch 1/4: Zeroing gradients...
  Epoch 364, Batch 1/4: Forward pass...
  Epoch 364, Batch 1/4: Calculating loss...
  Epoch 364, Batch 1/4: Backward pass...
  Epoch 364, Batch 1/4: Clipping gradients...
  Epoch 364, Batch 1/4: Optimizer step...
  Epoch 364, Batch 1/4: Completed in 0.19s
  Epoch 364, Batch 2/4: Loading data to device...
  Epoch 364, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 364, Batch 2/4: Zeroing gradients...
  Epoch 364, Batch 2/4: Forward pass...
  Epoch 364, Batch 2/4: Calculating loss...
  Epoch 364, Batch 2/4: Backward pass...
  Epoch 364, Batch 2/4: Clipping gradients...
  Epoch 364, Batch 2/4: Optimizer step...
  Epoch 364, Batch 2/4: Completed in 0.20s
  Epoch 364, Batch 3/4: Loading data to device...
  Epoch 364, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 364, Batch 3/4: Zeroing gradients...
  Epoch 364, Batch 3/4: Forward pass...
  Epoch 364, Batch 3/4: Calculating loss...
  Epoch 364, Batch 3/4: Backward pass...
  Epoch 364, Batch 3/4: Clipping gradients...
  Epoch 364, Batch 3/4: Optimizer step...
  Epoch 364, Batch 3/4: Completed in 0.19s
  Epoch 364, Batch 4/4: Loading data to device...
  Epoch 364, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 364, Batch 4/4: Zeroing gradients...
  Epoch 364, Batch 4/4: Forward pass...
  Epoch 364, Batch 4/4: Calculating loss...
  Epoch 364, Batch 4/4: Backward pass...
  Epoch 364, Batch 4/4: Clipping gradients...
  Epoch 364, Batch 4/4: Optimizer step...
  Epoch 364, Batch 4/4: Completed in 0.03s
Epoch 364: Training phase completed. Average Train Loss: 0.3417
Epoch 364: Starting validation phase...
  Epoch 364, Val Batch 1/1: Loading data...
  Epoch 364, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 364, Val Batch 1/1: Forward pass...
  Epoch 364, Val Batch 1/1: Calculating loss...
Epoch 364: Validation phase completed. Average Val Loss: 0.2504
Epoch 364 Summary ---> Train Loss: 0.3417 / Validation Loss: 0.2504
Epoch 364: Checking early stopping... (Current Best Loss: 0.2491, Epochs No Improve: 4)
  Epoch 364: Validation loss did not improve. Epochs without improvement: 5
Epoch 364: Stepping scheduler...
--- Epoch 364 completed in 0.68 seconds ---

--- Starting Epoch 365/1000 ---
Epoch 365: Starting training phase (4 batches)
  Epoch 365, Batch 1/4: Loading data to device...
  Epoch 365, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 365, Batch 1/4: Zeroing gradients...
  Epoch 365, Batch 1/4: Forward pass...
  Epoch 365, Batch 1/4: Calculating loss...
  Epoch 365, Batch 1/4: Backward pass...
  Epoch 365, Batch 1/4: Clipping gradients...
  Epoch 365, Batch 1/4: Optimizer step...
  Epoch 365, Batch 1/4: Completed in 0.20s
  Epoch 365, Batch 2/4: Loading data to device...
  Epoch 365, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 365, Batch 2/4: Zeroing gradients...
  Epoch 365, Batch 2/4: Forward pass...
  Epoch 365, Batch 2/4: Calculating loss...
  Epoch 365, Batch 2/4: Backward pass...
  Epoch 365, Batch 2/4: Clipping gradients...
  Epoch 365, Batch 2/4: Optimizer step...
  Epoch 365, Batch 2/4: Completed in 0.20s
  Epoch 365, Batch 3/4: Loading data to device...
  Epoch 365, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 365, Batch 3/4: Zeroing gradients...
  Epoch 365, Batch 3/4: Forward pass...
  Epoch 365, Batch 3/4: Calculating loss...
  Epoch 365, Batch 3/4: Backward pass...
  Epoch 365, Batch 3/4: Clipping gradients...
  Epoch 365, Batch 3/4: Optimizer step...
  Epoch 365, Batch 3/4: Completed in 0.19s
  Epoch 365, Batch 4/4: Loading data to device...
  Epoch 365, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 365, Batch 4/4: Zeroing gradients...
  Epoch 365, Batch 4/4: Forward pass...
  Epoch 365, Batch 4/4: Calculating loss...
  Epoch 365, Batch 4/4: Backward pass...
  Epoch 365, Batch 4/4: Clipping gradients...
  Epoch 365, Batch 4/4: Optimizer step...
  Epoch 365, Batch 4/4: Completed in 0.03s
Epoch 365: Training phase completed. Average Train Loss: 0.3550
Epoch 365: Starting validation phase...
  Epoch 365, Val Batch 1/1: Loading data...
  Epoch 365, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 365, Val Batch 1/1: Forward pass...
  Epoch 365, Val Batch 1/1: Calculating loss...
Epoch 365: Validation phase completed. Average Val Loss: 0.2536
Epoch 365 Summary ---> Train Loss: 0.3550 / Validation Loss: 0.2536
Epoch 365: Checking early stopping... (Current Best Loss: 0.2491, Epochs No Improve: 5)
  Epoch 365: Validation loss did not improve. Epochs without improvement: 6
Epoch 365: Stepping scheduler...
--- Epoch 365 completed in 0.69 seconds ---

--- Starting Epoch 366/1000 ---
Epoch 366: Starting training phase (4 batches)
  Epoch 366, Batch 1/4: Loading data to device...
  Epoch 366, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 366, Batch 1/4: Zeroing gradients...
  Epoch 366, Batch 1/4: Forward pass...
  Epoch 366, Batch 1/4: Calculating loss...
  Epoch 366, Batch 1/4: Backward pass...
  Epoch 366, Batch 1/4: Clipping gradients...
  Epoch 366, Batch 1/4: Optimizer step...
  Epoch 366, Batch 1/4: Completed in 0.19s
  Epoch 366, Batch 2/4: Loading data to device...
  Epoch 366, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 366, Batch 2/4: Zeroing gradients...
  Epoch 366, Batch 2/4: Forward pass...
  Epoch 366, Batch 2/4: Calculating loss...
  Epoch 366, Batch 2/4: Backward pass...
  Epoch 366, Batch 2/4: Clipping gradients...
  Epoch 366, Batch 2/4: Optimizer step...
  Epoch 366, Batch 2/4: Completed in 0.19s
  Epoch 366, Batch 3/4: Loading data to device...
  Epoch 366, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 366, Batch 3/4: Zeroing gradients...
  Epoch 366, Batch 3/4: Forward pass...
  Epoch 366, Batch 3/4: Calculating loss...
  Epoch 366, Batch 3/4: Backward pass...
  Epoch 366, Batch 3/4: Clipping gradients...
  Epoch 366, Batch 3/4: Optimizer step...
  Epoch 366, Batch 3/4: Completed in 0.19s
  Epoch 366, Batch 4/4: Loading data to device...
  Epoch 366, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 366, Batch 4/4: Zeroing gradients...
  Epoch 366, Batch 4/4: Forward pass...
  Epoch 366, Batch 4/4: Calculating loss...
  Epoch 366, Batch 4/4: Backward pass...
  Epoch 366, Batch 4/4: Clipping gradients...
  Epoch 366, Batch 4/4: Optimizer step...
  Epoch 366, Batch 4/4: Completed in 0.03s
Epoch 366: Training phase completed. Average Train Loss: 0.3413
Epoch 366: Starting validation phase...
  Epoch 366, Val Batch 1/1: Loading data...
  Epoch 366, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 366, Val Batch 1/1: Forward pass...
  Epoch 366, Val Batch 1/1: Calculating loss...
Epoch 366: Validation phase completed. Average Val Loss: 0.2530
Epoch 366 Summary ---> Train Loss: 0.3413 / Validation Loss: 0.2530
Epoch 366: Checking early stopping... (Current Best Loss: 0.2491, Epochs No Improve: 6)
  Epoch 366: Validation loss did not improve. Epochs without improvement: 7
Epoch 366: Stepping scheduler...
--- Epoch 366 completed in 0.67 seconds ---

--- Starting Epoch 367/1000 ---
Epoch 367: Starting training phase (4 batches)
  Epoch 367, Batch 1/4: Loading data to device...
  Epoch 367, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 367, Batch 1/4: Zeroing gradients...
  Epoch 367, Batch 1/4: Forward pass...
  Epoch 367, Batch 1/4: Calculating loss...
  Epoch 367, Batch 1/4: Backward pass...
  Epoch 367, Batch 1/4: Clipping gradients...
  Epoch 367, Batch 1/4: Optimizer step...
  Epoch 367, Batch 1/4: Completed in 0.19s
  Epoch 367, Batch 2/4: Loading data to device...
  Epoch 367, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 367, Batch 2/4: Zeroing gradients...
  Epoch 367, Batch 2/4: Forward pass...
  Epoch 367, Batch 2/4: Calculating loss...
  Epoch 367, Batch 2/4: Backward pass...
  Epoch 367, Batch 2/4: Clipping gradients...
  Epoch 367, Batch 2/4: Optimizer step...
  Epoch 367, Batch 2/4: Completed in 0.19s
  Epoch 367, Batch 3/4: Loading data to device...
  Epoch 367, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 367, Batch 3/4: Zeroing gradients...
  Epoch 367, Batch 3/4: Forward pass...
  Epoch 367, Batch 3/4: Calculating loss...
  Epoch 367, Batch 3/4: Backward pass...
  Epoch 367, Batch 3/4: Clipping gradients...
  Epoch 367, Batch 3/4: Optimizer step...
  Epoch 367, Batch 3/4: Completed in 0.19s
  Epoch 367, Batch 4/4: Loading data to device...
  Epoch 367, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 367, Batch 4/4: Zeroing gradients...
  Epoch 367, Batch 4/4: Forward pass...
  Epoch 367, Batch 4/4: Calculating loss...
  Epoch 367, Batch 4/4: Backward pass...
  Epoch 367, Batch 4/4: Clipping gradients...
  Epoch 367, Batch 4/4: Optimizer step...
  Epoch 367, Batch 4/4: Completed in 0.03s
Epoch 367: Training phase completed. Average Train Loss: 0.3051
Epoch 367: Starting validation phase...
  Epoch 367, Val Batch 1/1: Loading data...
  Epoch 367, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 367, Val Batch 1/1: Forward pass...
  Epoch 367, Val Batch 1/1: Calculating loss...
Epoch 367: Validation phase completed. Average Val Loss: 0.2598
Epoch 367 Summary ---> Train Loss: 0.3051 / Validation Loss: 0.2598
Epoch 367: Checking early stopping... (Current Best Loss: 0.2491, Epochs No Improve: 7)
  Epoch 367: Validation loss did not improve. Epochs without improvement: 8
Epoch 367: Stepping scheduler...
--- Epoch 367 completed in 0.66 seconds ---

--- Starting Epoch 368/1000 ---
Epoch 368: Starting training phase (4 batches)
  Epoch 368, Batch 1/4: Loading data to device...
  Epoch 368, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 368, Batch 1/4: Zeroing gradients...
  Epoch 368, Batch 1/4: Forward pass...
  Epoch 368, Batch 1/4: Calculating loss...
  Epoch 368, Batch 1/4: Backward pass...
  Epoch 368, Batch 1/4: Clipping gradients...
  Epoch 368, Batch 1/4: Optimizer step...
  Epoch 368, Batch 1/4: Completed in 0.19s
  Epoch 368, Batch 2/4: Loading data to device...
  Epoch 368, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 368, Batch 2/4: Zeroing gradients...
  Epoch 368, Batch 2/4: Forward pass...
  Epoch 368, Batch 2/4: Calculating loss...
  Epoch 368, Batch 2/4: Backward pass...
  Epoch 368, Batch 2/4: Clipping gradients...
  Epoch 368, Batch 2/4: Optimizer step...
  Epoch 368, Batch 2/4: Completed in 0.20s
  Epoch 368, Batch 3/4: Loading data to device...
  Epoch 368, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 368, Batch 3/4: Zeroing gradients...
  Epoch 368, Batch 3/4: Forward pass...
  Epoch 368, Batch 3/4: Calculating loss...
  Epoch 368, Batch 3/4: Backward pass...
  Epoch 368, Batch 3/4: Clipping gradients...
  Epoch 368, Batch 3/4: Optimizer step...
  Epoch 368, Batch 3/4: Completed in 0.20s
  Epoch 368, Batch 4/4: Loading data to device...
  Epoch 368, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 368, Batch 4/4: Zeroing gradients...
  Epoch 368, Batch 4/4: Forward pass...
  Epoch 368, Batch 4/4: Calculating loss...
  Epoch 368, Batch 4/4: Backward pass...
  Epoch 368, Batch 4/4: Clipping gradients...
  Epoch 368, Batch 4/4: Optimizer step...
  Epoch 368, Batch 4/4: Completed in 0.03s
Epoch 368: Training phase completed. Average Train Loss: 0.3179
Epoch 368: Starting validation phase...
  Epoch 368, Val Batch 1/1: Loading data...
  Epoch 368, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 368, Val Batch 1/1: Forward pass...
  Epoch 368, Val Batch 1/1: Calculating loss...
Epoch 368: Validation phase completed. Average Val Loss: 0.2596
Epoch 368 Summary ---> Train Loss: 0.3179 / Validation Loss: 0.2596
Epoch 368: Checking early stopping... (Current Best Loss: 0.2491, Epochs No Improve: 8)
  Epoch 368: Validation loss did not improve. Epochs without improvement: 9
Epoch 368: Stepping scheduler...
--- Epoch 368 completed in 0.68 seconds ---

--- Starting Epoch 369/1000 ---
Epoch 369: Starting training phase (4 batches)
  Epoch 369, Batch 1/4: Loading data to device...
  Epoch 369, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 369, Batch 1/4: Zeroing gradients...
  Epoch 369, Batch 1/4: Forward pass...
  Epoch 369, Batch 1/4: Calculating loss...
  Epoch 369, Batch 1/4: Backward pass...
  Epoch 369, Batch 1/4: Clipping gradients...
  Epoch 369, Batch 1/4: Optimizer step...
  Epoch 369, Batch 1/4: Completed in 0.19s
  Epoch 369, Batch 2/4: Loading data to device...
  Epoch 369, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 369, Batch 2/4: Zeroing gradients...
  Epoch 369, Batch 2/4: Forward pass...
  Epoch 369, Batch 2/4: Calculating loss...
  Epoch 369, Batch 2/4: Backward pass...
  Epoch 369, Batch 2/4: Clipping gradients...
  Epoch 369, Batch 2/4: Optimizer step...
  Epoch 369, Batch 2/4: Completed in 0.19s
  Epoch 369, Batch 3/4: Loading data to device...
  Epoch 369, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 369, Batch 3/4: Zeroing gradients...
  Epoch 369, Batch 3/4: Forward pass...
  Epoch 369, Batch 3/4: Calculating loss...
  Epoch 369, Batch 3/4: Backward pass...
  Epoch 369, Batch 3/4: Clipping gradients...
  Epoch 369, Batch 3/4: Optimizer step...
  Epoch 369, Batch 3/4: Completed in 0.19s
  Epoch 369, Batch 4/4: Loading data to device...
  Epoch 369, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 369, Batch 4/4: Zeroing gradients...
  Epoch 369, Batch 4/4: Forward pass...
  Epoch 369, Batch 4/4: Calculating loss...
  Epoch 369, Batch 4/4: Backward pass...
  Epoch 369, Batch 4/4: Clipping gradients...
  Epoch 369, Batch 4/4: Optimizer step...
  Epoch 369, Batch 4/4: Completed in 0.04s
Epoch 369: Training phase completed. Average Train Loss: 0.3320
Epoch 369: Starting validation phase...
  Epoch 369, Val Batch 1/1: Loading data...
  Epoch 369, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 369, Val Batch 1/1: Forward pass...
  Epoch 369, Val Batch 1/1: Calculating loss...
Epoch 369: Validation phase completed. Average Val Loss: 0.2542
Epoch 369 Summary ---> Train Loss: 0.3320 / Validation Loss: 0.2542
Epoch 369: Checking early stopping... (Current Best Loss: 0.2491, Epochs No Improve: 9)
  Epoch 369: Validation loss did not improve. Epochs without improvement: 10
Epoch 369: Stepping scheduler...
--- Epoch 369 completed in 0.68 seconds ---

--- Starting Epoch 370/1000 ---
Epoch 370: Starting training phase (4 batches)
  Epoch 370, Batch 1/4: Loading data to device...
  Epoch 370, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 370, Batch 1/4: Zeroing gradients...
  Epoch 370, Batch 1/4: Forward pass...
  Epoch 370, Batch 1/4: Calculating loss...
  Epoch 370, Batch 1/4: Backward pass...
  Epoch 370, Batch 1/4: Clipping gradients...
  Epoch 370, Batch 1/4: Optimizer step...
  Epoch 370, Batch 1/4: Completed in 0.19s
  Epoch 370, Batch 2/4: Loading data to device...
  Epoch 370, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 370, Batch 2/4: Zeroing gradients...
  Epoch 370, Batch 2/4: Forward pass...
  Epoch 370, Batch 2/4: Calculating loss...
  Epoch 370, Batch 2/4: Backward pass...
  Epoch 370, Batch 2/4: Clipping gradients...
  Epoch 370, Batch 2/4: Optimizer step...
  Epoch 370, Batch 2/4: Completed in 0.20s
  Epoch 370, Batch 3/4: Loading data to device...
  Epoch 370, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 370, Batch 3/4: Zeroing gradients...
  Epoch 370, Batch 3/4: Forward pass...
  Epoch 370, Batch 3/4: Calculating loss...
  Epoch 370, Batch 3/4: Backward pass...
  Epoch 370, Batch 3/4: Clipping gradients...
  Epoch 370, Batch 3/4: Optimizer step...
  Epoch 370, Batch 3/4: Completed in 0.20s
  Epoch 370, Batch 4/4: Loading data to device...
  Epoch 370, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 370, Batch 4/4: Zeroing gradients...
  Epoch 370, Batch 4/4: Forward pass...
  Epoch 370, Batch 4/4: Calculating loss...
  Epoch 370, Batch 4/4: Backward pass...
  Epoch 370, Batch 4/4: Clipping gradients...
  Epoch 370, Batch 4/4: Optimizer step...
  Epoch 370, Batch 4/4: Completed in 0.03s
Epoch 370: Training phase completed. Average Train Loss: 0.3138
Epoch 370: Starting validation phase...
  Epoch 370, Val Batch 1/1: Loading data...
  Epoch 370, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 370, Val Batch 1/1: Forward pass...
  Epoch 370, Val Batch 1/1: Calculating loss...
Epoch 370: Validation phase completed. Average Val Loss: 0.2521
Epoch 370 Summary ---> Train Loss: 0.3138 / Validation Loss: 0.2521
Epoch 370: Checking early stopping... (Current Best Loss: 0.2491, Epochs No Improve: 10)
  Epoch 370: Validation loss did not improve. Epochs without improvement: 11
Epoch 370: Stepping scheduler...
--- Epoch 370 completed in 0.69 seconds ---

--- Starting Epoch 371/1000 ---
Epoch 371: Starting training phase (4 batches)
  Epoch 371, Batch 1/4: Loading data to device...
  Epoch 371, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 371, Batch 1/4: Zeroing gradients...
  Epoch 371, Batch 1/4: Forward pass...
  Epoch 371, Batch 1/4: Calculating loss...
  Epoch 371, Batch 1/4: Backward pass...
  Epoch 371, Batch 1/4: Clipping gradients...
  Epoch 371, Batch 1/4: Optimizer step...
  Epoch 371, Batch 1/4: Completed in 0.19s
  Epoch 371, Batch 2/4: Loading data to device...
  Epoch 371, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 371, Batch 2/4: Zeroing gradients...
  Epoch 371, Batch 2/4: Forward pass...
  Epoch 371, Batch 2/4: Calculating loss...
  Epoch 371, Batch 2/4: Backward pass...
  Epoch 371, Batch 2/4: Clipping gradients...
  Epoch 371, Batch 2/4: Optimizer step...
  Epoch 371, Batch 2/4: Completed in 0.19s
  Epoch 371, Batch 3/4: Loading data to device...
  Epoch 371, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 371, Batch 3/4: Zeroing gradients...
  Epoch 371, Batch 3/4: Forward pass...
  Epoch 371, Batch 3/4: Calculating loss...
  Epoch 371, Batch 3/4: Backward pass...
  Epoch 371, Batch 3/4: Clipping gradients...
  Epoch 371, Batch 3/4: Optimizer step...
  Epoch 371, Batch 3/4: Completed in 0.20s
  Epoch 371, Batch 4/4: Loading data to device...
  Epoch 371, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 371, Batch 4/4: Zeroing gradients...
  Epoch 371, Batch 4/4: Forward pass...
  Epoch 371, Batch 4/4: Calculating loss...
  Epoch 371, Batch 4/4: Backward pass...
  Epoch 371, Batch 4/4: Clipping gradients...
  Epoch 371, Batch 4/4: Optimizer step...
  Epoch 371, Batch 4/4: Completed in 0.03s
Epoch 371: Training phase completed. Average Train Loss: 0.3273
Epoch 371: Starting validation phase...
  Epoch 371, Val Batch 1/1: Loading data...
  Epoch 371, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 371, Val Batch 1/1: Forward pass...
  Epoch 371, Val Batch 1/1: Calculating loss...
Epoch 371: Validation phase completed. Average Val Loss: 0.2488
Epoch 371 Summary ---> Train Loss: 0.3273 / Validation Loss: 0.2488
Epoch 371: Checking early stopping... (Current Best Loss: 0.2491, Epochs No Improve: 11)
  Epoch 371: Validation loss improved (0.2491 --> 0.2488). Saving model.
Epoch 371: Stepping scheduler...
--- Epoch 371 completed in 0.67 seconds ---

--- Starting Epoch 372/1000 ---
Epoch 372: Starting training phase (4 batches)
  Epoch 372, Batch 1/4: Loading data to device...
  Epoch 372, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 372, Batch 1/4: Zeroing gradients...
  Epoch 372, Batch 1/4: Forward pass...
  Epoch 372, Batch 1/4: Calculating loss...
  Epoch 372, Batch 1/4: Backward pass...
  Epoch 372, Batch 1/4: Clipping gradients...
  Epoch 372, Batch 1/4: Optimizer step...
  Epoch 372, Batch 1/4: Completed in 0.20s
  Epoch 372, Batch 2/4: Loading data to device...
  Epoch 372, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 372, Batch 2/4: Zeroing gradients...
  Epoch 372, Batch 2/4: Forward pass...
  Epoch 372, Batch 2/4: Calculating loss...
  Epoch 372, Batch 2/4: Backward pass...
  Epoch 372, Batch 2/4: Clipping gradients...
  Epoch 372, Batch 2/4: Optimizer step...
  Epoch 372, Batch 2/4: Completed in 0.20s
  Epoch 372, Batch 3/4: Loading data to device...
  Epoch 372, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 372, Batch 3/4: Zeroing gradients...
  Epoch 372, Batch 3/4: Forward pass...
  Epoch 372, Batch 3/4: Calculating loss...
  Epoch 372, Batch 3/4: Backward pass...
  Epoch 372, Batch 3/4: Clipping gradients...
  Epoch 372, Batch 3/4: Optimizer step...
  Epoch 372, Batch 3/4: Completed in 0.20s
  Epoch 372, Batch 4/4: Loading data to device...
  Epoch 372, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 372, Batch 4/4: Zeroing gradients...
  Epoch 372, Batch 4/4: Forward pass...
  Epoch 372, Batch 4/4: Calculating loss...
  Epoch 372, Batch 4/4: Backward pass...
  Epoch 372, Batch 4/4: Clipping gradients...
  Epoch 372, Batch 4/4: Optimizer step...
  Epoch 372, Batch 4/4: Completed in 0.03s
Epoch 372: Training phase completed. Average Train Loss: 0.4286
Epoch 372: Starting validation phase...
  Epoch 372, Val Batch 1/1: Loading data...
  Epoch 372, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 372, Val Batch 1/1: Forward pass...
  Epoch 372, Val Batch 1/1: Calculating loss...
Epoch 372: Validation phase completed. Average Val Loss: 0.2444
Epoch 372 Summary ---> Train Loss: 0.4286 / Validation Loss: 0.2444
Epoch 372: Checking early stopping... (Current Best Loss: 0.2488, Epochs No Improve: 0)
  Epoch 372: Validation loss improved (0.2488 --> 0.2444). Saving model.
Epoch 372: Stepping scheduler...
--- Epoch 372 completed in 0.69 seconds ---

--- Starting Epoch 373/1000 ---
Epoch 373: Starting training phase (4 batches)
  Epoch 373, Batch 1/4: Loading data to device...
  Epoch 373, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 373, Batch 1/4: Zeroing gradients...
  Epoch 373, Batch 1/4: Forward pass...
  Epoch 373, Batch 1/4: Calculating loss...
  Epoch 373, Batch 1/4: Backward pass...
  Epoch 373, Batch 1/4: Clipping gradients...
  Epoch 373, Batch 1/4: Optimizer step...
  Epoch 373, Batch 1/4: Completed in 0.21s
  Epoch 373, Batch 2/4: Loading data to device...
  Epoch 373, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 373, Batch 2/4: Zeroing gradients...
  Epoch 373, Batch 2/4: Forward pass...
  Epoch 373, Batch 2/4: Calculating loss...
  Epoch 373, Batch 2/4: Backward pass...
  Epoch 373, Batch 2/4: Clipping gradients...
  Epoch 373, Batch 2/4: Optimizer step...
  Epoch 373, Batch 2/4: Completed in 0.21s
  Epoch 373, Batch 3/4: Loading data to device...
  Epoch 373, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 373, Batch 3/4: Zeroing gradients...
  Epoch 373, Batch 3/4: Forward pass...
  Epoch 373, Batch 3/4: Calculating loss...
  Epoch 373, Batch 3/4: Backward pass...
  Epoch 373, Batch 3/4: Clipping gradients...
  Epoch 373, Batch 3/4: Optimizer step...
  Epoch 373, Batch 3/4: Completed in 0.20s
  Epoch 373, Batch 4/4: Loading data to device...
  Epoch 373, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 373, Batch 4/4: Zeroing gradients...
  Epoch 373, Batch 4/4: Forward pass...
  Epoch 373, Batch 4/4: Calculating loss...
  Epoch 373, Batch 4/4: Backward pass...
  Epoch 373, Batch 4/4: Clipping gradients...
  Epoch 373, Batch 4/4: Optimizer step...
  Epoch 373, Batch 4/4: Completed in 0.03s
Epoch 373: Training phase completed. Average Train Loss: 0.3221
Epoch 373: Starting validation phase...
  Epoch 373, Val Batch 1/1: Loading data...
  Epoch 373, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 373, Val Batch 1/1: Forward pass...
  Epoch 373, Val Batch 1/1: Calculating loss...
Epoch 373: Validation phase completed. Average Val Loss: 0.2480
Epoch 373 Summary ---> Train Loss: 0.3221 / Validation Loss: 0.2480
Epoch 373: Checking early stopping... (Current Best Loss: 0.2444, Epochs No Improve: 0)
  Epoch 373: Validation loss did not improve. Epochs without improvement: 1
Epoch 373: Stepping scheduler...
--- Epoch 373 completed in 0.72 seconds ---

--- Starting Epoch 374/1000 ---
Epoch 374: Starting training phase (4 batches)
  Epoch 374, Batch 1/4: Loading data to device...
  Epoch 374, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 374, Batch 1/4: Zeroing gradients...
  Epoch 374, Batch 1/4: Forward pass...
  Epoch 374, Batch 1/4: Calculating loss...
  Epoch 374, Batch 1/4: Backward pass...
  Epoch 374, Batch 1/4: Clipping gradients...
  Epoch 374, Batch 1/4: Optimizer step...
  Epoch 374, Batch 1/4: Completed in 0.19s
  Epoch 374, Batch 2/4: Loading data to device...
  Epoch 374, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 374, Batch 2/4: Zeroing gradients...
  Epoch 374, Batch 2/4: Forward pass...
  Epoch 374, Batch 2/4: Calculating loss...
  Epoch 374, Batch 2/4: Backward pass...
  Epoch 374, Batch 2/4: Clipping gradients...
  Epoch 374, Batch 2/4: Optimizer step...
  Epoch 374, Batch 2/4: Completed in 0.20s
  Epoch 374, Batch 3/4: Loading data to device...
  Epoch 374, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 374, Batch 3/4: Zeroing gradients...
  Epoch 374, Batch 3/4: Forward pass...
  Epoch 374, Batch 3/4: Calculating loss...
  Epoch 374, Batch 3/4: Backward pass...
  Epoch 374, Batch 3/4: Clipping gradients...
  Epoch 374, Batch 3/4: Optimizer step...
  Epoch 374, Batch 3/4: Completed in 0.20s
  Epoch 374, Batch 4/4: Loading data to device...
  Epoch 374, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 374, Batch 4/4: Zeroing gradients...
  Epoch 374, Batch 4/4: Forward pass...
  Epoch 374, Batch 4/4: Calculating loss...
  Epoch 374, Batch 4/4: Backward pass...
  Epoch 374, Batch 4/4: Clipping gradients...
  Epoch 374, Batch 4/4: Optimizer step...
  Epoch 374, Batch 4/4: Completed in 0.03s
Epoch 374: Training phase completed. Average Train Loss: 0.3167
Epoch 374: Starting validation phase...
  Epoch 374, Val Batch 1/1: Loading data...
  Epoch 374, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 374, Val Batch 1/1: Forward pass...
  Epoch 374, Val Batch 1/1: Calculating loss...
Epoch 374: Validation phase completed. Average Val Loss: 0.2519
Epoch 374 Summary ---> Train Loss: 0.3167 / Validation Loss: 0.2519
Epoch 374: Checking early stopping... (Current Best Loss: 0.2444, Epochs No Improve: 1)
  Epoch 374: Validation loss did not improve. Epochs without improvement: 2
Epoch 374: Stepping scheduler...
--- Epoch 374 completed in 0.70 seconds ---

--- Starting Epoch 375/1000 ---
Epoch 375: Starting training phase (4 batches)
  Epoch 375, Batch 1/4: Loading data to device...
  Epoch 375, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 375, Batch 1/4: Zeroing gradients...
  Epoch 375, Batch 1/4: Forward pass...
  Epoch 375, Batch 1/4: Calculating loss...
  Epoch 375, Batch 1/4: Backward pass...
  Epoch 375, Batch 1/4: Clipping gradients...
  Epoch 375, Batch 1/4: Optimizer step...
  Epoch 375, Batch 1/4: Completed in 0.20s
  Epoch 375, Batch 2/4: Loading data to device...
  Epoch 375, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 375, Batch 2/4: Zeroing gradients...
  Epoch 375, Batch 2/4: Forward pass...
  Epoch 375, Batch 2/4: Calculating loss...
  Epoch 375, Batch 2/4: Backward pass...
  Epoch 375, Batch 2/4: Clipping gradients...
  Epoch 375, Batch 2/4: Optimizer step...
  Epoch 375, Batch 2/4: Completed in 0.19s
  Epoch 375, Batch 3/4: Loading data to device...
  Epoch 375, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 375, Batch 3/4: Zeroing gradients...
  Epoch 375, Batch 3/4: Forward pass...
  Epoch 375, Batch 3/4: Calculating loss...
  Epoch 375, Batch 3/4: Backward pass...
  Epoch 375, Batch 3/4: Clipping gradients...
  Epoch 375, Batch 3/4: Optimizer step...
  Epoch 375, Batch 3/4: Completed in 0.19s
  Epoch 375, Batch 4/4: Loading data to device...
  Epoch 375, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 375, Batch 4/4: Zeroing gradients...
  Epoch 375, Batch 4/4: Forward pass...
  Epoch 375, Batch 4/4: Calculating loss...
  Epoch 375, Batch 4/4: Backward pass...
  Epoch 375, Batch 4/4: Clipping gradients...
  Epoch 375, Batch 4/4: Optimizer step...
  Epoch 375, Batch 4/4: Completed in 0.03s
Epoch 375: Training phase completed. Average Train Loss: 0.3514
Epoch 375: Starting validation phase...
  Epoch 375, Val Batch 1/1: Loading data...
  Epoch 375, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 375, Val Batch 1/1: Forward pass...
  Epoch 375, Val Batch 1/1: Calculating loss...
Epoch 375: Validation phase completed. Average Val Loss: 0.2542
Epoch 375 Summary ---> Train Loss: 0.3514 / Validation Loss: 0.2542
Epoch 375: Checking early stopping... (Current Best Loss: 0.2444, Epochs No Improve: 2)
  Epoch 375: Validation loss did not improve. Epochs without improvement: 3
Epoch 375: Stepping scheduler...
--- Epoch 375 completed in 0.67 seconds ---

--- Starting Epoch 376/1000 ---
Epoch 376: Starting training phase (4 batches)
  Epoch 376, Batch 1/4: Loading data to device...
  Epoch 376, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 376, Batch 1/4: Zeroing gradients...
  Epoch 376, Batch 1/4: Forward pass...
  Epoch 376, Batch 1/4: Calculating loss...
  Epoch 376, Batch 1/4: Backward pass...
  Epoch 376, Batch 1/4: Clipping gradients...
  Epoch 376, Batch 1/4: Optimizer step...
  Epoch 376, Batch 1/4: Completed in 0.19s
  Epoch 376, Batch 2/4: Loading data to device...
  Epoch 376, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 376, Batch 2/4: Zeroing gradients...
  Epoch 376, Batch 2/4: Forward pass...
  Epoch 376, Batch 2/4: Calculating loss...
  Epoch 376, Batch 2/4: Backward pass...
  Epoch 376, Batch 2/4: Clipping gradients...
  Epoch 376, Batch 2/4: Optimizer step...
  Epoch 376, Batch 2/4: Completed in 0.19s
  Epoch 376, Batch 3/4: Loading data to device...
  Epoch 376, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 376, Batch 3/4: Zeroing gradients...
  Epoch 376, Batch 3/4: Forward pass...
  Epoch 376, Batch 3/4: Calculating loss...
  Epoch 376, Batch 3/4: Backward pass...
  Epoch 376, Batch 3/4: Clipping gradients...
  Epoch 376, Batch 3/4: Optimizer step...
  Epoch 376, Batch 3/4: Completed in 0.19s
  Epoch 376, Batch 4/4: Loading data to device...
  Epoch 376, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 376, Batch 4/4: Zeroing gradients...
  Epoch 376, Batch 4/4: Forward pass...
  Epoch 376, Batch 4/4: Calculating loss...
  Epoch 376, Batch 4/4: Backward pass...
  Epoch 376, Batch 4/4: Clipping gradients...
  Epoch 376, Batch 4/4: Optimizer step...
  Epoch 376, Batch 4/4: Completed in 0.03s
Epoch 376: Training phase completed. Average Train Loss: 0.3810
Epoch 376: Starting validation phase...
  Epoch 376, Val Batch 1/1: Loading data...
  Epoch 376, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 376, Val Batch 1/1: Forward pass...
  Epoch 376, Val Batch 1/1: Calculating loss...
Epoch 376: Validation phase completed. Average Val Loss: 0.2445
Epoch 376 Summary ---> Train Loss: 0.3810 / Validation Loss: 0.2445
Epoch 376: Checking early stopping... (Current Best Loss: 0.2444, Epochs No Improve: 3)
  Epoch 376: Validation loss did not improve. Epochs without improvement: 4
Epoch 376: Stepping scheduler...
--- Epoch 376 completed in 0.67 seconds ---

--- Starting Epoch 377/1000 ---
Epoch 377: Starting training phase (4 batches)
  Epoch 377, Batch 1/4: Loading data to device...
  Epoch 377, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 377, Batch 1/4: Zeroing gradients...
  Epoch 377, Batch 1/4: Forward pass...
  Epoch 377, Batch 1/4: Calculating loss...
  Epoch 377, Batch 1/4: Backward pass...
  Epoch 377, Batch 1/4: Clipping gradients...
  Epoch 377, Batch 1/4: Optimizer step...
  Epoch 377, Batch 1/4: Completed in 0.19s
  Epoch 377, Batch 2/4: Loading data to device...
  Epoch 377, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 377, Batch 2/4: Zeroing gradients...
  Epoch 377, Batch 2/4: Forward pass...
  Epoch 377, Batch 2/4: Calculating loss...
  Epoch 377, Batch 2/4: Backward pass...
  Epoch 377, Batch 2/4: Clipping gradients...
  Epoch 377, Batch 2/4: Optimizer step...
  Epoch 377, Batch 2/4: Completed in 0.19s
  Epoch 377, Batch 3/4: Loading data to device...
  Epoch 377, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 377, Batch 3/4: Zeroing gradients...
  Epoch 377, Batch 3/4: Forward pass...
  Epoch 377, Batch 3/4: Calculating loss...
  Epoch 377, Batch 3/4: Backward pass...
  Epoch 377, Batch 3/4: Clipping gradients...
  Epoch 377, Batch 3/4: Optimizer step...
  Epoch 377, Batch 3/4: Completed in 0.20s
  Epoch 377, Batch 4/4: Loading data to device...
  Epoch 377, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 377, Batch 4/4: Zeroing gradients...
  Epoch 377, Batch 4/4: Forward pass...
  Epoch 377, Batch 4/4: Calculating loss...
  Epoch 377, Batch 4/4: Backward pass...
  Epoch 377, Batch 4/4: Clipping gradients...
  Epoch 377, Batch 4/4: Optimizer step...
  Epoch 377, Batch 4/4: Completed in 0.04s
Epoch 377: Training phase completed. Average Train Loss: 0.2880
Epoch 377: Starting validation phase...
  Epoch 377, Val Batch 1/1: Loading data...
  Epoch 377, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 377, Val Batch 1/1: Forward pass...
  Epoch 377, Val Batch 1/1: Calculating loss...
Epoch 377: Validation phase completed. Average Val Loss: 0.2500
Epoch 377 Summary ---> Train Loss: 0.2880 / Validation Loss: 0.2500
Epoch 377: Checking early stopping... (Current Best Loss: 0.2444, Epochs No Improve: 4)
  Epoch 377: Validation loss did not improve. Epochs without improvement: 5
Epoch 377: Stepping scheduler...
--- Epoch 377 completed in 0.69 seconds ---

--- Starting Epoch 378/1000 ---
Epoch 378: Starting training phase (4 batches)
  Epoch 378, Batch 1/4: Loading data to device...
  Epoch 378, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 378, Batch 1/4: Zeroing gradients...
  Epoch 378, Batch 1/4: Forward pass...
  Epoch 378, Batch 1/4: Calculating loss...
  Epoch 378, Batch 1/4: Backward pass...
  Epoch 378, Batch 1/4: Clipping gradients...
  Epoch 378, Batch 1/4: Optimizer step...
  Epoch 378, Batch 1/4: Completed in 0.19s
  Epoch 378, Batch 2/4: Loading data to device...
  Epoch 378, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 378, Batch 2/4: Zeroing gradients...
  Epoch 378, Batch 2/4: Forward pass...
  Epoch 378, Batch 2/4: Calculating loss...
  Epoch 378, Batch 2/4: Backward pass...
  Epoch 378, Batch 2/4: Clipping gradients...
  Epoch 378, Batch 2/4: Optimizer step...
  Epoch 378, Batch 2/4: Completed in 0.19s
  Epoch 378, Batch 3/4: Loading data to device...
  Epoch 378, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 378, Batch 3/4: Zeroing gradients...
  Epoch 378, Batch 3/4: Forward pass...
  Epoch 378, Batch 3/4: Calculating loss...
  Epoch 378, Batch 3/4: Backward pass...
  Epoch 378, Batch 3/4: Clipping gradients...
  Epoch 378, Batch 3/4: Optimizer step...
  Epoch 378, Batch 3/4: Completed in 0.19s
  Epoch 378, Batch 4/4: Loading data to device...
  Epoch 378, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 378, Batch 4/4: Zeroing gradients...
  Epoch 378, Batch 4/4: Forward pass...
  Epoch 378, Batch 4/4: Calculating loss...
  Epoch 378, Batch 4/4: Backward pass...
  Epoch 378, Batch 4/4: Clipping gradients...
  Epoch 378, Batch 4/4: Optimizer step...
  Epoch 378, Batch 4/4: Completed in 0.03s
Epoch 378: Training phase completed. Average Train Loss: 0.3802
Epoch 378: Starting validation phase...
  Epoch 378, Val Batch 1/1: Loading data...
  Epoch 378, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 378, Val Batch 1/1: Forward pass...
  Epoch 378, Val Batch 1/1: Calculating loss...
Epoch 378: Validation phase completed. Average Val Loss: 0.2437
Epoch 378 Summary ---> Train Loss: 0.3802 / Validation Loss: 0.2437
Epoch 378: Checking early stopping... (Current Best Loss: 0.2444, Epochs No Improve: 5)
  Epoch 378: Validation loss improved (0.2444 --> 0.2437). Saving model.
Epoch 378: Stepping scheduler...
--- Epoch 378 completed in 0.67 seconds ---

--- Starting Epoch 379/1000 ---
Epoch 379: Starting training phase (4 batches)
  Epoch 379, Batch 1/4: Loading data to device...
  Epoch 379, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 379, Batch 1/4: Zeroing gradients...
  Epoch 379, Batch 1/4: Forward pass...
  Epoch 379, Batch 1/4: Calculating loss...
  Epoch 379, Batch 1/4: Backward pass...
  Epoch 379, Batch 1/4: Clipping gradients...
  Epoch 379, Batch 1/4: Optimizer step...
  Epoch 379, Batch 1/4: Completed in 0.20s
  Epoch 379, Batch 2/4: Loading data to device...
  Epoch 379, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 379, Batch 2/4: Zeroing gradients...
  Epoch 379, Batch 2/4: Forward pass...
  Epoch 379, Batch 2/4: Calculating loss...
  Epoch 379, Batch 2/4: Backward pass...
  Epoch 379, Batch 2/4: Clipping gradients...
  Epoch 379, Batch 2/4: Optimizer step...
  Epoch 379, Batch 2/4: Completed in 0.19s
  Epoch 379, Batch 3/4: Loading data to device...
  Epoch 379, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 379, Batch 3/4: Zeroing gradients...
  Epoch 379, Batch 3/4: Forward pass...
  Epoch 379, Batch 3/4: Calculating loss...
  Epoch 379, Batch 3/4: Backward pass...
  Epoch 379, Batch 3/4: Clipping gradients...
  Epoch 379, Batch 3/4: Optimizer step...
  Epoch 379, Batch 3/4: Completed in 0.19s
  Epoch 379, Batch 4/4: Loading data to device...
  Epoch 379, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 379, Batch 4/4: Zeroing gradients...
  Epoch 379, Batch 4/4: Forward pass...
  Epoch 379, Batch 4/4: Calculating loss...
  Epoch 379, Batch 4/4: Backward pass...
  Epoch 379, Batch 4/4: Clipping gradients...
  Epoch 379, Batch 4/4: Optimizer step...
  Epoch 379, Batch 4/4: Completed in 0.03s
Epoch 379: Training phase completed. Average Train Loss: 0.3422
Epoch 379: Starting validation phase...
  Epoch 379, Val Batch 1/1: Loading data...
  Epoch 379, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 379, Val Batch 1/1: Forward pass...
  Epoch 379, Val Batch 1/1: Calculating loss...
Epoch 379: Validation phase completed. Average Val Loss: 0.2489
Epoch 379 Summary ---> Train Loss: 0.3422 / Validation Loss: 0.2489
Epoch 379: Checking early stopping... (Current Best Loss: 0.2437, Epochs No Improve: 0)
  Epoch 379: Validation loss did not improve. Epochs without improvement: 1
Epoch 379: Stepping scheduler...
--- Epoch 379 completed in 0.67 seconds ---

--- Starting Epoch 380/1000 ---
Epoch 380: Starting training phase (4 batches)
  Epoch 380, Batch 1/4: Loading data to device...
  Epoch 380, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 380, Batch 1/4: Zeroing gradients...
  Epoch 380, Batch 1/4: Forward pass...
  Epoch 380, Batch 1/4: Calculating loss...
  Epoch 380, Batch 1/4: Backward pass...
  Epoch 380, Batch 1/4: Clipping gradients...
  Epoch 380, Batch 1/4: Optimizer step...
  Epoch 380, Batch 1/4: Completed in 0.20s
  Epoch 380, Batch 2/4: Loading data to device...
  Epoch 380, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 380, Batch 2/4: Zeroing gradients...
  Epoch 380, Batch 2/4: Forward pass...
  Epoch 380, Batch 2/4: Calculating loss...
  Epoch 380, Batch 2/4: Backward pass...
  Epoch 380, Batch 2/4: Clipping gradients...
  Epoch 380, Batch 2/4: Optimizer step...
  Epoch 380, Batch 2/4: Completed in 0.20s
  Epoch 380, Batch 3/4: Loading data to device...
  Epoch 380, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 380, Batch 3/4: Zeroing gradients...
  Epoch 380, Batch 3/4: Forward pass...
  Epoch 380, Batch 3/4: Calculating loss...
  Epoch 380, Batch 3/4: Backward pass...
  Epoch 380, Batch 3/4: Clipping gradients...
  Epoch 380, Batch 3/4: Optimizer step...
  Epoch 380, Batch 3/4: Completed in 0.20s
  Epoch 380, Batch 4/4: Loading data to device...
  Epoch 380, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 380, Batch 4/4: Zeroing gradients...
  Epoch 380, Batch 4/4: Forward pass...
  Epoch 380, Batch 4/4: Calculating loss...
  Epoch 380, Batch 4/4: Backward pass...
  Epoch 380, Batch 4/4: Clipping gradients...
  Epoch 380, Batch 4/4: Optimizer step...
  Epoch 380, Batch 4/4: Completed in 0.03s
Epoch 380: Training phase completed. Average Train Loss: 0.3591
Epoch 380: Starting validation phase...
  Epoch 380, Val Batch 1/1: Loading data...
  Epoch 380, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 380, Val Batch 1/1: Forward pass...
  Epoch 380, Val Batch 1/1: Calculating loss...
Epoch 380: Validation phase completed. Average Val Loss: 0.2494
Epoch 380 Summary ---> Train Loss: 0.3591 / Validation Loss: 0.2494
Epoch 380: Checking early stopping... (Current Best Loss: 0.2437, Epochs No Improve: 1)
  Epoch 380: Validation loss did not improve. Epochs without improvement: 2
Epoch 380: Stepping scheduler...
--- Epoch 380 completed in 0.69 seconds ---

--- Starting Epoch 381/1000 ---
Epoch 381: Starting training phase (4 batches)
  Epoch 381, Batch 1/4: Loading data to device...
  Epoch 381, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 381, Batch 1/4: Zeroing gradients...
  Epoch 381, Batch 1/4: Forward pass...
  Epoch 381, Batch 1/4: Calculating loss...
  Epoch 381, Batch 1/4: Backward pass...
  Epoch 381, Batch 1/4: Clipping gradients...
  Epoch 381, Batch 1/4: Optimizer step...
  Epoch 381, Batch 1/4: Completed in 0.19s
  Epoch 381, Batch 2/4: Loading data to device...
  Epoch 381, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 381, Batch 2/4: Zeroing gradients...
  Epoch 381, Batch 2/4: Forward pass...
  Epoch 381, Batch 2/4: Calculating loss...
  Epoch 381, Batch 2/4: Backward pass...
  Epoch 381, Batch 2/4: Clipping gradients...
  Epoch 381, Batch 2/4: Optimizer step...
  Epoch 381, Batch 2/4: Completed in 0.19s
  Epoch 381, Batch 3/4: Loading data to device...
  Epoch 381, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 381, Batch 3/4: Zeroing gradients...
  Epoch 381, Batch 3/4: Forward pass...
  Epoch 381, Batch 3/4: Calculating loss...
  Epoch 381, Batch 3/4: Backward pass...
  Epoch 381, Batch 3/4: Clipping gradients...
  Epoch 381, Batch 3/4: Optimizer step...
  Epoch 381, Batch 3/4: Completed in 0.19s
  Epoch 381, Batch 4/4: Loading data to device...
  Epoch 381, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 381, Batch 4/4: Zeroing gradients...
  Epoch 381, Batch 4/4: Forward pass...
  Epoch 381, Batch 4/4: Calculating loss...
  Epoch 381, Batch 4/4: Backward pass...
  Epoch 381, Batch 4/4: Clipping gradients...
  Epoch 381, Batch 4/4: Optimizer step...
  Epoch 381, Batch 4/4: Completed in 0.03s
Epoch 381: Training phase completed. Average Train Loss: 0.3526
Epoch 381: Starting validation phase...
  Epoch 381, Val Batch 1/1: Loading data...
  Epoch 381, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 381, Val Batch 1/1: Forward pass...
  Epoch 381, Val Batch 1/1: Calculating loss...
Epoch 381: Validation phase completed. Average Val Loss: 0.2492
Epoch 381 Summary ---> Train Loss: 0.3526 / Validation Loss: 0.2492
Epoch 381: Checking early stopping... (Current Best Loss: 0.2437, Epochs No Improve: 2)
  Epoch 381: Validation loss did not improve. Epochs without improvement: 3
Epoch 381: Stepping scheduler...
--- Epoch 381 completed in 0.67 seconds ---

--- Starting Epoch 382/1000 ---
Epoch 382: Starting training phase (4 batches)
  Epoch 382, Batch 1/4: Loading data to device...
  Epoch 382, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 382, Batch 1/4: Zeroing gradients...
  Epoch 382, Batch 1/4: Forward pass...
  Epoch 382, Batch 1/4: Calculating loss...
  Epoch 382, Batch 1/4: Backward pass...
  Epoch 382, Batch 1/4: Clipping gradients...
  Epoch 382, Batch 1/4: Optimizer step...
  Epoch 382, Batch 1/4: Completed in 0.19s
  Epoch 382, Batch 2/4: Loading data to device...
  Epoch 382, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 382, Batch 2/4: Zeroing gradients...
  Epoch 382, Batch 2/4: Forward pass...
  Epoch 382, Batch 2/4: Calculating loss...
  Epoch 382, Batch 2/4: Backward pass...
  Epoch 382, Batch 2/4: Clipping gradients...
  Epoch 382, Batch 2/4: Optimizer step...
  Epoch 382, Batch 2/4: Completed in 0.19s
  Epoch 382, Batch 3/4: Loading data to device...
  Epoch 382, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 382, Batch 3/4: Zeroing gradients...
  Epoch 382, Batch 3/4: Forward pass...
  Epoch 382, Batch 3/4: Calculating loss...
  Epoch 382, Batch 3/4: Backward pass...
  Epoch 382, Batch 3/4: Clipping gradients...
  Epoch 382, Batch 3/4: Optimizer step...
  Epoch 382, Batch 3/4: Completed in 0.19s
  Epoch 382, Batch 4/4: Loading data to device...
  Epoch 382, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 382, Batch 4/4: Zeroing gradients...
  Epoch 382, Batch 4/4: Forward pass...
  Epoch 382, Batch 4/4: Calculating loss...
  Epoch 382, Batch 4/4: Backward pass...
  Epoch 382, Batch 4/4: Clipping gradients...
  Epoch 382, Batch 4/4: Optimizer step...
  Epoch 382, Batch 4/4: Completed in 0.03s
Epoch 382: Training phase completed. Average Train Loss: 0.2981
Epoch 382: Starting validation phase...
  Epoch 382, Val Batch 1/1: Loading data...
  Epoch 382, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 382, Val Batch 1/1: Forward pass...
  Epoch 382, Val Batch 1/1: Calculating loss...
Epoch 382: Validation phase completed. Average Val Loss: 0.2482
Epoch 382 Summary ---> Train Loss: 0.2981 / Validation Loss: 0.2482
Epoch 382: Checking early stopping... (Current Best Loss: 0.2437, Epochs No Improve: 3)
  Epoch 382: Validation loss did not improve. Epochs without improvement: 4
Epoch 382: Stepping scheduler...
--- Epoch 382 completed in 0.66 seconds ---

--- Starting Epoch 383/1000 ---
Epoch 383: Starting training phase (4 batches)
  Epoch 383, Batch 1/4: Loading data to device...
  Epoch 383, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 383, Batch 1/4: Zeroing gradients...
  Epoch 383, Batch 1/4: Forward pass...
  Epoch 383, Batch 1/4: Calculating loss...
  Epoch 383, Batch 1/4: Backward pass...
  Epoch 383, Batch 1/4: Clipping gradients...
  Epoch 383, Batch 1/4: Optimizer step...
  Epoch 383, Batch 1/4: Completed in 0.19s
  Epoch 383, Batch 2/4: Loading data to device...
  Epoch 383, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 383, Batch 2/4: Zeroing gradients...
  Epoch 383, Batch 2/4: Forward pass...
  Epoch 383, Batch 2/4: Calculating loss...
  Epoch 383, Batch 2/4: Backward pass...
  Epoch 383, Batch 2/4: Clipping gradients...
  Epoch 383, Batch 2/4: Optimizer step...
  Epoch 383, Batch 2/4: Completed in 0.19s
  Epoch 383, Batch 3/4: Loading data to device...
  Epoch 383, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 383, Batch 3/4: Zeroing gradients...
  Epoch 383, Batch 3/4: Forward pass...
  Epoch 383, Batch 3/4: Calculating loss...
  Epoch 383, Batch 3/4: Backward pass...
  Epoch 383, Batch 3/4: Clipping gradients...
  Epoch 383, Batch 3/4: Optimizer step...
  Epoch 383, Batch 3/4: Completed in 0.19s
  Epoch 383, Batch 4/4: Loading data to device...
  Epoch 383, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 383, Batch 4/4: Zeroing gradients...
  Epoch 383, Batch 4/4: Forward pass...
  Epoch 383, Batch 4/4: Calculating loss...
  Epoch 383, Batch 4/4: Backward pass...
  Epoch 383, Batch 4/4: Clipping gradients...
  Epoch 383, Batch 4/4: Optimizer step...
  Epoch 383, Batch 4/4: Completed in 0.03s
Epoch 383: Training phase completed. Average Train Loss: 0.3563
Epoch 383: Starting validation phase...
  Epoch 383, Val Batch 1/1: Loading data...
  Epoch 383, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 383, Val Batch 1/1: Forward pass...
  Epoch 383, Val Batch 1/1: Calculating loss...
Epoch 383: Validation phase completed. Average Val Loss: 0.2479
Epoch 383 Summary ---> Train Loss: 0.3563 / Validation Loss: 0.2479
Epoch 383: Checking early stopping... (Current Best Loss: 0.2437, Epochs No Improve: 4)
  Epoch 383: Validation loss did not improve. Epochs without improvement: 5
Epoch 383: Stepping scheduler...
--- Epoch 383 completed in 0.66 seconds ---

--- Starting Epoch 384/1000 ---
Epoch 384: Starting training phase (4 batches)
  Epoch 384, Batch 1/4: Loading data to device...
  Epoch 384, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 384, Batch 1/4: Zeroing gradients...
  Epoch 384, Batch 1/4: Forward pass...
  Epoch 384, Batch 1/4: Calculating loss...
  Epoch 384, Batch 1/4: Backward pass...
  Epoch 384, Batch 1/4: Clipping gradients...
  Epoch 384, Batch 1/4: Optimizer step...
  Epoch 384, Batch 1/4: Completed in 0.19s
  Epoch 384, Batch 2/4: Loading data to device...
  Epoch 384, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 384, Batch 2/4: Zeroing gradients...
  Epoch 384, Batch 2/4: Forward pass...
  Epoch 384, Batch 2/4: Calculating loss...
  Epoch 384, Batch 2/4: Backward pass...
  Epoch 384, Batch 2/4: Clipping gradients...
  Epoch 384, Batch 2/4: Optimizer step...
  Epoch 384, Batch 2/4: Completed in 0.18s
  Epoch 384, Batch 3/4: Loading data to device...
  Epoch 384, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 384, Batch 3/4: Zeroing gradients...
  Epoch 384, Batch 3/4: Forward pass...
  Epoch 384, Batch 3/4: Calculating loss...
  Epoch 384, Batch 3/4: Backward pass...
  Epoch 384, Batch 3/4: Clipping gradients...
  Epoch 384, Batch 3/4: Optimizer step...
  Epoch 384, Batch 3/4: Completed in 0.19s
  Epoch 384, Batch 4/4: Loading data to device...
  Epoch 384, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 384, Batch 4/4: Zeroing gradients...
  Epoch 384, Batch 4/4: Forward pass...
  Epoch 384, Batch 4/4: Calculating loss...
  Epoch 384, Batch 4/4: Backward pass...
  Epoch 384, Batch 4/4: Clipping gradients...
  Epoch 384, Batch 4/4: Optimizer step...
  Epoch 384, Batch 4/4: Completed in 0.04s
Epoch 384: Training phase completed. Average Train Loss: 0.3492
Epoch 384: Starting validation phase...
  Epoch 384, Val Batch 1/1: Loading data...
  Epoch 384, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 384, Val Batch 1/1: Forward pass...
  Epoch 384, Val Batch 1/1: Calculating loss...
Epoch 384: Validation phase completed. Average Val Loss: 0.2463
Epoch 384 Summary ---> Train Loss: 0.3492 / Validation Loss: 0.2463
Epoch 384: Checking early stopping... (Current Best Loss: 0.2437, Epochs No Improve: 5)
  Epoch 384: Validation loss did not improve. Epochs without improvement: 6
Epoch 384: Stepping scheduler...
--- Epoch 384 completed in 0.67 seconds ---

--- Starting Epoch 385/1000 ---
Epoch 385: Starting training phase (4 batches)
  Epoch 385, Batch 1/4: Loading data to device...
  Epoch 385, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 385, Batch 1/4: Zeroing gradients...
  Epoch 385, Batch 1/4: Forward pass...
  Epoch 385, Batch 1/4: Calculating loss...
  Epoch 385, Batch 1/4: Backward pass...
  Epoch 385, Batch 1/4: Clipping gradients...
  Epoch 385, Batch 1/4: Optimizer step...
  Epoch 385, Batch 1/4: Completed in 0.19s
  Epoch 385, Batch 2/4: Loading data to device...
  Epoch 385, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 385, Batch 2/4: Zeroing gradients...
  Epoch 385, Batch 2/4: Forward pass...
  Epoch 385, Batch 2/4: Calculating loss...
  Epoch 385, Batch 2/4: Backward pass...
  Epoch 385, Batch 2/4: Clipping gradients...
  Epoch 385, Batch 2/4: Optimizer step...
  Epoch 385, Batch 2/4: Completed in 0.20s
  Epoch 385, Batch 3/4: Loading data to device...
  Epoch 385, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 385, Batch 3/4: Zeroing gradients...
  Epoch 385, Batch 3/4: Forward pass...
  Epoch 385, Batch 3/4: Calculating loss...
  Epoch 385, Batch 3/4: Backward pass...
  Epoch 385, Batch 3/4: Clipping gradients...
  Epoch 385, Batch 3/4: Optimizer step...
  Epoch 385, Batch 3/4: Completed in 0.19s
  Epoch 385, Batch 4/4: Loading data to device...
  Epoch 385, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 385, Batch 4/4: Zeroing gradients...
  Epoch 385, Batch 4/4: Forward pass...
  Epoch 385, Batch 4/4: Calculating loss...
  Epoch 385, Batch 4/4: Backward pass...
  Epoch 385, Batch 4/4: Clipping gradients...
  Epoch 385, Batch 4/4: Optimizer step...
  Epoch 385, Batch 4/4: Completed in 0.03s
Epoch 385: Training phase completed. Average Train Loss: 0.2805
Epoch 385: Starting validation phase...
  Epoch 385, Val Batch 1/1: Loading data...
  Epoch 385, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 385, Val Batch 1/1: Forward pass...
  Epoch 385, Val Batch 1/1: Calculating loss...
Epoch 385: Validation phase completed. Average Val Loss: 0.2494
Epoch 385 Summary ---> Train Loss: 0.2805 / Validation Loss: 0.2494
Epoch 385: Checking early stopping... (Current Best Loss: 0.2437, Epochs No Improve: 6)
  Epoch 385: Validation loss did not improve. Epochs without improvement: 7
Epoch 385: Stepping scheduler...
--- Epoch 385 completed in 0.68 seconds ---

--- Starting Epoch 386/1000 ---
Epoch 386: Starting training phase (4 batches)
  Epoch 386, Batch 1/4: Loading data to device...
  Epoch 386, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 386, Batch 1/4: Zeroing gradients...
  Epoch 386, Batch 1/4: Forward pass...
  Epoch 386, Batch 1/4: Calculating loss...
  Epoch 386, Batch 1/4: Backward pass...
  Epoch 386, Batch 1/4: Clipping gradients...
  Epoch 386, Batch 1/4: Optimizer step...
  Epoch 386, Batch 1/4: Completed in 0.19s
  Epoch 386, Batch 2/4: Loading data to device...
  Epoch 386, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 386, Batch 2/4: Zeroing gradients...
  Epoch 386, Batch 2/4: Forward pass...
  Epoch 386, Batch 2/4: Calculating loss...
  Epoch 386, Batch 2/4: Backward pass...
  Epoch 386, Batch 2/4: Clipping gradients...
  Epoch 386, Batch 2/4: Optimizer step...
  Epoch 386, Batch 2/4: Completed in 0.19s
  Epoch 386, Batch 3/4: Loading data to device...
  Epoch 386, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 386, Batch 3/4: Zeroing gradients...
  Epoch 386, Batch 3/4: Forward pass...
  Epoch 386, Batch 3/4: Calculating loss...
  Epoch 386, Batch 3/4: Backward pass...
  Epoch 386, Batch 3/4: Clipping gradients...
  Epoch 386, Batch 3/4: Optimizer step...
  Epoch 386, Batch 3/4: Completed in 0.20s
  Epoch 386, Batch 4/4: Loading data to device...
  Epoch 386, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 386, Batch 4/4: Zeroing gradients...
  Epoch 386, Batch 4/4: Forward pass...
  Epoch 386, Batch 4/4: Calculating loss...
  Epoch 386, Batch 4/4: Backward pass...
  Epoch 386, Batch 4/4: Clipping gradients...
  Epoch 386, Batch 4/4: Optimizer step...
  Epoch 386, Batch 4/4: Completed in 0.03s
Epoch 386: Training phase completed. Average Train Loss: 0.3424
Epoch 386: Starting validation phase...
  Epoch 386, Val Batch 1/1: Loading data...
  Epoch 386, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 386, Val Batch 1/1: Forward pass...
  Epoch 386, Val Batch 1/1: Calculating loss...
Epoch 386: Validation phase completed. Average Val Loss: 0.2464
Epoch 386 Summary ---> Train Loss: 0.3424 / Validation Loss: 0.2464
Epoch 386: Checking early stopping... (Current Best Loss: 0.2437, Epochs No Improve: 7)
  Epoch 386: Validation loss did not improve. Epochs without improvement: 8
Epoch 386: Stepping scheduler...
--- Epoch 386 completed in 0.68 seconds ---

--- Starting Epoch 387/1000 ---
Epoch 387: Starting training phase (4 batches)
  Epoch 387, Batch 1/4: Loading data to device...
  Epoch 387, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 387, Batch 1/4: Zeroing gradients...
  Epoch 387, Batch 1/4: Forward pass...
  Epoch 387, Batch 1/4: Calculating loss...
  Epoch 387, Batch 1/4: Backward pass...
  Epoch 387, Batch 1/4: Clipping gradients...
  Epoch 387, Batch 1/4: Optimizer step...
  Epoch 387, Batch 1/4: Completed in 0.20s
  Epoch 387, Batch 2/4: Loading data to device...
  Epoch 387, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 387, Batch 2/4: Zeroing gradients...
  Epoch 387, Batch 2/4: Forward pass...
  Epoch 387, Batch 2/4: Calculating loss...
  Epoch 387, Batch 2/4: Backward pass...
  Epoch 387, Batch 2/4: Clipping gradients...
  Epoch 387, Batch 2/4: Optimizer step...
  Epoch 387, Batch 2/4: Completed in 0.20s
  Epoch 387, Batch 3/4: Loading data to device...
  Epoch 387, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 387, Batch 3/4: Zeroing gradients...
  Epoch 387, Batch 3/4: Forward pass...
  Epoch 387, Batch 3/4: Calculating loss...
  Epoch 387, Batch 3/4: Backward pass...
  Epoch 387, Batch 3/4: Clipping gradients...
  Epoch 387, Batch 3/4: Optimizer step...
  Epoch 387, Batch 3/4: Completed in 0.20s
  Epoch 387, Batch 4/4: Loading data to device...
  Epoch 387, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 387, Batch 4/4: Zeroing gradients...
  Epoch 387, Batch 4/4: Forward pass...
  Epoch 387, Batch 4/4: Calculating loss...
  Epoch 387, Batch 4/4: Backward pass...
  Epoch 387, Batch 4/4: Clipping gradients...
  Epoch 387, Batch 4/4: Optimizer step...
  Epoch 387, Batch 4/4: Completed in 0.03s
Epoch 387: Training phase completed. Average Train Loss: 0.2946
Epoch 387: Starting validation phase...
  Epoch 387, Val Batch 1/1: Loading data...
  Epoch 387, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 387, Val Batch 1/1: Forward pass...
  Epoch 387, Val Batch 1/1: Calculating loss...
Epoch 387: Validation phase completed. Average Val Loss: 0.2468
Epoch 387 Summary ---> Train Loss: 0.2946 / Validation Loss: 0.2468
Epoch 387: Checking early stopping... (Current Best Loss: 0.2437, Epochs No Improve: 8)
  Epoch 387: Validation loss did not improve. Epochs without improvement: 9
Epoch 387: Stepping scheduler...
--- Epoch 387 completed in 0.69 seconds ---

--- Starting Epoch 388/1000 ---
Epoch 388: Starting training phase (4 batches)
  Epoch 388, Batch 1/4: Loading data to device...
  Epoch 388, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 388, Batch 1/4: Zeroing gradients...
  Epoch 388, Batch 1/4: Forward pass...
  Epoch 388, Batch 1/4: Calculating loss...
  Epoch 388, Batch 1/4: Backward pass...
  Epoch 388, Batch 1/4: Clipping gradients...
  Epoch 388, Batch 1/4: Optimizer step...
  Epoch 388, Batch 1/4: Completed in 0.19s
  Epoch 388, Batch 2/4: Loading data to device...
  Epoch 388, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 388, Batch 2/4: Zeroing gradients...
  Epoch 388, Batch 2/4: Forward pass...
  Epoch 388, Batch 2/4: Calculating loss...
  Epoch 388, Batch 2/4: Backward pass...
  Epoch 388, Batch 2/4: Clipping gradients...
  Epoch 388, Batch 2/4: Optimizer step...
  Epoch 388, Batch 2/4: Completed in 0.20s
  Epoch 388, Batch 3/4: Loading data to device...
  Epoch 388, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 388, Batch 3/4: Zeroing gradients...
  Epoch 388, Batch 3/4: Forward pass...
  Epoch 388, Batch 3/4: Calculating loss...
  Epoch 388, Batch 3/4: Backward pass...
  Epoch 388, Batch 3/4: Clipping gradients...
  Epoch 388, Batch 3/4: Optimizer step...
  Epoch 388, Batch 3/4: Completed in 0.20s
  Epoch 388, Batch 4/4: Loading data to device...
  Epoch 388, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 388, Batch 4/4: Zeroing gradients...
  Epoch 388, Batch 4/4: Forward pass...
  Epoch 388, Batch 4/4: Calculating loss...
  Epoch 388, Batch 4/4: Backward pass...
  Epoch 388, Batch 4/4: Clipping gradients...
  Epoch 388, Batch 4/4: Optimizer step...
  Epoch 388, Batch 4/4: Completed in 0.03s
Epoch 388: Training phase completed. Average Train Loss: 0.3697
Epoch 388: Starting validation phase...
  Epoch 388, Val Batch 1/1: Loading data...
  Epoch 388, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 388, Val Batch 1/1: Forward pass...
  Epoch 388, Val Batch 1/1: Calculating loss...
Epoch 388: Validation phase completed. Average Val Loss: 0.2476
Epoch 388 Summary ---> Train Loss: 0.3697 / Validation Loss: 0.2476
Epoch 388: Checking early stopping... (Current Best Loss: 0.2437, Epochs No Improve: 9)
  Epoch 388: Validation loss did not improve. Epochs without improvement: 10
Epoch 388: Stepping scheduler...
--- Epoch 388 completed in 0.69 seconds ---

--- Starting Epoch 389/1000 ---
Epoch 389: Starting training phase (4 batches)
  Epoch 389, Batch 1/4: Loading data to device...
  Epoch 389, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 389, Batch 1/4: Zeroing gradients...
  Epoch 389, Batch 1/4: Forward pass...
  Epoch 389, Batch 1/4: Calculating loss...
  Epoch 389, Batch 1/4: Backward pass...
  Epoch 389, Batch 1/4: Clipping gradients...
  Epoch 389, Batch 1/4: Optimizer step...
  Epoch 389, Batch 1/4: Completed in 0.19s
  Epoch 389, Batch 2/4: Loading data to device...
  Epoch 389, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 389, Batch 2/4: Zeroing gradients...
  Epoch 389, Batch 2/4: Forward pass...
  Epoch 389, Batch 2/4: Calculating loss...
  Epoch 389, Batch 2/4: Backward pass...
  Epoch 389, Batch 2/4: Clipping gradients...
  Epoch 389, Batch 2/4: Optimizer step...
  Epoch 389, Batch 2/4: Completed in 0.19s
  Epoch 389, Batch 3/4: Loading data to device...
  Epoch 389, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 389, Batch 3/4: Zeroing gradients...
  Epoch 389, Batch 3/4: Forward pass...
  Epoch 389, Batch 3/4: Calculating loss...
  Epoch 389, Batch 3/4: Backward pass...
  Epoch 389, Batch 3/4: Clipping gradients...
  Epoch 389, Batch 3/4: Optimizer step...
  Epoch 389, Batch 3/4: Completed in 0.19s
  Epoch 389, Batch 4/4: Loading data to device...
  Epoch 389, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 389, Batch 4/4: Zeroing gradients...
  Epoch 389, Batch 4/4: Forward pass...
  Epoch 389, Batch 4/4: Calculating loss...
  Epoch 389, Batch 4/4: Backward pass...
  Epoch 389, Batch 4/4: Clipping gradients...
  Epoch 389, Batch 4/4: Optimizer step...
  Epoch 389, Batch 4/4: Completed in 0.03s
Epoch 389: Training phase completed. Average Train Loss: 0.2931
Epoch 389: Starting validation phase...
  Epoch 389, Val Batch 1/1: Loading data...
  Epoch 389, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 389, Val Batch 1/1: Forward pass...
  Epoch 389, Val Batch 1/1: Calculating loss...
Epoch 389: Validation phase completed. Average Val Loss: 0.2509
Epoch 389 Summary ---> Train Loss: 0.2931 / Validation Loss: 0.2509
Epoch 389: Checking early stopping... (Current Best Loss: 0.2437, Epochs No Improve: 10)
  Epoch 389: Validation loss did not improve. Epochs without improvement: 11
Epoch 389: Stepping scheduler...
--- Epoch 389 completed in 0.67 seconds ---

--- Starting Epoch 390/1000 ---
Epoch 390: Starting training phase (4 batches)
  Epoch 390, Batch 1/4: Loading data to device...
  Epoch 390, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 390, Batch 1/4: Zeroing gradients...
  Epoch 390, Batch 1/4: Forward pass...
  Epoch 390, Batch 1/4: Calculating loss...
  Epoch 390, Batch 1/4: Backward pass...
  Epoch 390, Batch 1/4: Clipping gradients...
  Epoch 390, Batch 1/4: Optimizer step...
  Epoch 390, Batch 1/4: Completed in 0.19s
  Epoch 390, Batch 2/4: Loading data to device...
  Epoch 390, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 390, Batch 2/4: Zeroing gradients...
  Epoch 390, Batch 2/4: Forward pass...
  Epoch 390, Batch 2/4: Calculating loss...
  Epoch 390, Batch 2/4: Backward pass...
  Epoch 390, Batch 2/4: Clipping gradients...
  Epoch 390, Batch 2/4: Optimizer step...
  Epoch 390, Batch 2/4: Completed in 0.19s
  Epoch 390, Batch 3/4: Loading data to device...
  Epoch 390, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 390, Batch 3/4: Zeroing gradients...
  Epoch 390, Batch 3/4: Forward pass...
  Epoch 390, Batch 3/4: Calculating loss...
  Epoch 390, Batch 3/4: Backward pass...
  Epoch 390, Batch 3/4: Clipping gradients...
  Epoch 390, Batch 3/4: Optimizer step...
  Epoch 390, Batch 3/4: Completed in 0.19s
  Epoch 390, Batch 4/4: Loading data to device...
  Epoch 390, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 390, Batch 4/4: Zeroing gradients...
  Epoch 390, Batch 4/4: Forward pass...
  Epoch 390, Batch 4/4: Calculating loss...
  Epoch 390, Batch 4/4: Backward pass...
  Epoch 390, Batch 4/4: Clipping gradients...
  Epoch 390, Batch 4/4: Optimizer step...
  Epoch 390, Batch 4/4: Completed in 0.04s
Epoch 390: Training phase completed. Average Train Loss: 0.4059
Epoch 390: Starting validation phase...
  Epoch 390, Val Batch 1/1: Loading data...
  Epoch 390, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 390, Val Batch 1/1: Forward pass...
  Epoch 390, Val Batch 1/1: Calculating loss...
Epoch 390: Validation phase completed. Average Val Loss: 0.2439
Epoch 390 Summary ---> Train Loss: 0.4059 / Validation Loss: 0.2439
Epoch 390: Checking early stopping... (Current Best Loss: 0.2437, Epochs No Improve: 11)
  Epoch 390: Validation loss did not improve. Epochs without improvement: 12
Epoch 390: Stepping scheduler...
--- Epoch 390 completed in 0.69 seconds ---

--- Starting Epoch 391/1000 ---
Epoch 391: Starting training phase (4 batches)
  Epoch 391, Batch 1/4: Loading data to device...
  Epoch 391, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 391, Batch 1/4: Zeroing gradients...
  Epoch 391, Batch 1/4: Forward pass...
  Epoch 391, Batch 1/4: Calculating loss...
  Epoch 391, Batch 1/4: Backward pass...
  Epoch 391, Batch 1/4: Clipping gradients...
  Epoch 391, Batch 1/4: Optimizer step...
  Epoch 391, Batch 1/4: Completed in 0.20s
  Epoch 391, Batch 2/4: Loading data to device...
  Epoch 391, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 391, Batch 2/4: Zeroing gradients...
  Epoch 391, Batch 2/4: Forward pass...
  Epoch 391, Batch 2/4: Calculating loss...
  Epoch 391, Batch 2/4: Backward pass...
  Epoch 391, Batch 2/4: Clipping gradients...
  Epoch 391, Batch 2/4: Optimizer step...
  Epoch 391, Batch 2/4: Completed in 0.19s
  Epoch 391, Batch 3/4: Loading data to device...
  Epoch 391, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 391, Batch 3/4: Zeroing gradients...
  Epoch 391, Batch 3/4: Forward pass...
  Epoch 391, Batch 3/4: Calculating loss...
  Epoch 391, Batch 3/4: Backward pass...
  Epoch 391, Batch 3/4: Clipping gradients...
  Epoch 391, Batch 3/4: Optimizer step...
  Epoch 391, Batch 3/4: Completed in 0.19s
  Epoch 391, Batch 4/4: Loading data to device...
  Epoch 391, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 391, Batch 4/4: Zeroing gradients...
  Epoch 391, Batch 4/4: Forward pass...
  Epoch 391, Batch 4/4: Calculating loss...
  Epoch 391, Batch 4/4: Backward pass...
  Epoch 391, Batch 4/4: Clipping gradients...
  Epoch 391, Batch 4/4: Optimizer step...
  Epoch 391, Batch 4/4: Completed in 0.03s
Epoch 391: Training phase completed. Average Train Loss: 0.3020
Epoch 391: Starting validation phase...
  Epoch 391, Val Batch 1/1: Loading data...
  Epoch 391, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 391, Val Batch 1/1: Forward pass...
  Epoch 391, Val Batch 1/1: Calculating loss...
Epoch 391: Validation phase completed. Average Val Loss: 0.2420
Epoch 391 Summary ---> Train Loss: 0.3020 / Validation Loss: 0.2420
Epoch 391: Checking early stopping... (Current Best Loss: 0.2437, Epochs No Improve: 12)
  Epoch 391: Validation loss improved (0.2437 --> 0.2420). Saving model.
Epoch 391: Stepping scheduler...
--- Epoch 391 completed in 0.69 seconds ---

--- Starting Epoch 392/1000 ---
Epoch 392: Starting training phase (4 batches)
  Epoch 392, Batch 1/4: Loading data to device...
  Epoch 392, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 392, Batch 1/4: Zeroing gradients...
  Epoch 392, Batch 1/4: Forward pass...
  Epoch 392, Batch 1/4: Calculating loss...
  Epoch 392, Batch 1/4: Backward pass...
  Epoch 392, Batch 1/4: Clipping gradients...
  Epoch 392, Batch 1/4: Optimizer step...
  Epoch 392, Batch 1/4: Completed in 0.19s
  Epoch 392, Batch 2/4: Loading data to device...
  Epoch 392, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 392, Batch 2/4: Zeroing gradients...
  Epoch 392, Batch 2/4: Forward pass...
  Epoch 392, Batch 2/4: Calculating loss...
  Epoch 392, Batch 2/4: Backward pass...
  Epoch 392, Batch 2/4: Clipping gradients...
  Epoch 392, Batch 2/4: Optimizer step...
  Epoch 392, Batch 2/4: Completed in 0.19s
  Epoch 392, Batch 3/4: Loading data to device...
  Epoch 392, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 392, Batch 3/4: Zeroing gradients...
  Epoch 392, Batch 3/4: Forward pass...
  Epoch 392, Batch 3/4: Calculating loss...
  Epoch 392, Batch 3/4: Backward pass...
  Epoch 392, Batch 3/4: Clipping gradients...
  Epoch 392, Batch 3/4: Optimizer step...
  Epoch 392, Batch 3/4: Completed in 0.19s
  Epoch 392, Batch 4/4: Loading data to device...
  Epoch 392, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 392, Batch 4/4: Zeroing gradients...
  Epoch 392, Batch 4/4: Forward pass...
  Epoch 392, Batch 4/4: Calculating loss...
  Epoch 392, Batch 4/4: Backward pass...
  Epoch 392, Batch 4/4: Clipping gradients...
  Epoch 392, Batch 4/4: Optimizer step...
  Epoch 392, Batch 4/4: Completed in 0.03s
Epoch 392: Training phase completed. Average Train Loss: 0.3056
Epoch 392: Starting validation phase...
  Epoch 392, Val Batch 1/1: Loading data...
  Epoch 392, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 392, Val Batch 1/1: Forward pass...
  Epoch 392, Val Batch 1/1: Calculating loss...
Epoch 392: Validation phase completed. Average Val Loss: 0.2493
Epoch 392 Summary ---> Train Loss: 0.3056 / Validation Loss: 0.2493
Epoch 392: Checking early stopping... (Current Best Loss: 0.2420, Epochs No Improve: 0)
  Epoch 392: Validation loss did not improve. Epochs without improvement: 1
Epoch 392: Stepping scheduler...
--- Epoch 392 completed in 0.67 seconds ---

--- Starting Epoch 393/1000 ---
Epoch 393: Starting training phase (4 batches)
  Epoch 393, Batch 1/4: Loading data to device...
  Epoch 393, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 393, Batch 1/4: Zeroing gradients...
  Epoch 393, Batch 1/4: Forward pass...
  Epoch 393, Batch 1/4: Calculating loss...
  Epoch 393, Batch 1/4: Backward pass...
  Epoch 393, Batch 1/4: Clipping gradients...
  Epoch 393, Batch 1/4: Optimizer step...
  Epoch 393, Batch 1/4: Completed in 0.19s
  Epoch 393, Batch 2/4: Loading data to device...
  Epoch 393, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 393, Batch 2/4: Zeroing gradients...
  Epoch 393, Batch 2/4: Forward pass...
  Epoch 393, Batch 2/4: Calculating loss...
  Epoch 393, Batch 2/4: Backward pass...
  Epoch 393, Batch 2/4: Clipping gradients...
  Epoch 393, Batch 2/4: Optimizer step...
  Epoch 393, Batch 2/4: Completed in 0.19s
  Epoch 393, Batch 3/4: Loading data to device...
  Epoch 393, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 393, Batch 3/4: Zeroing gradients...
  Epoch 393, Batch 3/4: Forward pass...
  Epoch 393, Batch 3/4: Calculating loss...
  Epoch 393, Batch 3/4: Backward pass...
  Epoch 393, Batch 3/4: Clipping gradients...
  Epoch 393, Batch 3/4: Optimizer step...
  Epoch 393, Batch 3/4: Completed in 0.20s
  Epoch 393, Batch 4/4: Loading data to device...
  Epoch 393, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 393, Batch 4/4: Zeroing gradients...
  Epoch 393, Batch 4/4: Forward pass...
  Epoch 393, Batch 4/4: Calculating loss...
  Epoch 393, Batch 4/4: Backward pass...
  Epoch 393, Batch 4/4: Clipping gradients...
  Epoch 393, Batch 4/4: Optimizer step...
  Epoch 393, Batch 4/4: Completed in 0.03s
Epoch 393: Training phase completed. Average Train Loss: 0.3479
Epoch 393: Starting validation phase...
  Epoch 393, Val Batch 1/1: Loading data...
  Epoch 393, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 393, Val Batch 1/1: Forward pass...
  Epoch 393, Val Batch 1/1: Calculating loss...
Epoch 393: Validation phase completed. Average Val Loss: 0.2443
Epoch 393 Summary ---> Train Loss: 0.3479 / Validation Loss: 0.2443
Epoch 393: Checking early stopping... (Current Best Loss: 0.2420, Epochs No Improve: 1)
  Epoch 393: Validation loss did not improve. Epochs without improvement: 2
Epoch 393: Stepping scheduler...
--- Epoch 393 completed in 0.68 seconds ---

--- Starting Epoch 394/1000 ---
Epoch 394: Starting training phase (4 batches)
  Epoch 394, Batch 1/4: Loading data to device...
  Epoch 394, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 394, Batch 1/4: Zeroing gradients...
  Epoch 394, Batch 1/4: Forward pass...
  Epoch 394, Batch 1/4: Calculating loss...
  Epoch 394, Batch 1/4: Backward pass...
  Epoch 394, Batch 1/4: Clipping gradients...
  Epoch 394, Batch 1/4: Optimizer step...
  Epoch 394, Batch 1/4: Completed in 0.20s
  Epoch 394, Batch 2/4: Loading data to device...
  Epoch 394, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 394, Batch 2/4: Zeroing gradients...
  Epoch 394, Batch 2/4: Forward pass...
  Epoch 394, Batch 2/4: Calculating loss...
  Epoch 394, Batch 2/4: Backward pass...
  Epoch 394, Batch 2/4: Clipping gradients...
  Epoch 394, Batch 2/4: Optimizer step...
  Epoch 394, Batch 2/4: Completed in 0.19s
  Epoch 394, Batch 3/4: Loading data to device...
  Epoch 394, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 394, Batch 3/4: Zeroing gradients...
  Epoch 394, Batch 3/4: Forward pass...
  Epoch 394, Batch 3/4: Calculating loss...
  Epoch 394, Batch 3/4: Backward pass...
  Epoch 394, Batch 3/4: Clipping gradients...
  Epoch 394, Batch 3/4: Optimizer step...
  Epoch 394, Batch 3/4: Completed in 0.20s
  Epoch 394, Batch 4/4: Loading data to device...
  Epoch 394, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 394, Batch 4/4: Zeroing gradients...
  Epoch 394, Batch 4/4: Forward pass...
  Epoch 394, Batch 4/4: Calculating loss...
  Epoch 394, Batch 4/4: Backward pass...
  Epoch 394, Batch 4/4: Clipping gradients...
  Epoch 394, Batch 4/4: Optimizer step...
  Epoch 394, Batch 4/4: Completed in 0.03s
Epoch 394: Training phase completed. Average Train Loss: 0.2966
Epoch 394: Starting validation phase...
  Epoch 394, Val Batch 1/1: Loading data...
  Epoch 394, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 394, Val Batch 1/1: Forward pass...
  Epoch 394, Val Batch 1/1: Calculating loss...
Epoch 394: Validation phase completed. Average Val Loss: 0.2407
Epoch 394 Summary ---> Train Loss: 0.2966 / Validation Loss: 0.2407
Epoch 394: Checking early stopping... (Current Best Loss: 0.2420, Epochs No Improve: 2)
  Epoch 394: Validation loss improved (0.2420 --> 0.2407). Saving model.
Epoch 394: Stepping scheduler...
--- Epoch 394 completed in 0.69 seconds ---

--- Starting Epoch 395/1000 ---
Epoch 395: Starting training phase (4 batches)
  Epoch 395, Batch 1/4: Loading data to device...
  Epoch 395, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 395, Batch 1/4: Zeroing gradients...
  Epoch 395, Batch 1/4: Forward pass...
  Epoch 395, Batch 1/4: Calculating loss...
  Epoch 395, Batch 1/4: Backward pass...
  Epoch 395, Batch 1/4: Clipping gradients...
  Epoch 395, Batch 1/4: Optimizer step...
  Epoch 395, Batch 1/4: Completed in 0.19s
  Epoch 395, Batch 2/4: Loading data to device...
  Epoch 395, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 395, Batch 2/4: Zeroing gradients...
  Epoch 395, Batch 2/4: Forward pass...
  Epoch 395, Batch 2/4: Calculating loss...
  Epoch 395, Batch 2/4: Backward pass...
  Epoch 395, Batch 2/4: Clipping gradients...
  Epoch 395, Batch 2/4: Optimizer step...
  Epoch 395, Batch 2/4: Completed in 0.19s
  Epoch 395, Batch 3/4: Loading data to device...
  Epoch 395, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 395, Batch 3/4: Zeroing gradients...
  Epoch 395, Batch 3/4: Forward pass...
  Epoch 395, Batch 3/4: Calculating loss...
  Epoch 395, Batch 3/4: Backward pass...
  Epoch 395, Batch 3/4: Clipping gradients...
  Epoch 395, Batch 3/4: Optimizer step...
  Epoch 395, Batch 3/4: Completed in 0.19s
  Epoch 395, Batch 4/4: Loading data to device...
  Epoch 395, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 395, Batch 4/4: Zeroing gradients...
  Epoch 395, Batch 4/4: Forward pass...
  Epoch 395, Batch 4/4: Calculating loss...
  Epoch 395, Batch 4/4: Backward pass...
  Epoch 395, Batch 4/4: Clipping gradients...
  Epoch 395, Batch 4/4: Optimizer step...
  Epoch 395, Batch 4/4: Completed in 0.03s
Epoch 395: Training phase completed. Average Train Loss: 0.3391
Epoch 395: Starting validation phase...
  Epoch 395, Val Batch 1/1: Loading data...
  Epoch 395, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 395, Val Batch 1/1: Forward pass...
  Epoch 395, Val Batch 1/1: Calculating loss...
Epoch 395: Validation phase completed. Average Val Loss: 0.2451
Epoch 395 Summary ---> Train Loss: 0.3391 / Validation Loss: 0.2451
Epoch 395: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 0)
  Epoch 395: Validation loss did not improve. Epochs without improvement: 1
Epoch 395: Stepping scheduler...
--- Epoch 395 completed in 0.67 seconds ---

--- Starting Epoch 396/1000 ---
Epoch 396: Starting training phase (4 batches)
  Epoch 396, Batch 1/4: Loading data to device...
  Epoch 396, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 396, Batch 1/4: Zeroing gradients...
  Epoch 396, Batch 1/4: Forward pass...
  Epoch 396, Batch 1/4: Calculating loss...
  Epoch 396, Batch 1/4: Backward pass...
  Epoch 396, Batch 1/4: Clipping gradients...
  Epoch 396, Batch 1/4: Optimizer step...
  Epoch 396, Batch 1/4: Completed in 0.19s
  Epoch 396, Batch 2/4: Loading data to device...
  Epoch 396, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 396, Batch 2/4: Zeroing gradients...
  Epoch 396, Batch 2/4: Forward pass...
  Epoch 396, Batch 2/4: Calculating loss...
  Epoch 396, Batch 2/4: Backward pass...
  Epoch 396, Batch 2/4: Clipping gradients...
  Epoch 396, Batch 2/4: Optimizer step...
  Epoch 396, Batch 2/4: Completed in 0.19s
  Epoch 396, Batch 3/4: Loading data to device...
  Epoch 396, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 396, Batch 3/4: Zeroing gradients...
  Epoch 396, Batch 3/4: Forward pass...
  Epoch 396, Batch 3/4: Calculating loss...
  Epoch 396, Batch 3/4: Backward pass...
  Epoch 396, Batch 3/4: Clipping gradients...
  Epoch 396, Batch 3/4: Optimizer step...
  Epoch 396, Batch 3/4: Completed in 0.19s
  Epoch 396, Batch 4/4: Loading data to device...
  Epoch 396, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 396, Batch 4/4: Zeroing gradients...
  Epoch 396, Batch 4/4: Forward pass...
  Epoch 396, Batch 4/4: Calculating loss...
  Epoch 396, Batch 4/4: Backward pass...
  Epoch 396, Batch 4/4: Clipping gradients...
  Epoch 396, Batch 4/4: Optimizer step...
  Epoch 396, Batch 4/4: Completed in 0.03s
Epoch 396: Training phase completed. Average Train Loss: 0.3131
Epoch 396: Starting validation phase...
  Epoch 396, Val Batch 1/1: Loading data...
  Epoch 396, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 396, Val Batch 1/1: Forward pass...
  Epoch 396, Val Batch 1/1: Calculating loss...
Epoch 396: Validation phase completed. Average Val Loss: 0.2526
Epoch 396 Summary ---> Train Loss: 0.3131 / Validation Loss: 0.2526
Epoch 396: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 1)
  Epoch 396: Validation loss did not improve. Epochs without improvement: 2
Epoch 396: Stepping scheduler...
--- Epoch 396 completed in 0.67 seconds ---

--- Starting Epoch 397/1000 ---
Epoch 397: Starting training phase (4 batches)
  Epoch 397, Batch 1/4: Loading data to device...
  Epoch 397, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 397, Batch 1/4: Zeroing gradients...
  Epoch 397, Batch 1/4: Forward pass...
  Epoch 397, Batch 1/4: Calculating loss...
  Epoch 397, Batch 1/4: Backward pass...
  Epoch 397, Batch 1/4: Clipping gradients...
  Epoch 397, Batch 1/4: Optimizer step...
  Epoch 397, Batch 1/4: Completed in 0.19s
  Epoch 397, Batch 2/4: Loading data to device...
  Epoch 397, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 397, Batch 2/4: Zeroing gradients...
  Epoch 397, Batch 2/4: Forward pass...
  Epoch 397, Batch 2/4: Calculating loss...
  Epoch 397, Batch 2/4: Backward pass...
  Epoch 397, Batch 2/4: Clipping gradients...
  Epoch 397, Batch 2/4: Optimizer step...
  Epoch 397, Batch 2/4: Completed in 0.18s
  Epoch 397, Batch 3/4: Loading data to device...
  Epoch 397, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 397, Batch 3/4: Zeroing gradients...
  Epoch 397, Batch 3/4: Forward pass...
  Epoch 397, Batch 3/4: Calculating loss...
  Epoch 397, Batch 3/4: Backward pass...
  Epoch 397, Batch 3/4: Clipping gradients...
  Epoch 397, Batch 3/4: Optimizer step...
  Epoch 397, Batch 3/4: Completed in 0.19s
  Epoch 397, Batch 4/4: Loading data to device...
  Epoch 397, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 397, Batch 4/4: Zeroing gradients...
  Epoch 397, Batch 4/4: Forward pass...
  Epoch 397, Batch 4/4: Calculating loss...
  Epoch 397, Batch 4/4: Backward pass...
  Epoch 397, Batch 4/4: Clipping gradients...
  Epoch 397, Batch 4/4: Optimizer step...
  Epoch 397, Batch 4/4: Completed in 0.03s
Epoch 397: Training phase completed. Average Train Loss: 0.4095
Epoch 397: Starting validation phase...
  Epoch 397, Val Batch 1/1: Loading data...
  Epoch 397, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 397, Val Batch 1/1: Forward pass...
  Epoch 397, Val Batch 1/1: Calculating loss...
Epoch 397: Validation phase completed. Average Val Loss: 0.2542
Epoch 397 Summary ---> Train Loss: 0.4095 / Validation Loss: 0.2542
Epoch 397: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 2)
  Epoch 397: Validation loss did not improve. Epochs without improvement: 3
Epoch 397: Stepping scheduler...
--- Epoch 397 completed in 0.65 seconds ---

--- Starting Epoch 398/1000 ---
Epoch 398: Starting training phase (4 batches)
  Epoch 398, Batch 1/4: Loading data to device...
  Epoch 398, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 398, Batch 1/4: Zeroing gradients...
  Epoch 398, Batch 1/4: Forward pass...
  Epoch 398, Batch 1/4: Calculating loss...
  Epoch 398, Batch 1/4: Backward pass...
  Epoch 398, Batch 1/4: Clipping gradients...
  Epoch 398, Batch 1/4: Optimizer step...
  Epoch 398, Batch 1/4: Completed in 0.19s
  Epoch 398, Batch 2/4: Loading data to device...
  Epoch 398, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 398, Batch 2/4: Zeroing gradients...
  Epoch 398, Batch 2/4: Forward pass...
  Epoch 398, Batch 2/4: Calculating loss...
  Epoch 398, Batch 2/4: Backward pass...
  Epoch 398, Batch 2/4: Clipping gradients...
  Epoch 398, Batch 2/4: Optimizer step...
  Epoch 398, Batch 2/4: Completed in 0.19s
  Epoch 398, Batch 3/4: Loading data to device...
  Epoch 398, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 398, Batch 3/4: Zeroing gradients...
  Epoch 398, Batch 3/4: Forward pass...
  Epoch 398, Batch 3/4: Calculating loss...
  Epoch 398, Batch 3/4: Backward pass...
  Epoch 398, Batch 3/4: Clipping gradients...
  Epoch 398, Batch 3/4: Optimizer step...
  Epoch 398, Batch 3/4: Completed in 0.19s
  Epoch 398, Batch 4/4: Loading data to device...
  Epoch 398, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 398, Batch 4/4: Zeroing gradients...
  Epoch 398, Batch 4/4: Forward pass...
  Epoch 398, Batch 4/4: Calculating loss...
  Epoch 398, Batch 4/4: Backward pass...
  Epoch 398, Batch 4/4: Clipping gradients...
  Epoch 398, Batch 4/4: Optimizer step...
  Epoch 398, Batch 4/4: Completed in 0.03s
Epoch 398: Training phase completed. Average Train Loss: 0.3183
Epoch 398: Starting validation phase...
  Epoch 398, Val Batch 1/1: Loading data...
  Epoch 398, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 398, Val Batch 1/1: Forward pass...
  Epoch 398, Val Batch 1/1: Calculating loss...
Epoch 398: Validation phase completed. Average Val Loss: 0.2501
Epoch 398 Summary ---> Train Loss: 0.3183 / Validation Loss: 0.2501
Epoch 398: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 3)
  Epoch 398: Validation loss did not improve. Epochs without improvement: 4
Epoch 398: Stepping scheduler...
--- Epoch 398 completed in 0.66 seconds ---

--- Starting Epoch 399/1000 ---
Epoch 399: Starting training phase (4 batches)
  Epoch 399, Batch 1/4: Loading data to device...
  Epoch 399, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 399, Batch 1/4: Zeroing gradients...
  Epoch 399, Batch 1/4: Forward pass...
  Epoch 399, Batch 1/4: Calculating loss...
  Epoch 399, Batch 1/4: Backward pass...
  Epoch 399, Batch 1/4: Clipping gradients...
  Epoch 399, Batch 1/4: Optimizer step...
  Epoch 399, Batch 1/4: Completed in 0.20s
  Epoch 399, Batch 2/4: Loading data to device...
  Epoch 399, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 399, Batch 2/4: Zeroing gradients...
  Epoch 399, Batch 2/4: Forward pass...
  Epoch 399, Batch 2/4: Calculating loss...
  Epoch 399, Batch 2/4: Backward pass...
  Epoch 399, Batch 2/4: Clipping gradients...
  Epoch 399, Batch 2/4: Optimizer step...
  Epoch 399, Batch 2/4: Completed in 0.20s
  Epoch 399, Batch 3/4: Loading data to device...
  Epoch 399, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 399, Batch 3/4: Zeroing gradients...
  Epoch 399, Batch 3/4: Forward pass...
  Epoch 399, Batch 3/4: Calculating loss...
  Epoch 399, Batch 3/4: Backward pass...
  Epoch 399, Batch 3/4: Clipping gradients...
  Epoch 399, Batch 3/4: Optimizer step...
  Epoch 399, Batch 3/4: Completed in 0.20s
  Epoch 399, Batch 4/4: Loading data to device...
  Epoch 399, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 399, Batch 4/4: Zeroing gradients...
  Epoch 399, Batch 4/4: Forward pass...
  Epoch 399, Batch 4/4: Calculating loss...
  Epoch 399, Batch 4/4: Backward pass...
  Epoch 399, Batch 4/4: Clipping gradients...
  Epoch 399, Batch 4/4: Optimizer step...
  Epoch 399, Batch 4/4: Completed in 0.03s
Epoch 399: Training phase completed. Average Train Loss: 0.3009
Epoch 399: Starting validation phase...
  Epoch 399, Val Batch 1/1: Loading data...
  Epoch 399, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 399, Val Batch 1/1: Forward pass...
  Epoch 399, Val Batch 1/1: Calculating loss...
Epoch 399: Validation phase completed. Average Val Loss: 0.2502
Epoch 399 Summary ---> Train Loss: 0.3009 / Validation Loss: 0.2502
Epoch 399: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 4)
  Epoch 399: Validation loss did not improve. Epochs without improvement: 5
Epoch 399: Stepping scheduler...
--- Epoch 399 completed in 0.69 seconds ---

--- Starting Epoch 400/1000 ---
Epoch 400: Starting training phase (4 batches)
  Epoch 400, Batch 1/4: Loading data to device...
  Epoch 400, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 400, Batch 1/4: Zeroing gradients...
  Epoch 400, Batch 1/4: Forward pass...
  Epoch 400, Batch 1/4: Calculating loss...
  Epoch 400, Batch 1/4: Backward pass...
  Epoch 400, Batch 1/4: Clipping gradients...
  Epoch 400, Batch 1/4: Optimizer step...
  Epoch 400, Batch 1/4: Completed in 0.19s
  Epoch 400, Batch 2/4: Loading data to device...
  Epoch 400, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 400, Batch 2/4: Zeroing gradients...
  Epoch 400, Batch 2/4: Forward pass...
  Epoch 400, Batch 2/4: Calculating loss...
  Epoch 400, Batch 2/4: Backward pass...
  Epoch 400, Batch 2/4: Clipping gradients...
  Epoch 400, Batch 2/4: Optimizer step...
  Epoch 400, Batch 2/4: Completed in 0.19s
  Epoch 400, Batch 3/4: Loading data to device...
  Epoch 400, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 400, Batch 3/4: Zeroing gradients...
  Epoch 400, Batch 3/4: Forward pass...
  Epoch 400, Batch 3/4: Calculating loss...
  Epoch 400, Batch 3/4: Backward pass...
  Epoch 400, Batch 3/4: Clipping gradients...
  Epoch 400, Batch 3/4: Optimizer step...
  Epoch 400, Batch 3/4: Completed in 0.19s
  Epoch 400, Batch 4/4: Loading data to device...
  Epoch 400, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 400, Batch 4/4: Zeroing gradients...
  Epoch 400, Batch 4/4: Forward pass...
  Epoch 400, Batch 4/4: Calculating loss...
  Epoch 400, Batch 4/4: Backward pass...
  Epoch 400, Batch 4/4: Clipping gradients...
  Epoch 400, Batch 4/4: Optimizer step...
  Epoch 400, Batch 4/4: Completed in 0.03s
Epoch 400: Training phase completed. Average Train Loss: 0.3313
Epoch 400: Starting validation phase...
  Epoch 400, Val Batch 1/1: Loading data...
  Epoch 400, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 400, Val Batch 1/1: Forward pass...
  Epoch 400, Val Batch 1/1: Calculating loss...
Epoch 400: Validation phase completed. Average Val Loss: 0.2494
Epoch 400 Summary ---> Train Loss: 0.3313 / Validation Loss: 0.2494
Epoch 400: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 5)
  Epoch 400: Validation loss did not improve. Epochs without improvement: 6
Epoch 400: Stepping scheduler...
--- Epoch 400 completed in 0.68 seconds ---

--- Starting Epoch 401/1000 ---
Epoch 401: Starting training phase (4 batches)
  Epoch 401, Batch 1/4: Loading data to device...
  Epoch 401, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 401, Batch 1/4: Zeroing gradients...
  Epoch 401, Batch 1/4: Forward pass...
  Epoch 401, Batch 1/4: Calculating loss...
  Epoch 401, Batch 1/4: Backward pass...
  Epoch 401, Batch 1/4: Clipping gradients...
  Epoch 401, Batch 1/4: Optimizer step...
  Epoch 401, Batch 1/4: Completed in 0.19s
  Epoch 401, Batch 2/4: Loading data to device...
  Epoch 401, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 401, Batch 2/4: Zeroing gradients...
  Epoch 401, Batch 2/4: Forward pass...
  Epoch 401, Batch 2/4: Calculating loss...
  Epoch 401, Batch 2/4: Backward pass...
  Epoch 401, Batch 2/4: Clipping gradients...
  Epoch 401, Batch 2/4: Optimizer step...
  Epoch 401, Batch 2/4: Completed in 0.19s
  Epoch 401, Batch 3/4: Loading data to device...
  Epoch 401, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 401, Batch 3/4: Zeroing gradients...
  Epoch 401, Batch 3/4: Forward pass...
  Epoch 401, Batch 3/4: Calculating loss...
  Epoch 401, Batch 3/4: Backward pass...
  Epoch 401, Batch 3/4: Clipping gradients...
  Epoch 401, Batch 3/4: Optimizer step...
  Epoch 401, Batch 3/4: Completed in 0.19s
  Epoch 401, Batch 4/4: Loading data to device...
  Epoch 401, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 401, Batch 4/4: Zeroing gradients...
  Epoch 401, Batch 4/4: Forward pass...
  Epoch 401, Batch 4/4: Calculating loss...
  Epoch 401, Batch 4/4: Backward pass...
  Epoch 401, Batch 4/4: Clipping gradients...
  Epoch 401, Batch 4/4: Optimizer step...
  Epoch 401, Batch 4/4: Completed in 0.03s
Epoch 401: Training phase completed. Average Train Loss: 0.3359
Epoch 401: Starting validation phase...
  Epoch 401, Val Batch 1/1: Loading data...
  Epoch 401, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 401, Val Batch 1/1: Forward pass...
  Epoch 401, Val Batch 1/1: Calculating loss...
Epoch 401: Validation phase completed. Average Val Loss: 0.2453
Epoch 401 Summary ---> Train Loss: 0.3359 / Validation Loss: 0.2453
Epoch 401: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 6)
  Epoch 401: Validation loss did not improve. Epochs without improvement: 7
Epoch 401: Stepping scheduler...
--- Epoch 401 completed in 0.66 seconds ---

--- Starting Epoch 402/1000 ---
Epoch 402: Starting training phase (4 batches)
  Epoch 402, Batch 1/4: Loading data to device...
  Epoch 402, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 402, Batch 1/4: Zeroing gradients...
  Epoch 402, Batch 1/4: Forward pass...
  Epoch 402, Batch 1/4: Calculating loss...
  Epoch 402, Batch 1/4: Backward pass...
  Epoch 402, Batch 1/4: Clipping gradients...
  Epoch 402, Batch 1/4: Optimizer step...
  Epoch 402, Batch 1/4: Completed in 0.20s
  Epoch 402, Batch 2/4: Loading data to device...
  Epoch 402, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 402, Batch 2/4: Zeroing gradients...
  Epoch 402, Batch 2/4: Forward pass...
  Epoch 402, Batch 2/4: Calculating loss...
  Epoch 402, Batch 2/4: Backward pass...
  Epoch 402, Batch 2/4: Clipping gradients...
  Epoch 402, Batch 2/4: Optimizer step...
  Epoch 402, Batch 2/4: Completed in 0.20s
  Epoch 402, Batch 3/4: Loading data to device...
  Epoch 402, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 402, Batch 3/4: Zeroing gradients...
  Epoch 402, Batch 3/4: Forward pass...
  Epoch 402, Batch 3/4: Calculating loss...
  Epoch 402, Batch 3/4: Backward pass...
  Epoch 402, Batch 3/4: Clipping gradients...
  Epoch 402, Batch 3/4: Optimizer step...
  Epoch 402, Batch 3/4: Completed in 0.20s
  Epoch 402, Batch 4/4: Loading data to device...
  Epoch 402, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 402, Batch 4/4: Zeroing gradients...
  Epoch 402, Batch 4/4: Forward pass...
  Epoch 402, Batch 4/4: Calculating loss...
  Epoch 402, Batch 4/4: Backward pass...
  Epoch 402, Batch 4/4: Clipping gradients...
  Epoch 402, Batch 4/4: Optimizer step...
  Epoch 402, Batch 4/4: Completed in 0.03s
Epoch 402: Training phase completed. Average Train Loss: 0.3180
Epoch 402: Starting validation phase...
  Epoch 402, Val Batch 1/1: Loading data...
  Epoch 402, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 402, Val Batch 1/1: Forward pass...
  Epoch 402, Val Batch 1/1: Calculating loss...
Epoch 402: Validation phase completed. Average Val Loss: 0.2453
Epoch 402 Summary ---> Train Loss: 0.3180 / Validation Loss: 0.2453
Epoch 402: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 7)
  Epoch 402: Validation loss did not improve. Epochs without improvement: 8
Epoch 402: Stepping scheduler...
--- Epoch 402 completed in 0.69 seconds ---

--- Starting Epoch 403/1000 ---
Epoch 403: Starting training phase (4 batches)
  Epoch 403, Batch 1/4: Loading data to device...
  Epoch 403, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 403, Batch 1/4: Zeroing gradients...
  Epoch 403, Batch 1/4: Forward pass...
  Epoch 403, Batch 1/4: Calculating loss...
  Epoch 403, Batch 1/4: Backward pass...
  Epoch 403, Batch 1/4: Clipping gradients...
  Epoch 403, Batch 1/4: Optimizer step...
  Epoch 403, Batch 1/4: Completed in 0.19s
  Epoch 403, Batch 2/4: Loading data to device...
  Epoch 403, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 403, Batch 2/4: Zeroing gradients...
  Epoch 403, Batch 2/4: Forward pass...
  Epoch 403, Batch 2/4: Calculating loss...
  Epoch 403, Batch 2/4: Backward pass...
  Epoch 403, Batch 2/4: Clipping gradients...
  Epoch 403, Batch 2/4: Optimizer step...
  Epoch 403, Batch 2/4: Completed in 0.19s
  Epoch 403, Batch 3/4: Loading data to device...
  Epoch 403, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 403, Batch 3/4: Zeroing gradients...
  Epoch 403, Batch 3/4: Forward pass...
  Epoch 403, Batch 3/4: Calculating loss...
  Epoch 403, Batch 3/4: Backward pass...
  Epoch 403, Batch 3/4: Clipping gradients...
  Epoch 403, Batch 3/4: Optimizer step...
  Epoch 403, Batch 3/4: Completed in 0.19s
  Epoch 403, Batch 4/4: Loading data to device...
  Epoch 403, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 403, Batch 4/4: Zeroing gradients...
  Epoch 403, Batch 4/4: Forward pass...
  Epoch 403, Batch 4/4: Calculating loss...
  Epoch 403, Batch 4/4: Backward pass...
  Epoch 403, Batch 4/4: Clipping gradients...
  Epoch 403, Batch 4/4: Optimizer step...
  Epoch 403, Batch 4/4: Completed in 0.03s
Epoch 403: Training phase completed. Average Train Loss: 0.3177
Epoch 403: Starting validation phase...
  Epoch 403, Val Batch 1/1: Loading data...
  Epoch 403, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 403, Val Batch 1/1: Forward pass...
  Epoch 403, Val Batch 1/1: Calculating loss...
Epoch 403: Validation phase completed. Average Val Loss: 0.2457
Epoch 403 Summary ---> Train Loss: 0.3177 / Validation Loss: 0.2457
Epoch 403: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 8)
  Epoch 403: Validation loss did not improve. Epochs without improvement: 9
Epoch 403: Stepping scheduler...
--- Epoch 403 completed in 0.67 seconds ---

--- Starting Epoch 404/1000 ---
Epoch 404: Starting training phase (4 batches)
  Epoch 404, Batch 1/4: Loading data to device...
  Epoch 404, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 404, Batch 1/4: Zeroing gradients...
  Epoch 404, Batch 1/4: Forward pass...
  Epoch 404, Batch 1/4: Calculating loss...
  Epoch 404, Batch 1/4: Backward pass...
  Epoch 404, Batch 1/4: Clipping gradients...
  Epoch 404, Batch 1/4: Optimizer step...
  Epoch 404, Batch 1/4: Completed in 0.20s
  Epoch 404, Batch 2/4: Loading data to device...
  Epoch 404, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 404, Batch 2/4: Zeroing gradients...
  Epoch 404, Batch 2/4: Forward pass...
  Epoch 404, Batch 2/4: Calculating loss...
  Epoch 404, Batch 2/4: Backward pass...
  Epoch 404, Batch 2/4: Clipping gradients...
  Epoch 404, Batch 2/4: Optimizer step...
  Epoch 404, Batch 2/4: Completed in 0.19s
  Epoch 404, Batch 3/4: Loading data to device...
  Epoch 404, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 404, Batch 3/4: Zeroing gradients...
  Epoch 404, Batch 3/4: Forward pass...
  Epoch 404, Batch 3/4: Calculating loss...
  Epoch 404, Batch 3/4: Backward pass...
  Epoch 404, Batch 3/4: Clipping gradients...
  Epoch 404, Batch 3/4: Optimizer step...
  Epoch 404, Batch 3/4: Completed in 0.19s
  Epoch 404, Batch 4/4: Loading data to device...
  Epoch 404, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 404, Batch 4/4: Zeroing gradients...
  Epoch 404, Batch 4/4: Forward pass...
  Epoch 404, Batch 4/4: Calculating loss...
  Epoch 404, Batch 4/4: Backward pass...
  Epoch 404, Batch 4/4: Clipping gradients...
  Epoch 404, Batch 4/4: Optimizer step...
  Epoch 404, Batch 4/4: Completed in 0.03s
Epoch 404: Training phase completed. Average Train Loss: 0.3074
Epoch 404: Starting validation phase...
  Epoch 404, Val Batch 1/1: Loading data...
  Epoch 404, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 404, Val Batch 1/1: Forward pass...
  Epoch 404, Val Batch 1/1: Calculating loss...
Epoch 404: Validation phase completed. Average Val Loss: 0.2455
Epoch 404 Summary ---> Train Loss: 0.3074 / Validation Loss: 0.2455
Epoch 404: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 9)
  Epoch 404: Validation loss did not improve. Epochs without improvement: 10
Epoch 404: Stepping scheduler...
--- Epoch 404 completed in 0.68 seconds ---

--- Starting Epoch 405/1000 ---
Epoch 405: Starting training phase (4 batches)
  Epoch 405, Batch 1/4: Loading data to device...
  Epoch 405, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 405, Batch 1/4: Zeroing gradients...
  Epoch 405, Batch 1/4: Forward pass...
  Epoch 405, Batch 1/4: Calculating loss...
  Epoch 405, Batch 1/4: Backward pass...
  Epoch 405, Batch 1/4: Clipping gradients...
  Epoch 405, Batch 1/4: Optimizer step...
  Epoch 405, Batch 1/4: Completed in 0.20s
  Epoch 405, Batch 2/4: Loading data to device...
  Epoch 405, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 405, Batch 2/4: Zeroing gradients...
  Epoch 405, Batch 2/4: Forward pass...
  Epoch 405, Batch 2/4: Calculating loss...
  Epoch 405, Batch 2/4: Backward pass...
  Epoch 405, Batch 2/4: Clipping gradients...
  Epoch 405, Batch 2/4: Optimizer step...
  Epoch 405, Batch 2/4: Completed in 0.19s
  Epoch 405, Batch 3/4: Loading data to device...
  Epoch 405, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 405, Batch 3/4: Zeroing gradients...
  Epoch 405, Batch 3/4: Forward pass...
  Epoch 405, Batch 3/4: Calculating loss...
  Epoch 405, Batch 3/4: Backward pass...
  Epoch 405, Batch 3/4: Clipping gradients...
  Epoch 405, Batch 3/4: Optimizer step...
  Epoch 405, Batch 3/4: Completed in 0.19s
  Epoch 405, Batch 4/4: Loading data to device...
  Epoch 405, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 405, Batch 4/4: Zeroing gradients...
  Epoch 405, Batch 4/4: Forward pass...
  Epoch 405, Batch 4/4: Calculating loss...
  Epoch 405, Batch 4/4: Backward pass...
  Epoch 405, Batch 4/4: Clipping gradients...
  Epoch 405, Batch 4/4: Optimizer step...
  Epoch 405, Batch 4/4: Completed in 0.03s
Epoch 405: Training phase completed. Average Train Loss: 0.2953
Epoch 405: Starting validation phase...
  Epoch 405, Val Batch 1/1: Loading data...
  Epoch 405, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 405, Val Batch 1/1: Forward pass...
  Epoch 405, Val Batch 1/1: Calculating loss...
Epoch 405: Validation phase completed. Average Val Loss: 0.2469
Epoch 405 Summary ---> Train Loss: 0.2953 / Validation Loss: 0.2469
Epoch 405: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 10)
  Epoch 405: Validation loss did not improve. Epochs without improvement: 11
Epoch 405: Stepping scheduler...
--- Epoch 405 completed in 0.68 seconds ---

--- Starting Epoch 406/1000 ---
Epoch 406: Starting training phase (4 batches)
  Epoch 406, Batch 1/4: Loading data to device...
  Epoch 406, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 406, Batch 1/4: Zeroing gradients...
  Epoch 406, Batch 1/4: Forward pass...
  Epoch 406, Batch 1/4: Calculating loss...
  Epoch 406, Batch 1/4: Backward pass...
  Epoch 406, Batch 1/4: Clipping gradients...
  Epoch 406, Batch 1/4: Optimizer step...
  Epoch 406, Batch 1/4: Completed in 0.19s
  Epoch 406, Batch 2/4: Loading data to device...
  Epoch 406, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 406, Batch 2/4: Zeroing gradients...
  Epoch 406, Batch 2/4: Forward pass...
  Epoch 406, Batch 2/4: Calculating loss...
  Epoch 406, Batch 2/4: Backward pass...
  Epoch 406, Batch 2/4: Clipping gradients...
  Epoch 406, Batch 2/4: Optimizer step...
  Epoch 406, Batch 2/4: Completed in 0.19s
  Epoch 406, Batch 3/4: Loading data to device...
  Epoch 406, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 406, Batch 3/4: Zeroing gradients...
  Epoch 406, Batch 3/4: Forward pass...
  Epoch 406, Batch 3/4: Calculating loss...
  Epoch 406, Batch 3/4: Backward pass...
  Epoch 406, Batch 3/4: Clipping gradients...
  Epoch 406, Batch 3/4: Optimizer step...
  Epoch 406, Batch 3/4: Completed in 0.20s
  Epoch 406, Batch 4/4: Loading data to device...
  Epoch 406, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 406, Batch 4/4: Zeroing gradients...
  Epoch 406, Batch 4/4: Forward pass...
  Epoch 406, Batch 4/4: Calculating loss...
  Epoch 406, Batch 4/4: Backward pass...
  Epoch 406, Batch 4/4: Clipping gradients...
  Epoch 406, Batch 4/4: Optimizer step...
  Epoch 406, Batch 4/4: Completed in 0.03s
Epoch 406: Training phase completed. Average Train Loss: 0.2983
Epoch 406: Starting validation phase...
  Epoch 406, Val Batch 1/1: Loading data...
  Epoch 406, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 406, Val Batch 1/1: Forward pass...
  Epoch 406, Val Batch 1/1: Calculating loss...
Epoch 406: Validation phase completed. Average Val Loss: 0.2457
Epoch 406 Summary ---> Train Loss: 0.2983 / Validation Loss: 0.2457
Epoch 406: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 11)
  Epoch 406: Validation loss did not improve. Epochs without improvement: 12
Epoch 406: Stepping scheduler...
--- Epoch 406 completed in 0.68 seconds ---

--- Starting Epoch 407/1000 ---
Epoch 407: Starting training phase (4 batches)
  Epoch 407, Batch 1/4: Loading data to device...
  Epoch 407, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 407, Batch 1/4: Zeroing gradients...
  Epoch 407, Batch 1/4: Forward pass...
  Epoch 407, Batch 1/4: Calculating loss...
  Epoch 407, Batch 1/4: Backward pass...
  Epoch 407, Batch 1/4: Clipping gradients...
  Epoch 407, Batch 1/4: Optimizer step...
  Epoch 407, Batch 1/4: Completed in 0.19s
  Epoch 407, Batch 2/4: Loading data to device...
  Epoch 407, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 407, Batch 2/4: Zeroing gradients...
  Epoch 407, Batch 2/4: Forward pass...
  Epoch 407, Batch 2/4: Calculating loss...
  Epoch 407, Batch 2/4: Backward pass...
  Epoch 407, Batch 2/4: Clipping gradients...
  Epoch 407, Batch 2/4: Optimizer step...
  Epoch 407, Batch 2/4: Completed in 0.19s
  Epoch 407, Batch 3/4: Loading data to device...
  Epoch 407, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 407, Batch 3/4: Zeroing gradients...
  Epoch 407, Batch 3/4: Forward pass...
  Epoch 407, Batch 3/4: Calculating loss...
  Epoch 407, Batch 3/4: Backward pass...
  Epoch 407, Batch 3/4: Clipping gradients...
  Epoch 407, Batch 3/4: Optimizer step...
  Epoch 407, Batch 3/4: Completed in 0.19s
  Epoch 407, Batch 4/4: Loading data to device...
  Epoch 407, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 407, Batch 4/4: Zeroing gradients...
  Epoch 407, Batch 4/4: Forward pass...
  Epoch 407, Batch 4/4: Calculating loss...
  Epoch 407, Batch 4/4: Backward pass...
  Epoch 407, Batch 4/4: Clipping gradients...
  Epoch 407, Batch 4/4: Optimizer step...
  Epoch 407, Batch 4/4: Completed in 0.03s
Epoch 407: Training phase completed. Average Train Loss: 0.3038
Epoch 407: Starting validation phase...
  Epoch 407, Val Batch 1/1: Loading data...
  Epoch 407, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 407, Val Batch 1/1: Forward pass...
  Epoch 407, Val Batch 1/1: Calculating loss...
Epoch 407: Validation phase completed. Average Val Loss: 0.2464
Epoch 407 Summary ---> Train Loss: 0.3038 / Validation Loss: 0.2464
Epoch 407: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 12)
  Epoch 407: Validation loss did not improve. Epochs without improvement: 13
Epoch 407: Stepping scheduler...
--- Epoch 407 completed in 0.68 seconds ---

--- Starting Epoch 408/1000 ---
Epoch 408: Starting training phase (4 batches)
  Epoch 408, Batch 1/4: Loading data to device...
  Epoch 408, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 408, Batch 1/4: Zeroing gradients...
  Epoch 408, Batch 1/4: Forward pass...
  Epoch 408, Batch 1/4: Calculating loss...
  Epoch 408, Batch 1/4: Backward pass...
  Epoch 408, Batch 1/4: Clipping gradients...
  Epoch 408, Batch 1/4: Optimizer step...
  Epoch 408, Batch 1/4: Completed in 0.20s
  Epoch 408, Batch 2/4: Loading data to device...
  Epoch 408, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 408, Batch 2/4: Zeroing gradients...
  Epoch 408, Batch 2/4: Forward pass...
  Epoch 408, Batch 2/4: Calculating loss...
  Epoch 408, Batch 2/4: Backward pass...
  Epoch 408, Batch 2/4: Clipping gradients...
  Epoch 408, Batch 2/4: Optimizer step...
  Epoch 408, Batch 2/4: Completed in 0.20s
  Epoch 408, Batch 3/4: Loading data to device...
  Epoch 408, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 408, Batch 3/4: Zeroing gradients...
  Epoch 408, Batch 3/4: Forward pass...
  Epoch 408, Batch 3/4: Calculating loss...
  Epoch 408, Batch 3/4: Backward pass...
  Epoch 408, Batch 3/4: Clipping gradients...
  Epoch 408, Batch 3/4: Optimizer step...
  Epoch 408, Batch 3/4: Completed in 0.20s
  Epoch 408, Batch 4/4: Loading data to device...
  Epoch 408, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 408, Batch 4/4: Zeroing gradients...
  Epoch 408, Batch 4/4: Forward pass...
  Epoch 408, Batch 4/4: Calculating loss...
  Epoch 408, Batch 4/4: Backward pass...
  Epoch 408, Batch 4/4: Clipping gradients...
  Epoch 408, Batch 4/4: Optimizer step...
  Epoch 408, Batch 4/4: Completed in 0.03s
Epoch 408: Training phase completed. Average Train Loss: 0.2862
Epoch 408: Starting validation phase...
  Epoch 408, Val Batch 1/1: Loading data...
  Epoch 408, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 408, Val Batch 1/1: Forward pass...
  Epoch 408, Val Batch 1/1: Calculating loss...
Epoch 408: Validation phase completed. Average Val Loss: 0.2443
Epoch 408 Summary ---> Train Loss: 0.2862 / Validation Loss: 0.2443
Epoch 408: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 13)
  Epoch 408: Validation loss did not improve. Epochs without improvement: 14
Epoch 408: Stepping scheduler...
--- Epoch 408 completed in 0.69 seconds ---

--- Starting Epoch 409/1000 ---
Epoch 409: Starting training phase (4 batches)
  Epoch 409, Batch 1/4: Loading data to device...
  Epoch 409, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 409, Batch 1/4: Zeroing gradients...
  Epoch 409, Batch 1/4: Forward pass...
  Epoch 409, Batch 1/4: Calculating loss...
  Epoch 409, Batch 1/4: Backward pass...
  Epoch 409, Batch 1/4: Clipping gradients...
  Epoch 409, Batch 1/4: Optimizer step...
  Epoch 409, Batch 1/4: Completed in 0.19s
  Epoch 409, Batch 2/4: Loading data to device...
  Epoch 409, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 409, Batch 2/4: Zeroing gradients...
  Epoch 409, Batch 2/4: Forward pass...
  Epoch 409, Batch 2/4: Calculating loss...
  Epoch 409, Batch 2/4: Backward pass...
  Epoch 409, Batch 2/4: Clipping gradients...
  Epoch 409, Batch 2/4: Optimizer step...
  Epoch 409, Batch 2/4: Completed in 0.19s
  Epoch 409, Batch 3/4: Loading data to device...
  Epoch 409, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 409, Batch 3/4: Zeroing gradients...
  Epoch 409, Batch 3/4: Forward pass...
  Epoch 409, Batch 3/4: Calculating loss...
  Epoch 409, Batch 3/4: Backward pass...
  Epoch 409, Batch 3/4: Clipping gradients...
  Epoch 409, Batch 3/4: Optimizer step...
  Epoch 409, Batch 3/4: Completed in 0.19s
  Epoch 409, Batch 4/4: Loading data to device...
  Epoch 409, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 409, Batch 4/4: Zeroing gradients...
  Epoch 409, Batch 4/4: Forward pass...
  Epoch 409, Batch 4/4: Calculating loss...
  Epoch 409, Batch 4/4: Backward pass...
  Epoch 409, Batch 4/4: Clipping gradients...
  Epoch 409, Batch 4/4: Optimizer step...
  Epoch 409, Batch 4/4: Completed in 0.03s
Epoch 409: Training phase completed. Average Train Loss: 0.2938
Epoch 409: Starting validation phase...
  Epoch 409, Val Batch 1/1: Loading data...
  Epoch 409, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 409, Val Batch 1/1: Forward pass...
  Epoch 409, Val Batch 1/1: Calculating loss...
Epoch 409: Validation phase completed. Average Val Loss: 0.2473
Epoch 409 Summary ---> Train Loss: 0.2938 / Validation Loss: 0.2473
Epoch 409: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 14)
  Epoch 409: Validation loss did not improve. Epochs without improvement: 15
Epoch 409: Stepping scheduler...
--- Epoch 409 completed in 0.67 seconds ---

--- Starting Epoch 410/1000 ---
Epoch 410: Starting training phase (4 batches)
  Epoch 410, Batch 1/4: Loading data to device...
  Epoch 410, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 410, Batch 1/4: Zeroing gradients...
  Epoch 410, Batch 1/4: Forward pass...
  Epoch 410, Batch 1/4: Calculating loss...
  Epoch 410, Batch 1/4: Backward pass...
  Epoch 410, Batch 1/4: Clipping gradients...
  Epoch 410, Batch 1/4: Optimizer step...
  Epoch 410, Batch 1/4: Completed in 0.19s
  Epoch 410, Batch 2/4: Loading data to device...
  Epoch 410, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 410, Batch 2/4: Zeroing gradients...
  Epoch 410, Batch 2/4: Forward pass...
  Epoch 410, Batch 2/4: Calculating loss...
  Epoch 410, Batch 2/4: Backward pass...
  Epoch 410, Batch 2/4: Clipping gradients...
  Epoch 410, Batch 2/4: Optimizer step...
  Epoch 410, Batch 2/4: Completed in 0.19s
  Epoch 410, Batch 3/4: Loading data to device...
  Epoch 410, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 410, Batch 3/4: Zeroing gradients...
  Epoch 410, Batch 3/4: Forward pass...
  Epoch 410, Batch 3/4: Calculating loss...
  Epoch 410, Batch 3/4: Backward pass...
  Epoch 410, Batch 3/4: Clipping gradients...
  Epoch 410, Batch 3/4: Optimizer step...
  Epoch 410, Batch 3/4: Completed in 0.18s
  Epoch 410, Batch 4/4: Loading data to device...
  Epoch 410, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 410, Batch 4/4: Zeroing gradients...
  Epoch 410, Batch 4/4: Forward pass...
  Epoch 410, Batch 4/4: Calculating loss...
  Epoch 410, Batch 4/4: Backward pass...
  Epoch 410, Batch 4/4: Clipping gradients...
  Epoch 410, Batch 4/4: Optimizer step...
  Epoch 410, Batch 4/4: Completed in 0.04s
Epoch 410: Training phase completed. Average Train Loss: 0.2833
Epoch 410: Starting validation phase...
  Epoch 410, Val Batch 1/1: Loading data...
  Epoch 410, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 410, Val Batch 1/1: Forward pass...
  Epoch 410, Val Batch 1/1: Calculating loss...
Epoch 410: Validation phase completed. Average Val Loss: 0.2513
Epoch 410 Summary ---> Train Loss: 0.2833 / Validation Loss: 0.2513
Epoch 410: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 15)
  Epoch 410: Validation loss did not improve. Epochs without improvement: 16
Epoch 410: Stepping scheduler...
--- Epoch 410 completed in 0.67 seconds ---

--- Starting Epoch 411/1000 ---
Epoch 411: Starting training phase (4 batches)
  Epoch 411, Batch 1/4: Loading data to device...
  Epoch 411, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 411, Batch 1/4: Zeroing gradients...
  Epoch 411, Batch 1/4: Forward pass...
  Epoch 411, Batch 1/4: Calculating loss...
  Epoch 411, Batch 1/4: Backward pass...
  Epoch 411, Batch 1/4: Clipping gradients...
  Epoch 411, Batch 1/4: Optimizer step...
  Epoch 411, Batch 1/4: Completed in 0.19s
  Epoch 411, Batch 2/4: Loading data to device...
  Epoch 411, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 411, Batch 2/4: Zeroing gradients...
  Epoch 411, Batch 2/4: Forward pass...
  Epoch 411, Batch 2/4: Calculating loss...
  Epoch 411, Batch 2/4: Backward pass...
  Epoch 411, Batch 2/4: Clipping gradients...
  Epoch 411, Batch 2/4: Optimizer step...
  Epoch 411, Batch 2/4: Completed in 0.19s
  Epoch 411, Batch 3/4: Loading data to device...
  Epoch 411, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 411, Batch 3/4: Zeroing gradients...
  Epoch 411, Batch 3/4: Forward pass...
  Epoch 411, Batch 3/4: Calculating loss...
  Epoch 411, Batch 3/4: Backward pass...
  Epoch 411, Batch 3/4: Clipping gradients...
  Epoch 411, Batch 3/4: Optimizer step...
  Epoch 411, Batch 3/4: Completed in 0.19s
  Epoch 411, Batch 4/4: Loading data to device...
  Epoch 411, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 411, Batch 4/4: Zeroing gradients...
  Epoch 411, Batch 4/4: Forward pass...
  Epoch 411, Batch 4/4: Calculating loss...
  Epoch 411, Batch 4/4: Backward pass...
  Epoch 411, Batch 4/4: Clipping gradients...
  Epoch 411, Batch 4/4: Optimizer step...
  Epoch 411, Batch 4/4: Completed in 0.03s
Epoch 411: Training phase completed. Average Train Loss: 0.3008
Epoch 411: Starting validation phase...
  Epoch 411, Val Batch 1/1: Loading data...
  Epoch 411, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 411, Val Batch 1/1: Forward pass...
  Epoch 411, Val Batch 1/1: Calculating loss...
Epoch 411: Validation phase completed. Average Val Loss: 0.2523
Epoch 411 Summary ---> Train Loss: 0.3008 / Validation Loss: 0.2523
Epoch 411: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 16)
  Epoch 411: Validation loss did not improve. Epochs without improvement: 17
Epoch 411: Stepping scheduler...
--- Epoch 411 completed in 0.67 seconds ---

--- Starting Epoch 412/1000 ---
Epoch 412: Starting training phase (4 batches)
  Epoch 412, Batch 1/4: Loading data to device...
  Epoch 412, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 412, Batch 1/4: Zeroing gradients...
  Epoch 412, Batch 1/4: Forward pass...
  Epoch 412, Batch 1/4: Calculating loss...
  Epoch 412, Batch 1/4: Backward pass...
  Epoch 412, Batch 1/4: Clipping gradients...
  Epoch 412, Batch 1/4: Optimizer step...
  Epoch 412, Batch 1/4: Completed in 0.19s
  Epoch 412, Batch 2/4: Loading data to device...
  Epoch 412, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 412, Batch 2/4: Zeroing gradients...
  Epoch 412, Batch 2/4: Forward pass...
  Epoch 412, Batch 2/4: Calculating loss...
  Epoch 412, Batch 2/4: Backward pass...
  Epoch 412, Batch 2/4: Clipping gradients...
  Epoch 412, Batch 2/4: Optimizer step...
  Epoch 412, Batch 2/4: Completed in 0.20s
  Epoch 412, Batch 3/4: Loading data to device...
  Epoch 412, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 412, Batch 3/4: Zeroing gradients...
  Epoch 412, Batch 3/4: Forward pass...
  Epoch 412, Batch 3/4: Calculating loss...
  Epoch 412, Batch 3/4: Backward pass...
  Epoch 412, Batch 3/4: Clipping gradients...
  Epoch 412, Batch 3/4: Optimizer step...
  Epoch 412, Batch 3/4: Completed in 0.20s
  Epoch 412, Batch 4/4: Loading data to device...
  Epoch 412, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 412, Batch 4/4: Zeroing gradients...
  Epoch 412, Batch 4/4: Forward pass...
  Epoch 412, Batch 4/4: Calculating loss...
  Epoch 412, Batch 4/4: Backward pass...
  Epoch 412, Batch 4/4: Clipping gradients...
  Epoch 412, Batch 4/4: Optimizer step...
  Epoch 412, Batch 4/4: Completed in 0.03s
Epoch 412: Training phase completed. Average Train Loss: 0.3052
Epoch 412: Starting validation phase...
  Epoch 412, Val Batch 1/1: Loading data...
  Epoch 412, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 412, Val Batch 1/1: Forward pass...
  Epoch 412, Val Batch 1/1: Calculating loss...
Epoch 412: Validation phase completed. Average Val Loss: 0.2454
Epoch 412 Summary ---> Train Loss: 0.3052 / Validation Loss: 0.2454
Epoch 412: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 17)
  Epoch 412: Validation loss did not improve. Epochs without improvement: 18
Epoch 412: Stepping scheduler...
--- Epoch 412 completed in 0.68 seconds ---

--- Starting Epoch 413/1000 ---
Epoch 413: Starting training phase (4 batches)
  Epoch 413, Batch 1/4: Loading data to device...
  Epoch 413, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 413, Batch 1/4: Zeroing gradients...
  Epoch 413, Batch 1/4: Forward pass...
  Epoch 413, Batch 1/4: Calculating loss...
  Epoch 413, Batch 1/4: Backward pass...
  Epoch 413, Batch 1/4: Clipping gradients...
  Epoch 413, Batch 1/4: Optimizer step...
  Epoch 413, Batch 1/4: Completed in 0.20s
  Epoch 413, Batch 2/4: Loading data to device...
  Epoch 413, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 413, Batch 2/4: Zeroing gradients...
  Epoch 413, Batch 2/4: Forward pass...
  Epoch 413, Batch 2/4: Calculating loss...
  Epoch 413, Batch 2/4: Backward pass...
  Epoch 413, Batch 2/4: Clipping gradients...
  Epoch 413, Batch 2/4: Optimizer step...
  Epoch 413, Batch 2/4: Completed in 0.19s
  Epoch 413, Batch 3/4: Loading data to device...
  Epoch 413, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 413, Batch 3/4: Zeroing gradients...
  Epoch 413, Batch 3/4: Forward pass...
  Epoch 413, Batch 3/4: Calculating loss...
  Epoch 413, Batch 3/4: Backward pass...
  Epoch 413, Batch 3/4: Clipping gradients...
  Epoch 413, Batch 3/4: Optimizer step...
  Epoch 413, Batch 3/4: Completed in 0.19s
  Epoch 413, Batch 4/4: Loading data to device...
  Epoch 413, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 413, Batch 4/4: Zeroing gradients...
  Epoch 413, Batch 4/4: Forward pass...
  Epoch 413, Batch 4/4: Calculating loss...
  Epoch 413, Batch 4/4: Backward pass...
  Epoch 413, Batch 4/4: Clipping gradients...
  Epoch 413, Batch 4/4: Optimizer step...
  Epoch 413, Batch 4/4: Completed in 0.03s
Epoch 413: Training phase completed. Average Train Loss: 0.3261
Epoch 413: Starting validation phase...
  Epoch 413, Val Batch 1/1: Loading data...
  Epoch 413, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 413, Val Batch 1/1: Forward pass...
  Epoch 413, Val Batch 1/1: Calculating loss...
Epoch 413: Validation phase completed. Average Val Loss: 0.2475
Epoch 413 Summary ---> Train Loss: 0.3261 / Validation Loss: 0.2475
Epoch 413: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 18)
  Epoch 413: Validation loss did not improve. Epochs without improvement: 19
Epoch 413: Stepping scheduler...
--- Epoch 413 completed in 0.68 seconds ---

--- Starting Epoch 414/1000 ---
Epoch 414: Starting training phase (4 batches)
  Epoch 414, Batch 1/4: Loading data to device...
  Epoch 414, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 414, Batch 1/4: Zeroing gradients...
  Epoch 414, Batch 1/4: Forward pass...
  Epoch 414, Batch 1/4: Calculating loss...
  Epoch 414, Batch 1/4: Backward pass...
  Epoch 414, Batch 1/4: Clipping gradients...
  Epoch 414, Batch 1/4: Optimizer step...
  Epoch 414, Batch 1/4: Completed in 0.19s
  Epoch 414, Batch 2/4: Loading data to device...
  Epoch 414, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 414, Batch 2/4: Zeroing gradients...
  Epoch 414, Batch 2/4: Forward pass...
  Epoch 414, Batch 2/4: Calculating loss...
  Epoch 414, Batch 2/4: Backward pass...
  Epoch 414, Batch 2/4: Clipping gradients...
  Epoch 414, Batch 2/4: Optimizer step...
  Epoch 414, Batch 2/4: Completed in 0.19s
  Epoch 414, Batch 3/4: Loading data to device...
  Epoch 414, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 414, Batch 3/4: Zeroing gradients...
  Epoch 414, Batch 3/4: Forward pass...
  Epoch 414, Batch 3/4: Calculating loss...
  Epoch 414, Batch 3/4: Backward pass...
  Epoch 414, Batch 3/4: Clipping gradients...
  Epoch 414, Batch 3/4: Optimizer step...
  Epoch 414, Batch 3/4: Completed in 0.20s
  Epoch 414, Batch 4/4: Loading data to device...
  Epoch 414, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 414, Batch 4/4: Zeroing gradients...
  Epoch 414, Batch 4/4: Forward pass...
  Epoch 414, Batch 4/4: Calculating loss...
  Epoch 414, Batch 4/4: Backward pass...
  Epoch 414, Batch 4/4: Clipping gradients...
  Epoch 414, Batch 4/4: Optimizer step...
  Epoch 414, Batch 4/4: Completed in 0.03s
Epoch 414: Training phase completed. Average Train Loss: 0.2977
Epoch 414: Starting validation phase...
  Epoch 414, Val Batch 1/1: Loading data...
  Epoch 414, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 414, Val Batch 1/1: Forward pass...
  Epoch 414, Val Batch 1/1: Calculating loss...
Epoch 414: Validation phase completed. Average Val Loss: 0.2472
Epoch 414 Summary ---> Train Loss: 0.2977 / Validation Loss: 0.2472
Epoch 414: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 19)
  Epoch 414: Validation loss did not improve. Epochs without improvement: 20
Epoch 414: Stepping scheduler...
--- Epoch 414 completed in 0.68 seconds ---

--- Starting Epoch 415/1000 ---
Epoch 415: Starting training phase (4 batches)
  Epoch 415, Batch 1/4: Loading data to device...
  Epoch 415, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 415, Batch 1/4: Zeroing gradients...
  Epoch 415, Batch 1/4: Forward pass...
  Epoch 415, Batch 1/4: Calculating loss...
  Epoch 415, Batch 1/4: Backward pass...
  Epoch 415, Batch 1/4: Clipping gradients...
  Epoch 415, Batch 1/4: Optimizer step...
  Epoch 415, Batch 1/4: Completed in 0.19s
  Epoch 415, Batch 2/4: Loading data to device...
  Epoch 415, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 415, Batch 2/4: Zeroing gradients...
  Epoch 415, Batch 2/4: Forward pass...
  Epoch 415, Batch 2/4: Calculating loss...
  Epoch 415, Batch 2/4: Backward pass...
  Epoch 415, Batch 2/4: Clipping gradients...
  Epoch 415, Batch 2/4: Optimizer step...
  Epoch 415, Batch 2/4: Completed in 0.19s
  Epoch 415, Batch 3/4: Loading data to device...
  Epoch 415, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 415, Batch 3/4: Zeroing gradients...
  Epoch 415, Batch 3/4: Forward pass...
  Epoch 415, Batch 3/4: Calculating loss...
  Epoch 415, Batch 3/4: Backward pass...
  Epoch 415, Batch 3/4: Clipping gradients...
  Epoch 415, Batch 3/4: Optimizer step...
  Epoch 415, Batch 3/4: Completed in 0.19s
  Epoch 415, Batch 4/4: Loading data to device...
  Epoch 415, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 415, Batch 4/4: Zeroing gradients...
  Epoch 415, Batch 4/4: Forward pass...
  Epoch 415, Batch 4/4: Calculating loss...
  Epoch 415, Batch 4/4: Backward pass...
  Epoch 415, Batch 4/4: Clipping gradients...
  Epoch 415, Batch 4/4: Optimizer step...
  Epoch 415, Batch 4/4: Completed in 0.03s
Epoch 415: Training phase completed. Average Train Loss: 0.3758
Epoch 415: Starting validation phase...
  Epoch 415, Val Batch 1/1: Loading data...
  Epoch 415, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 415, Val Batch 1/1: Forward pass...
  Epoch 415, Val Batch 1/1: Calculating loss...
Epoch 415: Validation phase completed. Average Val Loss: 0.2488
Epoch 415 Summary ---> Train Loss: 0.3758 / Validation Loss: 0.2488
Epoch 415: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 20)
  Epoch 415: Validation loss did not improve. Epochs without improvement: 21
Epoch 415: Stepping scheduler...
--- Epoch 415 completed in 0.67 seconds ---

--- Starting Epoch 416/1000 ---
Epoch 416: Starting training phase (4 batches)
  Epoch 416, Batch 1/4: Loading data to device...
  Epoch 416, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 416, Batch 1/4: Zeroing gradients...
  Epoch 416, Batch 1/4: Forward pass...
  Epoch 416, Batch 1/4: Calculating loss...
  Epoch 416, Batch 1/4: Backward pass...
  Epoch 416, Batch 1/4: Clipping gradients...
  Epoch 416, Batch 1/4: Optimizer step...
  Epoch 416, Batch 1/4: Completed in 0.20s
  Epoch 416, Batch 2/4: Loading data to device...
  Epoch 416, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 416, Batch 2/4: Zeroing gradients...
  Epoch 416, Batch 2/4: Forward pass...
  Epoch 416, Batch 2/4: Calculating loss...
  Epoch 416, Batch 2/4: Backward pass...
  Epoch 416, Batch 2/4: Clipping gradients...
  Epoch 416, Batch 2/4: Optimizer step...
  Epoch 416, Batch 2/4: Completed in 0.19s
  Epoch 416, Batch 3/4: Loading data to device...
  Epoch 416, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 416, Batch 3/4: Zeroing gradients...
  Epoch 416, Batch 3/4: Forward pass...
  Epoch 416, Batch 3/4: Calculating loss...
  Epoch 416, Batch 3/4: Backward pass...
  Epoch 416, Batch 3/4: Clipping gradients...
  Epoch 416, Batch 3/4: Optimizer step...
  Epoch 416, Batch 3/4: Completed in 0.20s
  Epoch 416, Batch 4/4: Loading data to device...
  Epoch 416, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 416, Batch 4/4: Zeroing gradients...
  Epoch 416, Batch 4/4: Forward pass...
  Epoch 416, Batch 4/4: Calculating loss...
  Epoch 416, Batch 4/4: Backward pass...
  Epoch 416, Batch 4/4: Clipping gradients...
  Epoch 416, Batch 4/4: Optimizer step...
  Epoch 416, Batch 4/4: Completed in 0.03s
Epoch 416: Training phase completed. Average Train Loss: 0.3554
Epoch 416: Starting validation phase...
  Epoch 416, Val Batch 1/1: Loading data...
  Epoch 416, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 416, Val Batch 1/1: Forward pass...
  Epoch 416, Val Batch 1/1: Calculating loss...
Epoch 416: Validation phase completed. Average Val Loss: 0.2437
Epoch 416 Summary ---> Train Loss: 0.3554 / Validation Loss: 0.2437
Epoch 416: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 21)
  Epoch 416: Validation loss did not improve. Epochs without improvement: 22
Epoch 416: Stepping scheduler...
--- Epoch 416 completed in 0.69 seconds ---

--- Starting Epoch 417/1000 ---
Epoch 417: Starting training phase (4 batches)
  Epoch 417, Batch 1/4: Loading data to device...
  Epoch 417, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 417, Batch 1/4: Zeroing gradients...
  Epoch 417, Batch 1/4: Forward pass...
  Epoch 417, Batch 1/4: Calculating loss...
  Epoch 417, Batch 1/4: Backward pass...
  Epoch 417, Batch 1/4: Clipping gradients...
  Epoch 417, Batch 1/4: Optimizer step...
  Epoch 417, Batch 1/4: Completed in 0.19s
  Epoch 417, Batch 2/4: Loading data to device...
  Epoch 417, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 417, Batch 2/4: Zeroing gradients...
  Epoch 417, Batch 2/4: Forward pass...
  Epoch 417, Batch 2/4: Calculating loss...
  Epoch 417, Batch 2/4: Backward pass...
  Epoch 417, Batch 2/4: Clipping gradients...
  Epoch 417, Batch 2/4: Optimizer step...
  Epoch 417, Batch 2/4: Completed in 0.19s
  Epoch 417, Batch 3/4: Loading data to device...
  Epoch 417, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 417, Batch 3/4: Zeroing gradients...
  Epoch 417, Batch 3/4: Forward pass...
  Epoch 417, Batch 3/4: Calculating loss...
  Epoch 417, Batch 3/4: Backward pass...
  Epoch 417, Batch 3/4: Clipping gradients...
  Epoch 417, Batch 3/4: Optimizer step...
  Epoch 417, Batch 3/4: Completed in 0.19s
  Epoch 417, Batch 4/4: Loading data to device...
  Epoch 417, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 417, Batch 4/4: Zeroing gradients...
  Epoch 417, Batch 4/4: Forward pass...
  Epoch 417, Batch 4/4: Calculating loss...
  Epoch 417, Batch 4/4: Backward pass...
  Epoch 417, Batch 4/4: Clipping gradients...
  Epoch 417, Batch 4/4: Optimizer step...
  Epoch 417, Batch 4/4: Completed in 0.03s
Epoch 417: Training phase completed. Average Train Loss: 0.3201
Epoch 417: Starting validation phase...
  Epoch 417, Val Batch 1/1: Loading data...
  Epoch 417, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 417, Val Batch 1/1: Forward pass...
  Epoch 417, Val Batch 1/1: Calculating loss...
Epoch 417: Validation phase completed. Average Val Loss: 0.2419
Epoch 417 Summary ---> Train Loss: 0.3201 / Validation Loss: 0.2419
Epoch 417: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 22)
  Epoch 417: Validation loss did not improve. Epochs without improvement: 23
Epoch 417: Stepping scheduler...
--- Epoch 417 completed in 0.67 seconds ---

--- Starting Epoch 418/1000 ---
Epoch 418: Starting training phase (4 batches)
  Epoch 418, Batch 1/4: Loading data to device...
  Epoch 418, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 418, Batch 1/4: Zeroing gradients...
  Epoch 418, Batch 1/4: Forward pass...
  Epoch 418, Batch 1/4: Calculating loss...
  Epoch 418, Batch 1/4: Backward pass...
  Epoch 418, Batch 1/4: Clipping gradients...
  Epoch 418, Batch 1/4: Optimizer step...
  Epoch 418, Batch 1/4: Completed in 0.20s
  Epoch 418, Batch 2/4: Loading data to device...
  Epoch 418, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 418, Batch 2/4: Zeroing gradients...
  Epoch 418, Batch 2/4: Forward pass...
  Epoch 418, Batch 2/4: Calculating loss...
  Epoch 418, Batch 2/4: Backward pass...
  Epoch 418, Batch 2/4: Clipping gradients...
  Epoch 418, Batch 2/4: Optimizer step...
  Epoch 418, Batch 2/4: Completed in 0.20s
  Epoch 418, Batch 3/4: Loading data to device...
  Epoch 418, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 418, Batch 3/4: Zeroing gradients...
  Epoch 418, Batch 3/4: Forward pass...
  Epoch 418, Batch 3/4: Calculating loss...
  Epoch 418, Batch 3/4: Backward pass...
  Epoch 418, Batch 3/4: Clipping gradients...
  Epoch 418, Batch 3/4: Optimizer step...
  Epoch 418, Batch 3/4: Completed in 0.19s
  Epoch 418, Batch 4/4: Loading data to device...
  Epoch 418, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 418, Batch 4/4: Zeroing gradients...
  Epoch 418, Batch 4/4: Forward pass...
  Epoch 418, Batch 4/4: Calculating loss...
  Epoch 418, Batch 4/4: Backward pass...
  Epoch 418, Batch 4/4: Clipping gradients...
  Epoch 418, Batch 4/4: Optimizer step...
  Epoch 418, Batch 4/4: Completed in 0.04s
Epoch 418: Training phase completed. Average Train Loss: 0.4136
Epoch 418: Starting validation phase...
  Epoch 418, Val Batch 1/1: Loading data...
  Epoch 418, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 418, Val Batch 1/1: Forward pass...
  Epoch 418, Val Batch 1/1: Calculating loss...
Epoch 418: Validation phase completed. Average Val Loss: 0.2397
Epoch 418 Summary ---> Train Loss: 0.4136 / Validation Loss: 0.2397
Epoch 418: Checking early stopping... (Current Best Loss: 0.2407, Epochs No Improve: 23)
  Epoch 418: Validation loss improved (0.2407 --> 0.2397). Saving model.
Epoch 418: Stepping scheduler...
--- Epoch 418 completed in 0.70 seconds ---

--- Starting Epoch 419/1000 ---
Epoch 419: Starting training phase (4 batches)
  Epoch 419, Batch 1/4: Loading data to device...
  Epoch 419, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 419, Batch 1/4: Zeroing gradients...
  Epoch 419, Batch 1/4: Forward pass...
  Epoch 419, Batch 1/4: Calculating loss...
  Epoch 419, Batch 1/4: Backward pass...
  Epoch 419, Batch 1/4: Clipping gradients...
  Epoch 419, Batch 1/4: Optimizer step...
  Epoch 419, Batch 1/4: Completed in 0.19s
  Epoch 419, Batch 2/4: Loading data to device...
  Epoch 419, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 419, Batch 2/4: Zeroing gradients...
  Epoch 419, Batch 2/4: Forward pass...
  Epoch 419, Batch 2/4: Calculating loss...
  Epoch 419, Batch 2/4: Backward pass...
  Epoch 419, Batch 2/4: Clipping gradients...
  Epoch 419, Batch 2/4: Optimizer step...
  Epoch 419, Batch 2/4: Completed in 0.19s
  Epoch 419, Batch 3/4: Loading data to device...
  Epoch 419, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 419, Batch 3/4: Zeroing gradients...
  Epoch 419, Batch 3/4: Forward pass...
  Epoch 419, Batch 3/4: Calculating loss...
  Epoch 419, Batch 3/4: Backward pass...
  Epoch 419, Batch 3/4: Clipping gradients...
  Epoch 419, Batch 3/4: Optimizer step...
  Epoch 419, Batch 3/4: Completed in 0.20s
  Epoch 419, Batch 4/4: Loading data to device...
  Epoch 419, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 419, Batch 4/4: Zeroing gradients...
  Epoch 419, Batch 4/4: Forward pass...
  Epoch 419, Batch 4/4: Calculating loss...
  Epoch 419, Batch 4/4: Backward pass...
  Epoch 419, Batch 4/4: Clipping gradients...
  Epoch 419, Batch 4/4: Optimizer step...
  Epoch 419, Batch 4/4: Completed in 0.03s
Epoch 419: Training phase completed. Average Train Loss: 0.3897
Epoch 419: Starting validation phase...
  Epoch 419, Val Batch 1/1: Loading data...
  Epoch 419, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 419, Val Batch 1/1: Forward pass...
  Epoch 419, Val Batch 1/1: Calculating loss...
Epoch 419: Validation phase completed. Average Val Loss: 0.2417
Epoch 419 Summary ---> Train Loss: 0.3897 / Validation Loss: 0.2417
Epoch 419: Checking early stopping... (Current Best Loss: 0.2397, Epochs No Improve: 0)
  Epoch 419: Validation loss did not improve. Epochs without improvement: 1
Epoch 419: Stepping scheduler...
--- Epoch 419 completed in 0.68 seconds ---

--- Starting Epoch 420/1000 ---
Epoch 420: Starting training phase (4 batches)
  Epoch 420, Batch 1/4: Loading data to device...
  Epoch 420, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 420, Batch 1/4: Zeroing gradients...
  Epoch 420, Batch 1/4: Forward pass...
  Epoch 420, Batch 1/4: Calculating loss...
  Epoch 420, Batch 1/4: Backward pass...
  Epoch 420, Batch 1/4: Clipping gradients...
  Epoch 420, Batch 1/4: Optimizer step...
  Epoch 420, Batch 1/4: Completed in 0.19s
  Epoch 420, Batch 2/4: Loading data to device...
  Epoch 420, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 420, Batch 2/4: Zeroing gradients...
  Epoch 420, Batch 2/4: Forward pass...
  Epoch 420, Batch 2/4: Calculating loss...
  Epoch 420, Batch 2/4: Backward pass...
  Epoch 420, Batch 2/4: Clipping gradients...
  Epoch 420, Batch 2/4: Optimizer step...
  Epoch 420, Batch 2/4: Completed in 0.19s
  Epoch 420, Batch 3/4: Loading data to device...
  Epoch 420, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 420, Batch 3/4: Zeroing gradients...
  Epoch 420, Batch 3/4: Forward pass...
  Epoch 420, Batch 3/4: Calculating loss...
  Epoch 420, Batch 3/4: Backward pass...
  Epoch 420, Batch 3/4: Clipping gradients...
  Epoch 420, Batch 3/4: Optimizer step...
  Epoch 420, Batch 3/4: Completed in 0.20s
  Epoch 420, Batch 4/4: Loading data to device...
  Epoch 420, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 420, Batch 4/4: Zeroing gradients...
  Epoch 420, Batch 4/4: Forward pass...
  Epoch 420, Batch 4/4: Calculating loss...
  Epoch 420, Batch 4/4: Backward pass...
  Epoch 420, Batch 4/4: Clipping gradients...
  Epoch 420, Batch 4/4: Optimizer step...
  Epoch 420, Batch 4/4: Completed in 0.03s
Epoch 420: Training phase completed. Average Train Loss: 0.2896
Epoch 420: Starting validation phase...
  Epoch 420, Val Batch 1/1: Loading data...
  Epoch 420, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 420, Val Batch 1/1: Forward pass...
  Epoch 420, Val Batch 1/1: Calculating loss...
Epoch 420: Validation phase completed. Average Val Loss: 0.2431
Epoch 420 Summary ---> Train Loss: 0.2896 / Validation Loss: 0.2431
Epoch 420: Checking early stopping... (Current Best Loss: 0.2397, Epochs No Improve: 1)
  Epoch 420: Validation loss did not improve. Epochs without improvement: 2
Epoch 420: Stepping scheduler...
--- Epoch 420 completed in 0.67 seconds ---

--- Starting Epoch 421/1000 ---
Epoch 421: Starting training phase (4 batches)
  Epoch 421, Batch 1/4: Loading data to device...
  Epoch 421, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 421, Batch 1/4: Zeroing gradients...
  Epoch 421, Batch 1/4: Forward pass...
  Epoch 421, Batch 1/4: Calculating loss...
  Epoch 421, Batch 1/4: Backward pass...
  Epoch 421, Batch 1/4: Clipping gradients...
  Epoch 421, Batch 1/4: Optimizer step...
  Epoch 421, Batch 1/4: Completed in 0.19s
  Epoch 421, Batch 2/4: Loading data to device...
  Epoch 421, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 421, Batch 2/4: Zeroing gradients...
  Epoch 421, Batch 2/4: Forward pass...
  Epoch 421, Batch 2/4: Calculating loss...
  Epoch 421, Batch 2/4: Backward pass...
  Epoch 421, Batch 2/4: Clipping gradients...
  Epoch 421, Batch 2/4: Optimizer step...
  Epoch 421, Batch 2/4: Completed in 0.19s
  Epoch 421, Batch 3/4: Loading data to device...
  Epoch 421, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 421, Batch 3/4: Zeroing gradients...
  Epoch 421, Batch 3/4: Forward pass...
  Epoch 421, Batch 3/4: Calculating loss...
  Epoch 421, Batch 3/4: Backward pass...
  Epoch 421, Batch 3/4: Clipping gradients...
  Epoch 421, Batch 3/4: Optimizer step...
  Epoch 421, Batch 3/4: Completed in 0.19s
  Epoch 421, Batch 4/4: Loading data to device...
  Epoch 421, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 421, Batch 4/4: Zeroing gradients...
  Epoch 421, Batch 4/4: Forward pass...
  Epoch 421, Batch 4/4: Calculating loss...
  Epoch 421, Batch 4/4: Backward pass...
  Epoch 421, Batch 4/4: Clipping gradients...
  Epoch 421, Batch 4/4: Optimizer step...
  Epoch 421, Batch 4/4: Completed in 0.03s
Epoch 421: Training phase completed. Average Train Loss: 0.2707
Epoch 421: Starting validation phase...
  Epoch 421, Val Batch 1/1: Loading data...
  Epoch 421, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 421, Val Batch 1/1: Forward pass...
  Epoch 421, Val Batch 1/1: Calculating loss...
Epoch 421: Validation phase completed. Average Val Loss: 0.2402
Epoch 421 Summary ---> Train Loss: 0.2707 / Validation Loss: 0.2402
Epoch 421: Checking early stopping... (Current Best Loss: 0.2397, Epochs No Improve: 2)
  Epoch 421: Validation loss did not improve. Epochs without improvement: 3
Epoch 421: Stepping scheduler...
--- Epoch 421 completed in 0.66 seconds ---

--- Starting Epoch 422/1000 ---
Epoch 422: Starting training phase (4 batches)
  Epoch 422, Batch 1/4: Loading data to device...
  Epoch 422, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 422, Batch 1/4: Zeroing gradients...
  Epoch 422, Batch 1/4: Forward pass...
  Epoch 422, Batch 1/4: Calculating loss...
  Epoch 422, Batch 1/4: Backward pass...
  Epoch 422, Batch 1/4: Clipping gradients...
  Epoch 422, Batch 1/4: Optimizer step...
  Epoch 422, Batch 1/4: Completed in 0.19s
  Epoch 422, Batch 2/4: Loading data to device...
  Epoch 422, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 422, Batch 2/4: Zeroing gradients...
  Epoch 422, Batch 2/4: Forward pass...
  Epoch 422, Batch 2/4: Calculating loss...
  Epoch 422, Batch 2/4: Backward pass...
  Epoch 422, Batch 2/4: Clipping gradients...
  Epoch 422, Batch 2/4: Optimizer step...
  Epoch 422, Batch 2/4: Completed in 0.19s
  Epoch 422, Batch 3/4: Loading data to device...
  Epoch 422, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 422, Batch 3/4: Zeroing gradients...
  Epoch 422, Batch 3/4: Forward pass...
  Epoch 422, Batch 3/4: Calculating loss...
  Epoch 422, Batch 3/4: Backward pass...
  Epoch 422, Batch 3/4: Clipping gradients...
  Epoch 422, Batch 3/4: Optimizer step...
  Epoch 422, Batch 3/4: Completed in 0.19s
  Epoch 422, Batch 4/4: Loading data to device...
  Epoch 422, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 422, Batch 4/4: Zeroing gradients...
  Epoch 422, Batch 4/4: Forward pass...
  Epoch 422, Batch 4/4: Calculating loss...
  Epoch 422, Batch 4/4: Backward pass...
  Epoch 422, Batch 4/4: Clipping gradients...
  Epoch 422, Batch 4/4: Optimizer step...
  Epoch 422, Batch 4/4: Completed in 0.03s
Epoch 422: Training phase completed. Average Train Loss: 0.2928
Epoch 422: Starting validation phase...
  Epoch 422, Val Batch 1/1: Loading data...
  Epoch 422, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 422, Val Batch 1/1: Forward pass...
  Epoch 422, Val Batch 1/1: Calculating loss...
Epoch 422: Validation phase completed. Average Val Loss: 0.2441
Epoch 422 Summary ---> Train Loss: 0.2928 / Validation Loss: 0.2441
Epoch 422: Checking early stopping... (Current Best Loss: 0.2397, Epochs No Improve: 3)
  Epoch 422: Validation loss did not improve. Epochs without improvement: 4
Epoch 422: Stepping scheduler...
--- Epoch 422 completed in 0.67 seconds ---

--- Starting Epoch 423/1000 ---
Epoch 423: Starting training phase (4 batches)
  Epoch 423, Batch 1/4: Loading data to device...
  Epoch 423, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 423, Batch 1/4: Zeroing gradients...
  Epoch 423, Batch 1/4: Forward pass...
  Epoch 423, Batch 1/4: Calculating loss...
  Epoch 423, Batch 1/4: Backward pass...
  Epoch 423, Batch 1/4: Clipping gradients...
  Epoch 423, Batch 1/4: Optimizer step...
  Epoch 423, Batch 1/4: Completed in 0.19s
  Epoch 423, Batch 2/4: Loading data to device...
  Epoch 423, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 423, Batch 2/4: Zeroing gradients...
  Epoch 423, Batch 2/4: Forward pass...
  Epoch 423, Batch 2/4: Calculating loss...
  Epoch 423, Batch 2/4: Backward pass...
  Epoch 423, Batch 2/4: Clipping gradients...
  Epoch 423, Batch 2/4: Optimizer step...
  Epoch 423, Batch 2/4: Completed in 0.19s
  Epoch 423, Batch 3/4: Loading data to device...
  Epoch 423, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 423, Batch 3/4: Zeroing gradients...
  Epoch 423, Batch 3/4: Forward pass...
  Epoch 423, Batch 3/4: Calculating loss...
  Epoch 423, Batch 3/4: Backward pass...
  Epoch 423, Batch 3/4: Clipping gradients...
  Epoch 423, Batch 3/4: Optimizer step...
  Epoch 423, Batch 3/4: Completed in 0.20s
  Epoch 423, Batch 4/4: Loading data to device...
  Epoch 423, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 423, Batch 4/4: Zeroing gradients...
  Epoch 423, Batch 4/4: Forward pass...
  Epoch 423, Batch 4/4: Calculating loss...
  Epoch 423, Batch 4/4: Backward pass...
  Epoch 423, Batch 4/4: Clipping gradients...
  Epoch 423, Batch 4/4: Optimizer step...
  Epoch 423, Batch 4/4: Completed in 0.03s
Epoch 423: Training phase completed. Average Train Loss: 0.2913
Epoch 423: Starting validation phase...
  Epoch 423, Val Batch 1/1: Loading data...
  Epoch 423, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 423, Val Batch 1/1: Forward pass...
  Epoch 423, Val Batch 1/1: Calculating loss...
Epoch 423: Validation phase completed. Average Val Loss: 0.2485
Epoch 423 Summary ---> Train Loss: 0.2913 / Validation Loss: 0.2485
Epoch 423: Checking early stopping... (Current Best Loss: 0.2397, Epochs No Improve: 4)
  Epoch 423: Validation loss did not improve. Epochs without improvement: 5
Epoch 423: Stepping scheduler...
--- Epoch 423 completed in 0.67 seconds ---

--- Starting Epoch 424/1000 ---
Epoch 424: Starting training phase (4 batches)
  Epoch 424, Batch 1/4: Loading data to device...
  Epoch 424, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 424, Batch 1/4: Zeroing gradients...
  Epoch 424, Batch 1/4: Forward pass...
  Epoch 424, Batch 1/4: Calculating loss...
  Epoch 424, Batch 1/4: Backward pass...
  Epoch 424, Batch 1/4: Clipping gradients...
  Epoch 424, Batch 1/4: Optimizer step...
  Epoch 424, Batch 1/4: Completed in 0.20s
  Epoch 424, Batch 2/4: Loading data to device...
  Epoch 424, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 424, Batch 2/4: Zeroing gradients...
  Epoch 424, Batch 2/4: Forward pass...
  Epoch 424, Batch 2/4: Calculating loss...
  Epoch 424, Batch 2/4: Backward pass...
  Epoch 424, Batch 2/4: Clipping gradients...
  Epoch 424, Batch 2/4: Optimizer step...
  Epoch 424, Batch 2/4: Completed in 0.20s
  Epoch 424, Batch 3/4: Loading data to device...
  Epoch 424, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 424, Batch 3/4: Zeroing gradients...
  Epoch 424, Batch 3/4: Forward pass...
  Epoch 424, Batch 3/4: Calculating loss...
  Epoch 424, Batch 3/4: Backward pass...
  Epoch 424, Batch 3/4: Clipping gradients...
  Epoch 424, Batch 3/4: Optimizer step...
  Epoch 424, Batch 3/4: Completed in 0.20s
  Epoch 424, Batch 4/4: Loading data to device...
  Epoch 424, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 424, Batch 4/4: Zeroing gradients...
  Epoch 424, Batch 4/4: Forward pass...
  Epoch 424, Batch 4/4: Calculating loss...
  Epoch 424, Batch 4/4: Backward pass...
  Epoch 424, Batch 4/4: Clipping gradients...
  Epoch 424, Batch 4/4: Optimizer step...
  Epoch 424, Batch 4/4: Completed in 0.03s
Epoch 424: Training phase completed. Average Train Loss: 0.3080
Epoch 424: Starting validation phase...
  Epoch 424, Val Batch 1/1: Loading data...
  Epoch 424, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 424, Val Batch 1/1: Forward pass...
  Epoch 424, Val Batch 1/1: Calculating loss...
Epoch 424: Validation phase completed. Average Val Loss: 0.2448
Epoch 424 Summary ---> Train Loss: 0.3080 / Validation Loss: 0.2448
Epoch 424: Checking early stopping... (Current Best Loss: 0.2397, Epochs No Improve: 5)
  Epoch 424: Validation loss did not improve. Epochs without improvement: 6
Epoch 424: Stepping scheduler...
--- Epoch 424 completed in 0.69 seconds ---

--- Starting Epoch 425/1000 ---
Epoch 425: Starting training phase (4 batches)
  Epoch 425, Batch 1/4: Loading data to device...
  Epoch 425, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 425, Batch 1/4: Zeroing gradients...
  Epoch 425, Batch 1/4: Forward pass...
  Epoch 425, Batch 1/4: Calculating loss...
  Epoch 425, Batch 1/4: Backward pass...
  Epoch 425, Batch 1/4: Clipping gradients...
  Epoch 425, Batch 1/4: Optimizer step...
  Epoch 425, Batch 1/4: Completed in 0.20s
  Epoch 425, Batch 2/4: Loading data to device...
  Epoch 425, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 425, Batch 2/4: Zeroing gradients...
  Epoch 425, Batch 2/4: Forward pass...
  Epoch 425, Batch 2/4: Calculating loss...
  Epoch 425, Batch 2/4: Backward pass...
  Epoch 425, Batch 2/4: Clipping gradients...
  Epoch 425, Batch 2/4: Optimizer step...
  Epoch 425, Batch 2/4: Completed in 0.19s
  Epoch 425, Batch 3/4: Loading data to device...
  Epoch 425, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 425, Batch 3/4: Zeroing gradients...
  Epoch 425, Batch 3/4: Forward pass...
  Epoch 425, Batch 3/4: Calculating loss...
  Epoch 425, Batch 3/4: Backward pass...
  Epoch 425, Batch 3/4: Clipping gradients...
  Epoch 425, Batch 3/4: Optimizer step...
  Epoch 425, Batch 3/4: Completed in 0.19s
  Epoch 425, Batch 4/4: Loading data to device...
  Epoch 425, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 425, Batch 4/4: Zeroing gradients...
  Epoch 425, Batch 4/4: Forward pass...
  Epoch 425, Batch 4/4: Calculating loss...
  Epoch 425, Batch 4/4: Backward pass...
  Epoch 425, Batch 4/4: Clipping gradients...
  Epoch 425, Batch 4/4: Optimizer step...
  Epoch 425, Batch 4/4: Completed in 0.03s
Epoch 425: Training phase completed. Average Train Loss: 0.3094
Epoch 425: Starting validation phase...
  Epoch 425, Val Batch 1/1: Loading data...
  Epoch 425, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 425, Val Batch 1/1: Forward pass...
  Epoch 425, Val Batch 1/1: Calculating loss...
Epoch 425: Validation phase completed. Average Val Loss: 0.2449
Epoch 425 Summary ---> Train Loss: 0.3094 / Validation Loss: 0.2449
Epoch 425: Checking early stopping... (Current Best Loss: 0.2397, Epochs No Improve: 6)
  Epoch 425: Validation loss did not improve. Epochs without improvement: 7
Epoch 425: Stepping scheduler...
--- Epoch 425 completed in 0.68 seconds ---

--- Starting Epoch 426/1000 ---
Epoch 426: Starting training phase (4 batches)
  Epoch 426, Batch 1/4: Loading data to device...
  Epoch 426, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 426, Batch 1/4: Zeroing gradients...
  Epoch 426, Batch 1/4: Forward pass...
  Epoch 426, Batch 1/4: Calculating loss...
  Epoch 426, Batch 1/4: Backward pass...
  Epoch 426, Batch 1/4: Clipping gradients...
  Epoch 426, Batch 1/4: Optimizer step...
  Epoch 426, Batch 1/4: Completed in 0.19s
  Epoch 426, Batch 2/4: Loading data to device...
  Epoch 426, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 426, Batch 2/4: Zeroing gradients...
  Epoch 426, Batch 2/4: Forward pass...
  Epoch 426, Batch 2/4: Calculating loss...
  Epoch 426, Batch 2/4: Backward pass...
  Epoch 426, Batch 2/4: Clipping gradients...
  Epoch 426, Batch 2/4: Optimizer step...
  Epoch 426, Batch 2/4: Completed in 0.19s
  Epoch 426, Batch 3/4: Loading data to device...
  Epoch 426, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 426, Batch 3/4: Zeroing gradients...
  Epoch 426, Batch 3/4: Forward pass...
  Epoch 426, Batch 3/4: Calculating loss...
  Epoch 426, Batch 3/4: Backward pass...
  Epoch 426, Batch 3/4: Clipping gradients...
  Epoch 426, Batch 3/4: Optimizer step...
  Epoch 426, Batch 3/4: Completed in 0.19s
  Epoch 426, Batch 4/4: Loading data to device...
  Epoch 426, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 426, Batch 4/4: Zeroing gradients...
  Epoch 426, Batch 4/4: Forward pass...
  Epoch 426, Batch 4/4: Calculating loss...
  Epoch 426, Batch 4/4: Backward pass...
  Epoch 426, Batch 4/4: Clipping gradients...
  Epoch 426, Batch 4/4: Optimizer step...
  Epoch 426, Batch 4/4: Completed in 0.03s
Epoch 426: Training phase completed. Average Train Loss: 0.2822
Epoch 426: Starting validation phase...
  Epoch 426, Val Batch 1/1: Loading data...
  Epoch 426, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 426, Val Batch 1/1: Forward pass...
  Epoch 426, Val Batch 1/1: Calculating loss...
Epoch 426: Validation phase completed. Average Val Loss: 0.2440
Epoch 426 Summary ---> Train Loss: 0.2822 / Validation Loss: 0.2440
Epoch 426: Checking early stopping... (Current Best Loss: 0.2397, Epochs No Improve: 7)
  Epoch 426: Validation loss did not improve. Epochs without improvement: 8
Epoch 426: Stepping scheduler...
--- Epoch 426 completed in 0.66 seconds ---

--- Starting Epoch 427/1000 ---
Epoch 427: Starting training phase (4 batches)
  Epoch 427, Batch 1/4: Loading data to device...
  Epoch 427, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 427, Batch 1/4: Zeroing gradients...
  Epoch 427, Batch 1/4: Forward pass...
  Epoch 427, Batch 1/4: Calculating loss...
  Epoch 427, Batch 1/4: Backward pass...
  Epoch 427, Batch 1/4: Clipping gradients...
  Epoch 427, Batch 1/4: Optimizer step...
  Epoch 427, Batch 1/4: Completed in 0.19s
  Epoch 427, Batch 2/4: Loading data to device...
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
  Epoch 427, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 427, Batch 2/4: Zeroing gradients...
  Epoch 427, Batch 2/4: Forward pass...
  Epoch 427, Batch 2/4: Calculating loss...
  Epoch 427, Batch 2/4: Backward pass...
  Epoch 427, Batch 2/4: Clipping gradients...
  Epoch 427, Batch 2/4: Optimizer step...
  Epoch 427, Batch 2/4: Completed in 0.19s
  Epoch 427, Batch 3/4: Loading data to device...
  Epoch 427, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 427, Batch 3/4: Zeroing gradients...
  Epoch 427, Batch 3/4: Forward pass...
  Epoch 427, Batch 3/4: Calculating loss...
  Epoch 427, Batch 3/4: Backward pass...
  Epoch 427, Batch 3/4: Clipping gradients...
  Epoch 427, Batch 3/4: Optimizer step...
  Epoch 427, Batch 3/4: Completed in 0.20s
  Epoch 427, Batch 4/4: Loading data to device...
  Epoch 427, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 427, Batch 4/4: Zeroing gradients...
  Epoch 427, Batch 4/4: Forward pass...
  Epoch 427, Batch 4/4: Calculating loss...
  Epoch 427, Batch 4/4: Backward pass...
  Epoch 427, Batch 4/4: Clipping gradients...
  Epoch 427, Batch 4/4: Optimizer step...
  Epoch 427, Batch 4/4: Completed in 0.03s
Epoch 427: Training phase completed. Average Train Loss: 0.3099
Epoch 427: Starting validation phase...
  Epoch 427, Val Batch 1/1: Loading data...
  Epoch 427, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 427, Val Batch 1/1: Forward pass...
  Epoch 427, Val Batch 1/1: Calculating loss...
Epoch 427: Validation phase completed. Average Val Loss: 0.2425
Epoch 427 Summary ---> Train Loss: 0.3099 / Validation Loss: 0.2425
Epoch 427: Checking early stopping... (Current Best Loss: 0.2397, Epochs No Improve: 8)
  Epoch 427: Validation loss did not improve. Epochs without improvement: 9
Epoch 427: Stepping scheduler...
--- Epoch 427 completed in 0.68 seconds ---

--- Starting Epoch 428/1000 ---
Epoch 428: Starting training phase (4 batches)
  Epoch 428, Batch 1/4: Loading data to device...
  Epoch 428, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 428, Batch 1/4: Zeroing gradients...
  Epoch 428, Batch 1/4: Forward pass...
  Epoch 428, Batch 1/4: Calculating loss...
  Epoch 428, Batch 1/4: Backward pass...
  Epoch 428, Batch 1/4: Clipping gradients...
  Epoch 428, Batch 1/4: Optimizer step...
  Epoch 428, Batch 1/4: Completed in 0.19s
  Epoch 428, Batch 2/4: Loading data to device...
  Epoch 428, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 428, Batch 2/4: Zeroing gradients...
  Epoch 428, Batch 2/4: Forward pass...
  Epoch 428, Batch 2/4: Calculating loss...
  Epoch 428, Batch 2/4: Backward pass...
  Epoch 428, Batch 2/4: Clipping gradients...
  Epoch 428, Batch 2/4: Optimizer step...
  Epoch 428, Batch 2/4: Completed in 0.20s
  Epoch 428, Batch 3/4: Loading data to device...
  Epoch 428, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 428, Batch 3/4: Zeroing gradients...
  Epoch 428, Batch 3/4: Forward pass...
  Epoch 428, Batch 3/4: Calculating loss...
  Epoch 428, Batch 3/4: Backward pass...
  Epoch 428, Batch 3/4: Clipping gradients...
  Epoch 428, Batch 3/4: Optimizer step...
  Epoch 428, Batch 3/4: Completed in 0.19s
  Epoch 428, Batch 4/4: Loading data to device...
  Epoch 428, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 428, Batch 4/4: Zeroing gradients...
  Epoch 428, Batch 4/4: Forward pass...
  Epoch 428, Batch 4/4: Calculating loss...
  Epoch 428, Batch 4/4: Backward pass...
  Epoch 428, Batch 4/4: Clipping gradients...
  Epoch 428, Batch 4/4: Optimizer step...
  Epoch 428, Batch 4/4: Completed in 0.03s
Epoch 428: Training phase completed. Average Train Loss: 0.2900
Epoch 428: Starting validation phase...
  Epoch 428, Val Batch 1/1: Loading data...
  Epoch 428, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 428, Val Batch 1/1: Forward pass...
  Epoch 428, Val Batch 1/1: Calculating loss...
Epoch 428: Validation phase completed. Average Val Loss: 0.2435
Epoch 428 Summary ---> Train Loss: 0.2900 / Validation Loss: 0.2435
Epoch 428: Checking early stopping... (Current Best Loss: 0.2397, Epochs No Improve: 9)
  Epoch 428: Validation loss did not improve. Epochs without improvement: 10
Epoch 428: Stepping scheduler...
--- Epoch 428 completed in 0.67 seconds ---

--- Starting Epoch 429/1000 ---
Epoch 429: Starting training phase (4 batches)
  Epoch 429, Batch 1/4: Loading data to device...
  Epoch 429, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 429, Batch 1/4: Zeroing gradients...
  Epoch 429, Batch 1/4: Forward pass...
  Epoch 429, Batch 1/4: Calculating loss...
  Epoch 429, Batch 1/4: Backward pass...
  Epoch 429, Batch 1/4: Clipping gradients...
  Epoch 429, Batch 1/4: Optimizer step...
  Epoch 429, Batch 1/4: Completed in 0.19s
  Epoch 429, Batch 2/4: Loading data to device...
  Epoch 429, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 429, Batch 2/4: Zeroing gradients...
  Epoch 429, Batch 2/4: Forward pass...
  Epoch 429, Batch 2/4: Calculating loss...
  Epoch 429, Batch 2/4: Backward pass...
  Epoch 429, Batch 2/4: Clipping gradients...
  Epoch 429, Batch 2/4: Optimizer step...
  Epoch 429, Batch 2/4: Completed in 0.20s
  Epoch 429, Batch 3/4: Loading data to device...
  Epoch 429, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 429, Batch 3/4: Zeroing gradients...
  Epoch 429, Batch 3/4: Forward pass...
  Epoch 429, Batch 3/4: Calculating loss...
  Epoch 429, Batch 3/4: Backward pass...
  Epoch 429, Batch 3/4: Clipping gradients...
  Epoch 429, Batch 3/4: Optimizer step...
  Epoch 429, Batch 3/4: Completed in 0.20s
  Epoch 429, Batch 4/4: Loading data to device...
  Epoch 429, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 429, Batch 4/4: Zeroing gradients...
  Epoch 429, Batch 4/4: Forward pass...
  Epoch 429, Batch 4/4: Calculating loss...
  Epoch 429, Batch 4/4: Backward pass...
  Epoch 429, Batch 4/4: Clipping gradients...
  Epoch 429, Batch 4/4: Optimizer step...
  Epoch 429, Batch 4/4: Completed in 0.03s
Epoch 429: Training phase completed. Average Train Loss: 0.3103
Epoch 429: Starting validation phase...
  Epoch 429, Val Batch 1/1: Loading data...
  Epoch 429, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 429, Val Batch 1/1: Forward pass...
  Epoch 429, Val Batch 1/1: Calculating loss...
Epoch 429: Validation phase completed. Average Val Loss: 0.2390
Epoch 429 Summary ---> Train Loss: 0.3103 / Validation Loss: 0.2390
Epoch 429: Checking early stopping... (Current Best Loss: 0.2397, Epochs No Improve: 10)
  Epoch 429: Validation loss improved (0.2397 --> 0.2390). Saving model.
Epoch 429: Stepping scheduler...
--- Epoch 429 completed in 0.70 seconds ---

--- Starting Epoch 430/1000 ---
Epoch 430: Starting training phase (4 batches)
  Epoch 430, Batch 1/4: Loading data to device...
  Epoch 430, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 430, Batch 1/4: Zeroing gradients...
  Epoch 430, Batch 1/4: Forward pass...
  Epoch 430, Batch 1/4: Calculating loss...
  Epoch 430, Batch 1/4: Backward pass...
  Epoch 430, Batch 1/4: Clipping gradients...
  Epoch 430, Batch 1/4: Optimizer step...
  Epoch 430, Batch 1/4: Completed in 0.20s
  Epoch 430, Batch 2/4: Loading data to device...
  Epoch 430, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 430, Batch 2/4: Zeroing gradients...
  Epoch 430, Batch 2/4: Forward pass...
  Epoch 430, Batch 2/4: Calculating loss...
  Epoch 430, Batch 2/4: Backward pass...
  Epoch 430, Batch 2/4: Clipping gradients...
  Epoch 430, Batch 2/4: Optimizer step...
  Epoch 430, Batch 2/4: Completed in 0.20s
  Epoch 430, Batch 3/4: Loading data to device...
  Epoch 430, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 430, Batch 3/4: Zeroing gradients...
  Epoch 430, Batch 3/4: Forward pass...
  Epoch 430, Batch 3/4: Calculating loss...
  Epoch 430, Batch 3/4: Backward pass...
  Epoch 430, Batch 3/4: Clipping gradients...
  Epoch 430, Batch 3/4: Optimizer step...
  Epoch 430, Batch 3/4: Completed in 0.22s
  Epoch 430, Batch 4/4: Loading data to device...
  Epoch 430, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 430, Batch 4/4: Zeroing gradients...
  Epoch 430, Batch 4/4: Forward pass...
  Epoch 430, Batch 4/4: Calculating loss...
  Epoch 430, Batch 4/4: Backward pass...
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
  Epoch 430, Batch 4/4: Clipping gradients...
  Epoch 430, Batch 4/4: Optimizer step...
  Epoch 430, Batch 4/4: Completed in 0.04s
Epoch 430: Training phase completed. Average Train Loss: 0.3094
Epoch 430: Starting validation phase...
  Epoch 430, Val Batch 1/1: Loading data...
  Epoch 430, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 430, Val Batch 1/1: Forward pass...
  Epoch 430, Val Batch 1/1: Calculating loss...
Epoch 430: Validation phase completed. Average Val Loss: 0.2407
Epoch 430 Summary ---> Train Loss: 0.3094 / Validation Loss: 0.2407
Epoch 430: Checking early stopping... (Current Best Loss: 0.2390, Epochs No Improve: 0)
  Epoch 430: Validation loss did not improve. Epochs without improvement: 1
Epoch 430: Stepping scheduler...
--- Epoch 430 completed in 0.73 seconds ---

--- Starting Epoch 431/1000 ---
Epoch 431: Starting training phase (4 batches)
  Epoch 431, Batch 1/4: Loading data to device...
  Epoch 431, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 431, Batch 1/4: Zeroing gradients...
  Epoch 431, Batch 1/4: Forward pass...
  Epoch 431, Batch 1/4: Calculating loss...
  Epoch 431, Batch 1/4: Backward pass...
  Epoch 431, Batch 1/4: Clipping gradients...
  Epoch 431, Batch 1/4: Optimizer step...
  Epoch 431, Batch 1/4: Completed in 0.21s
  Epoch 431, Batch 2/4: Loading data to device...
  Epoch 431, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 431, Batch 2/4: Zeroing gradients...
  Epoch 431, Batch 2/4: Forward pass...
  Epoch 431, Batch 2/4: Calculating loss...
  Epoch 431, Batch 2/4: Backward pass...
  Epoch 431, Batch 2/4: Clipping gradients...
  Epoch 431, Batch 2/4: Optimizer step...
  Epoch 431, Batch 2/4: Completed in 0.22s
  Epoch 431, Batch 3/4: Loading data to device...
  Epoch 431, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 431, Batch 3/4: Zeroing gradients...
  Epoch 431, Batch 3/4: Forward pass...
  Epoch 431, Batch 3/4: Calculating loss...
  Epoch 431, Batch 3/4: Backward pass...
  Epoch 431, Batch 3/4: Clipping gradients...
  Epoch 431, Batch 3/4: Optimizer step...
  Epoch 431, Batch 3/4: Completed in 0.22s
  Epoch 431, Batch 4/4: Loading data to device...
  Epoch 431, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 431, Batch 4/4: Zeroing gradients...
  Epoch 431, Batch 4/4: Forward pass...
  Epoch 431, Batch 4/4: Calculating loss...
  Epoch 431, Batch 4/4: Backward pass...
  Epoch 431, Batch 4/4: Clipping gradients...
  Epoch 431, Batch 4/4: Optimizer step...
  Epoch 431, Batch 4/4: Completed in 0.03s
Epoch 431: Training phase completed. Average Train Loss: 0.2928
Epoch 431: Starting validation phase...
  Epoch 431, Val Batch 1/1: Loading data...
  Epoch 431, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 431, Val Batch 1/1: Forward pass...
  Epoch 431, Val Batch 1/1: Calculating loss...
Epoch 431: Validation phase completed. Average Val Loss: 0.2411
Epoch 431 Summary ---> Train Loss: 0.2928 / Validation Loss: 0.2411
Epoch 431: Checking early stopping... (Current Best Loss: 0.2390, Epochs No Improve: 1)
  Epoch 431: Validation loss did not improve. Epochs without improvement: 2
Epoch 431: Stepping scheduler...
--- Epoch 431 completed in 0.75 seconds ---

--- Starting Epoch 432/1000 ---
Epoch 432: Starting training phase (4 batches)
  Epoch 432, Batch 1/4: Loading data to device...
  Epoch 432, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 432, Batch 1/4: Zeroing gradients...
  Epoch 432, Batch 1/4: Forward pass...
  Epoch 432, Batch 1/4: Calculating loss...
  Epoch 432, Batch 1/4: Backward pass...
  Epoch 432, Batch 1/4: Clipping gradients...
  Epoch 432, Batch 1/4: Optimizer step...
  Epoch 432, Batch 1/4: Completed in 0.22s
  Epoch 432, Batch 2/4: Loading data to device...
  Epoch 432, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 432, Batch 2/4: Zeroing gradients...
  Epoch 432, Batch 2/4: Forward pass...
  Epoch 432, Batch 2/4: Calculating loss...
  Epoch 432, Batch 2/4: Backward pass...
  Epoch 432, Batch 2/4: Clipping gradients...
  Epoch 432, Batch 2/4: Optimizer step...
  Epoch 432, Batch 2/4: Completed in 0.22s
  Epoch 432, Batch 3/4: Loading data to device...
  Epoch 432, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 432, Batch 3/4: Zeroing gradients...
  Epoch 432, Batch 3/4: Forward pass...
  Epoch 432, Batch 3/4: Calculating loss...
  Epoch 432, Batch 3/4: Backward pass...
  Epoch 432, Batch 3/4: Clipping gradients...
  Epoch 432, Batch 3/4: Optimizer step...
  Epoch 432, Batch 3/4: Completed in 0.21s
  Epoch 432, Batch 4/4: Loading data to device...
  Epoch 432, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 432, Batch 4/4: Zeroing gradients...
  Epoch 432, Batch 4/4: Forward pass...
  Epoch 432, Batch 4/4: Calculating loss...
  Epoch 432, Batch 4/4: Backward pass...
  Epoch 432, Batch 4/4: Clipping gradients...
  Epoch 432, Batch 4/4: Optimizer step...
  Epoch 432, Batch 4/4: Completed in 0.03s
Epoch 432: Training phase completed. Average Train Loss: 0.3540
Epoch 432: Starting validation phase...
  Epoch 432, Val Batch 1/1: Loading data...
  Epoch 432, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 432, Val Batch 1/1: Forward pass...
  Epoch 432, Val Batch 1/1: Calculating loss...
Epoch 432: Validation phase completed. Average Val Loss: 0.2346
Epoch 432 Summary ---> Train Loss: 0.3540 / Validation Loss: 0.2346
Epoch 432: Checking early stopping... (Current Best Loss: 0.2390, Epochs No Improve: 2)
  Epoch 432: Validation loss improved (0.2390 --> 0.2346). Saving model.
Epoch 432: Stepping scheduler...
--- Epoch 432 completed in 0.76 seconds ---

--- Starting Epoch 433/1000 ---
Epoch 433: Starting training phase (4 batches)
  Epoch 433, Batch 1/4: Loading data to device...
  Epoch 433, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 433, Batch 1/4: Zeroing gradients...
  Epoch 433, Batch 1/4: Forward pass...
  Epoch 433, Batch 1/4: Calculating loss...
  Epoch 433, Batch 1/4: Backward pass...
  Epoch 433, Batch 1/4: Clipping gradients...
  Epoch 433, Batch 1/4: Optimizer step...
  Epoch 433, Batch 1/4: Completed in 0.22s
  Epoch 433, Batch 2/4: Loading data to device...
  Epoch 433, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 433, Batch 2/4: Zeroing gradients...
  Epoch 433, Batch 2/4: Forward pass...
  Epoch 433, Batch 2/4: Calculating loss...
  Epoch 433, Batch 2/4: Backward pass...
  Epoch 433, Batch 2/4: Clipping gradients...
  Epoch 433, Batch 2/4: Optimizer step...
  Epoch 433, Batch 2/4: Completed in 0.21s
  Epoch 433, Batch 3/4: Loading data to device...
  Epoch 433, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 433, Batch 3/4: Zeroing gradients...
  Epoch 433, Batch 3/4: Forward pass...
  Epoch 433, Batch 3/4: Calculating loss...
  Epoch 433, Batch 3/4: Backward pass...
  Epoch 433, Batch 3/4: Clipping gradients...
  Epoch 433, Batch 3/4: Optimizer step...
  Epoch 433, Batch 3/4: Completed in 0.22s
  Epoch 433, Batch 4/4: Loading data to device...
  Epoch 433, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 433, Batch 4/4: Zeroing gradients...
  Epoch 433, Batch 4/4: Forward pass...
  Epoch 433, Batch 4/4: Calculating loss...
  Epoch 433, Batch 4/4: Backward pass...
  Epoch 433, Batch 4/4: Clipping gradients...
  Epoch 433, Batch 4/4: Optimizer step...
  Epoch 433, Batch 4/4: Completed in 0.04s
Epoch 433: Training phase completed. Average Train Loss: 0.3238
Epoch 433: Starting validation phase...
  Epoch 433, Val Batch 1/1: Loading data...
  Epoch 433, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 433, Val Batch 1/1: Forward pass...
  Epoch 433, Val Batch 1/1: Calculating loss...
Epoch 433: Validation phase completed. Average Val Loss: 0.2350
Epoch 433 Summary ---> Train Loss: 0.3238 / Validation Loss: 0.2350
Epoch 433: Checking early stopping... (Current Best Loss: 0.2346, Epochs No Improve: 0)
  Epoch 433: Validation loss did not improve. Epochs without improvement: 1
Epoch 433: Stepping scheduler...
--- Epoch 433 completed in 0.76 seconds ---

--- Starting Epoch 434/1000 ---
Epoch 434: Starting training phase (4 batches)
  Epoch 434, Batch 1/4: Loading data to device...
  Epoch 434, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 434, Batch 1/4: Zeroing gradients...
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
DEBUG: Extracting coordinates from /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/WT.pdb for 1 sequence(s)
DEBUG: Extracted coordinates for 1 sequences
  Epoch 434, Batch 1/4: Forward pass...
  Epoch 434, Batch 1/4: Calculating loss...
  Epoch 434, Batch 1/4: Backward pass...
  Epoch 434, Batch 1/4: Clipping gradients...
  Epoch 434, Batch 1/4: Optimizer step...
  Epoch 434, Batch 1/4: Completed in 0.22s
  Epoch 434, Batch 2/4: Loading data to device...
  Epoch 434, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 434, Batch 2/4: Zeroing gradients...
  Epoch 434, Batch 2/4: Forward pass...
  Epoch 434, Batch 2/4: Calculating loss...
  Epoch 434, Batch 2/4: Backward pass...
  Epoch 434, Batch 2/4: Clipping gradients...
  Epoch 434, Batch 2/4: Optimizer step...
  Epoch 434, Batch 2/4: Completed in 0.21s
  Epoch 434, Batch 3/4: Loading data to device...
  Epoch 434, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 434, Batch 3/4: Zeroing gradients...
  Epoch 434, Batch 3/4: Forward pass...
  Epoch 434, Batch 3/4: Calculating loss...
  Epoch 434, Batch 3/4: Backward pass...
  Epoch 434, Batch 3/4: Clipping gradients...
  Epoch 434, Batch 3/4: Optimizer step...
  Epoch 434, Batch 3/4: Completed in 0.20s
  Epoch 434, Batch 4/4: Loading data to device...
  Epoch 434, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 434, Batch 4/4: Zeroing gradients...
  Epoch 434, Batch 4/4: Forward pass...
  Epoch 434, Batch 4/4: Calculating loss...
  Epoch 434, Batch 4/4: Backward pass...
  Epoch 434, Batch 4/4: Clipping gradients...
  Epoch 434, Batch 4/4: Optimizer step...
  Epoch 434, Batch 4/4: Completed in 0.03s
Epoch 434: Training phase completed. Average Train Loss: 0.3210
Epoch 434: Starting validation phase...
  Epoch 434, Val Batch 1/1: Loading data...
  Epoch 434, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 434, Val Batch 1/1: Forward pass...
  Epoch 434, Val Batch 1/1: Calculating loss...
Epoch 434: Validation phase completed. Average Val Loss: 0.2400
Epoch 434 Summary ---> Train Loss: 0.3210 / Validation Loss: 0.2400
Epoch 434: Checking early stopping... (Current Best Loss: 0.2346, Epochs No Improve: 1)
  Epoch 434: Validation loss did not improve. Epochs without improvement: 2
Epoch 434: Stepping scheduler...
--- Epoch 434 completed in 0.73 seconds ---

--- Starting Epoch 435/1000 ---
Epoch 435: Starting training phase (4 batches)
  Epoch 435, Batch 1/4: Loading data to device...
  Epoch 435, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 435, Batch 1/4: Zeroing gradients...
  Epoch 435, Batch 1/4: Forward pass...
  Epoch 435, Batch 1/4: Calculating loss...
  Epoch 435, Batch 1/4: Backward pass...
  Epoch 435, Batch 1/4: Clipping gradients...
  Epoch 435, Batch 1/4: Optimizer step...
  Epoch 435, Batch 1/4: Completed in 0.21s
  Epoch 435, Batch 2/4: Loading data to device...
  Epoch 435, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 435, Batch 2/4: Zeroing gradients...
  Epoch 435, Batch 2/4: Forward pass...
  Epoch 435, Batch 2/4: Calculating loss...
  Epoch 435, Batch 2/4: Backward pass...
  Epoch 435, Batch 2/4: Clipping gradients...
  Epoch 435, Batch 2/4: Optimizer step...
  Epoch 435, Batch 2/4: Completed in 0.20s
  Epoch 435, Batch 3/4: Loading data to device...
  Epoch 435, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 435, Batch 3/4: Zeroing gradients...
  Epoch 435, Batch 3/4: Forward pass...
  Epoch 435, Batch 3/4: Calculating loss...
  Epoch 435, Batch 3/4: Backward pass...
  Epoch 435, Batch 3/4: Clipping gradients...
  Epoch 435, Batch 3/4: Optimizer step...
  Epoch 435, Batch 3/4: Completed in 0.19s
  Epoch 435, Batch 4/4: Loading data to device...
  Epoch 435, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 435, Batch 4/4: Zeroing gradients...
  Epoch 435, Batch 4/4: Forward pass...
  Epoch 435, Batch 4/4: Calculating loss...
  Epoch 435, Batch 4/4: Backward pass...
  Epoch 435, Batch 4/4: Clipping gradients...
  Epoch 435, Batch 4/4: Optimizer step...
  Epoch 435, Batch 4/4: Completed in 0.03s
Epoch 435: Training phase completed. Average Train Loss: 0.2998
Epoch 435: Starting validation phase...
  Epoch 435, Val Batch 1/1: Loading data...
  Epoch 435, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 435, Val Batch 1/1: Forward pass...
  Epoch 435, Val Batch 1/1: Calculating loss...
Epoch 435: Validation phase completed. Average Val Loss: 0.2430
Epoch 435 Summary ---> Train Loss: 0.2998 / Validation Loss: 0.2430
Epoch 435: Checking early stopping... (Current Best Loss: 0.2346, Epochs No Improve: 2)
  Epoch 435: Validation loss did not improve. Epochs without improvement: 3
Epoch 435: Stepping scheduler...
--- Epoch 435 completed in 0.70 seconds ---

--- Starting Epoch 436/1000 ---
Epoch 436: Starting training phase (4 batches)
  Epoch 436, Batch 1/4: Loading data to device...
  Epoch 436, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 436, Batch 1/4: Zeroing gradients...
  Epoch 436, Batch 1/4: Forward pass...
  Epoch 436, Batch 1/4: Calculating loss...
  Epoch 436, Batch 1/4: Backward pass...
  Epoch 436, Batch 1/4: Clipping gradients...
  Epoch 436, Batch 1/4: Optimizer step...
  Epoch 436, Batch 1/4: Completed in 0.19s
  Epoch 436, Batch 2/4: Loading data to device...
  Epoch 436, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 436, Batch 2/4: Zeroing gradients...
  Epoch 436, Batch 2/4: Forward pass...
  Epoch 436, Batch 2/4: Calculating loss...
  Epoch 436, Batch 2/4: Backward pass...
  Epoch 436, Batch 2/4: Clipping gradients...
  Epoch 436, Batch 2/4: Optimizer step...
  Epoch 436, Batch 2/4: Completed in 0.19s
  Epoch 436, Batch 3/4: Loading data to device...
  Epoch 436, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 436, Batch 3/4: Zeroing gradients...
  Epoch 436, Batch 3/4: Forward pass...
  Epoch 436, Batch 3/4: Calculating loss...
  Epoch 436, Batch 3/4: Backward pass...
  Epoch 436, Batch 3/4: Clipping gradients...
  Epoch 436, Batch 3/4: Optimizer step...
  Epoch 436, Batch 3/4: Completed in 0.19s
  Epoch 436, Batch 4/4: Loading data to device...
  Epoch 436, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 436, Batch 4/4: Zeroing gradients...
  Epoch 436, Batch 4/4: Forward pass...
  Epoch 436, Batch 4/4: Calculating loss...
  Epoch 436, Batch 4/4: Backward pass...
  Epoch 436, Batch 4/4: Clipping gradients...
  Epoch 436, Batch 4/4: Optimizer step...
  Epoch 436, Batch 4/4: Completed in 0.03s
Epoch 436: Training phase completed. Average Train Loss: 0.3158
Epoch 436: Starting validation phase...
  Epoch 436, Val Batch 1/1: Loading data...
  Epoch 436, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 436, Val Batch 1/1: Forward pass...
  Epoch 436, Val Batch 1/1: Calculating loss...
Epoch 436: Validation phase completed. Average Val Loss: 0.2360
Epoch 436 Summary ---> Train Loss: 0.3158 / Validation Loss: 0.2360
Epoch 436: Checking early stopping... (Current Best Loss: 0.2346, Epochs No Improve: 3)
  Epoch 436: Validation loss did not improve. Epochs without improvement: 4
Epoch 436: Stepping scheduler...
--- Epoch 436 completed in 0.68 seconds ---

--- Starting Epoch 437/1000 ---
Epoch 437: Starting training phase (4 batches)
  Epoch 437, Batch 1/4: Loading data to device...
  Epoch 437, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 437, Batch 1/4: Zeroing gradients...
  Epoch 437, Batch 1/4: Forward pass...
  Epoch 437, Batch 1/4: Calculating loss...
  Epoch 437, Batch 1/4: Backward pass...
  Epoch 437, Batch 1/4: Clipping gradients...
  Epoch 437, Batch 1/4: Optimizer step...
  Epoch 437, Batch 1/4: Completed in 0.19s
  Epoch 437, Batch 2/4: Loading data to device...
  Epoch 437, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 437, Batch 2/4: Zeroing gradients...
  Epoch 437, Batch 2/4: Forward pass...
  Epoch 437, Batch 2/4: Calculating loss...
  Epoch 437, Batch 2/4: Backward pass...
  Epoch 437, Batch 2/4: Clipping gradients...
  Epoch 437, Batch 2/4: Optimizer step...
  Epoch 437, Batch 2/4: Completed in 0.19s
  Epoch 437, Batch 3/4: Loading data to device...
  Epoch 437, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 437, Batch 3/4: Zeroing gradients...
  Epoch 437, Batch 3/4: Forward pass...
  Epoch 437, Batch 3/4: Calculating loss...
  Epoch 437, Batch 3/4: Backward pass...
  Epoch 437, Batch 3/4: Clipping gradients...
  Epoch 437, Batch 3/4: Optimizer step...
  Epoch 437, Batch 3/4: Completed in 0.19s
  Epoch 437, Batch 4/4: Loading data to device...
  Epoch 437, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 437, Batch 4/4: Zeroing gradients...
  Epoch 437, Batch 4/4: Forward pass...
  Epoch 437, Batch 4/4: Calculating loss...
  Epoch 437, Batch 4/4: Backward pass...
  Epoch 437, Batch 4/4: Clipping gradients...
  Epoch 437, Batch 4/4: Optimizer step...
  Epoch 437, Batch 4/4: Completed in 0.03s
Epoch 437: Training phase completed. Average Train Loss: 0.3209
Epoch 437: Starting validation phase...
  Epoch 437, Val Batch 1/1: Loading data...
  Epoch 437, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 437, Val Batch 1/1: Forward pass...
  Epoch 437, Val Batch 1/1: Calculating loss...
Epoch 437: Validation phase completed. Average Val Loss: 0.2382
Epoch 437 Summary ---> Train Loss: 0.3209 / Validation Loss: 0.2382
Epoch 437: Checking early stopping... (Current Best Loss: 0.2346, Epochs No Improve: 4)
  Epoch 437: Validation loss did not improve. Epochs without improvement: 5
Epoch 437: Stepping scheduler...
--- Epoch 437 completed in 0.68 seconds ---

--- Starting Epoch 438/1000 ---
Epoch 438: Starting training phase (4 batches)
  Epoch 438, Batch 1/4: Loading data to device...
  Epoch 438, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 438, Batch 1/4: Zeroing gradients...
  Epoch 438, Batch 1/4: Forward pass...
  Epoch 438, Batch 1/4: Calculating loss...
  Epoch 438, Batch 1/4: Backward pass...
  Epoch 438, Batch 1/4: Clipping gradients...
  Epoch 438, Batch 1/4: Optimizer step...
  Epoch 438, Batch 1/4: Completed in 0.19s
  Epoch 438, Batch 2/4: Loading data to device...
  Epoch 438, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 438, Batch 2/4: Zeroing gradients...
  Epoch 438, Batch 2/4: Forward pass...
  Epoch 438, Batch 2/4: Calculating loss...
  Epoch 438, Batch 2/4: Backward pass...
  Epoch 438, Batch 2/4: Clipping gradients...
  Epoch 438, Batch 2/4: Optimizer step...
  Epoch 438, Batch 2/4: Completed in 0.19s
  Epoch 438, Batch 3/4: Loading data to device...
  Epoch 438, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 438, Batch 3/4: Zeroing gradients...
  Epoch 438, Batch 3/4: Forward pass...
  Epoch 438, Batch 3/4: Calculating loss...
  Epoch 438, Batch 3/4: Backward pass...
  Epoch 438, Batch 3/4: Clipping gradients...
  Epoch 438, Batch 3/4: Optimizer step...
  Epoch 438, Batch 3/4: Completed in 0.20s
  Epoch 438, Batch 4/4: Loading data to device...
  Epoch 438, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 438, Batch 4/4: Zeroing gradients...
  Epoch 438, Batch 4/4: Forward pass...
  Epoch 438, Batch 4/4: Calculating loss...
  Epoch 438, Batch 4/4: Backward pass...
  Epoch 438, Batch 4/4: Clipping gradients...
  Epoch 438, Batch 4/4: Optimizer step...
  Epoch 438, Batch 4/4: Completed in 0.04s
Epoch 438: Training phase completed. Average Train Loss: 0.3769
Epoch 438: Starting validation phase...
  Epoch 438, Val Batch 1/1: Loading data...
  Epoch 438, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 438, Val Batch 1/1: Forward pass...
  Epoch 438, Val Batch 1/1: Calculating loss...
Epoch 438: Validation phase completed. Average Val Loss: 0.2325
Epoch 438 Summary ---> Train Loss: 0.3769 / Validation Loss: 0.2325
Epoch 438: Checking early stopping... (Current Best Loss: 0.2346, Epochs No Improve: 5)
  Epoch 438: Validation loss improved (0.2346 --> 0.2325). Saving model.
Epoch 438: Stepping scheduler...
--- Epoch 438 completed in 0.70 seconds ---

--- Starting Epoch 439/1000 ---
Epoch 439: Starting training phase (4 batches)
  Epoch 439, Batch 1/4: Loading data to device...
  Epoch 439, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 439, Batch 1/4: Zeroing gradients...
  Epoch 439, Batch 1/4: Forward pass...
  Epoch 439, Batch 1/4: Calculating loss...
  Epoch 439, Batch 1/4: Backward pass...
  Epoch 439, Batch 1/4: Clipping gradients...
  Epoch 439, Batch 1/4: Optimizer step...
  Epoch 439, Batch 1/4: Completed in 0.20s
  Epoch 439, Batch 2/4: Loading data to device...
  Epoch 439, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 439, Batch 2/4: Zeroing gradients...
  Epoch 439, Batch 2/4: Forward pass...
  Epoch 439, Batch 2/4: Calculating loss...
  Epoch 439, Batch 2/4: Backward pass...
  Epoch 439, Batch 2/4: Clipping gradients...
  Epoch 439, Batch 2/4: Optimizer step...
  Epoch 439, Batch 2/4: Completed in 0.20s
  Epoch 439, Batch 3/4: Loading data to device...
  Epoch 439, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 439, Batch 3/4: Zeroing gradients...
  Epoch 439, Batch 3/4: Forward pass...
  Epoch 439, Batch 3/4: Calculating loss...
  Epoch 439, Batch 3/4: Backward pass...
  Epoch 439, Batch 3/4: Clipping gradients...
  Epoch 439, Batch 3/4: Optimizer step...
  Epoch 439, Batch 3/4: Completed in 0.20s
  Epoch 439, Batch 4/4: Loading data to device...
  Epoch 439, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 439, Batch 4/4: Zeroing gradients...
  Epoch 439, Batch 4/4: Forward pass...
  Epoch 439, Batch 4/4: Calculating loss...
  Epoch 439, Batch 4/4: Backward pass...
  Epoch 439, Batch 4/4: Clipping gradients...
  Epoch 439, Batch 4/4: Optimizer step...
  Epoch 439, Batch 4/4: Completed in 0.03s
Epoch 439: Training phase completed. Average Train Loss: 0.3436
Epoch 439: Starting validation phase...
  Epoch 439, Val Batch 1/1: Loading data...
  Epoch 439, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 439, Val Batch 1/1: Forward pass...
  Epoch 439, Val Batch 1/1: Calculating loss...
Epoch 439: Validation phase completed. Average Val Loss: 0.2291
Epoch 439 Summary ---> Train Loss: 0.3436 / Validation Loss: 0.2291
Epoch 439: Checking early stopping... (Current Best Loss: 0.2325, Epochs No Improve: 0)
  Epoch 439: Validation loss improved (0.2325 --> 0.2291). Saving model.
Epoch 439: Stepping scheduler...
--- Epoch 439 completed in 0.71 seconds ---

--- Starting Epoch 440/1000 ---
Epoch 440: Starting training phase (4 batches)
  Epoch 440, Batch 1/4: Loading data to device...
  Epoch 440, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 440, Batch 1/4: Zeroing gradients...
  Epoch 440, Batch 1/4: Forward pass...
  Epoch 440, Batch 1/4: Calculating loss...
  Epoch 440, Batch 1/4: Backward pass...
  Epoch 440, Batch 1/4: Clipping gradients...
  Epoch 440, Batch 1/4: Optimizer step...
  Epoch 440, Batch 1/4: Completed in 0.21s
  Epoch 440, Batch 2/4: Loading data to device...
  Epoch 440, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 440, Batch 2/4: Zeroing gradients...
  Epoch 440, Batch 2/4: Forward pass...
  Epoch 440, Batch 2/4: Calculating loss...
  Epoch 440, Batch 2/4: Backward pass...
  Epoch 440, Batch 2/4: Clipping gradients...
  Epoch 440, Batch 2/4: Optimizer step...
  Epoch 440, Batch 2/4: Completed in 0.21s
  Epoch 440, Batch 3/4: Loading data to device...
  Epoch 440, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 440, Batch 3/4: Zeroing gradients...
  Epoch 440, Batch 3/4: Forward pass...
  Epoch 440, Batch 3/4: Calculating loss...
  Epoch 440, Batch 3/4: Backward pass...
  Epoch 440, Batch 3/4: Clipping gradients...
  Epoch 440, Batch 3/4: Optimizer step...
  Epoch 440, Batch 3/4: Completed in 0.21s
  Epoch 440, Batch 4/4: Loading data to device...
  Epoch 440, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 440, Batch 4/4: Zeroing gradients...
  Epoch 440, Batch 4/4: Forward pass...
  Epoch 440, Batch 4/4: Calculating loss...
  Epoch 440, Batch 4/4: Backward pass...
  Epoch 440, Batch 4/4: Clipping gradients...
  Epoch 440, Batch 4/4: Optimizer step...
  Epoch 440, Batch 4/4: Completed in 0.03s
Epoch 440: Training phase completed. Average Train Loss: 0.2877
Epoch 440: Starting validation phase...
  Epoch 440, Val Batch 1/1: Loading data...
  Epoch 440, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 440, Val Batch 1/1: Forward pass...
  Epoch 440, Val Batch 1/1: Calculating loss...
Epoch 440: Validation phase completed. Average Val Loss: 0.2342
Epoch 440 Summary ---> Train Loss: 0.2877 / Validation Loss: 0.2342
Epoch 440: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 0)
  Epoch 440: Validation loss did not improve. Epochs without improvement: 1
Epoch 440: Stepping scheduler...
--- Epoch 440 completed in 0.72 seconds ---

--- Starting Epoch 441/1000 ---
Epoch 441: Starting training phase (4 batches)
  Epoch 441, Batch 1/4: Loading data to device...
  Epoch 441, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 441, Batch 1/4: Zeroing gradients...
  Epoch 441, Batch 1/4: Forward pass...
  Epoch 441, Batch 1/4: Calculating loss...
  Epoch 441, Batch 1/4: Backward pass...
  Epoch 441, Batch 1/4: Clipping gradients...
  Epoch 441, Batch 1/4: Optimizer step...
  Epoch 441, Batch 1/4: Completed in 0.21s
  Epoch 441, Batch 2/4: Loading data to device...
  Epoch 441, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 441, Batch 2/4: Zeroing gradients...
  Epoch 441, Batch 2/4: Forward pass...
  Epoch 441, Batch 2/4: Calculating loss...
  Epoch 441, Batch 2/4: Backward pass...
  Epoch 441, Batch 2/4: Clipping gradients...
  Epoch 441, Batch 2/4: Optimizer step...
  Epoch 441, Batch 2/4: Completed in 0.20s
  Epoch 441, Batch 3/4: Loading data to device...
  Epoch 441, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 441, Batch 3/4: Zeroing gradients...
  Epoch 441, Batch 3/4: Forward pass...
  Epoch 441, Batch 3/4: Calculating loss...
  Epoch 441, Batch 3/4: Backward pass...
  Epoch 441, Batch 3/4: Clipping gradients...
  Epoch 441, Batch 3/4: Optimizer step...
  Epoch 441, Batch 3/4: Completed in 0.20s
  Epoch 441, Batch 4/4: Loading data to device...
  Epoch 441, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 441, Batch 4/4: Zeroing gradients...
  Epoch 441, Batch 4/4: Forward pass...
  Epoch 441, Batch 4/4: Calculating loss...
  Epoch 441, Batch 4/4: Backward pass...
  Epoch 441, Batch 4/4: Clipping gradients...
  Epoch 441, Batch 4/4: Optimizer step...
  Epoch 441, Batch 4/4: Completed in 0.03s
Epoch 441: Training phase completed. Average Train Loss: 0.3111
Epoch 441: Starting validation phase...
  Epoch 441, Val Batch 1/1: Loading data...
  Epoch 441, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 441, Val Batch 1/1: Forward pass...
  Epoch 441, Val Batch 1/1: Calculating loss...
Epoch 441: Validation phase completed. Average Val Loss: 0.2396
Epoch 441 Summary ---> Train Loss: 0.3111 / Validation Loss: 0.2396
Epoch 441: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 1)
  Epoch 441: Validation loss did not improve. Epochs without improvement: 2
Epoch 441: Stepping scheduler...
--- Epoch 441 completed in 0.71 seconds ---

--- Starting Epoch 442/1000 ---
Epoch 442: Starting training phase (4 batches)
  Epoch 442, Batch 1/4: Loading data to device...
  Epoch 442, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 442, Batch 1/4: Zeroing gradients...
  Epoch 442, Batch 1/4: Forward pass...
  Epoch 442, Batch 1/4: Calculating loss...
  Epoch 442, Batch 1/4: Backward pass...
  Epoch 442, Batch 1/4: Clipping gradients...
  Epoch 442, Batch 1/4: Optimizer step...
  Epoch 442, Batch 1/4: Completed in 0.20s
  Epoch 442, Batch 2/4: Loading data to device...
  Epoch 442, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 442, Batch 2/4: Zeroing gradients...
  Epoch 442, Batch 2/4: Forward pass...
  Epoch 442, Batch 2/4: Calculating loss...
  Epoch 442, Batch 2/4: Backward pass...
  Epoch 442, Batch 2/4: Clipping gradients...
  Epoch 442, Batch 2/4: Optimizer step...
  Epoch 442, Batch 2/4: Completed in 0.19s
  Epoch 442, Batch 3/4: Loading data to device...
  Epoch 442, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 442, Batch 3/4: Zeroing gradients...
  Epoch 442, Batch 3/4: Forward pass...
  Epoch 442, Batch 3/4: Calculating loss...
  Epoch 442, Batch 3/4: Backward pass...
  Epoch 442, Batch 3/4: Clipping gradients...
  Epoch 442, Batch 3/4: Optimizer step...
  Epoch 442, Batch 3/4: Completed in 0.19s
  Epoch 442, Batch 4/4: Loading data to device...
  Epoch 442, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 442, Batch 4/4: Zeroing gradients...
  Epoch 442, Batch 4/4: Forward pass...
  Epoch 442, Batch 4/4: Calculating loss...
  Epoch 442, Batch 4/4: Backward pass...
  Epoch 442, Batch 4/4: Clipping gradients...
  Epoch 442, Batch 4/4: Optimizer step...
  Epoch 442, Batch 4/4: Completed in 0.03s
Epoch 442: Training phase completed. Average Train Loss: 0.2852
Epoch 442: Starting validation phase...
  Epoch 442, Val Batch 1/1: Loading data...
  Epoch 442, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 442, Val Batch 1/1: Forward pass...
  Epoch 442, Val Batch 1/1: Calculating loss...
Epoch 442: Validation phase completed. Average Val Loss: 0.2293
Epoch 442 Summary ---> Train Loss: 0.2852 / Validation Loss: 0.2293
Epoch 442: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 2)
  Epoch 442: Validation loss did not improve. Epochs without improvement: 3
Epoch 442: Stepping scheduler...
--- Epoch 442 completed in 0.69 seconds ---

--- Starting Epoch 443/1000 ---
Epoch 443: Starting training phase (4 batches)
  Epoch 443, Batch 1/4: Loading data to device...
  Epoch 443, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 443, Batch 1/4: Zeroing gradients...
  Epoch 443, Batch 1/4: Forward pass...
  Epoch 443, Batch 1/4: Calculating loss...
  Epoch 443, Batch 1/4: Backward pass...
  Epoch 443, Batch 1/4: Clipping gradients...
  Epoch 443, Batch 1/4: Optimizer step...
  Epoch 443, Batch 1/4: Completed in 0.19s
  Epoch 443, Batch 2/4: Loading data to device...
  Epoch 443, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 443, Batch 2/4: Zeroing gradients...
  Epoch 443, Batch 2/4: Forward pass...
  Epoch 443, Batch 2/4: Calculating loss...
  Epoch 443, Batch 2/4: Backward pass...
  Epoch 443, Batch 2/4: Clipping gradients...
  Epoch 443, Batch 2/4: Optimizer step...
  Epoch 443, Batch 2/4: Completed in 0.19s
  Epoch 443, Batch 3/4: Loading data to device...
  Epoch 443, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 443, Batch 3/4: Zeroing gradients...
  Epoch 443, Batch 3/4: Forward pass...
  Epoch 443, Batch 3/4: Calculating loss...
  Epoch 443, Batch 3/4: Backward pass...
  Epoch 443, Batch 3/4: Clipping gradients...
  Epoch 443, Batch 3/4: Optimizer step...
  Epoch 443, Batch 3/4: Completed in 0.19s
  Epoch 443, Batch 4/4: Loading data to device...
  Epoch 443, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 443, Batch 4/4: Zeroing gradients...
  Epoch 443, Batch 4/4: Forward pass...
  Epoch 443, Batch 4/4: Calculating loss...
  Epoch 443, Batch 4/4: Backward pass...
  Epoch 443, Batch 4/4: Clipping gradients...
  Epoch 443, Batch 4/4: Optimizer step...
  Epoch 443, Batch 4/4: Completed in 0.03s
Epoch 443: Training phase completed. Average Train Loss: 0.3106
Epoch 443: Starting validation phase...
  Epoch 443, Val Batch 1/1: Loading data...
  Epoch 443, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 443, Val Batch 1/1: Forward pass...
  Epoch 443, Val Batch 1/1: Calculating loss...
Epoch 443: Validation phase completed. Average Val Loss: 0.2351
Epoch 443 Summary ---> Train Loss: 0.3106 / Validation Loss: 0.2351
Epoch 443: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 3)
  Epoch 443: Validation loss did not improve. Epochs without improvement: 4
Epoch 443: Stepping scheduler...
--- Epoch 443 completed in 0.68 seconds ---

--- Starting Epoch 444/1000 ---
Epoch 444: Starting training phase (4 batches)
  Epoch 444, Batch 1/4: Loading data to device...
  Epoch 444, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 444, Batch 1/4: Zeroing gradients...
  Epoch 444, Batch 1/4: Forward pass...
  Epoch 444, Batch 1/4: Calculating loss...
  Epoch 444, Batch 1/4: Backward pass...
  Epoch 444, Batch 1/4: Clipping gradients...
  Epoch 444, Batch 1/4: Optimizer step...
  Epoch 444, Batch 1/4: Completed in 0.20s
  Epoch 444, Batch 2/4: Loading data to device...
  Epoch 444, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 444, Batch 2/4: Zeroing gradients...
  Epoch 444, Batch 2/4: Forward pass...
  Epoch 444, Batch 2/4: Calculating loss...
  Epoch 444, Batch 2/4: Backward pass...
  Epoch 444, Batch 2/4: Clipping gradients...
  Epoch 444, Batch 2/4: Optimizer step...
  Epoch 444, Batch 2/4: Completed in 0.20s
  Epoch 444, Batch 3/4: Loading data to device...
  Epoch 444, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 444, Batch 3/4: Zeroing gradients...
  Epoch 444, Batch 3/4: Forward pass...
  Epoch 444, Batch 3/4: Calculating loss...
  Epoch 444, Batch 3/4: Backward pass...
  Epoch 444, Batch 3/4: Clipping gradients...
  Epoch 444, Batch 3/4: Optimizer step...
  Epoch 444, Batch 3/4: Completed in 0.21s
  Epoch 444, Batch 4/4: Loading data to device...
  Epoch 444, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 444, Batch 4/4: Zeroing gradients...
  Epoch 444, Batch 4/4: Forward pass...
  Epoch 444, Batch 4/4: Calculating loss...
  Epoch 444, Batch 4/4: Backward pass...
  Epoch 444, Batch 4/4: Clipping gradients...
  Epoch 444, Batch 4/4: Optimizer step...
  Epoch 444, Batch 4/4: Completed in 0.03s
Epoch 444: Training phase completed. Average Train Loss: 0.2806
Epoch 444: Starting validation phase...
  Epoch 444, Val Batch 1/1: Loading data...
  Epoch 444, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 444, Val Batch 1/1: Forward pass...
  Epoch 444, Val Batch 1/1: Calculating loss...
Epoch 444: Validation phase completed. Average Val Loss: 0.2381
Epoch 444 Summary ---> Train Loss: 0.2806 / Validation Loss: 0.2381
Epoch 444: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 4)
  Epoch 444: Validation loss did not improve. Epochs without improvement: 5
Epoch 444: Stepping scheduler...
--- Epoch 444 completed in 0.72 seconds ---

--- Starting Epoch 445/1000 ---
Epoch 445: Starting training phase (4 batches)
  Epoch 445, Batch 1/4: Loading data to device...
  Epoch 445, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 445, Batch 1/4: Zeroing gradients...
  Epoch 445, Batch 1/4: Forward pass...
  Epoch 445, Batch 1/4: Calculating loss...
  Epoch 445, Batch 1/4: Backward pass...
  Epoch 445, Batch 1/4: Clipping gradients...
  Epoch 445, Batch 1/4: Optimizer step...
  Epoch 445, Batch 1/4: Completed in 0.21s
  Epoch 445, Batch 2/4: Loading data to device...
  Epoch 445, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 445, Batch 2/4: Zeroing gradients...
  Epoch 445, Batch 2/4: Forward pass...
  Epoch 445, Batch 2/4: Calculating loss...
  Epoch 445, Batch 2/4: Backward pass...
  Epoch 445, Batch 2/4: Clipping gradients...
  Epoch 445, Batch 2/4: Optimizer step...
  Epoch 445, Batch 2/4: Completed in 0.21s
  Epoch 445, Batch 3/4: Loading data to device...
  Epoch 445, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 445, Batch 3/4: Zeroing gradients...
  Epoch 445, Batch 3/4: Forward pass...
  Epoch 445, Batch 3/4: Calculating loss...
  Epoch 445, Batch 3/4: Backward pass...
  Epoch 445, Batch 3/4: Clipping gradients...
  Epoch 445, Batch 3/4: Optimizer step...
  Epoch 445, Batch 3/4: Completed in 0.21s
  Epoch 445, Batch 4/4: Loading data to device...
  Epoch 445, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 445, Batch 4/4: Zeroing gradients...
  Epoch 445, Batch 4/4: Forward pass...
  Epoch 445, Batch 4/4: Calculating loss...
  Epoch 445, Batch 4/4: Backward pass...
  Epoch 445, Batch 4/4: Clipping gradients...
  Epoch 445, Batch 4/4: Optimizer step...
  Epoch 445, Batch 4/4: Completed in 0.03s
Epoch 445: Training phase completed. Average Train Loss: 0.2726
Epoch 445: Starting validation phase...
  Epoch 445, Val Batch 1/1: Loading data...
  Epoch 445, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 445, Val Batch 1/1: Forward pass...
  Epoch 445, Val Batch 1/1: Calculating loss...
Epoch 445: Validation phase completed. Average Val Loss: 0.2346
Epoch 445 Summary ---> Train Loss: 0.2726 / Validation Loss: 0.2346
Epoch 445: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 5)
  Epoch 445: Validation loss did not improve. Epochs without improvement: 6
Epoch 445: Stepping scheduler...
--- Epoch 445 completed in 0.73 seconds ---

--- Starting Epoch 446/1000 ---
Epoch 446: Starting training phase (4 batches)
  Epoch 446, Batch 1/4: Loading data to device...
  Epoch 446, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 446, Batch 1/4: Zeroing gradients...
  Epoch 446, Batch 1/4: Forward pass...
  Epoch 446, Batch 1/4: Calculating loss...
  Epoch 446, Batch 1/4: Backward pass...
  Epoch 446, Batch 1/4: Clipping gradients...
  Epoch 446, Batch 1/4: Optimizer step...
  Epoch 446, Batch 1/4: Completed in 0.21s
  Epoch 446, Batch 2/4: Loading data to device...
  Epoch 446, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 446, Batch 2/4: Zeroing gradients...
  Epoch 446, Batch 2/4: Forward pass...
  Epoch 446, Batch 2/4: Calculating loss...
  Epoch 446, Batch 2/4: Backward pass...
  Epoch 446, Batch 2/4: Clipping gradients...
  Epoch 446, Batch 2/4: Optimizer step...
  Epoch 446, Batch 2/4: Completed in 0.21s
  Epoch 446, Batch 3/4: Loading data to device...
  Epoch 446, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 446, Batch 3/4: Zeroing gradients...
  Epoch 446, Batch 3/4: Forward pass...
  Epoch 446, Batch 3/4: Calculating loss...
  Epoch 446, Batch 3/4: Backward pass...
  Epoch 446, Batch 3/4: Clipping gradients...
  Epoch 446, Batch 3/4: Optimizer step...
  Epoch 446, Batch 3/4: Completed in 0.21s
  Epoch 446, Batch 4/4: Loading data to device...
  Epoch 446, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 446, Batch 4/4: Zeroing gradients...
  Epoch 446, Batch 4/4: Forward pass...
  Epoch 446, Batch 4/4: Calculating loss...
  Epoch 446, Batch 4/4: Backward pass...
  Epoch 446, Batch 4/4: Clipping gradients...
  Epoch 446, Batch 4/4: Optimizer step...
  Epoch 446, Batch 4/4: Completed in 0.03s
Epoch 446: Training phase completed. Average Train Loss: 0.2800
Epoch 446: Starting validation phase...
  Epoch 446, Val Batch 1/1: Loading data...
  Epoch 446, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 446, Val Batch 1/1: Forward pass...
  Epoch 446, Val Batch 1/1: Calculating loss...
Epoch 446: Validation phase completed. Average Val Loss: 0.2362
Epoch 446 Summary ---> Train Loss: 0.2800 / Validation Loss: 0.2362
Epoch 446: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 6)
  Epoch 446: Validation loss did not improve. Epochs without improvement: 7
Epoch 446: Stepping scheduler...
--- Epoch 446 completed in 0.72 seconds ---

--- Starting Epoch 447/1000 ---
Epoch 447: Starting training phase (4 batches)
  Epoch 447, Batch 1/4: Loading data to device...
  Epoch 447, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 447, Batch 1/4: Zeroing gradients...
  Epoch 447, Batch 1/4: Forward pass...
  Epoch 447, Batch 1/4: Calculating loss...
  Epoch 447, Batch 1/4: Backward pass...
  Epoch 447, Batch 1/4: Clipping gradients...
  Epoch 447, Batch 1/4: Optimizer step...
  Epoch 447, Batch 1/4: Completed in 0.21s
  Epoch 447, Batch 2/4: Loading data to device...
  Epoch 447, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 447, Batch 2/4: Zeroing gradients...
  Epoch 447, Batch 2/4: Forward pass...
  Epoch 447, Batch 2/4: Calculating loss...
  Epoch 447, Batch 2/4: Backward pass...
  Epoch 447, Batch 2/4: Clipping gradients...
  Epoch 447, Batch 2/4: Optimizer step...
  Epoch 447, Batch 2/4: Completed in 0.21s
  Epoch 447, Batch 3/4: Loading data to device...
  Epoch 447, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 447, Batch 3/4: Zeroing gradients...
  Epoch 447, Batch 3/4: Forward pass...
  Epoch 447, Batch 3/4: Calculating loss...
  Epoch 447, Batch 3/4: Backward pass...
  Epoch 447, Batch 3/4: Clipping gradients...
  Epoch 447, Batch 3/4: Optimizer step...
  Epoch 447, Batch 3/4: Completed in 0.21s
  Epoch 447, Batch 4/4: Loading data to device...
  Epoch 447, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 447, Batch 4/4: Zeroing gradients...
  Epoch 447, Batch 4/4: Forward pass...
  Epoch 447, Batch 4/4: Calculating loss...
  Epoch 447, Batch 4/4: Backward pass...
  Epoch 447, Batch 4/4: Clipping gradients...
  Epoch 447, Batch 4/4: Optimizer step...
  Epoch 447, Batch 4/4: Completed in 0.03s
Epoch 447: Training phase completed. Average Train Loss: 0.2908
Epoch 447: Starting validation phase...
  Epoch 447, Val Batch 1/1: Loading data...
  Epoch 447, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 447, Val Batch 1/1: Forward pass...
  Epoch 447, Val Batch 1/1: Calculating loss...
Epoch 447: Validation phase completed. Average Val Loss: 0.2353
Epoch 447 Summary ---> Train Loss: 0.2908 / Validation Loss: 0.2353
Epoch 447: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 7)
  Epoch 447: Validation loss did not improve. Epochs without improvement: 8
Epoch 447: Stepping scheduler...
--- Epoch 447 completed in 0.72 seconds ---

--- Starting Epoch 448/1000 ---
Epoch 448: Starting training phase (4 batches)
  Epoch 448, Batch 1/4: Loading data to device...
  Epoch 448, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 448, Batch 1/4: Zeroing gradients...
  Epoch 448, Batch 1/4: Forward pass...
  Epoch 448, Batch 1/4: Calculating loss...
  Epoch 448, Batch 1/4: Backward pass...
  Epoch 448, Batch 1/4: Clipping gradients...
  Epoch 448, Batch 1/4: Optimizer step...
  Epoch 448, Batch 1/4: Completed in 0.21s
  Epoch 448, Batch 2/4: Loading data to device...
  Epoch 448, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 448, Batch 2/4: Zeroing gradients...
  Epoch 448, Batch 2/4: Forward pass...
  Epoch 448, Batch 2/4: Calculating loss...
  Epoch 448, Batch 2/4: Backward pass...
  Epoch 448, Batch 2/4: Clipping gradients...
  Epoch 448, Batch 2/4: Optimizer step...
  Epoch 448, Batch 2/4: Completed in 0.20s
  Epoch 448, Batch 3/4: Loading data to device...
  Epoch 448, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 448, Batch 3/4: Zeroing gradients...
  Epoch 448, Batch 3/4: Forward pass...
  Epoch 448, Batch 3/4: Calculating loss...
  Epoch 448, Batch 3/4: Backward pass...
  Epoch 448, Batch 3/4: Clipping gradients...
  Epoch 448, Batch 3/4: Optimizer step...
  Epoch 448, Batch 3/4: Completed in 0.20s
  Epoch 448, Batch 4/4: Loading data to device...
  Epoch 448, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 448, Batch 4/4: Zeroing gradients...
  Epoch 448, Batch 4/4: Forward pass...
  Epoch 448, Batch 4/4: Calculating loss...
  Epoch 448, Batch 4/4: Backward pass...
  Epoch 448, Batch 4/4: Clipping gradients...
  Epoch 448, Batch 4/4: Optimizer step...
  Epoch 448, Batch 4/4: Completed in 0.03s
Epoch 448: Training phase completed. Average Train Loss: 0.2783
Epoch 448: Starting validation phase...
  Epoch 448, Val Batch 1/1: Loading data...
  Epoch 448, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 448, Val Batch 1/1: Forward pass...
  Epoch 448, Val Batch 1/1: Calculating loss...
Epoch 448: Validation phase completed. Average Val Loss: 0.2347
Epoch 448 Summary ---> Train Loss: 0.2783 / Validation Loss: 0.2347
Epoch 448: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 8)
  Epoch 448: Validation loss did not improve. Epochs without improvement: 9
Epoch 448: Stepping scheduler...
--- Epoch 448 completed in 0.70 seconds ---

--- Starting Epoch 449/1000 ---
Epoch 449: Starting training phase (4 batches)
  Epoch 449, Batch 1/4: Loading data to device...
  Epoch 449, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 449, Batch 1/4: Zeroing gradients...
  Epoch 449, Batch 1/4: Forward pass...
  Epoch 449, Batch 1/4: Calculating loss...
  Epoch 449, Batch 1/4: Backward pass...
  Epoch 449, Batch 1/4: Clipping gradients...
  Epoch 449, Batch 1/4: Optimizer step...
  Epoch 449, Batch 1/4: Completed in 0.19s
  Epoch 449, Batch 2/4: Loading data to device...
  Epoch 449, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 449, Batch 2/4: Zeroing gradients...
  Epoch 449, Batch 2/4: Forward pass...
  Epoch 449, Batch 2/4: Calculating loss...
  Epoch 449, Batch 2/4: Backward pass...
  Epoch 449, Batch 2/4: Clipping gradients...
  Epoch 449, Batch 2/4: Optimizer step...
  Epoch 449, Batch 2/4: Completed in 0.22s
  Epoch 449, Batch 3/4: Loading data to device...
  Epoch 449, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 449, Batch 3/4: Zeroing gradients...
  Epoch 449, Batch 3/4: Forward pass...
  Epoch 449, Batch 3/4: Calculating loss...
  Epoch 449, Batch 3/4: Backward pass...
  Epoch 449, Batch 3/4: Clipping gradients...
  Epoch 449, Batch 3/4: Optimizer step...
  Epoch 449, Batch 3/4: Completed in 0.20s
  Epoch 449, Batch 4/4: Loading data to device...
  Epoch 449, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 449, Batch 4/4: Zeroing gradients...
  Epoch 449, Batch 4/4: Forward pass...
  Epoch 449, Batch 4/4: Calculating loss...
  Epoch 449, Batch 4/4: Backward pass...
  Epoch 449, Batch 4/4: Clipping gradients...
  Epoch 449, Batch 4/4: Optimizer step...
  Epoch 449, Batch 4/4: Completed in 0.03s
Epoch 449: Training phase completed. Average Train Loss: 0.3219
Epoch 449: Starting validation phase...
  Epoch 449, Val Batch 1/1: Loading data...
  Epoch 449, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 449, Val Batch 1/1: Forward pass...
  Epoch 449, Val Batch 1/1: Calculating loss...
Epoch 449: Validation phase completed. Average Val Loss: 0.2358
Epoch 449 Summary ---> Train Loss: 0.3219 / Validation Loss: 0.2358
Epoch 449: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 9)
  Epoch 449: Validation loss did not improve. Epochs without improvement: 10
Epoch 449: Stepping scheduler...
--- Epoch 449 completed in 0.71 seconds ---

--- Starting Epoch 450/1000 ---
Epoch 450: Starting training phase (4 batches)
  Epoch 450, Batch 1/4: Loading data to device...
  Epoch 450, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 450, Batch 1/4: Zeroing gradients...
  Epoch 450, Batch 1/4: Forward pass...
  Epoch 450, Batch 1/4: Calculating loss...
  Epoch 450, Batch 1/4: Backward pass...
  Epoch 450, Batch 1/4: Clipping gradients...
  Epoch 450, Batch 1/4: Optimizer step...
  Epoch 450, Batch 1/4: Completed in 0.20s
  Epoch 450, Batch 2/4: Loading data to device...
  Epoch 450, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 450, Batch 2/4: Zeroing gradients...
  Epoch 450, Batch 2/4: Forward pass...
  Epoch 450, Batch 2/4: Calculating loss...
  Epoch 450, Batch 2/4: Backward pass...
  Epoch 450, Batch 2/4: Clipping gradients...
  Epoch 450, Batch 2/4: Optimizer step...
  Epoch 450, Batch 2/4: Completed in 0.20s
  Epoch 450, Batch 3/4: Loading data to device...
  Epoch 450, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 450, Batch 3/4: Zeroing gradients...
  Epoch 450, Batch 3/4: Forward pass...
  Epoch 450, Batch 3/4: Calculating loss...
  Epoch 450, Batch 3/4: Backward pass...
  Epoch 450, Batch 3/4: Clipping gradients...
  Epoch 450, Batch 3/4: Optimizer step...
  Epoch 450, Batch 3/4: Completed in 0.19s
  Epoch 450, Batch 4/4: Loading data to device...
  Epoch 450, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 450, Batch 4/4: Zeroing gradients...
  Epoch 450, Batch 4/4: Forward pass...
  Epoch 450, Batch 4/4: Calculating loss...
  Epoch 450, Batch 4/4: Backward pass...
  Epoch 450, Batch 4/4: Clipping gradients...
  Epoch 450, Batch 4/4: Optimizer step...
  Epoch 450, Batch 4/4: Completed in 0.03s
Epoch 450: Training phase completed. Average Train Loss: 0.2931
Epoch 450: Starting validation phase...
  Epoch 450, Val Batch 1/1: Loading data...
  Epoch 450, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 450, Val Batch 1/1: Forward pass...
  Epoch 450, Val Batch 1/1: Calculating loss...
Epoch 450: Validation phase completed. Average Val Loss: 0.2370
Epoch 450 Summary ---> Train Loss: 0.2931 / Validation Loss: 0.2370
Epoch 450: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 10)
  Epoch 450: Validation loss did not improve. Epochs without improvement: 11
Epoch 450: Stepping scheduler...
--- Epoch 450 completed in 0.68 seconds ---

--- Starting Epoch 451/1000 ---
Epoch 451: Starting training phase (4 batches)
  Epoch 451, Batch 1/4: Loading data to device...
  Epoch 451, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 451, Batch 1/4: Zeroing gradients...
  Epoch 451, Batch 1/4: Forward pass...
  Epoch 451, Batch 1/4: Calculating loss...
  Epoch 451, Batch 1/4: Backward pass...
  Epoch 451, Batch 1/4: Clipping gradients...
  Epoch 451, Batch 1/4: Optimizer step...
  Epoch 451, Batch 1/4: Completed in 0.19s
  Epoch 451, Batch 2/4: Loading data to device...
  Epoch 451, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 451, Batch 2/4: Zeroing gradients...
  Epoch 451, Batch 2/4: Forward pass...
  Epoch 451, Batch 2/4: Calculating loss...
  Epoch 451, Batch 2/4: Backward pass...
  Epoch 451, Batch 2/4: Clipping gradients...
  Epoch 451, Batch 2/4: Optimizer step...
  Epoch 451, Batch 2/4: Completed in 0.18s
  Epoch 451, Batch 3/4: Loading data to device...
  Epoch 451, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 451, Batch 3/4: Zeroing gradients...
  Epoch 451, Batch 3/4: Forward pass...
  Epoch 451, Batch 3/4: Calculating loss...
  Epoch 451, Batch 3/4: Backward pass...
  Epoch 451, Batch 3/4: Clipping gradients...
  Epoch 451, Batch 3/4: Optimizer step...
  Epoch 451, Batch 3/4: Completed in 0.18s
  Epoch 451, Batch 4/4: Loading data to device...
  Epoch 451, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 451, Batch 4/4: Zeroing gradients...
  Epoch 451, Batch 4/4: Forward pass...
  Epoch 451, Batch 4/4: Calculating loss...
  Epoch 451, Batch 4/4: Backward pass...
  Epoch 451, Batch 4/4: Clipping gradients...
  Epoch 451, Batch 4/4: Optimizer step...
  Epoch 451, Batch 4/4: Completed in 0.03s
Epoch 451: Training phase completed. Average Train Loss: 0.3761
Epoch 451: Starting validation phase...
  Epoch 451, Val Batch 1/1: Loading data...
  Epoch 451, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 451, Val Batch 1/1: Forward pass...
  Epoch 451, Val Batch 1/1: Calculating loss...
Epoch 451: Validation phase completed. Average Val Loss: 0.2388
Epoch 451 Summary ---> Train Loss: 0.3761 / Validation Loss: 0.2388
Epoch 451: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 11)
  Epoch 451: Validation loss did not improve. Epochs without improvement: 12
Epoch 451: Stepping scheduler...
--- Epoch 451 completed in 0.64 seconds ---

--- Starting Epoch 452/1000 ---
Epoch 452: Starting training phase (4 batches)
  Epoch 452, Batch 1/4: Loading data to device...
  Epoch 452, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 452, Batch 1/4: Zeroing gradients...
  Epoch 452, Batch 1/4: Forward pass...
  Epoch 452, Batch 1/4: Calculating loss...
  Epoch 452, Batch 1/4: Backward pass...
  Epoch 452, Batch 1/4: Clipping gradients...
  Epoch 452, Batch 1/4: Optimizer step...
  Epoch 452, Batch 1/4: Completed in 0.20s
  Epoch 452, Batch 2/4: Loading data to device...
  Epoch 452, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 452, Batch 2/4: Zeroing gradients...
  Epoch 452, Batch 2/4: Forward pass...
  Epoch 452, Batch 2/4: Calculating loss...
  Epoch 452, Batch 2/4: Backward pass...
  Epoch 452, Batch 2/4: Clipping gradients...
  Epoch 452, Batch 2/4: Optimizer step...
  Epoch 452, Batch 2/4: Completed in 0.20s
  Epoch 452, Batch 3/4: Loading data to device...
  Epoch 452, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 452, Batch 3/4: Zeroing gradients...
  Epoch 452, Batch 3/4: Forward pass...
  Epoch 452, Batch 3/4: Calculating loss...
  Epoch 452, Batch 3/4: Backward pass...
  Epoch 452, Batch 3/4: Clipping gradients...
  Epoch 452, Batch 3/4: Optimizer step...
  Epoch 452, Batch 3/4: Completed in 0.19s
  Epoch 452, Batch 4/4: Loading data to device...
  Epoch 452, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 452, Batch 4/4: Zeroing gradients...
  Epoch 452, Batch 4/4: Forward pass...
  Epoch 452, Batch 4/4: Calculating loss...
  Epoch 452, Batch 4/4: Backward pass...
  Epoch 452, Batch 4/4: Clipping gradients...
  Epoch 452, Batch 4/4: Optimizer step...
  Epoch 452, Batch 4/4: Completed in 0.03s
Epoch 452: Training phase completed. Average Train Loss: 0.2966
Epoch 452: Starting validation phase...
  Epoch 452, Val Batch 1/1: Loading data...
  Epoch 452, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 452, Val Batch 1/1: Forward pass...
  Epoch 452, Val Batch 1/1: Calculating loss...
Epoch 452: Validation phase completed. Average Val Loss: 0.2388
Epoch 452 Summary ---> Train Loss: 0.2966 / Validation Loss: 0.2388
Epoch 452: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 12)
  Epoch 452: Validation loss did not improve. Epochs without improvement: 13
Epoch 452: Stepping scheduler...
--- Epoch 452 completed in 0.68 seconds ---

--- Starting Epoch 453/1000 ---
Epoch 453: Starting training phase (4 batches)
  Epoch 453, Batch 1/4: Loading data to device...
  Epoch 453, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 453, Batch 1/4: Zeroing gradients...
  Epoch 453, Batch 1/4: Forward pass...
  Epoch 453, Batch 1/4: Calculating loss...
  Epoch 453, Batch 1/4: Backward pass...
  Epoch 453, Batch 1/4: Clipping gradients...
  Epoch 453, Batch 1/4: Optimizer step...
  Epoch 453, Batch 1/4: Completed in 0.19s
  Epoch 453, Batch 2/4: Loading data to device...
  Epoch 453, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 453, Batch 2/4: Zeroing gradients...
  Epoch 453, Batch 2/4: Forward pass...
  Epoch 453, Batch 2/4: Calculating loss...
  Epoch 453, Batch 2/4: Backward pass...
  Epoch 453, Batch 2/4: Clipping gradients...
  Epoch 453, Batch 2/4: Optimizer step...
  Epoch 453, Batch 2/4: Completed in 0.20s
  Epoch 453, Batch 3/4: Loading data to device...
  Epoch 453, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 453, Batch 3/4: Zeroing gradients...
  Epoch 453, Batch 3/4: Forward pass...
  Epoch 453, Batch 3/4: Calculating loss...
  Epoch 453, Batch 3/4: Backward pass...
  Epoch 453, Batch 3/4: Clipping gradients...
  Epoch 453, Batch 3/4: Optimizer step...
  Epoch 453, Batch 3/4: Completed in 0.20s
  Epoch 453, Batch 4/4: Loading data to device...
  Epoch 453, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 453, Batch 4/4: Zeroing gradients...
  Epoch 453, Batch 4/4: Forward pass...
  Epoch 453, Batch 4/4: Calculating loss...
  Epoch 453, Batch 4/4: Backward pass...
  Epoch 453, Batch 4/4: Clipping gradients...
  Epoch 453, Batch 4/4: Optimizer step...
  Epoch 453, Batch 4/4: Completed in 0.03s
Epoch 453: Training phase completed. Average Train Loss: 0.3306
Epoch 453: Starting validation phase...
  Epoch 453, Val Batch 1/1: Loading data...
  Epoch 453, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 453, Val Batch 1/1: Forward pass...
  Epoch 453, Val Batch 1/1: Calculating loss...
Epoch 453: Validation phase completed. Average Val Loss: 0.2380
Epoch 453 Summary ---> Train Loss: 0.3306 / Validation Loss: 0.2380
Epoch 453: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 13)
  Epoch 453: Validation loss did not improve. Epochs without improvement: 14
Epoch 453: Stepping scheduler...
--- Epoch 453 completed in 0.68 seconds ---

--- Starting Epoch 454/1000 ---
Epoch 454: Starting training phase (4 batches)
  Epoch 454, Batch 1/4: Loading data to device...
  Epoch 454, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 454, Batch 1/4: Zeroing gradients...
  Epoch 454, Batch 1/4: Forward pass...
  Epoch 454, Batch 1/4: Calculating loss...
  Epoch 454, Batch 1/4: Backward pass...
  Epoch 454, Batch 1/4: Clipping gradients...
  Epoch 454, Batch 1/4: Optimizer step...
  Epoch 454, Batch 1/4: Completed in 0.19s
  Epoch 454, Batch 2/4: Loading data to device...
  Epoch 454, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 454, Batch 2/4: Zeroing gradients...
  Epoch 454, Batch 2/4: Forward pass...
  Epoch 454, Batch 2/4: Calculating loss...
  Epoch 454, Batch 2/4: Backward pass...
  Epoch 454, Batch 2/4: Clipping gradients...
  Epoch 454, Batch 2/4: Optimizer step...
  Epoch 454, Batch 2/4: Completed in 0.19s
  Epoch 454, Batch 3/4: Loading data to device...
  Epoch 454, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 454, Batch 3/4: Zeroing gradients...
  Epoch 454, Batch 3/4: Forward pass...
  Epoch 454, Batch 3/4: Calculating loss...
  Epoch 454, Batch 3/4: Backward pass...
  Epoch 454, Batch 3/4: Clipping gradients...
  Epoch 454, Batch 3/4: Optimizer step...
  Epoch 454, Batch 3/4: Completed in 0.18s
  Epoch 454, Batch 4/4: Loading data to device...
  Epoch 454, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 454, Batch 4/4: Zeroing gradients...
  Epoch 454, Batch 4/4: Forward pass...
  Epoch 454, Batch 4/4: Calculating loss...
  Epoch 454, Batch 4/4: Backward pass...
  Epoch 454, Batch 4/4: Clipping gradients...
  Epoch 454, Batch 4/4: Optimizer step...
  Epoch 454, Batch 4/4: Completed in 0.03s
Epoch 454: Training phase completed. Average Train Loss: 0.3876
Epoch 454: Starting validation phase...
  Epoch 454, Val Batch 1/1: Loading data...
  Epoch 454, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 454, Val Batch 1/1: Forward pass...
  Epoch 454, Val Batch 1/1: Calculating loss...
Epoch 454: Validation phase completed. Average Val Loss: 0.2330
Epoch 454 Summary ---> Train Loss: 0.3876 / Validation Loss: 0.2330
Epoch 454: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 14)
  Epoch 454: Validation loss did not improve. Epochs without improvement: 15
Epoch 454: Stepping scheduler...
--- Epoch 454 completed in 0.65 seconds ---

--- Starting Epoch 455/1000 ---
Epoch 455: Starting training phase (4 batches)
  Epoch 455, Batch 1/4: Loading data to device...
  Epoch 455, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 455, Batch 1/4: Zeroing gradients...
  Epoch 455, Batch 1/4: Forward pass...
  Epoch 455, Batch 1/4: Calculating loss...
  Epoch 455, Batch 1/4: Backward pass...
  Epoch 455, Batch 1/4: Clipping gradients...
  Epoch 455, Batch 1/4: Optimizer step...
  Epoch 455, Batch 1/4: Completed in 0.19s
  Epoch 455, Batch 2/4: Loading data to device...
  Epoch 455, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 455, Batch 2/4: Zeroing gradients...
  Epoch 455, Batch 2/4: Forward pass...
  Epoch 455, Batch 2/4: Calculating loss...
  Epoch 455, Batch 2/4: Backward pass...
  Epoch 455, Batch 2/4: Clipping gradients...
  Epoch 455, Batch 2/4: Optimizer step...
  Epoch 455, Batch 2/4: Completed in 0.20s
  Epoch 455, Batch 3/4: Loading data to device...
  Epoch 455, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 455, Batch 3/4: Zeroing gradients...
  Epoch 455, Batch 3/4: Forward pass...
  Epoch 455, Batch 3/4: Calculating loss...
  Epoch 455, Batch 3/4: Backward pass...
  Epoch 455, Batch 3/4: Clipping gradients...
  Epoch 455, Batch 3/4: Optimizer step...
  Epoch 455, Batch 3/4: Completed in 0.20s
  Epoch 455, Batch 4/4: Loading data to device...
  Epoch 455, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 455, Batch 4/4: Zeroing gradients...
  Epoch 455, Batch 4/4: Forward pass...
  Epoch 455, Batch 4/4: Calculating loss...
  Epoch 455, Batch 4/4: Backward pass...
  Epoch 455, Batch 4/4: Clipping gradients...
  Epoch 455, Batch 4/4: Optimizer step...
  Epoch 455, Batch 4/4: Completed in 0.03s
Epoch 455: Training phase completed. Average Train Loss: 0.3738
Epoch 455: Starting validation phase...
  Epoch 455, Val Batch 1/1: Loading data...
  Epoch 455, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 455, Val Batch 1/1: Forward pass...
  Epoch 455, Val Batch 1/1: Calculating loss...
Epoch 455: Validation phase completed. Average Val Loss: 0.2243
Epoch 455 Summary ---> Train Loss: 0.3738 / Validation Loss: 0.2243
Epoch 455: Checking early stopping... (Current Best Loss: 0.2291, Epochs No Improve: 15)
  Epoch 455: Validation loss improved (0.2291 --> 0.2243). Saving model.
Epoch 455: Stepping scheduler...
--- Epoch 455 completed in 0.69 seconds ---

--- Starting Epoch 456/1000 ---
Epoch 456: Starting training phase (4 batches)
  Epoch 456, Batch 1/4: Loading data to device...
  Epoch 456, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 456, Batch 1/4: Zeroing gradients...
  Epoch 456, Batch 1/4: Forward pass...
  Epoch 456, Batch 1/4: Calculating loss...
  Epoch 456, Batch 1/4: Backward pass...
  Epoch 456, Batch 1/4: Clipping gradients...
  Epoch 456, Batch 1/4: Optimizer step...
  Epoch 456, Batch 1/4: Completed in 0.19s
  Epoch 456, Batch 2/4: Loading data to device...
  Epoch 456, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 456, Batch 2/4: Zeroing gradients...
  Epoch 456, Batch 2/4: Forward pass...
  Epoch 456, Batch 2/4: Calculating loss...
  Epoch 456, Batch 2/4: Backward pass...
  Epoch 456, Batch 2/4: Clipping gradients...
  Epoch 456, Batch 2/4: Optimizer step...
  Epoch 456, Batch 2/4: Completed in 0.19s
  Epoch 456, Batch 3/4: Loading data to device...
  Epoch 456, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 456, Batch 3/4: Zeroing gradients...
  Epoch 456, Batch 3/4: Forward pass...
  Epoch 456, Batch 3/4: Calculating loss...
  Epoch 456, Batch 3/4: Backward pass...
  Epoch 456, Batch 3/4: Clipping gradients...
  Epoch 456, Batch 3/4: Optimizer step...
  Epoch 456, Batch 3/4: Completed in 0.19s
  Epoch 456, Batch 4/4: Loading data to device...
  Epoch 456, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 456, Batch 4/4: Zeroing gradients...
  Epoch 456, Batch 4/4: Forward pass...
  Epoch 456, Batch 4/4: Calculating loss...
  Epoch 456, Batch 4/4: Backward pass...
  Epoch 456, Batch 4/4: Clipping gradients...
  Epoch 456, Batch 4/4: Optimizer step...
  Epoch 456, Batch 4/4: Completed in 0.03s
Epoch 456: Training phase completed. Average Train Loss: 0.3684
Epoch 456: Starting validation phase...
  Epoch 456, Val Batch 1/1: Loading data...
  Epoch 456, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 456, Val Batch 1/1: Forward pass...
  Epoch 456, Val Batch 1/1: Calculating loss...
Epoch 456: Validation phase completed. Average Val Loss: 0.2275
Epoch 456 Summary ---> Train Loss: 0.3684 / Validation Loss: 0.2275
Epoch 456: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 0)
  Epoch 456: Validation loss did not improve. Epochs without improvement: 1
Epoch 456: Stepping scheduler...
--- Epoch 456 completed in 0.66 seconds ---

--- Starting Epoch 457/1000 ---
Epoch 457: Starting training phase (4 batches)
  Epoch 457, Batch 1/4: Loading data to device...
  Epoch 457, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 457, Batch 1/4: Zeroing gradients...
  Epoch 457, Batch 1/4: Forward pass...
  Epoch 457, Batch 1/4: Calculating loss...
  Epoch 457, Batch 1/4: Backward pass...
  Epoch 457, Batch 1/4: Clipping gradients...
  Epoch 457, Batch 1/4: Optimizer step...
  Epoch 457, Batch 1/4: Completed in 0.20s
  Epoch 457, Batch 2/4: Loading data to device...
  Epoch 457, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 457, Batch 2/4: Zeroing gradients...
  Epoch 457, Batch 2/4: Forward pass...
  Epoch 457, Batch 2/4: Calculating loss...
  Epoch 457, Batch 2/4: Backward pass...
  Epoch 457, Batch 2/4: Clipping gradients...
  Epoch 457, Batch 2/4: Optimizer step...
  Epoch 457, Batch 2/4: Completed in 0.19s
  Epoch 457, Batch 3/4: Loading data to device...
  Epoch 457, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 457, Batch 3/4: Zeroing gradients...
  Epoch 457, Batch 3/4: Forward pass...
  Epoch 457, Batch 3/4: Calculating loss...
  Epoch 457, Batch 3/4: Backward pass...
  Epoch 457, Batch 3/4: Clipping gradients...
  Epoch 457, Batch 3/4: Optimizer step...
  Epoch 457, Batch 3/4: Completed in 0.20s
  Epoch 457, Batch 4/4: Loading data to device...
  Epoch 457, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 457, Batch 4/4: Zeroing gradients...
  Epoch 457, Batch 4/4: Forward pass...
  Epoch 457, Batch 4/4: Calculating loss...
  Epoch 457, Batch 4/4: Backward pass...
  Epoch 457, Batch 4/4: Clipping gradients...
  Epoch 457, Batch 4/4: Optimizer step...
  Epoch 457, Batch 4/4: Completed in 0.03s
Epoch 457: Training phase completed. Average Train Loss: 0.2775
Epoch 457: Starting validation phase...
  Epoch 457, Val Batch 1/1: Loading data...
  Epoch 457, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 457, Val Batch 1/1: Forward pass...
  Epoch 457, Val Batch 1/1: Calculating loss...
Epoch 457: Validation phase completed. Average Val Loss: 0.2360
Epoch 457 Summary ---> Train Loss: 0.2775 / Validation Loss: 0.2360
Epoch 457: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 1)
  Epoch 457: Validation loss did not improve. Epochs without improvement: 2
Epoch 457: Stepping scheduler...
--- Epoch 457 completed in 0.69 seconds ---

--- Starting Epoch 458/1000 ---
Epoch 458: Starting training phase (4 batches)
  Epoch 458, Batch 1/4: Loading data to device...
  Epoch 458, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 458, Batch 1/4: Zeroing gradients...
  Epoch 458, Batch 1/4: Forward pass...
  Epoch 458, Batch 1/4: Calculating loss...
  Epoch 458, Batch 1/4: Backward pass...
  Epoch 458, Batch 1/4: Clipping gradients...
  Epoch 458, Batch 1/4: Optimizer step...
  Epoch 458, Batch 1/4: Completed in 0.20s
  Epoch 458, Batch 2/4: Loading data to device...
  Epoch 458, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 458, Batch 2/4: Zeroing gradients...
  Epoch 458, Batch 2/4: Forward pass...
  Epoch 458, Batch 2/4: Calculating loss...
  Epoch 458, Batch 2/4: Backward pass...
  Epoch 458, Batch 2/4: Clipping gradients...
  Epoch 458, Batch 2/4: Optimizer step...
  Epoch 458, Batch 2/4: Completed in 0.19s
  Epoch 458, Batch 3/4: Loading data to device...
  Epoch 458, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 458, Batch 3/4: Zeroing gradients...
  Epoch 458, Batch 3/4: Forward pass...
  Epoch 458, Batch 3/4: Calculating loss...
  Epoch 458, Batch 3/4: Backward pass...
  Epoch 458, Batch 3/4: Clipping gradients...
  Epoch 458, Batch 3/4: Optimizer step...
  Epoch 458, Batch 3/4: Completed in 0.19s
  Epoch 458, Batch 4/4: Loading data to device...
  Epoch 458, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 458, Batch 4/4: Zeroing gradients...
  Epoch 458, Batch 4/4: Forward pass...
  Epoch 458, Batch 4/4: Calculating loss...
  Epoch 458, Batch 4/4: Backward pass...
  Epoch 458, Batch 4/4: Clipping gradients...
  Epoch 458, Batch 4/4: Optimizer step...
  Epoch 458, Batch 4/4: Completed in 0.03s
Epoch 458: Training phase completed. Average Train Loss: 0.2818
Epoch 458: Starting validation phase...
  Epoch 458, Val Batch 1/1: Loading data...
  Epoch 458, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 458, Val Batch 1/1: Forward pass...
  Epoch 458, Val Batch 1/1: Calculating loss...
Epoch 458: Validation phase completed. Average Val Loss: 0.2349
Epoch 458 Summary ---> Train Loss: 0.2818 / Validation Loss: 0.2349
Epoch 458: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 2)
  Epoch 458: Validation loss did not improve. Epochs without improvement: 3
Epoch 458: Stepping scheduler...
--- Epoch 458 completed in 0.67 seconds ---

--- Starting Epoch 459/1000 ---
Epoch 459: Starting training phase (4 batches)
  Epoch 459, Batch 1/4: Loading data to device...
  Epoch 459, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 459, Batch 1/4: Zeroing gradients...
  Epoch 459, Batch 1/4: Forward pass...
  Epoch 459, Batch 1/4: Calculating loss...
  Epoch 459, Batch 1/4: Backward pass...
  Epoch 459, Batch 1/4: Clipping gradients...
  Epoch 459, Batch 1/4: Optimizer step...
  Epoch 459, Batch 1/4: Completed in 0.19s
  Epoch 459, Batch 2/4: Loading data to device...
  Epoch 459, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 459, Batch 2/4: Zeroing gradients...
  Epoch 459, Batch 2/4: Forward pass...
  Epoch 459, Batch 2/4: Calculating loss...
  Epoch 459, Batch 2/4: Backward pass...
  Epoch 459, Batch 2/4: Clipping gradients...
  Epoch 459, Batch 2/4: Optimizer step...
  Epoch 459, Batch 2/4: Completed in 0.19s
  Epoch 459, Batch 3/4: Loading data to device...
  Epoch 459, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 459, Batch 3/4: Zeroing gradients...
  Epoch 459, Batch 3/4: Forward pass...
  Epoch 459, Batch 3/4: Calculating loss...
  Epoch 459, Batch 3/4: Backward pass...
  Epoch 459, Batch 3/4: Clipping gradients...
  Epoch 459, Batch 3/4: Optimizer step...
  Epoch 459, Batch 3/4: Completed in 0.19s
  Epoch 459, Batch 4/4: Loading data to device...
  Epoch 459, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 459, Batch 4/4: Zeroing gradients...
  Epoch 459, Batch 4/4: Forward pass...
  Epoch 459, Batch 4/4: Calculating loss...
  Epoch 459, Batch 4/4: Backward pass...
  Epoch 459, Batch 4/4: Clipping gradients...
  Epoch 459, Batch 4/4: Optimizer step...
  Epoch 459, Batch 4/4: Completed in 0.03s
Epoch 459: Training phase completed. Average Train Loss: 0.2919
Epoch 459: Starting validation phase...
  Epoch 459, Val Batch 1/1: Loading data...
  Epoch 459, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 459, Val Batch 1/1: Forward pass...
  Epoch 459, Val Batch 1/1: Calculating loss...
Epoch 459: Validation phase completed. Average Val Loss: 0.2382
Epoch 459 Summary ---> Train Loss: 0.2919 / Validation Loss: 0.2382
Epoch 459: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 3)
  Epoch 459: Validation loss did not improve. Epochs without improvement: 4
Epoch 459: Stepping scheduler...
--- Epoch 459 completed in 0.67 seconds ---

--- Starting Epoch 460/1000 ---
Epoch 460: Starting training phase (4 batches)
  Epoch 460, Batch 1/4: Loading data to device...
  Epoch 460, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 460, Batch 1/4: Zeroing gradients...
  Epoch 460, Batch 1/4: Forward pass...
  Epoch 460, Batch 1/4: Calculating loss...
  Epoch 460, Batch 1/4: Backward pass...
  Epoch 460, Batch 1/4: Clipping gradients...
  Epoch 460, Batch 1/4: Optimizer step...
  Epoch 460, Batch 1/4: Completed in 0.20s
  Epoch 460, Batch 2/4: Loading data to device...
  Epoch 460, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 460, Batch 2/4: Zeroing gradients...
  Epoch 460, Batch 2/4: Forward pass...
  Epoch 460, Batch 2/4: Calculating loss...
  Epoch 460, Batch 2/4: Backward pass...
  Epoch 460, Batch 2/4: Clipping gradients...
  Epoch 460, Batch 2/4: Optimizer step...
  Epoch 460, Batch 2/4: Completed in 0.20s
  Epoch 460, Batch 3/4: Loading data to device...
  Epoch 460, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 460, Batch 3/4: Zeroing gradients...
  Epoch 460, Batch 3/4: Forward pass...
  Epoch 460, Batch 3/4: Calculating loss...
  Epoch 460, Batch 3/4: Backward pass...
  Epoch 460, Batch 3/4: Clipping gradients...
  Epoch 460, Batch 3/4: Optimizer step...
  Epoch 460, Batch 3/4: Completed in 0.22s
  Epoch 460, Batch 4/4: Loading data to device...
  Epoch 460, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 460, Batch 4/4: Zeroing gradients...
  Epoch 460, Batch 4/4: Forward pass...
  Epoch 460, Batch 4/4: Calculating loss...
  Epoch 460, Batch 4/4: Backward pass...
  Epoch 460, Batch 4/4: Clipping gradients...
  Epoch 460, Batch 4/4: Optimizer step...
  Epoch 460, Batch 4/4: Completed in 0.03s
Epoch 460: Training phase completed. Average Train Loss: 0.3378
Epoch 460: Starting validation phase...
  Epoch 460, Val Batch 1/1: Loading data...
  Epoch 460, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 460, Val Batch 1/1: Forward pass...
  Epoch 460, Val Batch 1/1: Calculating loss...
Epoch 460: Validation phase completed. Average Val Loss: 0.2381
Epoch 460 Summary ---> Train Loss: 0.3378 / Validation Loss: 0.2381
Epoch 460: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 4)
  Epoch 460: Validation loss did not improve. Epochs without improvement: 5
Epoch 460: Stepping scheduler...
--- Epoch 460 completed in 0.72 seconds ---

--- Starting Epoch 461/1000 ---
Epoch 461: Starting training phase (4 batches)
  Epoch 461, Batch 1/4: Loading data to device...
  Epoch 461, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 461, Batch 1/4: Zeroing gradients...
  Epoch 461, Batch 1/4: Forward pass...
  Epoch 461, Batch 1/4: Calculating loss...
  Epoch 461, Batch 1/4: Backward pass...
  Epoch 461, Batch 1/4: Clipping gradients...
  Epoch 461, Batch 1/4: Optimizer step...
  Epoch 461, Batch 1/4: Completed in 0.20s
  Epoch 461, Batch 2/4: Loading data to device...
  Epoch 461, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 461, Batch 2/4: Zeroing gradients...
  Epoch 461, Batch 2/4: Forward pass...
  Epoch 461, Batch 2/4: Calculating loss...
  Epoch 461, Batch 2/4: Backward pass...
  Epoch 461, Batch 2/4: Clipping gradients...
  Epoch 461, Batch 2/4: Optimizer step...
  Epoch 461, Batch 2/4: Completed in 0.19s
  Epoch 461, Batch 3/4: Loading data to device...
  Epoch 461, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 461, Batch 3/4: Zeroing gradients...
  Epoch 461, Batch 3/4: Forward pass...
  Epoch 461, Batch 3/4: Calculating loss...
  Epoch 461, Batch 3/4: Backward pass...
  Epoch 461, Batch 3/4: Clipping gradients...
  Epoch 461, Batch 3/4: Optimizer step...
  Epoch 461, Batch 3/4: Completed in 0.19s
  Epoch 461, Batch 4/4: Loading data to device...
  Epoch 461, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 461, Batch 4/4: Zeroing gradients...
  Epoch 461, Batch 4/4: Forward pass...
  Epoch 461, Batch 4/4: Calculating loss...
  Epoch 461, Batch 4/4: Backward pass...
  Epoch 461, Batch 4/4: Clipping gradients...
  Epoch 461, Batch 4/4: Optimizer step...
  Epoch 461, Batch 4/4: Completed in 0.03s
Epoch 461: Training phase completed. Average Train Loss: 0.3449
Epoch 461: Starting validation phase...
  Epoch 461, Val Batch 1/1: Loading data...
  Epoch 461, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 461, Val Batch 1/1: Forward pass...
  Epoch 461, Val Batch 1/1: Calculating loss...
Epoch 461: Validation phase completed. Average Val Loss: 0.2309
Epoch 461 Summary ---> Train Loss: 0.3449 / Validation Loss: 0.2309
Epoch 461: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 5)
  Epoch 461: Validation loss did not improve. Epochs without improvement: 6
Epoch 461: Stepping scheduler...
--- Epoch 461 completed in 0.68 seconds ---

--- Starting Epoch 462/1000 ---
Epoch 462: Starting training phase (4 batches)
  Epoch 462, Batch 1/4: Loading data to device...
  Epoch 462, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 462, Batch 1/4: Zeroing gradients...
  Epoch 462, Batch 1/4: Forward pass...
  Epoch 462, Batch 1/4: Calculating loss...
  Epoch 462, Batch 1/4: Backward pass...
  Epoch 462, Batch 1/4: Clipping gradients...
  Epoch 462, Batch 1/4: Optimizer step...
  Epoch 462, Batch 1/4: Completed in 0.19s
  Epoch 462, Batch 2/4: Loading data to device...
  Epoch 462, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 462, Batch 2/4: Zeroing gradients...
  Epoch 462, Batch 2/4: Forward pass...
  Epoch 462, Batch 2/4: Calculating loss...
  Epoch 462, Batch 2/4: Backward pass...
  Epoch 462, Batch 2/4: Clipping gradients...
  Epoch 462, Batch 2/4: Optimizer step...
  Epoch 462, Batch 2/4: Completed in 0.20s
  Epoch 462, Batch 3/4: Loading data to device...
  Epoch 462, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 462, Batch 3/4: Zeroing gradients...
  Epoch 462, Batch 3/4: Forward pass...
  Epoch 462, Batch 3/4: Calculating loss...
  Epoch 462, Batch 3/4: Backward pass...
  Epoch 462, Batch 3/4: Clipping gradients...
  Epoch 462, Batch 3/4: Optimizer step...
  Epoch 462, Batch 3/4: Completed in 0.20s
  Epoch 462, Batch 4/4: Loading data to device...
  Epoch 462, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 462, Batch 4/4: Zeroing gradients...
  Epoch 462, Batch 4/4: Forward pass...
  Epoch 462, Batch 4/4: Calculating loss...
  Epoch 462, Batch 4/4: Backward pass...
  Epoch 462, Batch 4/4: Clipping gradients...
  Epoch 462, Batch 4/4: Optimizer step...
  Epoch 462, Batch 4/4: Completed in 0.03s
Epoch 462: Training phase completed. Average Train Loss: 0.2735
Epoch 462: Starting validation phase...
  Epoch 462, Val Batch 1/1: Loading data...
  Epoch 462, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 462, Val Batch 1/1: Forward pass...
  Epoch 462, Val Batch 1/1: Calculating loss...
Epoch 462: Validation phase completed. Average Val Loss: 0.2321
Epoch 462 Summary ---> Train Loss: 0.2735 / Validation Loss: 0.2321
Epoch 462: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 6)
  Epoch 462: Validation loss did not improve. Epochs without improvement: 7
Epoch 462: Stepping scheduler...
--- Epoch 462 completed in 0.70 seconds ---

--- Starting Epoch 463/1000 ---
Epoch 463: Starting training phase (4 batches)
  Epoch 463, Batch 1/4: Loading data to device...
  Epoch 463, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 463, Batch 1/4: Zeroing gradients...
  Epoch 463, Batch 1/4: Forward pass...
  Epoch 463, Batch 1/4: Calculating loss...
  Epoch 463, Batch 1/4: Backward pass...
  Epoch 463, Batch 1/4: Clipping gradients...
  Epoch 463, Batch 1/4: Optimizer step...
  Epoch 463, Batch 1/4: Completed in 0.20s
  Epoch 463, Batch 2/4: Loading data to device...
  Epoch 463, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 463, Batch 2/4: Zeroing gradients...
  Epoch 463, Batch 2/4: Forward pass...
  Epoch 463, Batch 2/4: Calculating loss...
  Epoch 463, Batch 2/4: Backward pass...
  Epoch 463, Batch 2/4: Clipping gradients...
  Epoch 463, Batch 2/4: Optimizer step...
  Epoch 463, Batch 2/4: Completed in 0.20s
  Epoch 463, Batch 3/4: Loading data to device...
  Epoch 463, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 463, Batch 3/4: Zeroing gradients...
  Epoch 463, Batch 3/4: Forward pass...
  Epoch 463, Batch 3/4: Calculating loss...
  Epoch 463, Batch 3/4: Backward pass...
  Epoch 463, Batch 3/4: Clipping gradients...
  Epoch 463, Batch 3/4: Optimizer step...
  Epoch 463, Batch 3/4: Completed in 0.20s
  Epoch 463, Batch 4/4: Loading data to device...
  Epoch 463, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 463, Batch 4/4: Zeroing gradients...
  Epoch 463, Batch 4/4: Forward pass...
  Epoch 463, Batch 4/4: Calculating loss...
  Epoch 463, Batch 4/4: Backward pass...
  Epoch 463, Batch 4/4: Clipping gradients...
  Epoch 463, Batch 4/4: Optimizer step...
  Epoch 463, Batch 4/4: Completed in 0.03s
Epoch 463: Training phase completed. Average Train Loss: 0.3659
Epoch 463: Starting validation phase...
  Epoch 463, Val Batch 1/1: Loading data...
  Epoch 463, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 463, Val Batch 1/1: Forward pass...
  Epoch 463, Val Batch 1/1: Calculating loss...
Epoch 463: Validation phase completed. Average Val Loss: 0.2330
Epoch 463 Summary ---> Train Loss: 0.3659 / Validation Loss: 0.2330
Epoch 463: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 7)
  Epoch 463: Validation loss did not improve. Epochs without improvement: 8
Epoch 463: Stepping scheduler...
--- Epoch 463 completed in 0.70 seconds ---

--- Starting Epoch 464/1000 ---
Epoch 464: Starting training phase (4 batches)
  Epoch 464, Batch 1/4: Loading data to device...
  Epoch 464, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 464, Batch 1/4: Zeroing gradients...
  Epoch 464, Batch 1/4: Forward pass...
  Epoch 464, Batch 1/4: Calculating loss...
  Epoch 464, Batch 1/4: Backward pass...
  Epoch 464, Batch 1/4: Clipping gradients...
  Epoch 464, Batch 1/4: Optimizer step...
  Epoch 464, Batch 1/4: Completed in 0.20s
  Epoch 464, Batch 2/4: Loading data to device...
  Epoch 464, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 464, Batch 2/4: Zeroing gradients...
  Epoch 464, Batch 2/4: Forward pass...
  Epoch 464, Batch 2/4: Calculating loss...
  Epoch 464, Batch 2/4: Backward pass...
  Epoch 464, Batch 2/4: Clipping gradients...
  Epoch 464, Batch 2/4: Optimizer step...
  Epoch 464, Batch 2/4: Completed in 0.20s
  Epoch 464, Batch 3/4: Loading data to device...
  Epoch 464, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 464, Batch 3/4: Zeroing gradients...
  Epoch 464, Batch 3/4: Forward pass...
  Epoch 464, Batch 3/4: Calculating loss...
  Epoch 464, Batch 3/4: Backward pass...
  Epoch 464, Batch 3/4: Clipping gradients...
  Epoch 464, Batch 3/4: Optimizer step...
  Epoch 464, Batch 3/4: Completed in 0.20s
  Epoch 464, Batch 4/4: Loading data to device...
  Epoch 464, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 464, Batch 4/4: Zeroing gradients...
  Epoch 464, Batch 4/4: Forward pass...
  Epoch 464, Batch 4/4: Calculating loss...
  Epoch 464, Batch 4/4: Backward pass...
  Epoch 464, Batch 4/4: Clipping gradients...
  Epoch 464, Batch 4/4: Optimizer step...
  Epoch 464, Batch 4/4: Completed in 0.03s
Epoch 464: Training phase completed. Average Train Loss: 0.2848
Epoch 464: Starting validation phase...
  Epoch 464, Val Batch 1/1: Loading data...
  Epoch 464, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 464, Val Batch 1/1: Forward pass...
  Epoch 464, Val Batch 1/1: Calculating loss...
Epoch 464: Validation phase completed. Average Val Loss: 0.2330
Epoch 464 Summary ---> Train Loss: 0.2848 / Validation Loss: 0.2330
Epoch 464: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 8)
  Epoch 464: Validation loss did not improve. Epochs without improvement: 9
Epoch 464: Stepping scheduler...
--- Epoch 464 completed in 0.70 seconds ---

--- Starting Epoch 465/1000 ---
Epoch 465: Starting training phase (4 batches)
  Epoch 465, Batch 1/4: Loading data to device...
  Epoch 465, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 465, Batch 1/4: Zeroing gradients...
  Epoch 465, Batch 1/4: Forward pass...
  Epoch 465, Batch 1/4: Calculating loss...
  Epoch 465, Batch 1/4: Backward pass...
  Epoch 465, Batch 1/4: Clipping gradients...
  Epoch 465, Batch 1/4: Optimizer step...
  Epoch 465, Batch 1/4: Completed in 0.19s
  Epoch 465, Batch 2/4: Loading data to device...
  Epoch 465, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 465, Batch 2/4: Zeroing gradients...
  Epoch 465, Batch 2/4: Forward pass...
  Epoch 465, Batch 2/4: Calculating loss...
  Epoch 465, Batch 2/4: Backward pass...
  Epoch 465, Batch 2/4: Clipping gradients...
  Epoch 465, Batch 2/4: Optimizer step...
  Epoch 465, Batch 2/4: Completed in 0.20s
  Epoch 465, Batch 3/4: Loading data to device...
  Epoch 465, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 465, Batch 3/4: Zeroing gradients...
  Epoch 465, Batch 3/4: Forward pass...
  Epoch 465, Batch 3/4: Calculating loss...
  Epoch 465, Batch 3/4: Backward pass...
  Epoch 465, Batch 3/4: Clipping gradients...
  Epoch 465, Batch 3/4: Optimizer step...
  Epoch 465, Batch 3/4: Completed in 0.20s
  Epoch 465, Batch 4/4: Loading data to device...
  Epoch 465, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 465, Batch 4/4: Zeroing gradients...
  Epoch 465, Batch 4/4: Forward pass...
  Epoch 465, Batch 4/4: Calculating loss...
  Epoch 465, Batch 4/4: Backward pass...
  Epoch 465, Batch 4/4: Clipping gradients...
  Epoch 465, Batch 4/4: Optimizer step...
  Epoch 465, Batch 4/4: Completed in 0.03s
Epoch 465: Training phase completed. Average Train Loss: 0.3363
Epoch 465: Starting validation phase...
  Epoch 465, Val Batch 1/1: Loading data...
  Epoch 465, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 465, Val Batch 1/1: Forward pass...
  Epoch 465, Val Batch 1/1: Calculating loss...
Epoch 465: Validation phase completed. Average Val Loss: 0.2327
Epoch 465 Summary ---> Train Loss: 0.3363 / Validation Loss: 0.2327
Epoch 465: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 9)
  Epoch 465: Validation loss did not improve. Epochs without improvement: 10
Epoch 465: Stepping scheduler...
--- Epoch 465 completed in 0.68 seconds ---

--- Starting Epoch 466/1000 ---
Epoch 466: Starting training phase (4 batches)
  Epoch 466, Batch 1/4: Loading data to device...
  Epoch 466, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 466, Batch 1/4: Zeroing gradients...
  Epoch 466, Batch 1/4: Forward pass...
  Epoch 466, Batch 1/4: Calculating loss...
  Epoch 466, Batch 1/4: Backward pass...
  Epoch 466, Batch 1/4: Clipping gradients...
  Epoch 466, Batch 1/4: Optimizer step...
  Epoch 466, Batch 1/4: Completed in 0.20s
  Epoch 466, Batch 2/4: Loading data to device...
  Epoch 466, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 466, Batch 2/4: Zeroing gradients...
  Epoch 466, Batch 2/4: Forward pass...
  Epoch 466, Batch 2/4: Calculating loss...
  Epoch 466, Batch 2/4: Backward pass...
  Epoch 466, Batch 2/4: Clipping gradients...
  Epoch 466, Batch 2/4: Optimizer step...
  Epoch 466, Batch 2/4: Completed in 0.19s
  Epoch 466, Batch 3/4: Loading data to device...
  Epoch 466, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 466, Batch 3/4: Zeroing gradients...
  Epoch 466, Batch 3/4: Forward pass...
  Epoch 466, Batch 3/4: Calculating loss...
  Epoch 466, Batch 3/4: Backward pass...
  Epoch 466, Batch 3/4: Clipping gradients...
  Epoch 466, Batch 3/4: Optimizer step...
  Epoch 466, Batch 3/4: Completed in 0.20s
  Epoch 466, Batch 4/4: Loading data to device...
  Epoch 466, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 466, Batch 4/4: Zeroing gradients...
  Epoch 466, Batch 4/4: Forward pass...
  Epoch 466, Batch 4/4: Calculating loss...
  Epoch 466, Batch 4/4: Backward pass...
  Epoch 466, Batch 4/4: Clipping gradients...
  Epoch 466, Batch 4/4: Optimizer step...
  Epoch 466, Batch 4/4: Completed in 0.03s
Epoch 466: Training phase completed. Average Train Loss: 0.3014
Epoch 466: Starting validation phase...
  Epoch 466, Val Batch 1/1: Loading data...
  Epoch 466, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 466, Val Batch 1/1: Forward pass...
  Epoch 466, Val Batch 1/1: Calculating loss...
Epoch 466: Validation phase completed. Average Val Loss: 0.2304
Epoch 466 Summary ---> Train Loss: 0.3014 / Validation Loss: 0.2304
Epoch 466: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 10)
  Epoch 466: Validation loss did not improve. Epochs without improvement: 11
Epoch 466: Stepping scheduler...
--- Epoch 466 completed in 0.68 seconds ---

--- Starting Epoch 467/1000 ---
Epoch 467: Starting training phase (4 batches)
  Epoch 467, Batch 1/4: Loading data to device...
  Epoch 467, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 467, Batch 1/4: Zeroing gradients...
  Epoch 467, Batch 1/4: Forward pass...
  Epoch 467, Batch 1/4: Calculating loss...
  Epoch 467, Batch 1/4: Backward pass...
  Epoch 467, Batch 1/4: Clipping gradients...
  Epoch 467, Batch 1/4: Optimizer step...
  Epoch 467, Batch 1/4: Completed in 0.20s
  Epoch 467, Batch 2/4: Loading data to device...
  Epoch 467, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 467, Batch 2/4: Zeroing gradients...
  Epoch 467, Batch 2/4: Forward pass...
  Epoch 467, Batch 2/4: Calculating loss...
  Epoch 467, Batch 2/4: Backward pass...
  Epoch 467, Batch 2/4: Clipping gradients...
  Epoch 467, Batch 2/4: Optimizer step...
  Epoch 467, Batch 2/4: Completed in 0.20s
  Epoch 467, Batch 3/4: Loading data to device...
  Epoch 467, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 467, Batch 3/4: Zeroing gradients...
  Epoch 467, Batch 3/4: Forward pass...
  Epoch 467, Batch 3/4: Calculating loss...
  Epoch 467, Batch 3/4: Backward pass...
  Epoch 467, Batch 3/4: Clipping gradients...
  Epoch 467, Batch 3/4: Optimizer step...
  Epoch 467, Batch 3/4: Completed in 0.20s
  Epoch 467, Batch 4/4: Loading data to device...
  Epoch 467, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 467, Batch 4/4: Zeroing gradients...
  Epoch 467, Batch 4/4: Forward pass...
  Epoch 467, Batch 4/4: Calculating loss...
  Epoch 467, Batch 4/4: Backward pass...
  Epoch 467, Batch 4/4: Clipping gradients...
  Epoch 467, Batch 4/4: Optimizer step...
  Epoch 467, Batch 4/4: Completed in 0.03s
Epoch 467: Training phase completed. Average Train Loss: 0.5029
Epoch 467: Starting validation phase...
  Epoch 467, Val Batch 1/1: Loading data...
  Epoch 467, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 467, Val Batch 1/1: Forward pass...
  Epoch 467, Val Batch 1/1: Calculating loss...
Epoch 467: Validation phase completed. Average Val Loss: 0.2330
Epoch 467 Summary ---> Train Loss: 0.5029 / Validation Loss: 0.2330
Epoch 467: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 11)
  Epoch 467: Validation loss did not improve. Epochs without improvement: 12
Epoch 467: Stepping scheduler...
--- Epoch 467 completed in 0.69 seconds ---

--- Starting Epoch 468/1000 ---
Epoch 468: Starting training phase (4 batches)
  Epoch 468, Batch 1/4: Loading data to device...
  Epoch 468, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 468, Batch 1/4: Zeroing gradients...
  Epoch 468, Batch 1/4: Forward pass...
  Epoch 468, Batch 1/4: Calculating loss...
  Epoch 468, Batch 1/4: Backward pass...
  Epoch 468, Batch 1/4: Clipping gradients...
  Epoch 468, Batch 1/4: Optimizer step...
  Epoch 468, Batch 1/4: Completed in 0.19s
  Epoch 468, Batch 2/4: Loading data to device...
  Epoch 468, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 468, Batch 2/4: Zeroing gradients...
  Epoch 468, Batch 2/4: Forward pass...
  Epoch 468, Batch 2/4: Calculating loss...
  Epoch 468, Batch 2/4: Backward pass...
  Epoch 468, Batch 2/4: Clipping gradients...
  Epoch 468, Batch 2/4: Optimizer step...
  Epoch 468, Batch 2/4: Completed in 0.19s
  Epoch 468, Batch 3/4: Loading data to device...
  Epoch 468, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 468, Batch 3/4: Zeroing gradients...
  Epoch 468, Batch 3/4: Forward pass...
  Epoch 468, Batch 3/4: Calculating loss...
  Epoch 468, Batch 3/4: Backward pass...
  Epoch 468, Batch 3/4: Clipping gradients...
  Epoch 468, Batch 3/4: Optimizer step...
  Epoch 468, Batch 3/4: Completed in 0.19s
  Epoch 468, Batch 4/4: Loading data to device...
  Epoch 468, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 468, Batch 4/4: Zeroing gradients...
  Epoch 468, Batch 4/4: Forward pass...
  Epoch 468, Batch 4/4: Calculating loss...
  Epoch 468, Batch 4/4: Backward pass...
  Epoch 468, Batch 4/4: Clipping gradients...
  Epoch 468, Batch 4/4: Optimizer step...
  Epoch 468, Batch 4/4: Completed in 0.03s
Epoch 468: Training phase completed. Average Train Loss: 0.3133
Epoch 468: Starting validation phase...
  Epoch 468, Val Batch 1/1: Loading data...
  Epoch 468, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 468, Val Batch 1/1: Forward pass...
  Epoch 468, Val Batch 1/1: Calculating loss...
Epoch 468: Validation phase completed. Average Val Loss: 0.2353
Epoch 468 Summary ---> Train Loss: 0.3133 / Validation Loss: 0.2353
Epoch 468: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 12)
  Epoch 468: Validation loss did not improve. Epochs without improvement: 13
Epoch 468: Stepping scheduler...
--- Epoch 468 completed in 0.65 seconds ---

--- Starting Epoch 469/1000 ---
Epoch 469: Starting training phase (4 batches)
  Epoch 469, Batch 1/4: Loading data to device...
  Epoch 469, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 469, Batch 1/4: Zeroing gradients...
  Epoch 469, Batch 1/4: Forward pass...
  Epoch 469, Batch 1/4: Calculating loss...
  Epoch 469, Batch 1/4: Backward pass...
  Epoch 469, Batch 1/4: Clipping gradients...
  Epoch 469, Batch 1/4: Optimizer step...
  Epoch 469, Batch 1/4: Completed in 0.19s
  Epoch 469, Batch 2/4: Loading data to device...
  Epoch 469, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 469, Batch 2/4: Zeroing gradients...
  Epoch 469, Batch 2/4: Forward pass...
  Epoch 469, Batch 2/4: Calculating loss...
  Epoch 469, Batch 2/4: Backward pass...
  Epoch 469, Batch 2/4: Clipping gradients...
  Epoch 469, Batch 2/4: Optimizer step...
  Epoch 469, Batch 2/4: Completed in 0.19s
  Epoch 469, Batch 3/4: Loading data to device...
  Epoch 469, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 469, Batch 3/4: Zeroing gradients...
  Epoch 469, Batch 3/4: Forward pass...
  Epoch 469, Batch 3/4: Calculating loss...
  Epoch 469, Batch 3/4: Backward pass...
  Epoch 469, Batch 3/4: Clipping gradients...
  Epoch 469, Batch 3/4: Optimizer step...
  Epoch 469, Batch 3/4: Completed in 0.19s
  Epoch 469, Batch 4/4: Loading data to device...
  Epoch 469, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 469, Batch 4/4: Zeroing gradients...
  Epoch 469, Batch 4/4: Forward pass...
  Epoch 469, Batch 4/4: Calculating loss...
  Epoch 469, Batch 4/4: Backward pass...
  Epoch 469, Batch 4/4: Clipping gradients...
  Epoch 469, Batch 4/4: Optimizer step...
  Epoch 469, Batch 4/4: Completed in 0.03s
Epoch 469: Training phase completed. Average Train Loss: 0.2889
Epoch 469: Starting validation phase...
  Epoch 469, Val Batch 1/1: Loading data...
  Epoch 469, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 469, Val Batch 1/1: Forward pass...
  Epoch 469, Val Batch 1/1: Calculating loss...
Epoch 469: Validation phase completed. Average Val Loss: 0.2345
Epoch 469 Summary ---> Train Loss: 0.2889 / Validation Loss: 0.2345
Epoch 469: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 13)
  Epoch 469: Validation loss did not improve. Epochs without improvement: 14
Epoch 469: Stepping scheduler...
--- Epoch 469 completed in 0.66 seconds ---

--- Starting Epoch 470/1000 ---
Epoch 470: Starting training phase (4 batches)
  Epoch 470, Batch 1/4: Loading data to device...
  Epoch 470, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 470, Batch 1/4: Zeroing gradients...
  Epoch 470, Batch 1/4: Forward pass...
  Epoch 470, Batch 1/4: Calculating loss...
  Epoch 470, Batch 1/4: Backward pass...
  Epoch 470, Batch 1/4: Clipping gradients...
  Epoch 470, Batch 1/4: Optimizer step...
  Epoch 470, Batch 1/4: Completed in 0.19s
  Epoch 470, Batch 2/4: Loading data to device...
  Epoch 470, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 470, Batch 2/4: Zeroing gradients...
  Epoch 470, Batch 2/4: Forward pass...
  Epoch 470, Batch 2/4: Calculating loss...
  Epoch 470, Batch 2/4: Backward pass...
  Epoch 470, Batch 2/4: Clipping gradients...
  Epoch 470, Batch 2/4: Optimizer step...
  Epoch 470, Batch 2/4: Completed in 0.19s
  Epoch 470, Batch 3/4: Loading data to device...
  Epoch 470, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 470, Batch 3/4: Zeroing gradients...
  Epoch 470, Batch 3/4: Forward pass...
  Epoch 470, Batch 3/4: Calculating loss...
  Epoch 470, Batch 3/4: Backward pass...
  Epoch 470, Batch 3/4: Clipping gradients...
  Epoch 470, Batch 3/4: Optimizer step...
  Epoch 470, Batch 3/4: Completed in 0.20s
  Epoch 470, Batch 4/4: Loading data to device...
  Epoch 470, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 470, Batch 4/4: Zeroing gradients...
  Epoch 470, Batch 4/4: Forward pass...
  Epoch 470, Batch 4/4: Calculating loss...
  Epoch 470, Batch 4/4: Backward pass...
  Epoch 470, Batch 4/4: Clipping gradients...
  Epoch 470, Batch 4/4: Optimizer step...
  Epoch 470, Batch 4/4: Completed in 0.03s
Epoch 470: Training phase completed. Average Train Loss: 0.3763
Epoch 470: Starting validation phase...
  Epoch 470, Val Batch 1/1: Loading data...
  Epoch 470, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 470, Val Batch 1/1: Forward pass...
  Epoch 470, Val Batch 1/1: Calculating loss...
Epoch 470: Validation phase completed. Average Val Loss: 0.2323
Epoch 470 Summary ---> Train Loss: 0.3763 / Validation Loss: 0.2323
Epoch 470: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 14)
  Epoch 470: Validation loss did not improve. Epochs without improvement: 15
Epoch 470: Stepping scheduler...
--- Epoch 470 completed in 0.68 seconds ---

--- Starting Epoch 471/1000 ---
Epoch 471: Starting training phase (4 batches)
  Epoch 471, Batch 1/4: Loading data to device...
  Epoch 471, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 471, Batch 1/4: Zeroing gradients...
  Epoch 471, Batch 1/4: Forward pass...
  Epoch 471, Batch 1/4: Calculating loss...
  Epoch 471, Batch 1/4: Backward pass...
  Epoch 471, Batch 1/4: Clipping gradients...
  Epoch 471, Batch 1/4: Optimizer step...
  Epoch 471, Batch 1/4: Completed in 0.19s
  Epoch 471, Batch 2/4: Loading data to device...
  Epoch 471, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 471, Batch 2/4: Zeroing gradients...
  Epoch 471, Batch 2/4: Forward pass...
  Epoch 471, Batch 2/4: Calculating loss...
  Epoch 471, Batch 2/4: Backward pass...
  Epoch 471, Batch 2/4: Clipping gradients...
  Epoch 471, Batch 2/4: Optimizer step...
  Epoch 471, Batch 2/4: Completed in 0.19s
  Epoch 471, Batch 3/4: Loading data to device...
  Epoch 471, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 471, Batch 3/4: Zeroing gradients...
  Epoch 471, Batch 3/4: Forward pass...
  Epoch 471, Batch 3/4: Calculating loss...
  Epoch 471, Batch 3/4: Backward pass...
  Epoch 471, Batch 3/4: Clipping gradients...
  Epoch 471, Batch 3/4: Optimizer step...
  Epoch 471, Batch 3/4: Completed in 0.20s
  Epoch 471, Batch 4/4: Loading data to device...
  Epoch 471, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 471, Batch 4/4: Zeroing gradients...
  Epoch 471, Batch 4/4: Forward pass...
  Epoch 471, Batch 4/4: Calculating loss...
  Epoch 471, Batch 4/4: Backward pass...
  Epoch 471, Batch 4/4: Clipping gradients...
  Epoch 471, Batch 4/4: Optimizer step...
  Epoch 471, Batch 4/4: Completed in 0.03s
Epoch 471: Training phase completed. Average Train Loss: 0.2897
Epoch 471: Starting validation phase...
  Epoch 471, Val Batch 1/1: Loading data...
  Epoch 471, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 471, Val Batch 1/1: Forward pass...
  Epoch 471, Val Batch 1/1: Calculating loss...
Epoch 471: Validation phase completed. Average Val Loss: 0.2296
Epoch 471 Summary ---> Train Loss: 0.2897 / Validation Loss: 0.2296
Epoch 471: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 15)
  Epoch 471: Validation loss did not improve. Epochs without improvement: 16
Epoch 471: Stepping scheduler...
--- Epoch 471 completed in 0.67 seconds ---

--- Starting Epoch 472/1000 ---
Epoch 472: Starting training phase (4 batches)
  Epoch 472, Batch 1/4: Loading data to device...
  Epoch 472, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 472, Batch 1/4: Zeroing gradients...
  Epoch 472, Batch 1/4: Forward pass...
  Epoch 472, Batch 1/4: Calculating loss...
  Epoch 472, Batch 1/4: Backward pass...
  Epoch 472, Batch 1/4: Clipping gradients...
  Epoch 472, Batch 1/4: Optimizer step...
  Epoch 472, Batch 1/4: Completed in 0.20s
  Epoch 472, Batch 2/4: Loading data to device...
  Epoch 472, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 472, Batch 2/4: Zeroing gradients...
  Epoch 472, Batch 2/4: Forward pass...
  Epoch 472, Batch 2/4: Calculating loss...
  Epoch 472, Batch 2/4: Backward pass...
  Epoch 472, Batch 2/4: Clipping gradients...
  Epoch 472, Batch 2/4: Optimizer step...
  Epoch 472, Batch 2/4: Completed in 0.19s
  Epoch 472, Batch 3/4: Loading data to device...
  Epoch 472, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 472, Batch 3/4: Zeroing gradients...
  Epoch 472, Batch 3/4: Forward pass...
  Epoch 472, Batch 3/4: Calculating loss...
  Epoch 472, Batch 3/4: Backward pass...
  Epoch 472, Batch 3/4: Clipping gradients...
  Epoch 472, Batch 3/4: Optimizer step...
  Epoch 472, Batch 3/4: Completed in 0.20s
  Epoch 472, Batch 4/4: Loading data to device...
  Epoch 472, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 472, Batch 4/4: Zeroing gradients...
  Epoch 472, Batch 4/4: Forward pass...
  Epoch 472, Batch 4/4: Calculating loss...
  Epoch 472, Batch 4/4: Backward pass...
  Epoch 472, Batch 4/4: Clipping gradients...
  Epoch 472, Batch 4/4: Optimizer step...
  Epoch 472, Batch 4/4: Completed in 0.03s
Epoch 472: Training phase completed. Average Train Loss: 0.3835
Epoch 472: Starting validation phase...
  Epoch 472, Val Batch 1/1: Loading data...
  Epoch 472, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 472, Val Batch 1/1: Forward pass...
  Epoch 472, Val Batch 1/1: Calculating loss...
Epoch 472: Validation phase completed. Average Val Loss: 0.2261
Epoch 472 Summary ---> Train Loss: 0.3835 / Validation Loss: 0.2261
Epoch 472: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 16)
  Epoch 472: Validation loss did not improve. Epochs without improvement: 17
Epoch 472: Stepping scheduler...
--- Epoch 472 completed in 0.68 seconds ---

--- Starting Epoch 473/1000 ---
Epoch 473: Starting training phase (4 batches)
  Epoch 473, Batch 1/4: Loading data to device...
  Epoch 473, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 473, Batch 1/4: Zeroing gradients...
  Epoch 473, Batch 1/4: Forward pass...
  Epoch 473, Batch 1/4: Calculating loss...
  Epoch 473, Batch 1/4: Backward pass...
  Epoch 473, Batch 1/4: Clipping gradients...
  Epoch 473, Batch 1/4: Optimizer step...
  Epoch 473, Batch 1/4: Completed in 0.19s
  Epoch 473, Batch 2/4: Loading data to device...
  Epoch 473, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 473, Batch 2/4: Zeroing gradients...
  Epoch 473, Batch 2/4: Forward pass...
  Epoch 473, Batch 2/4: Calculating loss...
  Epoch 473, Batch 2/4: Backward pass...
  Epoch 473, Batch 2/4: Clipping gradients...
  Epoch 473, Batch 2/4: Optimizer step...
  Epoch 473, Batch 2/4: Completed in 0.19s
  Epoch 473, Batch 3/4: Loading data to device...
  Epoch 473, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 473, Batch 3/4: Zeroing gradients...
  Epoch 473, Batch 3/4: Forward pass...
  Epoch 473, Batch 3/4: Calculating loss...
  Epoch 473, Batch 3/4: Backward pass...
  Epoch 473, Batch 3/4: Clipping gradients...
  Epoch 473, Batch 3/4: Optimizer step...
  Epoch 473, Batch 3/4: Completed in 0.19s
  Epoch 473, Batch 4/4: Loading data to device...
  Epoch 473, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 473, Batch 4/4: Zeroing gradients...
  Epoch 473, Batch 4/4: Forward pass...
  Epoch 473, Batch 4/4: Calculating loss...
  Epoch 473, Batch 4/4: Backward pass...
  Epoch 473, Batch 4/4: Clipping gradients...
  Epoch 473, Batch 4/4: Optimizer step...
  Epoch 473, Batch 4/4: Completed in 0.03s
Epoch 473: Training phase completed. Average Train Loss: 0.4847
Epoch 473: Starting validation phase...
  Epoch 473, Val Batch 1/1: Loading data...
  Epoch 473, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 473, Val Batch 1/1: Forward pass...
  Epoch 473, Val Batch 1/1: Calculating loss...
Epoch 473: Validation phase completed. Average Val Loss: 0.2269
Epoch 473 Summary ---> Train Loss: 0.4847 / Validation Loss: 0.2269
Epoch 473: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 17)
  Epoch 473: Validation loss did not improve. Epochs without improvement: 18
Epoch 473: Stepping scheduler...
--- Epoch 473 completed in 0.67 seconds ---

--- Starting Epoch 474/1000 ---
Epoch 474: Starting training phase (4 batches)
  Epoch 474, Batch 1/4: Loading data to device...
  Epoch 474, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 474, Batch 1/4: Zeroing gradients...
  Epoch 474, Batch 1/4: Forward pass...
  Epoch 474, Batch 1/4: Calculating loss...
  Epoch 474, Batch 1/4: Backward pass...
  Epoch 474, Batch 1/4: Clipping gradients...
  Epoch 474, Batch 1/4: Optimizer step...
  Epoch 474, Batch 1/4: Completed in 0.19s
  Epoch 474, Batch 2/4: Loading data to device...
  Epoch 474, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 474, Batch 2/4: Zeroing gradients...
  Epoch 474, Batch 2/4: Forward pass...
  Epoch 474, Batch 2/4: Calculating loss...
  Epoch 474, Batch 2/4: Backward pass...
  Epoch 474, Batch 2/4: Clipping gradients...
  Epoch 474, Batch 2/4: Optimizer step...
  Epoch 474, Batch 2/4: Completed in 0.19s
  Epoch 474, Batch 3/4: Loading data to device...
  Epoch 474, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 474, Batch 3/4: Zeroing gradients...
  Epoch 474, Batch 3/4: Forward pass...
  Epoch 474, Batch 3/4: Calculating loss...
  Epoch 474, Batch 3/4: Backward pass...
  Epoch 474, Batch 3/4: Clipping gradients...
  Epoch 474, Batch 3/4: Optimizer step...
  Epoch 474, Batch 3/4: Completed in 0.19s
  Epoch 474, Batch 4/4: Loading data to device...
  Epoch 474, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 474, Batch 4/4: Zeroing gradients...
  Epoch 474, Batch 4/4: Forward pass...
  Epoch 474, Batch 4/4: Calculating loss...
  Epoch 474, Batch 4/4: Backward pass...
  Epoch 474, Batch 4/4: Clipping gradients...
  Epoch 474, Batch 4/4: Optimizer step...
  Epoch 474, Batch 4/4: Completed in 0.03s
Epoch 474: Training phase completed. Average Train Loss: 0.2856
Epoch 474: Starting validation phase...
  Epoch 474, Val Batch 1/1: Loading data...
  Epoch 474, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 474, Val Batch 1/1: Forward pass...
  Epoch 474, Val Batch 1/1: Calculating loss...
Epoch 474: Validation phase completed. Average Val Loss: 0.2229
Epoch 474 Summary ---> Train Loss: 0.2856 / Validation Loss: 0.2229
Epoch 474: Checking early stopping... (Current Best Loss: 0.2243, Epochs No Improve: 18)
  Epoch 474: Validation loss improved (0.2243 --> 0.2229). Saving model.
Epoch 474: Stepping scheduler...
--- Epoch 474 completed in 0.66 seconds ---

--- Starting Epoch 475/1000 ---
Epoch 475: Starting training phase (4 batches)
  Epoch 475, Batch 1/4: Loading data to device...
  Epoch 475, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 475, Batch 1/4: Zeroing gradients...
  Epoch 475, Batch 1/4: Forward pass...
  Epoch 475, Batch 1/4: Calculating loss...
  Epoch 475, Batch 1/4: Backward pass...
  Epoch 475, Batch 1/4: Clipping gradients...
  Epoch 475, Batch 1/4: Optimizer step...
  Epoch 475, Batch 1/4: Completed in 0.19s
  Epoch 475, Batch 2/4: Loading data to device...
  Epoch 475, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 475, Batch 2/4: Zeroing gradients...
  Epoch 475, Batch 2/4: Forward pass...
  Epoch 475, Batch 2/4: Calculating loss...
  Epoch 475, Batch 2/4: Backward pass...
  Epoch 475, Batch 2/4: Clipping gradients...
  Epoch 475, Batch 2/4: Optimizer step...
  Epoch 475, Batch 2/4: Completed in 0.19s
  Epoch 475, Batch 3/4: Loading data to device...
  Epoch 475, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 475, Batch 3/4: Zeroing gradients...
  Epoch 475, Batch 3/4: Forward pass...
  Epoch 475, Batch 3/4: Calculating loss...
  Epoch 475, Batch 3/4: Backward pass...
  Epoch 475, Batch 3/4: Clipping gradients...
  Epoch 475, Batch 3/4: Optimizer step...
  Epoch 475, Batch 3/4: Completed in 0.19s
  Epoch 475, Batch 4/4: Loading data to device...
  Epoch 475, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 475, Batch 4/4: Zeroing gradients...
  Epoch 475, Batch 4/4: Forward pass...
  Epoch 475, Batch 4/4: Calculating loss...
  Epoch 475, Batch 4/4: Backward pass...
  Epoch 475, Batch 4/4: Clipping gradients...
  Epoch 475, Batch 4/4: Optimizer step...
  Epoch 475, Batch 4/4: Completed in 0.03s
Epoch 475: Training phase completed. Average Train Loss: 0.3130
Epoch 475: Starting validation phase...
  Epoch 475, Val Batch 1/1: Loading data...
  Epoch 475, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 475, Val Batch 1/1: Forward pass...
  Epoch 475, Val Batch 1/1: Calculating loss...
Epoch 475: Validation phase completed. Average Val Loss: 0.2202
Epoch 475 Summary ---> Train Loss: 0.3130 / Validation Loss: 0.2202
Epoch 475: Checking early stopping... (Current Best Loss: 0.2229, Epochs No Improve: 0)
  Epoch 475: Validation loss improved (0.2229 --> 0.2202). Saving model.
Epoch 475: Stepping scheduler...
--- Epoch 475 completed in 0.66 seconds ---

--- Starting Epoch 476/1000 ---
Epoch 476: Starting training phase (4 batches)
  Epoch 476, Batch 1/4: Loading data to device...
  Epoch 476, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 476, Batch 1/4: Zeroing gradients...
  Epoch 476, Batch 1/4: Forward pass...
  Epoch 476, Batch 1/4: Calculating loss...
  Epoch 476, Batch 1/4: Backward pass...
  Epoch 476, Batch 1/4: Clipping gradients...
  Epoch 476, Batch 1/4: Optimizer step...
  Epoch 476, Batch 1/4: Completed in 0.20s
  Epoch 476, Batch 2/4: Loading data to device...
  Epoch 476, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 476, Batch 2/4: Zeroing gradients...
  Epoch 476, Batch 2/4: Forward pass...
  Epoch 476, Batch 2/4: Calculating loss...
  Epoch 476, Batch 2/4: Backward pass...
  Epoch 476, Batch 2/4: Clipping gradients...
  Epoch 476, Batch 2/4: Optimizer step...
  Epoch 476, Batch 2/4: Completed in 0.20s
  Epoch 476, Batch 3/4: Loading data to device...
  Epoch 476, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 476, Batch 3/4: Zeroing gradients...
  Epoch 476, Batch 3/4: Forward pass...
  Epoch 476, Batch 3/4: Calculating loss...
  Epoch 476, Batch 3/4: Backward pass...
  Epoch 476, Batch 3/4: Clipping gradients...
  Epoch 476, Batch 3/4: Optimizer step...
  Epoch 476, Batch 3/4: Completed in 0.21s
  Epoch 476, Batch 4/4: Loading data to device...
  Epoch 476, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 476, Batch 4/4: Zeroing gradients...
  Epoch 476, Batch 4/4: Forward pass...
  Epoch 476, Batch 4/4: Calculating loss...
  Epoch 476, Batch 4/4: Backward pass...
  Epoch 476, Batch 4/4: Clipping gradients...
  Epoch 476, Batch 4/4: Optimizer step...
  Epoch 476, Batch 4/4: Completed in 0.03s
Epoch 476: Training phase completed. Average Train Loss: 0.3597
Epoch 476: Starting validation phase...
  Epoch 476, Val Batch 1/1: Loading data...
  Epoch 476, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 476, Val Batch 1/1: Forward pass...
  Epoch 476, Val Batch 1/1: Calculating loss...
Epoch 476: Validation phase completed. Average Val Loss: 0.2233
Epoch 476 Summary ---> Train Loss: 0.3597 / Validation Loss: 0.2233
Epoch 476: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 0)
  Epoch 476: Validation loss did not improve. Epochs without improvement: 1
Epoch 476: Stepping scheduler...
--- Epoch 476 completed in 0.71 seconds ---

--- Starting Epoch 477/1000 ---
Epoch 477: Starting training phase (4 batches)
  Epoch 477, Batch 1/4: Loading data to device...
  Epoch 477, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 477, Batch 1/4: Zeroing gradients...
  Epoch 477, Batch 1/4: Forward pass...
  Epoch 477, Batch 1/4: Calculating loss...
  Epoch 477, Batch 1/4: Backward pass...
  Epoch 477, Batch 1/4: Clipping gradients...
  Epoch 477, Batch 1/4: Optimizer step...
  Epoch 477, Batch 1/4: Completed in 0.21s
  Epoch 477, Batch 2/4: Loading data to device...
  Epoch 477, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 477, Batch 2/4: Zeroing gradients...
  Epoch 477, Batch 2/4: Forward pass...
  Epoch 477, Batch 2/4: Calculating loss...
  Epoch 477, Batch 2/4: Backward pass...
  Epoch 477, Batch 2/4: Clipping gradients...
  Epoch 477, Batch 2/4: Optimizer step...
  Epoch 477, Batch 2/4: Completed in 0.21s
  Epoch 477, Batch 3/4: Loading data to device...
  Epoch 477, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 477, Batch 3/4: Zeroing gradients...
  Epoch 477, Batch 3/4: Forward pass...
  Epoch 477, Batch 3/4: Calculating loss...
  Epoch 477, Batch 3/4: Backward pass...
  Epoch 477, Batch 3/4: Clipping gradients...
  Epoch 477, Batch 3/4: Optimizer step...
  Epoch 477, Batch 3/4: Completed in 0.20s
  Epoch 477, Batch 4/4: Loading data to device...
  Epoch 477, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 477, Batch 4/4: Zeroing gradients...
  Epoch 477, Batch 4/4: Forward pass...
  Epoch 477, Batch 4/4: Calculating loss...
  Epoch 477, Batch 4/4: Backward pass...
  Epoch 477, Batch 4/4: Clipping gradients...
  Epoch 477, Batch 4/4: Optimizer step...
  Epoch 477, Batch 4/4: Completed in 0.03s
Epoch 477: Training phase completed. Average Train Loss: 0.2859
Epoch 477: Starting validation phase...
  Epoch 477, Val Batch 1/1: Loading data...
  Epoch 477, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 477, Val Batch 1/1: Forward pass...
  Epoch 477, Val Batch 1/1: Calculating loss...
Epoch 477: Validation phase completed. Average Val Loss: 0.2245
Epoch 477 Summary ---> Train Loss: 0.2859 / Validation Loss: 0.2245
Epoch 477: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 1)
  Epoch 477: Validation loss did not improve. Epochs without improvement: 2
Epoch 477: Stepping scheduler...
--- Epoch 477 completed in 0.72 seconds ---

--- Starting Epoch 478/1000 ---
Epoch 478: Starting training phase (4 batches)
  Epoch 478, Batch 1/4: Loading data to device...
  Epoch 478, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 478, Batch 1/4: Zeroing gradients...
  Epoch 478, Batch 1/4: Forward pass...
  Epoch 478, Batch 1/4: Calculating loss...
  Epoch 478, Batch 1/4: Backward pass...
  Epoch 478, Batch 1/4: Clipping gradients...
  Epoch 478, Batch 1/4: Optimizer step...
  Epoch 478, Batch 1/4: Completed in 0.19s
  Epoch 478, Batch 2/4: Loading data to device...
  Epoch 478, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 478, Batch 2/4: Zeroing gradients...
  Epoch 478, Batch 2/4: Forward pass...
  Epoch 478, Batch 2/4: Calculating loss...
  Epoch 478, Batch 2/4: Backward pass...
  Epoch 478, Batch 2/4: Clipping gradients...
  Epoch 478, Batch 2/4: Optimizer step...
  Epoch 478, Batch 2/4: Completed in 0.20s
  Epoch 478, Batch 3/4: Loading data to device...
  Epoch 478, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 478, Batch 3/4: Zeroing gradients...
  Epoch 478, Batch 3/4: Forward pass...
  Epoch 478, Batch 3/4: Calculating loss...
  Epoch 478, Batch 3/4: Backward pass...
  Epoch 478, Batch 3/4: Clipping gradients...
  Epoch 478, Batch 3/4: Optimizer step...
  Epoch 478, Batch 3/4: Completed in 0.20s
  Epoch 478, Batch 4/4: Loading data to device...
  Epoch 478, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 478, Batch 4/4: Zeroing gradients...
  Epoch 478, Batch 4/4: Forward pass...
  Epoch 478, Batch 4/4: Calculating loss...
  Epoch 478, Batch 4/4: Backward pass...
  Epoch 478, Batch 4/4: Clipping gradients...
  Epoch 478, Batch 4/4: Optimizer step...
  Epoch 478, Batch 4/4: Completed in 0.03s
Epoch 478: Training phase completed. Average Train Loss: 0.2768
Epoch 478: Starting validation phase...
  Epoch 478, Val Batch 1/1: Loading data...
  Epoch 478, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 478, Val Batch 1/1: Forward pass...
  Epoch 478, Val Batch 1/1: Calculating loss...
Epoch 478: Validation phase completed. Average Val Loss: 0.2283
Epoch 478 Summary ---> Train Loss: 0.2768 / Validation Loss: 0.2283
Epoch 478: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 2)
  Epoch 478: Validation loss did not improve. Epochs without improvement: 3
Epoch 478: Stepping scheduler...
--- Epoch 478 completed in 0.69 seconds ---

--- Starting Epoch 479/1000 ---
Epoch 479: Starting training phase (4 batches)
  Epoch 479, Batch 1/4: Loading data to device...
  Epoch 479, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 479, Batch 1/4: Zeroing gradients...
  Epoch 479, Batch 1/4: Forward pass...
  Epoch 479, Batch 1/4: Calculating loss...
  Epoch 479, Batch 1/4: Backward pass...
  Epoch 479, Batch 1/4: Clipping gradients...
  Epoch 479, Batch 1/4: Optimizer step...
  Epoch 479, Batch 1/4: Completed in 0.20s
  Epoch 479, Batch 2/4: Loading data to device...
  Epoch 479, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 479, Batch 2/4: Zeroing gradients...
  Epoch 479, Batch 2/4: Forward pass...
  Epoch 479, Batch 2/4: Calculating loss...
  Epoch 479, Batch 2/4: Backward pass...
  Epoch 479, Batch 2/4: Clipping gradients...
  Epoch 479, Batch 2/4: Optimizer step...
  Epoch 479, Batch 2/4: Completed in 0.20s
  Epoch 479, Batch 3/4: Loading data to device...
  Epoch 479, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 479, Batch 3/4: Zeroing gradients...
  Epoch 479, Batch 3/4: Forward pass...
  Epoch 479, Batch 3/4: Calculating loss...
  Epoch 479, Batch 3/4: Backward pass...
  Epoch 479, Batch 3/4: Clipping gradients...
  Epoch 479, Batch 3/4: Optimizer step...
  Epoch 479, Batch 3/4: Completed in 0.20s
  Epoch 479, Batch 4/4: Loading data to device...
  Epoch 479, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 479, Batch 4/4: Zeroing gradients...
  Epoch 479, Batch 4/4: Forward pass...
  Epoch 479, Batch 4/4: Calculating loss...
  Epoch 479, Batch 4/4: Backward pass...
  Epoch 479, Batch 4/4: Clipping gradients...
  Epoch 479, Batch 4/4: Optimizer step...
  Epoch 479, Batch 4/4: Completed in 0.03s
Epoch 479: Training phase completed. Average Train Loss: 0.3682
Epoch 479: Starting validation phase...
  Epoch 479, Val Batch 1/1: Loading data...
  Epoch 479, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 479, Val Batch 1/1: Forward pass...
  Epoch 479, Val Batch 1/1: Calculating loss...
Epoch 479: Validation phase completed. Average Val Loss: 0.2287
Epoch 479 Summary ---> Train Loss: 0.3682 / Validation Loss: 0.2287
Epoch 479: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 3)
  Epoch 479: Validation loss did not improve. Epochs without improvement: 4
Epoch 479: Stepping scheduler...
--- Epoch 479 completed in 0.69 seconds ---

--- Starting Epoch 480/1000 ---
Epoch 480: Starting training phase (4 batches)
  Epoch 480, Batch 1/4: Loading data to device...
  Epoch 480, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 480, Batch 1/4: Zeroing gradients...
  Epoch 480, Batch 1/4: Forward pass...
  Epoch 480, Batch 1/4: Calculating loss...
  Epoch 480, Batch 1/4: Backward pass...
  Epoch 480, Batch 1/4: Clipping gradients...
  Epoch 480, Batch 1/4: Optimizer step...
  Epoch 480, Batch 1/4: Completed in 0.19s
  Epoch 480, Batch 2/4: Loading data to device...
  Epoch 480, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 480, Batch 2/4: Zeroing gradients...
  Epoch 480, Batch 2/4: Forward pass...
  Epoch 480, Batch 2/4: Calculating loss...
  Epoch 480, Batch 2/4: Backward pass...
  Epoch 480, Batch 2/4: Clipping gradients...
  Epoch 480, Batch 2/4: Optimizer step...
  Epoch 480, Batch 2/4: Completed in 0.20s
  Epoch 480, Batch 3/4: Loading data to device...
  Epoch 480, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 480, Batch 3/4: Zeroing gradients...
  Epoch 480, Batch 3/4: Forward pass...
  Epoch 480, Batch 3/4: Calculating loss...
  Epoch 480, Batch 3/4: Backward pass...
  Epoch 480, Batch 3/4: Clipping gradients...
  Epoch 480, Batch 3/4: Optimizer step...
  Epoch 480, Batch 3/4: Completed in 0.20s
  Epoch 480, Batch 4/4: Loading data to device...
  Epoch 480, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 480, Batch 4/4: Zeroing gradients...
  Epoch 480, Batch 4/4: Forward pass...
  Epoch 480, Batch 4/4: Calculating loss...
  Epoch 480, Batch 4/4: Backward pass...
  Epoch 480, Batch 4/4: Clipping gradients...
  Epoch 480, Batch 4/4: Optimizer step...
  Epoch 480, Batch 4/4: Completed in 0.03s
Epoch 480: Training phase completed. Average Train Loss: 0.2904
Epoch 480: Starting validation phase...
  Epoch 480, Val Batch 1/1: Loading data...
  Epoch 480, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 480, Val Batch 1/1: Forward pass...
  Epoch 480, Val Batch 1/1: Calculating loss...
Epoch 480: Validation phase completed. Average Val Loss: 0.2297
Epoch 480 Summary ---> Train Loss: 0.2904 / Validation Loss: 0.2297
Epoch 480: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 4)
  Epoch 480: Validation loss did not improve. Epochs without improvement: 5
Epoch 480: Stepping scheduler...
--- Epoch 480 completed in 0.69 seconds ---

--- Starting Epoch 481/1000 ---
Epoch 481: Starting training phase (4 batches)
  Epoch 481, Batch 1/4: Loading data to device...
  Epoch 481, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 481, Batch 1/4: Zeroing gradients...
  Epoch 481, Batch 1/4: Forward pass...
  Epoch 481, Batch 1/4: Calculating loss...
  Epoch 481, Batch 1/4: Backward pass...
  Epoch 481, Batch 1/4: Clipping gradients...
  Epoch 481, Batch 1/4: Optimizer step...
  Epoch 481, Batch 1/4: Completed in 0.19s
  Epoch 481, Batch 2/4: Loading data to device...
  Epoch 481, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 481, Batch 2/4: Zeroing gradients...
  Epoch 481, Batch 2/4: Forward pass...
  Epoch 481, Batch 2/4: Calculating loss...
  Epoch 481, Batch 2/4: Backward pass...
  Epoch 481, Batch 2/4: Clipping gradients...
  Epoch 481, Batch 2/4: Optimizer step...
  Epoch 481, Batch 2/4: Completed in 0.19s
  Epoch 481, Batch 3/4: Loading data to device...
  Epoch 481, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 481, Batch 3/4: Zeroing gradients...
  Epoch 481, Batch 3/4: Forward pass...
  Epoch 481, Batch 3/4: Calculating loss...
  Epoch 481, Batch 3/4: Backward pass...
  Epoch 481, Batch 3/4: Clipping gradients...
  Epoch 481, Batch 3/4: Optimizer step...
  Epoch 481, Batch 3/4: Completed in 0.19s
  Epoch 481, Batch 4/4: Loading data to device...
  Epoch 481, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 481, Batch 4/4: Zeroing gradients...
  Epoch 481, Batch 4/4: Forward pass...
  Epoch 481, Batch 4/4: Calculating loss...
  Epoch 481, Batch 4/4: Backward pass...
  Epoch 481, Batch 4/4: Clipping gradients...
  Epoch 481, Batch 4/4: Optimizer step...
  Epoch 481, Batch 4/4: Completed in 0.03s
Epoch 481: Training phase completed. Average Train Loss: 0.3226
Epoch 481: Starting validation phase...
  Epoch 481, Val Batch 1/1: Loading data...
  Epoch 481, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 481, Val Batch 1/1: Forward pass...
  Epoch 481, Val Batch 1/1: Calculating loss...
Epoch 481: Validation phase completed. Average Val Loss: 0.2256
Epoch 481 Summary ---> Train Loss: 0.3226 / Validation Loss: 0.2256
Epoch 481: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 5)
  Epoch 481: Validation loss did not improve. Epochs without improvement: 6
Epoch 481: Stepping scheduler...
--- Epoch 481 completed in 0.67 seconds ---

--- Starting Epoch 482/1000 ---
Epoch 482: Starting training phase (4 batches)
  Epoch 482, Batch 1/4: Loading data to device...
  Epoch 482, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 482, Batch 1/4: Zeroing gradients...
  Epoch 482, Batch 1/4: Forward pass...
  Epoch 482, Batch 1/4: Calculating loss...
  Epoch 482, Batch 1/4: Backward pass...
  Epoch 482, Batch 1/4: Clipping gradients...
  Epoch 482, Batch 1/4: Optimizer step...
  Epoch 482, Batch 1/4: Completed in 0.20s
  Epoch 482, Batch 2/4: Loading data to device...
  Epoch 482, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 482, Batch 2/4: Zeroing gradients...
  Epoch 482, Batch 2/4: Forward pass...
  Epoch 482, Batch 2/4: Calculating loss...
  Epoch 482, Batch 2/4: Backward pass...
  Epoch 482, Batch 2/4: Clipping gradients...
  Epoch 482, Batch 2/4: Optimizer step...
  Epoch 482, Batch 2/4: Completed in 0.20s
  Epoch 482, Batch 3/4: Loading data to device...
  Epoch 482, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 482, Batch 3/4: Zeroing gradients...
  Epoch 482, Batch 3/4: Forward pass...
  Epoch 482, Batch 3/4: Calculating loss...
  Epoch 482, Batch 3/4: Backward pass...
  Epoch 482, Batch 3/4: Clipping gradients...
  Epoch 482, Batch 3/4: Optimizer step...
  Epoch 482, Batch 3/4: Completed in 0.20s
  Epoch 482, Batch 4/4: Loading data to device...
  Epoch 482, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 482, Batch 4/4: Zeroing gradients...
  Epoch 482, Batch 4/4: Forward pass...
  Epoch 482, Batch 4/4: Calculating loss...
  Epoch 482, Batch 4/4: Backward pass...
  Epoch 482, Batch 4/4: Clipping gradients...
  Epoch 482, Batch 4/4: Optimizer step...
  Epoch 482, Batch 4/4: Completed in 0.03s
Epoch 482: Training phase completed. Average Train Loss: 0.2911
Epoch 482: Starting validation phase...
  Epoch 482, Val Batch 1/1: Loading data...
  Epoch 482, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 482, Val Batch 1/1: Forward pass...
  Epoch 482, Val Batch 1/1: Calculating loss...
Epoch 482: Validation phase completed. Average Val Loss: 0.2264
Epoch 482 Summary ---> Train Loss: 0.2911 / Validation Loss: 0.2264
Epoch 482: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 6)
  Epoch 482: Validation loss did not improve. Epochs without improvement: 7
Epoch 482: Stepping scheduler...
--- Epoch 482 completed in 0.70 seconds ---

--- Starting Epoch 483/1000 ---
Epoch 483: Starting training phase (4 batches)
  Epoch 483, Batch 1/4: Loading data to device...
  Epoch 483, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 483, Batch 1/4: Zeroing gradients...
  Epoch 483, Batch 1/4: Forward pass...
  Epoch 483, Batch 1/4: Calculating loss...
  Epoch 483, Batch 1/4: Backward pass...
  Epoch 483, Batch 1/4: Clipping gradients...
  Epoch 483, Batch 1/4: Optimizer step...
  Epoch 483, Batch 1/4: Completed in 0.19s
  Epoch 483, Batch 2/4: Loading data to device...
  Epoch 483, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 483, Batch 2/4: Zeroing gradients...
  Epoch 483, Batch 2/4: Forward pass...
  Epoch 483, Batch 2/4: Calculating loss...
  Epoch 483, Batch 2/4: Backward pass...
  Epoch 483, Batch 2/4: Clipping gradients...
  Epoch 483, Batch 2/4: Optimizer step...
  Epoch 483, Batch 2/4: Completed in 0.20s
  Epoch 483, Batch 3/4: Loading data to device...
  Epoch 483, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 483, Batch 3/4: Zeroing gradients...
  Epoch 483, Batch 3/4: Forward pass...
  Epoch 483, Batch 3/4: Calculating loss...
  Epoch 483, Batch 3/4: Backward pass...
  Epoch 483, Batch 3/4: Clipping gradients...
  Epoch 483, Batch 3/4: Optimizer step...
  Epoch 483, Batch 3/4: Completed in 0.20s
  Epoch 483, Batch 4/4: Loading data to device...
  Epoch 483, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 483, Batch 4/4: Zeroing gradients...
  Epoch 483, Batch 4/4: Forward pass...
  Epoch 483, Batch 4/4: Calculating loss...
  Epoch 483, Batch 4/4: Backward pass...
  Epoch 483, Batch 4/4: Clipping gradients...
  Epoch 483, Batch 4/4: Optimizer step...
  Epoch 483, Batch 4/4: Completed in 0.03s
Epoch 483: Training phase completed. Average Train Loss: 0.2671
Epoch 483: Starting validation phase...
  Epoch 483, Val Batch 1/1: Loading data...
  Epoch 483, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 483, Val Batch 1/1: Forward pass...
  Epoch 483, Val Batch 1/1: Calculating loss...
Epoch 483: Validation phase completed. Average Val Loss: 0.2306
Epoch 483 Summary ---> Train Loss: 0.2671 / Validation Loss: 0.2306
Epoch 483: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 7)
  Epoch 483: Validation loss did not improve. Epochs without improvement: 8
Epoch 483: Stepping scheduler...
--- Epoch 483 completed in 0.69 seconds ---

--- Starting Epoch 484/1000 ---
Epoch 484: Starting training phase (4 batches)
  Epoch 484, Batch 1/4: Loading data to device...
  Epoch 484, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 484, Batch 1/4: Zeroing gradients...
  Epoch 484, Batch 1/4: Forward pass...
  Epoch 484, Batch 1/4: Calculating loss...
  Epoch 484, Batch 1/4: Backward pass...
  Epoch 484, Batch 1/4: Clipping gradients...
  Epoch 484, Batch 1/4: Optimizer step...
  Epoch 484, Batch 1/4: Completed in 0.19s
  Epoch 484, Batch 2/4: Loading data to device...
  Epoch 484, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 484, Batch 2/4: Zeroing gradients...
  Epoch 484, Batch 2/4: Forward pass...
  Epoch 484, Batch 2/4: Calculating loss...
  Epoch 484, Batch 2/4: Backward pass...
  Epoch 484, Batch 2/4: Clipping gradients...
  Epoch 484, Batch 2/4: Optimizer step...
  Epoch 484, Batch 2/4: Completed in 0.19s
  Epoch 484, Batch 3/4: Loading data to device...
  Epoch 484, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 484, Batch 3/4: Zeroing gradients...
  Epoch 484, Batch 3/4: Forward pass...
  Epoch 484, Batch 3/4: Calculating loss...
  Epoch 484, Batch 3/4: Backward pass...
  Epoch 484, Batch 3/4: Clipping gradients...
  Epoch 484, Batch 3/4: Optimizer step...
  Epoch 484, Batch 3/4: Completed in 0.20s
  Epoch 484, Batch 4/4: Loading data to device...
  Epoch 484, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 484, Batch 4/4: Zeroing gradients...
  Epoch 484, Batch 4/4: Forward pass...
  Epoch 484, Batch 4/4: Calculating loss...
  Epoch 484, Batch 4/4: Backward pass...
  Epoch 484, Batch 4/4: Clipping gradients...
  Epoch 484, Batch 4/4: Optimizer step...
  Epoch 484, Batch 4/4: Completed in 0.03s
Epoch 484: Training phase completed. Average Train Loss: 0.3145
Epoch 484: Starting validation phase...
  Epoch 484, Val Batch 1/1: Loading data...
  Epoch 484, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 484, Val Batch 1/1: Forward pass...
  Epoch 484, Val Batch 1/1: Calculating loss...
Epoch 484: Validation phase completed. Average Val Loss: 0.2257
Epoch 484 Summary ---> Train Loss: 0.3145 / Validation Loss: 0.2257
Epoch 484: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 8)
  Epoch 484: Validation loss did not improve. Epochs without improvement: 9
Epoch 484: Stepping scheduler...
--- Epoch 484 completed in 0.68 seconds ---

--- Starting Epoch 485/1000 ---
Epoch 485: Starting training phase (4 batches)
  Epoch 485, Batch 1/4: Loading data to device...
  Epoch 485, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 485, Batch 1/4: Zeroing gradients...
  Epoch 485, Batch 1/4: Forward pass...
  Epoch 485, Batch 1/4: Calculating loss...
  Epoch 485, Batch 1/4: Backward pass...
  Epoch 485, Batch 1/4: Clipping gradients...
  Epoch 485, Batch 1/4: Optimizer step...
  Epoch 485, Batch 1/4: Completed in 0.19s
  Epoch 485, Batch 2/4: Loading data to device...
  Epoch 485, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 485, Batch 2/4: Zeroing gradients...
  Epoch 485, Batch 2/4: Forward pass...
  Epoch 485, Batch 2/4: Calculating loss...
  Epoch 485, Batch 2/4: Backward pass...
  Epoch 485, Batch 2/4: Clipping gradients...
  Epoch 485, Batch 2/4: Optimizer step...
  Epoch 485, Batch 2/4: Completed in 0.20s
  Epoch 485, Batch 3/4: Loading data to device...
  Epoch 485, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 485, Batch 3/4: Zeroing gradients...
  Epoch 485, Batch 3/4: Forward pass...
  Epoch 485, Batch 3/4: Calculating loss...
  Epoch 485, Batch 3/4: Backward pass...
  Epoch 485, Batch 3/4: Clipping gradients...
  Epoch 485, Batch 3/4: Optimizer step...
  Epoch 485, Batch 3/4: Completed in 0.20s
  Epoch 485, Batch 4/4: Loading data to device...
  Epoch 485, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 485, Batch 4/4: Zeroing gradients...
  Epoch 485, Batch 4/4: Forward pass...
  Epoch 485, Batch 4/4: Calculating loss...
  Epoch 485, Batch 4/4: Backward pass...
  Epoch 485, Batch 4/4: Clipping gradients...
  Epoch 485, Batch 4/4: Optimizer step...
  Epoch 485, Batch 4/4: Completed in 0.03s
Epoch 485: Training phase completed. Average Train Loss: 0.3037
Epoch 485: Starting validation phase...
  Epoch 485, Val Batch 1/1: Loading data...
  Epoch 485, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 485, Val Batch 1/1: Forward pass...
  Epoch 485, Val Batch 1/1: Calculating loss...
Epoch 485: Validation phase completed. Average Val Loss: 0.2247
Epoch 485 Summary ---> Train Loss: 0.3037 / Validation Loss: 0.2247
Epoch 485: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 9)
  Epoch 485: Validation loss did not improve. Epochs without improvement: 10
Epoch 485: Stepping scheduler...
--- Epoch 485 completed in 0.69 seconds ---

--- Starting Epoch 486/1000 ---
Epoch 486: Starting training phase (4 batches)
  Epoch 486, Batch 1/4: Loading data to device...
  Epoch 486, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 486, Batch 1/4: Zeroing gradients...
  Epoch 486, Batch 1/4: Forward pass...
  Epoch 486, Batch 1/4: Calculating loss...
  Epoch 486, Batch 1/4: Backward pass...
  Epoch 486, Batch 1/4: Clipping gradients...
  Epoch 486, Batch 1/4: Optimizer step...
  Epoch 486, Batch 1/4: Completed in 0.20s
  Epoch 486, Batch 2/4: Loading data to device...
  Epoch 486, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 486, Batch 2/4: Zeroing gradients...
  Epoch 486, Batch 2/4: Forward pass...
  Epoch 486, Batch 2/4: Calculating loss...
  Epoch 486, Batch 2/4: Backward pass...
  Epoch 486, Batch 2/4: Clipping gradients...
  Epoch 486, Batch 2/4: Optimizer step...
  Epoch 486, Batch 2/4: Completed in 0.19s
  Epoch 486, Batch 3/4: Loading data to device...
  Epoch 486, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 486, Batch 3/4: Zeroing gradients...
  Epoch 486, Batch 3/4: Forward pass...
  Epoch 486, Batch 3/4: Calculating loss...
  Epoch 486, Batch 3/4: Backward pass...
  Epoch 486, Batch 3/4: Clipping gradients...
  Epoch 486, Batch 3/4: Optimizer step...
  Epoch 486, Batch 3/4: Completed in 0.19s
  Epoch 486, Batch 4/4: Loading data to device...
  Epoch 486, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 486, Batch 4/4: Zeroing gradients...
  Epoch 486, Batch 4/4: Forward pass...
  Epoch 486, Batch 4/4: Calculating loss...
  Epoch 486, Batch 4/4: Backward pass...
  Epoch 486, Batch 4/4: Clipping gradients...
  Epoch 486, Batch 4/4: Optimizer step...
  Epoch 486, Batch 4/4: Completed in 0.03s
Epoch 486: Training phase completed. Average Train Loss: 0.3079
Epoch 486: Starting validation phase...
  Epoch 486, Val Batch 1/1: Loading data...
  Epoch 486, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 486, Val Batch 1/1: Forward pass...
  Epoch 486, Val Batch 1/1: Calculating loss...
Epoch 486: Validation phase completed. Average Val Loss: 0.2267
Epoch 486 Summary ---> Train Loss: 0.3079 / Validation Loss: 0.2267
Epoch 486: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 10)
  Epoch 486: Validation loss did not improve. Epochs without improvement: 11
Epoch 486: Stepping scheduler...
--- Epoch 486 completed in 0.67 seconds ---

--- Starting Epoch 487/1000 ---
Epoch 487: Starting training phase (4 batches)
  Epoch 487, Batch 1/4: Loading data to device...
  Epoch 487, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 487, Batch 1/4: Zeroing gradients...
  Epoch 487, Batch 1/4: Forward pass...
  Epoch 487, Batch 1/4: Calculating loss...
  Epoch 487, Batch 1/4: Backward pass...
  Epoch 487, Batch 1/4: Clipping gradients...
  Epoch 487, Batch 1/4: Optimizer step...
  Epoch 487, Batch 1/4: Completed in 0.19s
  Epoch 487, Batch 2/4: Loading data to device...
  Epoch 487, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 487, Batch 2/4: Zeroing gradients...
  Epoch 487, Batch 2/4: Forward pass...
  Epoch 487, Batch 2/4: Calculating loss...
  Epoch 487, Batch 2/4: Backward pass...
  Epoch 487, Batch 2/4: Clipping gradients...
  Epoch 487, Batch 2/4: Optimizer step...
  Epoch 487, Batch 2/4: Completed in 0.19s
  Epoch 487, Batch 3/4: Loading data to device...
  Epoch 487, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 487, Batch 3/4: Zeroing gradients...
  Epoch 487, Batch 3/4: Forward pass...
  Epoch 487, Batch 3/4: Calculating loss...
  Epoch 487, Batch 3/4: Backward pass...
  Epoch 487, Batch 3/4: Clipping gradients...
  Epoch 487, Batch 3/4: Optimizer step...
  Epoch 487, Batch 3/4: Completed in 0.19s
  Epoch 487, Batch 4/4: Loading data to device...
  Epoch 487, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 487, Batch 4/4: Zeroing gradients...
  Epoch 487, Batch 4/4: Forward pass...
  Epoch 487, Batch 4/4: Calculating loss...
  Epoch 487, Batch 4/4: Backward pass...
  Epoch 487, Batch 4/4: Clipping gradients...
  Epoch 487, Batch 4/4: Optimizer step...
  Epoch 487, Batch 4/4: Completed in 0.03s
Epoch 487: Training phase completed. Average Train Loss: 0.2961
Epoch 487: Starting validation phase...
  Epoch 487, Val Batch 1/1: Loading data...
  Epoch 487, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 487, Val Batch 1/1: Forward pass...
  Epoch 487, Val Batch 1/1: Calculating loss...
Epoch 487: Validation phase completed. Average Val Loss: 0.2222
Epoch 487 Summary ---> Train Loss: 0.2961 / Validation Loss: 0.2222
Epoch 487: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 11)
  Epoch 487: Validation loss did not improve. Epochs without improvement: 12
Epoch 487: Stepping scheduler...
--- Epoch 487 completed in 0.67 seconds ---

--- Starting Epoch 488/1000 ---
Epoch 488: Starting training phase (4 batches)
  Epoch 488, Batch 1/4: Loading data to device...
  Epoch 488, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 488, Batch 1/4: Zeroing gradients...
  Epoch 488, Batch 1/4: Forward pass...
  Epoch 488, Batch 1/4: Calculating loss...
  Epoch 488, Batch 1/4: Backward pass...
  Epoch 488, Batch 1/4: Clipping gradients...
  Epoch 488, Batch 1/4: Optimizer step...
  Epoch 488, Batch 1/4: Completed in 0.20s
  Epoch 488, Batch 2/4: Loading data to device...
  Epoch 488, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 488, Batch 2/4: Zeroing gradients...
  Epoch 488, Batch 2/4: Forward pass...
  Epoch 488, Batch 2/4: Calculating loss...
  Epoch 488, Batch 2/4: Backward pass...
  Epoch 488, Batch 2/4: Clipping gradients...
  Epoch 488, Batch 2/4: Optimizer step...
  Epoch 488, Batch 2/4: Completed in 0.20s
  Epoch 488, Batch 3/4: Loading data to device...
  Epoch 488, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 488, Batch 3/4: Zeroing gradients...
  Epoch 488, Batch 3/4: Forward pass...
  Epoch 488, Batch 3/4: Calculating loss...
  Epoch 488, Batch 3/4: Backward pass...
  Epoch 488, Batch 3/4: Clipping gradients...
  Epoch 488, Batch 3/4: Optimizer step...
  Epoch 488, Batch 3/4: Completed in 0.20s
  Epoch 488, Batch 4/4: Loading data to device...
  Epoch 488, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 488, Batch 4/4: Zeroing gradients...
  Epoch 488, Batch 4/4: Forward pass...
  Epoch 488, Batch 4/4: Calculating loss...
  Epoch 488, Batch 4/4: Backward pass...
  Epoch 488, Batch 4/4: Clipping gradients...
  Epoch 488, Batch 4/4: Optimizer step...
  Epoch 488, Batch 4/4: Completed in 0.03s
Epoch 488: Training phase completed. Average Train Loss: 0.3084
Epoch 488: Starting validation phase...
  Epoch 488, Val Batch 1/1: Loading data...
  Epoch 488, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 488, Val Batch 1/1: Forward pass...
  Epoch 488, Val Batch 1/1: Calculating loss...
Epoch 488: Validation phase completed. Average Val Loss: 0.2257
Epoch 488 Summary ---> Train Loss: 0.3084 / Validation Loss: 0.2257
Epoch 488: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 12)
  Epoch 488: Validation loss did not improve. Epochs without improvement: 13
Epoch 488: Stepping scheduler...
--- Epoch 488 completed in 0.70 seconds ---

--- Starting Epoch 489/1000 ---
Epoch 489: Starting training phase (4 batches)
  Epoch 489, Batch 1/4: Loading data to device...
  Epoch 489, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 489, Batch 1/4: Zeroing gradients...
  Epoch 489, Batch 1/4: Forward pass...
  Epoch 489, Batch 1/4: Calculating loss...
  Epoch 489, Batch 1/4: Backward pass...
  Epoch 489, Batch 1/4: Clipping gradients...
  Epoch 489, Batch 1/4: Optimizer step...
  Epoch 489, Batch 1/4: Completed in 0.20s
  Epoch 489, Batch 2/4: Loading data to device...
  Epoch 489, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 489, Batch 2/4: Zeroing gradients...
  Epoch 489, Batch 2/4: Forward pass...
  Epoch 489, Batch 2/4: Calculating loss...
  Epoch 489, Batch 2/4: Backward pass...
  Epoch 489, Batch 2/4: Clipping gradients...
  Epoch 489, Batch 2/4: Optimizer step...
  Epoch 489, Batch 2/4: Completed in 0.20s
  Epoch 489, Batch 3/4: Loading data to device...
  Epoch 489, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 489, Batch 3/4: Zeroing gradients...
  Epoch 489, Batch 3/4: Forward pass...
  Epoch 489, Batch 3/4: Calculating loss...
  Epoch 489, Batch 3/4: Backward pass...
  Epoch 489, Batch 3/4: Clipping gradients...
  Epoch 489, Batch 3/4: Optimizer step...
  Epoch 489, Batch 3/4: Completed in 0.20s
  Epoch 489, Batch 4/4: Loading data to device...
  Epoch 489, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 489, Batch 4/4: Zeroing gradients...
  Epoch 489, Batch 4/4: Forward pass...
  Epoch 489, Batch 4/4: Calculating loss...
  Epoch 489, Batch 4/4: Backward pass...
  Epoch 489, Batch 4/4: Clipping gradients...
  Epoch 489, Batch 4/4: Optimizer step...
  Epoch 489, Batch 4/4: Completed in 0.03s
Epoch 489: Training phase completed. Average Train Loss: 0.3133
Epoch 489: Starting validation phase...
  Epoch 489, Val Batch 1/1: Loading data...
  Epoch 489, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 489, Val Batch 1/1: Forward pass...
  Epoch 489, Val Batch 1/1: Calculating loss...
Epoch 489: Validation phase completed. Average Val Loss: 0.2265
Epoch 489 Summary ---> Train Loss: 0.3133 / Validation Loss: 0.2265
Epoch 489: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 13)
  Epoch 489: Validation loss did not improve. Epochs without improvement: 14
Epoch 489: Stepping scheduler...
--- Epoch 489 completed in 0.68 seconds ---

--- Starting Epoch 490/1000 ---
Epoch 490: Starting training phase (4 batches)
  Epoch 490, Batch 1/4: Loading data to device...
  Epoch 490, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 490, Batch 1/4: Zeroing gradients...
  Epoch 490, Batch 1/4: Forward pass...
  Epoch 490, Batch 1/4: Calculating loss...
  Epoch 490, Batch 1/4: Backward pass...
  Epoch 490, Batch 1/4: Clipping gradients...
  Epoch 490, Batch 1/4: Optimizer step...
  Epoch 490, Batch 1/4: Completed in 0.19s
  Epoch 490, Batch 2/4: Loading data to device...
  Epoch 490, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 490, Batch 2/4: Zeroing gradients...
  Epoch 490, Batch 2/4: Forward pass...
  Epoch 490, Batch 2/4: Calculating loss...
  Epoch 490, Batch 2/4: Backward pass...
  Epoch 490, Batch 2/4: Clipping gradients...
  Epoch 490, Batch 2/4: Optimizer step...
  Epoch 490, Batch 2/4: Completed in 0.19s
  Epoch 490, Batch 3/4: Loading data to device...
  Epoch 490, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 490, Batch 3/4: Zeroing gradients...
  Epoch 490, Batch 3/4: Forward pass...
  Epoch 490, Batch 3/4: Calculating loss...
  Epoch 490, Batch 3/4: Backward pass...
  Epoch 490, Batch 3/4: Clipping gradients...
  Epoch 490, Batch 3/4: Optimizer step...
  Epoch 490, Batch 3/4: Completed in 0.19s
  Epoch 490, Batch 4/4: Loading data to device...
  Epoch 490, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 490, Batch 4/4: Zeroing gradients...
  Epoch 490, Batch 4/4: Forward pass...
  Epoch 490, Batch 4/4: Calculating loss...
  Epoch 490, Batch 4/4: Backward pass...
  Epoch 490, Batch 4/4: Clipping gradients...
  Epoch 490, Batch 4/4: Optimizer step...
  Epoch 490, Batch 4/4: Completed in 0.03s
Epoch 490: Training phase completed. Average Train Loss: 0.2944
Epoch 490: Starting validation phase...
  Epoch 490, Val Batch 1/1: Loading data...
  Epoch 490, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 490, Val Batch 1/1: Forward pass...
  Epoch 490, Val Batch 1/1: Calculating loss...
Epoch 490: Validation phase completed. Average Val Loss: 0.2235
Epoch 490 Summary ---> Train Loss: 0.2944 / Validation Loss: 0.2235
Epoch 490: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 14)
  Epoch 490: Validation loss did not improve. Epochs without improvement: 15
Epoch 490: Stepping scheduler...
--- Epoch 490 completed in 0.66 seconds ---

--- Starting Epoch 491/1000 ---
Epoch 491: Starting training phase (4 batches)
  Epoch 491, Batch 1/4: Loading data to device...
  Epoch 491, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 491, Batch 1/4: Zeroing gradients...
  Epoch 491, Batch 1/4: Forward pass...
  Epoch 491, Batch 1/4: Calculating loss...
  Epoch 491, Batch 1/4: Backward pass...
  Epoch 491, Batch 1/4: Clipping gradients...
  Epoch 491, Batch 1/4: Optimizer step...
  Epoch 491, Batch 1/4: Completed in 0.19s
  Epoch 491, Batch 2/4: Loading data to device...
  Epoch 491, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 491, Batch 2/4: Zeroing gradients...
  Epoch 491, Batch 2/4: Forward pass...
  Epoch 491, Batch 2/4: Calculating loss...
  Epoch 491, Batch 2/4: Backward pass...
  Epoch 491, Batch 2/4: Clipping gradients...
  Epoch 491, Batch 2/4: Optimizer step...
  Epoch 491, Batch 2/4: Completed in 0.20s
  Epoch 491, Batch 3/4: Loading data to device...
  Epoch 491, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 491, Batch 3/4: Zeroing gradients...
  Epoch 491, Batch 3/4: Forward pass...
  Epoch 491, Batch 3/4: Calculating loss...
  Epoch 491, Batch 3/4: Backward pass...
  Epoch 491, Batch 3/4: Clipping gradients...
  Epoch 491, Batch 3/4: Optimizer step...
  Epoch 491, Batch 3/4: Completed in 0.20s
  Epoch 491, Batch 4/4: Loading data to device...
  Epoch 491, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 491, Batch 4/4: Zeroing gradients...
  Epoch 491, Batch 4/4: Forward pass...
  Epoch 491, Batch 4/4: Calculating loss...
  Epoch 491, Batch 4/4: Backward pass...
  Epoch 491, Batch 4/4: Clipping gradients...
  Epoch 491, Batch 4/4: Optimizer step...
  Epoch 491, Batch 4/4: Completed in 0.03s
Epoch 491: Training phase completed. Average Train Loss: 0.3146
Epoch 491: Starting validation phase...
  Epoch 491, Val Batch 1/1: Loading data...
  Epoch 491, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 491, Val Batch 1/1: Forward pass...
  Epoch 491, Val Batch 1/1: Calculating loss...
Epoch 491: Validation phase completed. Average Val Loss: 0.2256
Epoch 491 Summary ---> Train Loss: 0.3146 / Validation Loss: 0.2256
Epoch 491: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 15)
  Epoch 491: Validation loss did not improve. Epochs without improvement: 16
Epoch 491: Stepping scheduler...
--- Epoch 491 completed in 0.69 seconds ---

--- Starting Epoch 492/1000 ---
Epoch 492: Starting training phase (4 batches)
  Epoch 492, Batch 1/4: Loading data to device...
  Epoch 492, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 492, Batch 1/4: Zeroing gradients...
  Epoch 492, Batch 1/4: Forward pass...
  Epoch 492, Batch 1/4: Calculating loss...
  Epoch 492, Batch 1/4: Backward pass...
  Epoch 492, Batch 1/4: Clipping gradients...
  Epoch 492, Batch 1/4: Optimizer step...
  Epoch 492, Batch 1/4: Completed in 0.20s
  Epoch 492, Batch 2/4: Loading data to device...
  Epoch 492, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 492, Batch 2/4: Zeroing gradients...
  Epoch 492, Batch 2/4: Forward pass...
  Epoch 492, Batch 2/4: Calculating loss...
  Epoch 492, Batch 2/4: Backward pass...
  Epoch 492, Batch 2/4: Clipping gradients...
  Epoch 492, Batch 2/4: Optimizer step...
  Epoch 492, Batch 2/4: Completed in 0.20s
  Epoch 492, Batch 3/4: Loading data to device...
  Epoch 492, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 492, Batch 3/4: Zeroing gradients...
  Epoch 492, Batch 3/4: Forward pass...
  Epoch 492, Batch 3/4: Calculating loss...
  Epoch 492, Batch 3/4: Backward pass...
  Epoch 492, Batch 3/4: Clipping gradients...
  Epoch 492, Batch 3/4: Optimizer step...
  Epoch 492, Batch 3/4: Completed in 0.20s
  Epoch 492, Batch 4/4: Loading data to device...
  Epoch 492, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 492, Batch 4/4: Zeroing gradients...
  Epoch 492, Batch 4/4: Forward pass...
  Epoch 492, Batch 4/4: Calculating loss...
  Epoch 492, Batch 4/4: Backward pass...
  Epoch 492, Batch 4/4: Clipping gradients...
  Epoch 492, Batch 4/4: Optimizer step...
  Epoch 492, Batch 4/4: Completed in 0.03s
Epoch 492: Training phase completed. Average Train Loss: 0.3039
Epoch 492: Starting validation phase...
  Epoch 492, Val Batch 1/1: Loading data...
  Epoch 492, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 492, Val Batch 1/1: Forward pass...
  Epoch 492, Val Batch 1/1: Calculating loss...
Epoch 492: Validation phase completed. Average Val Loss: 0.2245
Epoch 492 Summary ---> Train Loss: 0.3039 / Validation Loss: 0.2245
Epoch 492: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 16)
  Epoch 492: Validation loss did not improve. Epochs without improvement: 17
Epoch 492: Stepping scheduler...
--- Epoch 492 completed in 0.69 seconds ---

--- Starting Epoch 493/1000 ---
Epoch 493: Starting training phase (4 batches)
  Epoch 493, Batch 1/4: Loading data to device...
  Epoch 493, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 493, Batch 1/4: Zeroing gradients...
  Epoch 493, Batch 1/4: Forward pass...
  Epoch 493, Batch 1/4: Calculating loss...
  Epoch 493, Batch 1/4: Backward pass...
  Epoch 493, Batch 1/4: Clipping gradients...
  Epoch 493, Batch 1/4: Optimizer step...
  Epoch 493, Batch 1/4: Completed in 0.19s
  Epoch 493, Batch 2/4: Loading data to device...
  Epoch 493, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 493, Batch 2/4: Zeroing gradients...
  Epoch 493, Batch 2/4: Forward pass...
  Epoch 493, Batch 2/4: Calculating loss...
  Epoch 493, Batch 2/4: Backward pass...
  Epoch 493, Batch 2/4: Clipping gradients...
  Epoch 493, Batch 2/4: Optimizer step...
  Epoch 493, Batch 2/4: Completed in 0.19s
  Epoch 493, Batch 3/4: Loading data to device...
  Epoch 493, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 493, Batch 3/4: Zeroing gradients...
  Epoch 493, Batch 3/4: Forward pass...
  Epoch 493, Batch 3/4: Calculating loss...
  Epoch 493, Batch 3/4: Backward pass...
  Epoch 493, Batch 3/4: Clipping gradients...
  Epoch 493, Batch 3/4: Optimizer step...
  Epoch 493, Batch 3/4: Completed in 0.19s
  Epoch 493, Batch 4/4: Loading data to device...
  Epoch 493, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 493, Batch 4/4: Zeroing gradients...
  Epoch 493, Batch 4/4: Forward pass...
  Epoch 493, Batch 4/4: Calculating loss...
  Epoch 493, Batch 4/4: Backward pass...
  Epoch 493, Batch 4/4: Clipping gradients...
  Epoch 493, Batch 4/4: Optimizer step...
  Epoch 493, Batch 4/4: Completed in 0.03s
Epoch 493: Training phase completed. Average Train Loss: 0.3028
Epoch 493: Starting validation phase...
  Epoch 493, Val Batch 1/1: Loading data...
  Epoch 493, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 493, Val Batch 1/1: Forward pass...
  Epoch 493, Val Batch 1/1: Calculating loss...
Epoch 493: Validation phase completed. Average Val Loss: 0.2221
Epoch 493 Summary ---> Train Loss: 0.3028 / Validation Loss: 0.2221
Epoch 493: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 17)
  Epoch 493: Validation loss did not improve. Epochs without improvement: 18
Epoch 493: Stepping scheduler...
--- Epoch 493 completed in 0.66 seconds ---

--- Starting Epoch 494/1000 ---
Epoch 494: Starting training phase (4 batches)
  Epoch 494, Batch 1/4: Loading data to device...
  Epoch 494, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 494, Batch 1/4: Zeroing gradients...
  Epoch 494, Batch 1/4: Forward pass...
  Epoch 494, Batch 1/4: Calculating loss...
  Epoch 494, Batch 1/4: Backward pass...
  Epoch 494, Batch 1/4: Clipping gradients...
  Epoch 494, Batch 1/4: Optimizer step...
  Epoch 494, Batch 1/4: Completed in 0.20s
  Epoch 494, Batch 2/4: Loading data to device...
  Epoch 494, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 494, Batch 2/4: Zeroing gradients...
  Epoch 494, Batch 2/4: Forward pass...
  Epoch 494, Batch 2/4: Calculating loss...
  Epoch 494, Batch 2/4: Backward pass...
  Epoch 494, Batch 2/4: Clipping gradients...
  Epoch 494, Batch 2/4: Optimizer step...
  Epoch 494, Batch 2/4: Completed in 0.20s
  Epoch 494, Batch 3/4: Loading data to device...
  Epoch 494, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 494, Batch 3/4: Zeroing gradients...
  Epoch 494, Batch 3/4: Forward pass...
  Epoch 494, Batch 3/4: Calculating loss...
  Epoch 494, Batch 3/4: Backward pass...
  Epoch 494, Batch 3/4: Clipping gradients...
  Epoch 494, Batch 3/4: Optimizer step...
  Epoch 494, Batch 3/4: Completed in 0.19s
  Epoch 494, Batch 4/4: Loading data to device...
  Epoch 494, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 494, Batch 4/4: Zeroing gradients...
  Epoch 494, Batch 4/4: Forward pass...
  Epoch 494, Batch 4/4: Calculating loss...
  Epoch 494, Batch 4/4: Backward pass...
  Epoch 494, Batch 4/4: Clipping gradients...
  Epoch 494, Batch 4/4: Optimizer step...
  Epoch 494, Batch 4/4: Completed in 0.03s
Epoch 494: Training phase completed. Average Train Loss: 0.3430
Epoch 494: Starting validation phase...
  Epoch 494, Val Batch 1/1: Loading data...
  Epoch 494, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 494, Val Batch 1/1: Forward pass...
  Epoch 494, Val Batch 1/1: Calculating loss...
Epoch 494: Validation phase completed. Average Val Loss: 0.2244
Epoch 494 Summary ---> Train Loss: 0.3430 / Validation Loss: 0.2244
Epoch 494: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 18)
  Epoch 494: Validation loss did not improve. Epochs without improvement: 19
Epoch 494: Stepping scheduler...
--- Epoch 494 completed in 0.67 seconds ---

--- Starting Epoch 495/1000 ---
Epoch 495: Starting training phase (4 batches)
  Epoch 495, Batch 1/4: Loading data to device...
  Epoch 495, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 495, Batch 1/4: Zeroing gradients...
  Epoch 495, Batch 1/4: Forward pass...
  Epoch 495, Batch 1/4: Calculating loss...
  Epoch 495, Batch 1/4: Backward pass...
  Epoch 495, Batch 1/4: Clipping gradients...
  Epoch 495, Batch 1/4: Optimizer step...
  Epoch 495, Batch 1/4: Completed in 0.20s
  Epoch 495, Batch 2/4: Loading data to device...
  Epoch 495, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 495, Batch 2/4: Zeroing gradients...
  Epoch 495, Batch 2/4: Forward pass...
  Epoch 495, Batch 2/4: Calculating loss...
  Epoch 495, Batch 2/4: Backward pass...
  Epoch 495, Batch 2/4: Clipping gradients...
  Epoch 495, Batch 2/4: Optimizer step...
  Epoch 495, Batch 2/4: Completed in 0.21s
  Epoch 495, Batch 3/4: Loading data to device...
  Epoch 495, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 495, Batch 3/4: Zeroing gradients...
  Epoch 495, Batch 3/4: Forward pass...
  Epoch 495, Batch 3/4: Calculating loss...
  Epoch 495, Batch 3/4: Backward pass...
  Epoch 495, Batch 3/4: Clipping gradients...
  Epoch 495, Batch 3/4: Optimizer step...
  Epoch 495, Batch 3/4: Completed in 0.19s
  Epoch 495, Batch 4/4: Loading data to device...
  Epoch 495, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 495, Batch 4/4: Zeroing gradients...
  Epoch 495, Batch 4/4: Forward pass...
  Epoch 495, Batch 4/4: Calculating loss...
  Epoch 495, Batch 4/4: Backward pass...
  Epoch 495, Batch 4/4: Clipping gradients...
  Epoch 495, Batch 4/4: Optimizer step...
  Epoch 495, Batch 4/4: Completed in 0.03s
Epoch 495: Training phase completed. Average Train Loss: 0.2974
Epoch 495: Starting validation phase...
  Epoch 495, Val Batch 1/1: Loading data...
  Epoch 495, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 495, Val Batch 1/1: Forward pass...
  Epoch 495, Val Batch 1/1: Calculating loss...
Epoch 495: Validation phase completed. Average Val Loss: 0.2275
Epoch 495 Summary ---> Train Loss: 0.2974 / Validation Loss: 0.2275
Epoch 495: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 19)
  Epoch 495: Validation loss did not improve. Epochs without improvement: 20
Epoch 495: Stepping scheduler...
--- Epoch 495 completed in 0.70 seconds ---

--- Starting Epoch 496/1000 ---
Epoch 496: Starting training phase (4 batches)
  Epoch 496, Batch 1/4: Loading data to device...
  Epoch 496, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 496, Batch 1/4: Zeroing gradients...
  Epoch 496, Batch 1/4: Forward pass...
  Epoch 496, Batch 1/4: Calculating loss...
  Epoch 496, Batch 1/4: Backward pass...
  Epoch 496, Batch 1/4: Clipping gradients...
  Epoch 496, Batch 1/4: Optimizer step...
  Epoch 496, Batch 1/4: Completed in 0.19s
  Epoch 496, Batch 2/4: Loading data to device...
  Epoch 496, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 496, Batch 2/4: Zeroing gradients...
  Epoch 496, Batch 2/4: Forward pass...
  Epoch 496, Batch 2/4: Calculating loss...
  Epoch 496, Batch 2/4: Backward pass...
  Epoch 496, Batch 2/4: Clipping gradients...
  Epoch 496, Batch 2/4: Optimizer step...
  Epoch 496, Batch 2/4: Completed in 0.19s
  Epoch 496, Batch 3/4: Loading data to device...
  Epoch 496, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 496, Batch 3/4: Zeroing gradients...
  Epoch 496, Batch 3/4: Forward pass...
  Epoch 496, Batch 3/4: Calculating loss...
  Epoch 496, Batch 3/4: Backward pass...
  Epoch 496, Batch 3/4: Clipping gradients...
  Epoch 496, Batch 3/4: Optimizer step...
  Epoch 496, Batch 3/4: Completed in 0.19s
  Epoch 496, Batch 4/4: Loading data to device...
  Epoch 496, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 496, Batch 4/4: Zeroing gradients...
  Epoch 496, Batch 4/4: Forward pass...
  Epoch 496, Batch 4/4: Calculating loss...
  Epoch 496, Batch 4/4: Backward pass...
  Epoch 496, Batch 4/4: Clipping gradients...
  Epoch 496, Batch 4/4: Optimizer step...
  Epoch 496, Batch 4/4: Completed in 0.03s
Epoch 496: Training phase completed. Average Train Loss: 0.2884
Epoch 496: Starting validation phase...
  Epoch 496, Val Batch 1/1: Loading data...
  Epoch 496, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 496, Val Batch 1/1: Forward pass...
  Epoch 496, Val Batch 1/1: Calculating loss...
Epoch 496: Validation phase completed. Average Val Loss: 0.2286
Epoch 496 Summary ---> Train Loss: 0.2884 / Validation Loss: 0.2286
Epoch 496: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 20)
  Epoch 496: Validation loss did not improve. Epochs without improvement: 21
Epoch 496: Stepping scheduler...
--- Epoch 496 completed in 0.66 seconds ---

--- Starting Epoch 497/1000 ---
Epoch 497: Starting training phase (4 batches)
  Epoch 497, Batch 1/4: Loading data to device...
  Epoch 497, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 497, Batch 1/4: Zeroing gradients...
  Epoch 497, Batch 1/4: Forward pass...
  Epoch 497, Batch 1/4: Calculating loss...
  Epoch 497, Batch 1/4: Backward pass...
  Epoch 497, Batch 1/4: Clipping gradients...
  Epoch 497, Batch 1/4: Optimizer step...
  Epoch 497, Batch 1/4: Completed in 0.19s
  Epoch 497, Batch 2/4: Loading data to device...
  Epoch 497, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 497, Batch 2/4: Zeroing gradients...
  Epoch 497, Batch 2/4: Forward pass...
  Epoch 497, Batch 2/4: Calculating loss...
  Epoch 497, Batch 2/4: Backward pass...
  Epoch 497, Batch 2/4: Clipping gradients...
  Epoch 497, Batch 2/4: Optimizer step...
  Epoch 497, Batch 2/4: Completed in 0.18s
  Epoch 497, Batch 3/4: Loading data to device...
  Epoch 497, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 497, Batch 3/4: Zeroing gradients...
  Epoch 497, Batch 3/4: Forward pass...
  Epoch 497, Batch 3/4: Calculating loss...
  Epoch 497, Batch 3/4: Backward pass...
  Epoch 497, Batch 3/4: Clipping gradients...
  Epoch 497, Batch 3/4: Optimizer step...
  Epoch 497, Batch 3/4: Completed in 0.19s
  Epoch 497, Batch 4/4: Loading data to device...
  Epoch 497, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 497, Batch 4/4: Zeroing gradients...
  Epoch 497, Batch 4/4: Forward pass...
  Epoch 497, Batch 4/4: Calculating loss...
  Epoch 497, Batch 4/4: Backward pass...
  Epoch 497, Batch 4/4: Clipping gradients...
  Epoch 497, Batch 4/4: Optimizer step...
  Epoch 497, Batch 4/4: Completed in 0.03s
Epoch 497: Training phase completed. Average Train Loss: 0.2816
Epoch 497: Starting validation phase...
  Epoch 497, Val Batch 1/1: Loading data...
  Epoch 497, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 497, Val Batch 1/1: Forward pass...
  Epoch 497, Val Batch 1/1: Calculating loss...
Epoch 497: Validation phase completed. Average Val Loss: 0.2243
Epoch 497 Summary ---> Train Loss: 0.2816 / Validation Loss: 0.2243
Epoch 497: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 21)
  Epoch 497: Validation loss did not improve. Epochs without improvement: 22
Epoch 497: Stepping scheduler...
--- Epoch 497 completed in 0.66 seconds ---

--- Starting Epoch 498/1000 ---
Epoch 498: Starting training phase (4 batches)
  Epoch 498, Batch 1/4: Loading data to device...
  Epoch 498, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 498, Batch 1/4: Zeroing gradients...
  Epoch 498, Batch 1/4: Forward pass...
  Epoch 498, Batch 1/4: Calculating loss...
  Epoch 498, Batch 1/4: Backward pass...
  Epoch 498, Batch 1/4: Clipping gradients...
  Epoch 498, Batch 1/4: Optimizer step...
  Epoch 498, Batch 1/4: Completed in 0.20s
  Epoch 498, Batch 2/4: Loading data to device...
  Epoch 498, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 498, Batch 2/4: Zeroing gradients...
  Epoch 498, Batch 2/4: Forward pass...
  Epoch 498, Batch 2/4: Calculating loss...
  Epoch 498, Batch 2/4: Backward pass...
  Epoch 498, Batch 2/4: Clipping gradients...
  Epoch 498, Batch 2/4: Optimizer step...
  Epoch 498, Batch 2/4: Completed in 0.19s
  Epoch 498, Batch 3/4: Loading data to device...
  Epoch 498, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 498, Batch 3/4: Zeroing gradients...
  Epoch 498, Batch 3/4: Forward pass...
  Epoch 498, Batch 3/4: Calculating loss...
  Epoch 498, Batch 3/4: Backward pass...
  Epoch 498, Batch 3/4: Clipping gradients...
  Epoch 498, Batch 3/4: Optimizer step...
  Epoch 498, Batch 3/4: Completed in 0.19s
  Epoch 498, Batch 4/4: Loading data to device...
  Epoch 498, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 498, Batch 4/4: Zeroing gradients...
  Epoch 498, Batch 4/4: Forward pass...
  Epoch 498, Batch 4/4: Calculating loss...
  Epoch 498, Batch 4/4: Backward pass...
  Epoch 498, Batch 4/4: Clipping gradients...
  Epoch 498, Batch 4/4: Optimizer step...
  Epoch 498, Batch 4/4: Completed in 0.03s
Epoch 498: Training phase completed. Average Train Loss: 0.2787
Epoch 498: Starting validation phase...
  Epoch 498, Val Batch 1/1: Loading data...
  Epoch 498, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 498, Val Batch 1/1: Forward pass...
  Epoch 498, Val Batch 1/1: Calculating loss...
Epoch 498: Validation phase completed. Average Val Loss: 0.2255
Epoch 498 Summary ---> Train Loss: 0.2787 / Validation Loss: 0.2255
Epoch 498: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 22)
  Epoch 498: Validation loss did not improve. Epochs without improvement: 23
Epoch 498: Stepping scheduler...
--- Epoch 498 completed in 0.67 seconds ---

--- Starting Epoch 499/1000 ---
Epoch 499: Starting training phase (4 batches)
  Epoch 499, Batch 1/4: Loading data to device...
  Epoch 499, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 499, Batch 1/4: Zeroing gradients...
  Epoch 499, Batch 1/4: Forward pass...
  Epoch 499, Batch 1/4: Calculating loss...
  Epoch 499, Batch 1/4: Backward pass...
  Epoch 499, Batch 1/4: Clipping gradients...
  Epoch 499, Batch 1/4: Optimizer step...
  Epoch 499, Batch 1/4: Completed in 0.18s
  Epoch 499, Batch 2/4: Loading data to device...
  Epoch 499, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 499, Batch 2/4: Zeroing gradients...
  Epoch 499, Batch 2/4: Forward pass...
  Epoch 499, Batch 2/4: Calculating loss...
  Epoch 499, Batch 2/4: Backward pass...
  Epoch 499, Batch 2/4: Clipping gradients...
  Epoch 499, Batch 2/4: Optimizer step...
  Epoch 499, Batch 2/4: Completed in 0.19s
  Epoch 499, Batch 3/4: Loading data to device...
  Epoch 499, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 499, Batch 3/4: Zeroing gradients...
  Epoch 499, Batch 3/4: Forward pass...
  Epoch 499, Batch 3/4: Calculating loss...
  Epoch 499, Batch 3/4: Backward pass...
  Epoch 499, Batch 3/4: Clipping gradients...
  Epoch 499, Batch 3/4: Optimizer step...
  Epoch 499, Batch 3/4: Completed in 0.19s
  Epoch 499, Batch 4/4: Loading data to device...
  Epoch 499, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 499, Batch 4/4: Zeroing gradients...
  Epoch 499, Batch 4/4: Forward pass...
  Epoch 499, Batch 4/4: Calculating loss...
  Epoch 499, Batch 4/4: Backward pass...
  Epoch 499, Batch 4/4: Clipping gradients...
  Epoch 499, Batch 4/4: Optimizer step...
  Epoch 499, Batch 4/4: Completed in 0.03s
Epoch 499: Training phase completed. Average Train Loss: 0.2843
Epoch 499: Starting validation phase...
  Epoch 499, Val Batch 1/1: Loading data...
  Epoch 499, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 499, Val Batch 1/1: Forward pass...
  Epoch 499, Val Batch 1/1: Calculating loss...
Epoch 499: Validation phase completed. Average Val Loss: 0.2256
Epoch 499 Summary ---> Train Loss: 0.2843 / Validation Loss: 0.2256
Epoch 499: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 23)
  Epoch 499: Validation loss did not improve. Epochs without improvement: 24
Epoch 499: Stepping scheduler...
--- Epoch 499 completed in 0.66 seconds ---

--- Starting Epoch 500/1000 ---
Epoch 500: Starting training phase (4 batches)
  Epoch 500, Batch 1/4: Loading data to device...
  Epoch 500, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 500, Batch 1/4: Zeroing gradients...
  Epoch 500, Batch 1/4: Forward pass...
  Epoch 500, Batch 1/4: Calculating loss...
  Epoch 500, Batch 1/4: Backward pass...
  Epoch 500, Batch 1/4: Clipping gradients...
  Epoch 500, Batch 1/4: Optimizer step...
  Epoch 500, Batch 1/4: Completed in 0.20s
  Epoch 500, Batch 2/4: Loading data to device...
  Epoch 500, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 500, Batch 2/4: Zeroing gradients...
  Epoch 500, Batch 2/4: Forward pass...
  Epoch 500, Batch 2/4: Calculating loss...
  Epoch 500, Batch 2/4: Backward pass...
  Epoch 500, Batch 2/4: Clipping gradients...
  Epoch 500, Batch 2/4: Optimizer step...
  Epoch 500, Batch 2/4: Completed in 0.20s
  Epoch 500, Batch 3/4: Loading data to device...
  Epoch 500, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 500, Batch 3/4: Zeroing gradients...
  Epoch 500, Batch 3/4: Forward pass...
  Epoch 500, Batch 3/4: Calculating loss...
  Epoch 500, Batch 3/4: Backward pass...
  Epoch 500, Batch 3/4: Clipping gradients...
  Epoch 500, Batch 3/4: Optimizer step...
  Epoch 500, Batch 3/4: Completed in 0.20s
  Epoch 500, Batch 4/4: Loading data to device...
  Epoch 500, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 500, Batch 4/4: Zeroing gradients...
  Epoch 500, Batch 4/4: Forward pass...
  Epoch 500, Batch 4/4: Calculating loss...
  Epoch 500, Batch 4/4: Backward pass...
  Epoch 500, Batch 4/4: Clipping gradients...
  Epoch 500, Batch 4/4: Optimizer step...
  Epoch 500, Batch 4/4: Completed in 0.03s
Epoch 500: Training phase completed. Average Train Loss: 0.2648
Epoch 500: Starting validation phase...
  Epoch 500, Val Batch 1/1: Loading data...
  Epoch 500, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 500, Val Batch 1/1: Forward pass...
  Epoch 500, Val Batch 1/1: Calculating loss...
Epoch 500: Validation phase completed. Average Val Loss: 0.2284
Epoch 500 Summary ---> Train Loss: 0.2648 / Validation Loss: 0.2284
Epoch 500: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 24)
  Epoch 500: Validation loss did not improve. Epochs without improvement: 25
Epoch 500: Stepping scheduler...
--- Epoch 500 completed in 0.68 seconds ---

--- Starting Epoch 501/1000 ---
Epoch 501: Starting training phase (4 batches)
  Epoch 501, Batch 1/4: Loading data to device...
  Epoch 501, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 501, Batch 1/4: Zeroing gradients...
  Epoch 501, Batch 1/4: Forward pass...
  Epoch 501, Batch 1/4: Calculating loss...
  Epoch 501, Batch 1/4: Backward pass...
  Epoch 501, Batch 1/4: Clipping gradients...
  Epoch 501, Batch 1/4: Optimizer step...
  Epoch 501, Batch 1/4: Completed in 0.20s
  Epoch 501, Batch 2/4: Loading data to device...
  Epoch 501, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 501, Batch 2/4: Zeroing gradients...
  Epoch 501, Batch 2/4: Forward pass...
  Epoch 501, Batch 2/4: Calculating loss...
  Epoch 501, Batch 2/4: Backward pass...
  Epoch 501, Batch 2/4: Clipping gradients...
  Epoch 501, Batch 2/4: Optimizer step...
  Epoch 501, Batch 2/4: Completed in 0.20s
  Epoch 501, Batch 3/4: Loading data to device...
  Epoch 501, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 501, Batch 3/4: Zeroing gradients...
  Epoch 501, Batch 3/4: Forward pass...
  Epoch 501, Batch 3/4: Calculating loss...
  Epoch 501, Batch 3/4: Backward pass...
  Epoch 501, Batch 3/4: Clipping gradients...
  Epoch 501, Batch 3/4: Optimizer step...
  Epoch 501, Batch 3/4: Completed in 0.19s
  Epoch 501, Batch 4/4: Loading data to device...
  Epoch 501, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 501, Batch 4/4: Zeroing gradients...
  Epoch 501, Batch 4/4: Forward pass...
  Epoch 501, Batch 4/4: Calculating loss...
  Epoch 501, Batch 4/4: Backward pass...
  Epoch 501, Batch 4/4: Clipping gradients...
  Epoch 501, Batch 4/4: Optimizer step...
  Epoch 501, Batch 4/4: Completed in 0.03s
Epoch 501: Training phase completed. Average Train Loss: 0.3136
Epoch 501: Starting validation phase...
  Epoch 501, Val Batch 1/1: Loading data...
  Epoch 501, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 501, Val Batch 1/1: Forward pass...
  Epoch 501, Val Batch 1/1: Calculating loss...
Epoch 501: Validation phase completed. Average Val Loss: 0.2254
Epoch 501 Summary ---> Train Loss: 0.3136 / Validation Loss: 0.2254
Epoch 501: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 25)
  Epoch 501: Validation loss did not improve. Epochs without improvement: 26
Epoch 501: Stepping scheduler...
--- Epoch 501 completed in 0.68 seconds ---

--- Starting Epoch 502/1000 ---
Epoch 502: Starting training phase (4 batches)
  Epoch 502, Batch 1/4: Loading data to device...
  Epoch 502, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 502, Batch 1/4: Zeroing gradients...
  Epoch 502, Batch 1/4: Forward pass...
  Epoch 502, Batch 1/4: Calculating loss...
  Epoch 502, Batch 1/4: Backward pass...
  Epoch 502, Batch 1/4: Clipping gradients...
  Epoch 502, Batch 1/4: Optimizer step...
  Epoch 502, Batch 1/4: Completed in 0.19s
  Epoch 502, Batch 2/4: Loading data to device...
  Epoch 502, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 502, Batch 2/4: Zeroing gradients...
  Epoch 502, Batch 2/4: Forward pass...
  Epoch 502, Batch 2/4: Calculating loss...
  Epoch 502, Batch 2/4: Backward pass...
  Epoch 502, Batch 2/4: Clipping gradients...
  Epoch 502, Batch 2/4: Optimizer step...
  Epoch 502, Batch 2/4: Completed in 0.19s
  Epoch 502, Batch 3/4: Loading data to device...
  Epoch 502, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 502, Batch 3/4: Zeroing gradients...
  Epoch 502, Batch 3/4: Forward pass...
  Epoch 502, Batch 3/4: Calculating loss...
  Epoch 502, Batch 3/4: Backward pass...
  Epoch 502, Batch 3/4: Clipping gradients...
  Epoch 502, Batch 3/4: Optimizer step...
  Epoch 502, Batch 3/4: Completed in 0.20s
  Epoch 502, Batch 4/4: Loading data to device...
  Epoch 502, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 502, Batch 4/4: Zeroing gradients...
  Epoch 502, Batch 4/4: Forward pass...
  Epoch 502, Batch 4/4: Calculating loss...
  Epoch 502, Batch 4/4: Backward pass...
  Epoch 502, Batch 4/4: Clipping gradients...
  Epoch 502, Batch 4/4: Optimizer step...
  Epoch 502, Batch 4/4: Completed in 0.03s
Epoch 502: Training phase completed. Average Train Loss: 0.2823
Epoch 502: Starting validation phase...
  Epoch 502, Val Batch 1/1: Loading data...
  Epoch 502, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 502, Val Batch 1/1: Forward pass...
  Epoch 502, Val Batch 1/1: Calculating loss...
Epoch 502: Validation phase completed. Average Val Loss: 0.2262
Epoch 502 Summary ---> Train Loss: 0.2823 / Validation Loss: 0.2262
Epoch 502: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 26)
  Epoch 502: Validation loss did not improve. Epochs without improvement: 27
Epoch 502: Stepping scheduler...
--- Epoch 502 completed in 0.66 seconds ---

--- Starting Epoch 503/1000 ---
Epoch 503: Starting training phase (4 batches)
  Epoch 503, Batch 1/4: Loading data to device...
  Epoch 503, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 503, Batch 1/4: Zeroing gradients...
  Epoch 503, Batch 1/4: Forward pass...
  Epoch 503, Batch 1/4: Calculating loss...
  Epoch 503, Batch 1/4: Backward pass...
  Epoch 503, Batch 1/4: Clipping gradients...
  Epoch 503, Batch 1/4: Optimizer step...
  Epoch 503, Batch 1/4: Completed in 0.19s
  Epoch 503, Batch 2/4: Loading data to device...
  Epoch 503, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 503, Batch 2/4: Zeroing gradients...
  Epoch 503, Batch 2/4: Forward pass...
  Epoch 503, Batch 2/4: Calculating loss...
  Epoch 503, Batch 2/4: Backward pass...
  Epoch 503, Batch 2/4: Clipping gradients...
  Epoch 503, Batch 2/4: Optimizer step...
  Epoch 503, Batch 2/4: Completed in 0.20s
  Epoch 503, Batch 3/4: Loading data to device...
  Epoch 503, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 503, Batch 3/4: Zeroing gradients...
  Epoch 503, Batch 3/4: Forward pass...
  Epoch 503, Batch 3/4: Calculating loss...
  Epoch 503, Batch 3/4: Backward pass...
  Epoch 503, Batch 3/4: Clipping gradients...
  Epoch 503, Batch 3/4: Optimizer step...
  Epoch 503, Batch 3/4: Completed in 0.20s
  Epoch 503, Batch 4/4: Loading data to device...
  Epoch 503, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 503, Batch 4/4: Zeroing gradients...
  Epoch 503, Batch 4/4: Forward pass...
  Epoch 503, Batch 4/4: Calculating loss...
  Epoch 503, Batch 4/4: Backward pass...
  Epoch 503, Batch 4/4: Clipping gradients...
  Epoch 503, Batch 4/4: Optimizer step...
  Epoch 503, Batch 4/4: Completed in 0.03s
Epoch 503: Training phase completed. Average Train Loss: 0.2781
Epoch 503: Starting validation phase...
  Epoch 503, Val Batch 1/1: Loading data...
  Epoch 503, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 503, Val Batch 1/1: Forward pass...
  Epoch 503, Val Batch 1/1: Calculating loss...
Epoch 503: Validation phase completed. Average Val Loss: 0.2269
Epoch 503 Summary ---> Train Loss: 0.2781 / Validation Loss: 0.2269
Epoch 503: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 27)
  Epoch 503: Validation loss did not improve. Epochs without improvement: 28
Epoch 503: Stepping scheduler...
--- Epoch 503 completed in 0.68 seconds ---

--- Starting Epoch 504/1000 ---
Epoch 504: Starting training phase (4 batches)
  Epoch 504, Batch 1/4: Loading data to device...
  Epoch 504, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 504, Batch 1/4: Zeroing gradients...
  Epoch 504, Batch 1/4: Forward pass...
  Epoch 504, Batch 1/4: Calculating loss...
  Epoch 504, Batch 1/4: Backward pass...
  Epoch 504, Batch 1/4: Clipping gradients...
  Epoch 504, Batch 1/4: Optimizer step...
  Epoch 504, Batch 1/4: Completed in 0.19s
  Epoch 504, Batch 2/4: Loading data to device...
  Epoch 504, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 504, Batch 2/4: Zeroing gradients...
  Epoch 504, Batch 2/4: Forward pass...
  Epoch 504, Batch 2/4: Calculating loss...
  Epoch 504, Batch 2/4: Backward pass...
  Epoch 504, Batch 2/4: Clipping gradients...
  Epoch 504, Batch 2/4: Optimizer step...
  Epoch 504, Batch 2/4: Completed in 0.20s
  Epoch 504, Batch 3/4: Loading data to device...
  Epoch 504, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 504, Batch 3/4: Zeroing gradients...
  Epoch 504, Batch 3/4: Forward pass...
  Epoch 504, Batch 3/4: Calculating loss...
  Epoch 504, Batch 3/4: Backward pass...
  Epoch 504, Batch 3/4: Clipping gradients...
  Epoch 504, Batch 3/4: Optimizer step...
  Epoch 504, Batch 3/4: Completed in 0.19s
  Epoch 504, Batch 4/4: Loading data to device...
  Epoch 504, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 504, Batch 4/4: Zeroing gradients...
  Epoch 504, Batch 4/4: Forward pass...
  Epoch 504, Batch 4/4: Calculating loss...
  Epoch 504, Batch 4/4: Backward pass...
  Epoch 504, Batch 4/4: Clipping gradients...
  Epoch 504, Batch 4/4: Optimizer step...
  Epoch 504, Batch 4/4: Completed in 0.03s
Epoch 504: Training phase completed. Average Train Loss: 0.2819
Epoch 504: Starting validation phase...
  Epoch 504, Val Batch 1/1: Loading data...
  Epoch 504, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 504, Val Batch 1/1: Forward pass...
  Epoch 504, Val Batch 1/1: Calculating loss...
Epoch 504: Validation phase completed. Average Val Loss: 0.2233
Epoch 504 Summary ---> Train Loss: 0.2819 / Validation Loss: 0.2233
Epoch 504: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 28)
  Epoch 504: Validation loss did not improve. Epochs without improvement: 29
Epoch 504: Stepping scheduler...
--- Epoch 504 completed in 0.67 seconds ---

--- Starting Epoch 505/1000 ---
Epoch 505: Starting training phase (4 batches)
  Epoch 505, Batch 1/4: Loading data to device...
  Epoch 505, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 505, Batch 1/4: Zeroing gradients...
  Epoch 505, Batch 1/4: Forward pass...
  Epoch 505, Batch 1/4: Calculating loss...
  Epoch 505, Batch 1/4: Backward pass...
  Epoch 505, Batch 1/4: Clipping gradients...
  Epoch 505, Batch 1/4: Optimizer step...
  Epoch 505, Batch 1/4: Completed in 0.20s
  Epoch 505, Batch 2/4: Loading data to device...
  Epoch 505, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 505, Batch 2/4: Zeroing gradients...
  Epoch 505, Batch 2/4: Forward pass...
  Epoch 505, Batch 2/4: Calculating loss...
  Epoch 505, Batch 2/4: Backward pass...
  Epoch 505, Batch 2/4: Clipping gradients...
  Epoch 505, Batch 2/4: Optimizer step...
  Epoch 505, Batch 2/4: Completed in 0.19s
  Epoch 505, Batch 3/4: Loading data to device...
  Epoch 505, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 505, Batch 3/4: Zeroing gradients...
  Epoch 505, Batch 3/4: Forward pass...
  Epoch 505, Batch 3/4: Calculating loss...
  Epoch 505, Batch 3/4: Backward pass...
  Epoch 505, Batch 3/4: Clipping gradients...
  Epoch 505, Batch 3/4: Optimizer step...
  Epoch 505, Batch 3/4: Completed in 0.19s
  Epoch 505, Batch 4/4: Loading data to device...
  Epoch 505, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 505, Batch 4/4: Zeroing gradients...
  Epoch 505, Batch 4/4: Forward pass...
  Epoch 505, Batch 4/4: Calculating loss...
  Epoch 505, Batch 4/4: Backward pass...
  Epoch 505, Batch 4/4: Clipping gradients...
  Epoch 505, Batch 4/4: Optimizer step...
  Epoch 505, Batch 4/4: Completed in 0.03s
Epoch 505: Training phase completed. Average Train Loss: 0.2980
Epoch 505: Starting validation phase...
  Epoch 505, Val Batch 1/1: Loading data...
  Epoch 505, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 505, Val Batch 1/1: Forward pass...
  Epoch 505, Val Batch 1/1: Calculating loss...
Epoch 505: Validation phase completed. Average Val Loss: 0.2230
Epoch 505 Summary ---> Train Loss: 0.2980 / Validation Loss: 0.2230
Epoch 505: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 29)
  Epoch 505: Validation loss did not improve. Epochs without improvement: 30
Epoch 505: Stepping scheduler...
--- Epoch 505 completed in 0.67 seconds ---

--- Starting Epoch 506/1000 ---
Epoch 506: Starting training phase (4 batches)
  Epoch 506, Batch 1/4: Loading data to device...
  Epoch 506, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 506, Batch 1/4: Zeroing gradients...
  Epoch 506, Batch 1/4: Forward pass...
  Epoch 506, Batch 1/4: Calculating loss...
  Epoch 506, Batch 1/4: Backward pass...
  Epoch 506, Batch 1/4: Clipping gradients...
  Epoch 506, Batch 1/4: Optimizer step...
  Epoch 506, Batch 1/4: Completed in 0.20s
  Epoch 506, Batch 2/4: Loading data to device...
  Epoch 506, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 506, Batch 2/4: Zeroing gradients...
  Epoch 506, Batch 2/4: Forward pass...
  Epoch 506, Batch 2/4: Calculating loss...
  Epoch 506, Batch 2/4: Backward pass...
  Epoch 506, Batch 2/4: Clipping gradients...
  Epoch 506, Batch 2/4: Optimizer step...
  Epoch 506, Batch 2/4: Completed in 0.20s
  Epoch 506, Batch 3/4: Loading data to device...
  Epoch 506, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 506, Batch 3/4: Zeroing gradients...
  Epoch 506, Batch 3/4: Forward pass...
  Epoch 506, Batch 3/4: Calculating loss...
  Epoch 506, Batch 3/4: Backward pass...
  Epoch 506, Batch 3/4: Clipping gradients...
  Epoch 506, Batch 3/4: Optimizer step...
  Epoch 506, Batch 3/4: Completed in 0.19s
  Epoch 506, Batch 4/4: Loading data to device...
  Epoch 506, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 506, Batch 4/4: Zeroing gradients...
  Epoch 506, Batch 4/4: Forward pass...
  Epoch 506, Batch 4/4: Calculating loss...
  Epoch 506, Batch 4/4: Backward pass...
  Epoch 506, Batch 4/4: Clipping gradients...
  Epoch 506, Batch 4/4: Optimizer step...
  Epoch 506, Batch 4/4: Completed in 0.03s
Epoch 506: Training phase completed. Average Train Loss: 0.2782
Epoch 506: Starting validation phase...
  Epoch 506, Val Batch 1/1: Loading data...
  Epoch 506, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 506, Val Batch 1/1: Forward pass...
  Epoch 506, Val Batch 1/1: Calculating loss...
Epoch 506: Validation phase completed. Average Val Loss: 0.2268
Epoch 506 Summary ---> Train Loss: 0.2782 / Validation Loss: 0.2268
Epoch 506: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 30)
  Epoch 506: Validation loss did not improve. Epochs without improvement: 31
Epoch 506: Stepping scheduler...
--- Epoch 506 completed in 0.68 seconds ---

--- Starting Epoch 507/1000 ---
Epoch 507: Starting training phase (4 batches)
  Epoch 507, Batch 1/4: Loading data to device...
  Epoch 507, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 507, Batch 1/4: Zeroing gradients...
  Epoch 507, Batch 1/4: Forward pass...
  Epoch 507, Batch 1/4: Calculating loss...
  Epoch 507, Batch 1/4: Backward pass...
  Epoch 507, Batch 1/4: Clipping gradients...
  Epoch 507, Batch 1/4: Optimizer step...
  Epoch 507, Batch 1/4: Completed in 0.20s
  Epoch 507, Batch 2/4: Loading data to device...
  Epoch 507, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 507, Batch 2/4: Zeroing gradients...
  Epoch 507, Batch 2/4: Forward pass...
  Epoch 507, Batch 2/4: Calculating loss...
  Epoch 507, Batch 2/4: Backward pass...
  Epoch 507, Batch 2/4: Clipping gradients...
  Epoch 507, Batch 2/4: Optimizer step...
  Epoch 507, Batch 2/4: Completed in 0.19s
  Epoch 507, Batch 3/4: Loading data to device...
  Epoch 507, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 507, Batch 3/4: Zeroing gradients...
  Epoch 507, Batch 3/4: Forward pass...
  Epoch 507, Batch 3/4: Calculating loss...
  Epoch 507, Batch 3/4: Backward pass...
  Epoch 507, Batch 3/4: Clipping gradients...
  Epoch 507, Batch 3/4: Optimizer step...
  Epoch 507, Batch 3/4: Completed in 0.19s
  Epoch 507, Batch 4/4: Loading data to device...
  Epoch 507, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 507, Batch 4/4: Zeroing gradients...
  Epoch 507, Batch 4/4: Forward pass...
  Epoch 507, Batch 4/4: Calculating loss...
  Epoch 507, Batch 4/4: Backward pass...
  Epoch 507, Batch 4/4: Clipping gradients...
  Epoch 507, Batch 4/4: Optimizer step...
  Epoch 507, Batch 4/4: Completed in 0.03s
Epoch 507: Training phase completed. Average Train Loss: 0.3004
Epoch 507: Starting validation phase...
  Epoch 507, Val Batch 1/1: Loading data...
  Epoch 507, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 507, Val Batch 1/1: Forward pass...
  Epoch 507, Val Batch 1/1: Calculating loss...
Epoch 507: Validation phase completed. Average Val Loss: 0.2257
Epoch 507 Summary ---> Train Loss: 0.3004 / Validation Loss: 0.2257
Epoch 507: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 31)
  Epoch 507: Validation loss did not improve. Epochs without improvement: 32
Epoch 507: Stepping scheduler...
--- Epoch 507 completed in 0.68 seconds ---

--- Starting Epoch 508/1000 ---
Epoch 508: Starting training phase (4 batches)
  Epoch 508, Batch 1/4: Loading data to device...
  Epoch 508, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 508, Batch 1/4: Zeroing gradients...
  Epoch 508, Batch 1/4: Forward pass...
  Epoch 508, Batch 1/4: Calculating loss...
  Epoch 508, Batch 1/4: Backward pass...
  Epoch 508, Batch 1/4: Clipping gradients...
  Epoch 508, Batch 1/4: Optimizer step...
  Epoch 508, Batch 1/4: Completed in 0.18s
  Epoch 508, Batch 2/4: Loading data to device...
  Epoch 508, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 508, Batch 2/4: Zeroing gradients...
  Epoch 508, Batch 2/4: Forward pass...
  Epoch 508, Batch 2/4: Calculating loss...
  Epoch 508, Batch 2/4: Backward pass...
  Epoch 508, Batch 2/4: Clipping gradients...
  Epoch 508, Batch 2/4: Optimizer step...
  Epoch 508, Batch 2/4: Completed in 0.18s
  Epoch 508, Batch 3/4: Loading data to device...
  Epoch 508, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 508, Batch 3/4: Zeroing gradients...
  Epoch 508, Batch 3/4: Forward pass...
  Epoch 508, Batch 3/4: Calculating loss...
  Epoch 508, Batch 3/4: Backward pass...
  Epoch 508, Batch 3/4: Clipping gradients...
  Epoch 508, Batch 3/4: Optimizer step...
  Epoch 508, Batch 3/4: Completed in 0.19s
  Epoch 508, Batch 4/4: Loading data to device...
  Epoch 508, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 508, Batch 4/4: Zeroing gradients...
  Epoch 508, Batch 4/4: Forward pass...
  Epoch 508, Batch 4/4: Calculating loss...
  Epoch 508, Batch 4/4: Backward pass...
  Epoch 508, Batch 4/4: Clipping gradients...
  Epoch 508, Batch 4/4: Optimizer step...
  Epoch 508, Batch 4/4: Completed in 0.03s
Epoch 508: Training phase completed. Average Train Loss: 0.2716
Epoch 508: Starting validation phase...
  Epoch 508, Val Batch 1/1: Loading data...
  Epoch 508, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 508, Val Batch 1/1: Forward pass...
  Epoch 508, Val Batch 1/1: Calculating loss...
Epoch 508: Validation phase completed. Average Val Loss: 0.2250
Epoch 508 Summary ---> Train Loss: 0.2716 / Validation Loss: 0.2250
Epoch 508: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 32)
  Epoch 508: Validation loss did not improve. Epochs without improvement: 33
Epoch 508: Stepping scheduler...
--- Epoch 508 completed in 0.65 seconds ---

--- Starting Epoch 509/1000 ---
Epoch 509: Starting training phase (4 batches)
  Epoch 509, Batch 1/4: Loading data to device...
  Epoch 509, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 509, Batch 1/4: Zeroing gradients...
  Epoch 509, Batch 1/4: Forward pass...
  Epoch 509, Batch 1/4: Calculating loss...
  Epoch 509, Batch 1/4: Backward pass...
  Epoch 509, Batch 1/4: Clipping gradients...
  Epoch 509, Batch 1/4: Optimizer step...
  Epoch 509, Batch 1/4: Completed in 0.19s
  Epoch 509, Batch 2/4: Loading data to device...
  Epoch 509, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 509, Batch 2/4: Zeroing gradients...
  Epoch 509, Batch 2/4: Forward pass...
  Epoch 509, Batch 2/4: Calculating loss...
  Epoch 509, Batch 2/4: Backward pass...
  Epoch 509, Batch 2/4: Clipping gradients...
  Epoch 509, Batch 2/4: Optimizer step...
  Epoch 509, Batch 2/4: Completed in 0.20s
  Epoch 509, Batch 3/4: Loading data to device...
  Epoch 509, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 509, Batch 3/4: Zeroing gradients...
  Epoch 509, Batch 3/4: Forward pass...
  Epoch 509, Batch 3/4: Calculating loss...
  Epoch 509, Batch 3/4: Backward pass...
  Epoch 509, Batch 3/4: Clipping gradients...
  Epoch 509, Batch 3/4: Optimizer step...
  Epoch 509, Batch 3/4: Completed in 0.20s
  Epoch 509, Batch 4/4: Loading data to device...
  Epoch 509, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 509, Batch 4/4: Zeroing gradients...
  Epoch 509, Batch 4/4: Forward pass...
  Epoch 509, Batch 4/4: Calculating loss...
  Epoch 509, Batch 4/4: Backward pass...
  Epoch 509, Batch 4/4: Clipping gradients...
  Epoch 509, Batch 4/4: Optimizer step...
  Epoch 509, Batch 4/4: Completed in 0.03s
Epoch 509: Training phase completed. Average Train Loss: 0.4046
Epoch 509: Starting validation phase...
  Epoch 509, Val Batch 1/1: Loading data...
  Epoch 509, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 509, Val Batch 1/1: Forward pass...
  Epoch 509, Val Batch 1/1: Calculating loss...
Epoch 509: Validation phase completed. Average Val Loss: 0.2267
Epoch 509 Summary ---> Train Loss: 0.4046 / Validation Loss: 0.2267
Epoch 509: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 33)
  Epoch 509: Validation loss did not improve. Epochs without improvement: 34
Epoch 509: Stepping scheduler...
--- Epoch 509 completed in 0.68 seconds ---

--- Starting Epoch 510/1000 ---
Epoch 510: Starting training phase (4 batches)
  Epoch 510, Batch 1/4: Loading data to device...
  Epoch 510, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 510, Batch 1/4: Zeroing gradients...
  Epoch 510, Batch 1/4: Forward pass...
  Epoch 510, Batch 1/4: Calculating loss...
  Epoch 510, Batch 1/4: Backward pass...
  Epoch 510, Batch 1/4: Clipping gradients...
  Epoch 510, Batch 1/4: Optimizer step...
  Epoch 510, Batch 1/4: Completed in 0.20s
  Epoch 510, Batch 2/4: Loading data to device...
  Epoch 510, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 510, Batch 2/4: Zeroing gradients...
  Epoch 510, Batch 2/4: Forward pass...
  Epoch 510, Batch 2/4: Calculating loss...
  Epoch 510, Batch 2/4: Backward pass...
  Epoch 510, Batch 2/4: Clipping gradients...
  Epoch 510, Batch 2/4: Optimizer step...
  Epoch 510, Batch 2/4: Completed in 0.19s
  Epoch 510, Batch 3/4: Loading data to device...
  Epoch 510, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 510, Batch 3/4: Zeroing gradients...
  Epoch 510, Batch 3/4: Forward pass...
  Epoch 510, Batch 3/4: Calculating loss...
  Epoch 510, Batch 3/4: Backward pass...
  Epoch 510, Batch 3/4: Clipping gradients...
  Epoch 510, Batch 3/4: Optimizer step...
  Epoch 510, Batch 3/4: Completed in 0.20s
  Epoch 510, Batch 4/4: Loading data to device...
  Epoch 510, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 510, Batch 4/4: Zeroing gradients...
  Epoch 510, Batch 4/4: Forward pass...
  Epoch 510, Batch 4/4: Calculating loss...
  Epoch 510, Batch 4/4: Backward pass...
  Epoch 510, Batch 4/4: Clipping gradients...
  Epoch 510, Batch 4/4: Optimizer step...
  Epoch 510, Batch 4/4: Completed in 0.03s
Epoch 510: Training phase completed. Average Train Loss: 0.2851
Epoch 510: Starting validation phase...
  Epoch 510, Val Batch 1/1: Loading data...
  Epoch 510, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 510, Val Batch 1/1: Forward pass...
  Epoch 510, Val Batch 1/1: Calculating loss...
Epoch 510: Validation phase completed. Average Val Loss: 0.2281
Epoch 510 Summary ---> Train Loss: 0.2851 / Validation Loss: 0.2281
Epoch 510: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 34)
  Epoch 510: Validation loss did not improve. Epochs without improvement: 35
Epoch 510: Stepping scheduler...
--- Epoch 510 completed in 0.68 seconds ---

--- Starting Epoch 511/1000 ---
Epoch 511: Starting training phase (4 batches)
  Epoch 511, Batch 1/4: Loading data to device...
  Epoch 511, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 511, Batch 1/4: Zeroing gradients...
  Epoch 511, Batch 1/4: Forward pass...
  Epoch 511, Batch 1/4: Calculating loss...
  Epoch 511, Batch 1/4: Backward pass...
  Epoch 511, Batch 1/4: Clipping gradients...
  Epoch 511, Batch 1/4: Optimizer step...
  Epoch 511, Batch 1/4: Completed in 0.19s
  Epoch 511, Batch 2/4: Loading data to device...
  Epoch 511, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 511, Batch 2/4: Zeroing gradients...
  Epoch 511, Batch 2/4: Forward pass...
  Epoch 511, Batch 2/4: Calculating loss...
  Epoch 511, Batch 2/4: Backward pass...
  Epoch 511, Batch 2/4: Clipping gradients...
  Epoch 511, Batch 2/4: Optimizer step...
  Epoch 511, Batch 2/4: Completed in 0.19s
  Epoch 511, Batch 3/4: Loading data to device...
  Epoch 511, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 511, Batch 3/4: Zeroing gradients...
  Epoch 511, Batch 3/4: Forward pass...
  Epoch 511, Batch 3/4: Calculating loss...
  Epoch 511, Batch 3/4: Backward pass...
  Epoch 511, Batch 3/4: Clipping gradients...
  Epoch 511, Batch 3/4: Optimizer step...
  Epoch 511, Batch 3/4: Completed in 0.20s
  Epoch 511, Batch 4/4: Loading data to device...
  Epoch 511, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 511, Batch 4/4: Zeroing gradients...
  Epoch 511, Batch 4/4: Forward pass...
  Epoch 511, Batch 4/4: Calculating loss...
  Epoch 511, Batch 4/4: Backward pass...
  Epoch 511, Batch 4/4: Clipping gradients...
  Epoch 511, Batch 4/4: Optimizer step...
  Epoch 511, Batch 4/4: Completed in 0.03s
Epoch 511: Training phase completed. Average Train Loss: 0.3375
Epoch 511: Starting validation phase...
  Epoch 511, Val Batch 1/1: Loading data...
  Epoch 511, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 511, Val Batch 1/1: Forward pass...
  Epoch 511, Val Batch 1/1: Calculating loss...
Epoch 511: Validation phase completed. Average Val Loss: 0.2299
Epoch 511 Summary ---> Train Loss: 0.3375 / Validation Loss: 0.2299
Epoch 511: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 35)
  Epoch 511: Validation loss did not improve. Epochs without improvement: 36
Epoch 511: Stepping scheduler...
--- Epoch 511 completed in 0.67 seconds ---

--- Starting Epoch 512/1000 ---
Epoch 512: Starting training phase (4 batches)
  Epoch 512, Batch 1/4: Loading data to device...
  Epoch 512, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 512, Batch 1/4: Zeroing gradients...
  Epoch 512, Batch 1/4: Forward pass...
  Epoch 512, Batch 1/4: Calculating loss...
  Epoch 512, Batch 1/4: Backward pass...
  Epoch 512, Batch 1/4: Clipping gradients...
  Epoch 512, Batch 1/4: Optimizer step...
  Epoch 512, Batch 1/4: Completed in 0.20s
  Epoch 512, Batch 2/4: Loading data to device...
  Epoch 512, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 512, Batch 2/4: Zeroing gradients...
  Epoch 512, Batch 2/4: Forward pass...
  Epoch 512, Batch 2/4: Calculating loss...
  Epoch 512, Batch 2/4: Backward pass...
  Epoch 512, Batch 2/4: Clipping gradients...
  Epoch 512, Batch 2/4: Optimizer step...
  Epoch 512, Batch 2/4: Completed in 0.19s
  Epoch 512, Batch 3/4: Loading data to device...
  Epoch 512, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 512, Batch 3/4: Zeroing gradients...
  Epoch 512, Batch 3/4: Forward pass...
  Epoch 512, Batch 3/4: Calculating loss...
  Epoch 512, Batch 3/4: Backward pass...
  Epoch 512, Batch 3/4: Clipping gradients...
  Epoch 512, Batch 3/4: Optimizer step...
  Epoch 512, Batch 3/4: Completed in 0.19s
  Epoch 512, Batch 4/4: Loading data to device...
  Epoch 512, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 512, Batch 4/4: Zeroing gradients...
  Epoch 512, Batch 4/4: Forward pass...
  Epoch 512, Batch 4/4: Calculating loss...
  Epoch 512, Batch 4/4: Backward pass...
  Epoch 512, Batch 4/4: Clipping gradients...
  Epoch 512, Batch 4/4: Optimizer step...
  Epoch 512, Batch 4/4: Completed in 0.03s
Epoch 512: Training phase completed. Average Train Loss: 0.3569
Epoch 512: Starting validation phase...
  Epoch 512, Val Batch 1/1: Loading data...
  Epoch 512, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 512, Val Batch 1/1: Forward pass...
  Epoch 512, Val Batch 1/1: Calculating loss...
Epoch 512: Validation phase completed. Average Val Loss: 0.2281
Epoch 512 Summary ---> Train Loss: 0.3569 / Validation Loss: 0.2281
Epoch 512: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 36)
  Epoch 512: Validation loss did not improve. Epochs without improvement: 37
Epoch 512: Stepping scheduler...
--- Epoch 512 completed in 0.67 seconds ---

--- Starting Epoch 513/1000 ---
Epoch 513: Starting training phase (4 batches)
  Epoch 513, Batch 1/4: Loading data to device...
  Epoch 513, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 513, Batch 1/4: Zeroing gradients...
  Epoch 513, Batch 1/4: Forward pass...
  Epoch 513, Batch 1/4: Calculating loss...
  Epoch 513, Batch 1/4: Backward pass...
  Epoch 513, Batch 1/4: Clipping gradients...
  Epoch 513, Batch 1/4: Optimizer step...
  Epoch 513, Batch 1/4: Completed in 0.18s
  Epoch 513, Batch 2/4: Loading data to device...
  Epoch 513, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 513, Batch 2/4: Zeroing gradients...
  Epoch 513, Batch 2/4: Forward pass...
  Epoch 513, Batch 2/4: Calculating loss...
  Epoch 513, Batch 2/4: Backward pass...
  Epoch 513, Batch 2/4: Clipping gradients...
  Epoch 513, Batch 2/4: Optimizer step...
  Epoch 513, Batch 2/4: Completed in 0.19s
  Epoch 513, Batch 3/4: Loading data to device...
  Epoch 513, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 513, Batch 3/4: Zeroing gradients...
  Epoch 513, Batch 3/4: Forward pass...
  Epoch 513, Batch 3/4: Calculating loss...
  Epoch 513, Batch 3/4: Backward pass...
  Epoch 513, Batch 3/4: Clipping gradients...
  Epoch 513, Batch 3/4: Optimizer step...
  Epoch 513, Batch 3/4: Completed in 0.19s
  Epoch 513, Batch 4/4: Loading data to device...
  Epoch 513, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 513, Batch 4/4: Zeroing gradients...
  Epoch 513, Batch 4/4: Forward pass...
  Epoch 513, Batch 4/4: Calculating loss...
  Epoch 513, Batch 4/4: Backward pass...
  Epoch 513, Batch 4/4: Clipping gradients...
  Epoch 513, Batch 4/4: Optimizer step...
  Epoch 513, Batch 4/4: Completed in 0.03s
Epoch 513: Training phase completed. Average Train Loss: 0.3652
Epoch 513: Starting validation phase...
  Epoch 513, Val Batch 1/1: Loading data...
  Epoch 513, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 513, Val Batch 1/1: Forward pass...
  Epoch 513, Val Batch 1/1: Calculating loss...
Epoch 513: Validation phase completed. Average Val Loss: 0.2258
Epoch 513 Summary ---> Train Loss: 0.3652 / Validation Loss: 0.2258
Epoch 513: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 37)
  Epoch 513: Validation loss did not improve. Epochs without improvement: 38
Epoch 513: Stepping scheduler...
--- Epoch 513 completed in 0.65 seconds ---

--- Starting Epoch 514/1000 ---
Epoch 514: Starting training phase (4 batches)
  Epoch 514, Batch 1/4: Loading data to device...
  Epoch 514, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 514, Batch 1/4: Zeroing gradients...
  Epoch 514, Batch 1/4: Forward pass...
  Epoch 514, Batch 1/4: Calculating loss...
  Epoch 514, Batch 1/4: Backward pass...
  Epoch 514, Batch 1/4: Clipping gradients...
  Epoch 514, Batch 1/4: Optimizer step...
  Epoch 514, Batch 1/4: Completed in 0.19s
  Epoch 514, Batch 2/4: Loading data to device...
  Epoch 514, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 514, Batch 2/4: Zeroing gradients...
  Epoch 514, Batch 2/4: Forward pass...
  Epoch 514, Batch 2/4: Calculating loss...
  Epoch 514, Batch 2/4: Backward pass...
  Epoch 514, Batch 2/4: Clipping gradients...
  Epoch 514, Batch 2/4: Optimizer step...
  Epoch 514, Batch 2/4: Completed in 0.19s
  Epoch 514, Batch 3/4: Loading data to device...
  Epoch 514, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 514, Batch 3/4: Zeroing gradients...
  Epoch 514, Batch 3/4: Forward pass...
  Epoch 514, Batch 3/4: Calculating loss...
  Epoch 514, Batch 3/4: Backward pass...
  Epoch 514, Batch 3/4: Clipping gradients...
  Epoch 514, Batch 3/4: Optimizer step...
  Epoch 514, Batch 3/4: Completed in 0.20s
  Epoch 514, Batch 4/4: Loading data to device...
  Epoch 514, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 514, Batch 4/4: Zeroing gradients...
  Epoch 514, Batch 4/4: Forward pass...
  Epoch 514, Batch 4/4: Calculating loss...
  Epoch 514, Batch 4/4: Backward pass...
  Epoch 514, Batch 4/4: Clipping gradients...
  Epoch 514, Batch 4/4: Optimizer step...
  Epoch 514, Batch 4/4: Completed in 0.03s
Epoch 514: Training phase completed. Average Train Loss: 0.3776
Epoch 514: Starting validation phase...
  Epoch 514, Val Batch 1/1: Loading data...
  Epoch 514, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 514, Val Batch 1/1: Forward pass...
  Epoch 514, Val Batch 1/1: Calculating loss...
Epoch 514: Validation phase completed. Average Val Loss: 0.2262
Epoch 514 Summary ---> Train Loss: 0.3776 / Validation Loss: 0.2262
Epoch 514: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 38)
  Epoch 514: Validation loss did not improve. Epochs without improvement: 39
Epoch 514: Stepping scheduler...
--- Epoch 514 completed in 0.67 seconds ---

--- Starting Epoch 515/1000 ---
Epoch 515: Starting training phase (4 batches)
  Epoch 515, Batch 1/4: Loading data to device...
  Epoch 515, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 515, Batch 1/4: Zeroing gradients...
  Epoch 515, Batch 1/4: Forward pass...
  Epoch 515, Batch 1/4: Calculating loss...
  Epoch 515, Batch 1/4: Backward pass...
  Epoch 515, Batch 1/4: Clipping gradients...
  Epoch 515, Batch 1/4: Optimizer step...
  Epoch 515, Batch 1/4: Completed in 0.19s
  Epoch 515, Batch 2/4: Loading data to device...
  Epoch 515, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 515, Batch 2/4: Zeroing gradients...
  Epoch 515, Batch 2/4: Forward pass...
  Epoch 515, Batch 2/4: Calculating loss...
  Epoch 515, Batch 2/4: Backward pass...
  Epoch 515, Batch 2/4: Clipping gradients...
  Epoch 515, Batch 2/4: Optimizer step...
  Epoch 515, Batch 2/4: Completed in 0.19s
  Epoch 515, Batch 3/4: Loading data to device...
  Epoch 515, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 515, Batch 3/4: Zeroing gradients...
  Epoch 515, Batch 3/4: Forward pass...
  Epoch 515, Batch 3/4: Calculating loss...
  Epoch 515, Batch 3/4: Backward pass...
  Epoch 515, Batch 3/4: Clipping gradients...
  Epoch 515, Batch 3/4: Optimizer step...
  Epoch 515, Batch 3/4: Completed in 0.19s
  Epoch 515, Batch 4/4: Loading data to device...
  Epoch 515, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 515, Batch 4/4: Zeroing gradients...
  Epoch 515, Batch 4/4: Forward pass...
  Epoch 515, Batch 4/4: Calculating loss...
  Epoch 515, Batch 4/4: Backward pass...
  Epoch 515, Batch 4/4: Clipping gradients...
  Epoch 515, Batch 4/4: Optimizer step...
  Epoch 515, Batch 4/4: Completed in 0.03s
Epoch 515: Training phase completed. Average Train Loss: 0.3375
Epoch 515: Starting validation phase...
  Epoch 515, Val Batch 1/1: Loading data...
  Epoch 515, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 515, Val Batch 1/1: Forward pass...
  Epoch 515, Val Batch 1/1: Calculating loss...
Epoch 515: Validation phase completed. Average Val Loss: 0.2268
Epoch 515 Summary ---> Train Loss: 0.3375 / Validation Loss: 0.2268
Epoch 515: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 39)
  Epoch 515: Validation loss did not improve. Epochs without improvement: 40
Epoch 515: Stepping scheduler...
--- Epoch 515 completed in 0.66 seconds ---

--- Starting Epoch 516/1000 ---
Epoch 516: Starting training phase (4 batches)
  Epoch 516, Batch 1/4: Loading data to device...
  Epoch 516, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 516, Batch 1/4: Zeroing gradients...
  Epoch 516, Batch 1/4: Forward pass...
  Epoch 516, Batch 1/4: Calculating loss...
  Epoch 516, Batch 1/4: Backward pass...
  Epoch 516, Batch 1/4: Clipping gradients...
  Epoch 516, Batch 1/4: Optimizer step...
  Epoch 516, Batch 1/4: Completed in 0.19s
  Epoch 516, Batch 2/4: Loading data to device...
  Epoch 516, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 516, Batch 2/4: Zeroing gradients...
  Epoch 516, Batch 2/4: Forward pass...
  Epoch 516, Batch 2/4: Calculating loss...
  Epoch 516, Batch 2/4: Backward pass...
  Epoch 516, Batch 2/4: Clipping gradients...
  Epoch 516, Batch 2/4: Optimizer step...
  Epoch 516, Batch 2/4: Completed in 0.18s
  Epoch 516, Batch 3/4: Loading data to device...
  Epoch 516, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 516, Batch 3/4: Zeroing gradients...
  Epoch 516, Batch 3/4: Forward pass...
  Epoch 516, Batch 3/4: Calculating loss...
  Epoch 516, Batch 3/4: Backward pass...
  Epoch 516, Batch 3/4: Clipping gradients...
  Epoch 516, Batch 3/4: Optimizer step...
  Epoch 516, Batch 3/4: Completed in 0.19s
  Epoch 516, Batch 4/4: Loading data to device...
  Epoch 516, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 516, Batch 4/4: Zeroing gradients...
  Epoch 516, Batch 4/4: Forward pass...
  Epoch 516, Batch 4/4: Calculating loss...
  Epoch 516, Batch 4/4: Backward pass...
  Epoch 516, Batch 4/4: Clipping gradients...
  Epoch 516, Batch 4/4: Optimizer step...
  Epoch 516, Batch 4/4: Completed in 0.03s
Epoch 516: Training phase completed. Average Train Loss: 0.2942
Epoch 516: Starting validation phase...
  Epoch 516, Val Batch 1/1: Loading data...
  Epoch 516, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 516, Val Batch 1/1: Forward pass...
  Epoch 516, Val Batch 1/1: Calculating loss...
Epoch 516: Validation phase completed. Average Val Loss: 0.2261
Epoch 516 Summary ---> Train Loss: 0.2942 / Validation Loss: 0.2261
Epoch 516: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 40)
  Epoch 516: Validation loss did not improve. Epochs without improvement: 41
Epoch 516: Stepping scheduler...
--- Epoch 516 completed in 0.65 seconds ---

--- Starting Epoch 517/1000 ---
Epoch 517: Starting training phase (4 batches)
  Epoch 517, Batch 1/4: Loading data to device...
  Epoch 517, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 517, Batch 1/4: Zeroing gradients...
  Epoch 517, Batch 1/4: Forward pass...
  Epoch 517, Batch 1/4: Calculating loss...
  Epoch 517, Batch 1/4: Backward pass...
  Epoch 517, Batch 1/4: Clipping gradients...
  Epoch 517, Batch 1/4: Optimizer step...
  Epoch 517, Batch 1/4: Completed in 0.19s
  Epoch 517, Batch 2/4: Loading data to device...
  Epoch 517, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 517, Batch 2/4: Zeroing gradients...
  Epoch 517, Batch 2/4: Forward pass...
  Epoch 517, Batch 2/4: Calculating loss...
  Epoch 517, Batch 2/4: Backward pass...
  Epoch 517, Batch 2/4: Clipping gradients...
  Epoch 517, Batch 2/4: Optimizer step...
  Epoch 517, Batch 2/4: Completed in 0.20s
  Epoch 517, Batch 3/4: Loading data to device...
  Epoch 517, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 517, Batch 3/4: Zeroing gradients...
  Epoch 517, Batch 3/4: Forward pass...
  Epoch 517, Batch 3/4: Calculating loss...
  Epoch 517, Batch 3/4: Backward pass...
  Epoch 517, Batch 3/4: Clipping gradients...
  Epoch 517, Batch 3/4: Optimizer step...
  Epoch 517, Batch 3/4: Completed in 0.19s
  Epoch 517, Batch 4/4: Loading data to device...
  Epoch 517, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 517, Batch 4/4: Zeroing gradients...
  Epoch 517, Batch 4/4: Forward pass...
  Epoch 517, Batch 4/4: Calculating loss...
  Epoch 517, Batch 4/4: Backward pass...
  Epoch 517, Batch 4/4: Clipping gradients...
  Epoch 517, Batch 4/4: Optimizer step...
  Epoch 517, Batch 4/4: Completed in 0.03s
Epoch 517: Training phase completed. Average Train Loss: 0.3046
Epoch 517: Starting validation phase...
  Epoch 517, Val Batch 1/1: Loading data...
  Epoch 517, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 517, Val Batch 1/1: Forward pass...
  Epoch 517, Val Batch 1/1: Calculating loss...
Epoch 517: Validation phase completed. Average Val Loss: 0.2252
Epoch 517 Summary ---> Train Loss: 0.3046 / Validation Loss: 0.2252
Epoch 517: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 41)
  Epoch 517: Validation loss did not improve. Epochs without improvement: 42
Epoch 517: Stepping scheduler...
--- Epoch 517 completed in 0.66 seconds ---

--- Starting Epoch 518/1000 ---
Epoch 518: Starting training phase (4 batches)
  Epoch 518, Batch 1/4: Loading data to device...
  Epoch 518, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 518, Batch 1/4: Zeroing gradients...
  Epoch 518, Batch 1/4: Forward pass...
  Epoch 518, Batch 1/4: Calculating loss...
  Epoch 518, Batch 1/4: Backward pass...
  Epoch 518, Batch 1/4: Clipping gradients...
  Epoch 518, Batch 1/4: Optimizer step...
  Epoch 518, Batch 1/4: Completed in 0.18s
  Epoch 518, Batch 2/4: Loading data to device...
  Epoch 518, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 518, Batch 2/4: Zeroing gradients...
  Epoch 518, Batch 2/4: Forward pass...
  Epoch 518, Batch 2/4: Calculating loss...
  Epoch 518, Batch 2/4: Backward pass...
  Epoch 518, Batch 2/4: Clipping gradients...
  Epoch 518, Batch 2/4: Optimizer step...
  Epoch 518, Batch 2/4: Completed in 0.19s
  Epoch 518, Batch 3/4: Loading data to device...
  Epoch 518, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 518, Batch 3/4: Zeroing gradients...
  Epoch 518, Batch 3/4: Forward pass...
  Epoch 518, Batch 3/4: Calculating loss...
  Epoch 518, Batch 3/4: Backward pass...
  Epoch 518, Batch 3/4: Clipping gradients...
  Epoch 518, Batch 3/4: Optimizer step...
  Epoch 518, Batch 3/4: Completed in 0.19s
  Epoch 518, Batch 4/4: Loading data to device...
  Epoch 518, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 518, Batch 4/4: Zeroing gradients...
  Epoch 518, Batch 4/4: Forward pass...
  Epoch 518, Batch 4/4: Calculating loss...
  Epoch 518, Batch 4/4: Backward pass...
  Epoch 518, Batch 4/4: Clipping gradients...
  Epoch 518, Batch 4/4: Optimizer step...
  Epoch 518, Batch 4/4: Completed in 0.03s
Epoch 518: Training phase completed. Average Train Loss: 0.2676
Epoch 518: Starting validation phase...
  Epoch 518, Val Batch 1/1: Loading data...
  Epoch 518, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 518, Val Batch 1/1: Forward pass...
  Epoch 518, Val Batch 1/1: Calculating loss...
Epoch 518: Validation phase completed. Average Val Loss: 0.2247
Epoch 518 Summary ---> Train Loss: 0.2676 / Validation Loss: 0.2247
Epoch 518: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 42)
  Epoch 518: Validation loss did not improve. Epochs without improvement: 43
Epoch 518: Stepping scheduler...
--- Epoch 518 completed in 0.65 seconds ---

--- Starting Epoch 519/1000 ---
Epoch 519: Starting training phase (4 batches)
  Epoch 519, Batch 1/4: Loading data to device...
  Epoch 519, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 519, Batch 1/4: Zeroing gradients...
  Epoch 519, Batch 1/4: Forward pass...
  Epoch 519, Batch 1/4: Calculating loss...
  Epoch 519, Batch 1/4: Backward pass...
  Epoch 519, Batch 1/4: Clipping gradients...
  Epoch 519, Batch 1/4: Optimizer step...
  Epoch 519, Batch 1/4: Completed in 0.19s
  Epoch 519, Batch 2/4: Loading data to device...
  Epoch 519, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 519, Batch 2/4: Zeroing gradients...
  Epoch 519, Batch 2/4: Forward pass...
  Epoch 519, Batch 2/4: Calculating loss...
  Epoch 519, Batch 2/4: Backward pass...
  Epoch 519, Batch 2/4: Clipping gradients...
  Epoch 519, Batch 2/4: Optimizer step...
  Epoch 519, Batch 2/4: Completed in 0.20s
  Epoch 519, Batch 3/4: Loading data to device...
  Epoch 519, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 519, Batch 3/4: Zeroing gradients...
  Epoch 519, Batch 3/4: Forward pass...
  Epoch 519, Batch 3/4: Calculating loss...
  Epoch 519, Batch 3/4: Backward pass...
  Epoch 519, Batch 3/4: Clipping gradients...
  Epoch 519, Batch 3/4: Optimizer step...
  Epoch 519, Batch 3/4: Completed in 0.19s
  Epoch 519, Batch 4/4: Loading data to device...
  Epoch 519, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 519, Batch 4/4: Zeroing gradients...
  Epoch 519, Batch 4/4: Forward pass...
  Epoch 519, Batch 4/4: Calculating loss...
  Epoch 519, Batch 4/4: Backward pass...
  Epoch 519, Batch 4/4: Clipping gradients...
  Epoch 519, Batch 4/4: Optimizer step...
  Epoch 519, Batch 4/4: Completed in 0.03s
Epoch 519: Training phase completed. Average Train Loss: 0.3131
Epoch 519: Starting validation phase...
  Epoch 519, Val Batch 1/1: Loading data...
  Epoch 519, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 519, Val Batch 1/1: Forward pass...
  Epoch 519, Val Batch 1/1: Calculating loss...
Epoch 519: Validation phase completed. Average Val Loss: 0.2246
Epoch 519 Summary ---> Train Loss: 0.3131 / Validation Loss: 0.2246
Epoch 519: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 43)
  Epoch 519: Validation loss did not improve. Epochs without improvement: 44
Epoch 519: Stepping scheduler...
--- Epoch 519 completed in 0.67 seconds ---

--- Starting Epoch 520/1000 ---
Epoch 520: Starting training phase (4 batches)
  Epoch 520, Batch 1/4: Loading data to device...
  Epoch 520, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 520, Batch 1/4: Zeroing gradients...
  Epoch 520, Batch 1/4: Forward pass...
  Epoch 520, Batch 1/4: Calculating loss...
  Epoch 520, Batch 1/4: Backward pass...
  Epoch 520, Batch 1/4: Clipping gradients...
  Epoch 520, Batch 1/4: Optimizer step...
  Epoch 520, Batch 1/4: Completed in 0.19s
  Epoch 520, Batch 2/4: Loading data to device...
  Epoch 520, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 520, Batch 2/4: Zeroing gradients...
  Epoch 520, Batch 2/4: Forward pass...
  Epoch 520, Batch 2/4: Calculating loss...
  Epoch 520, Batch 2/4: Backward pass...
  Epoch 520, Batch 2/4: Clipping gradients...
  Epoch 520, Batch 2/4: Optimizer step...
  Epoch 520, Batch 2/4: Completed in 0.19s
  Epoch 520, Batch 3/4: Loading data to device...
  Epoch 520, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 520, Batch 3/4: Zeroing gradients...
  Epoch 520, Batch 3/4: Forward pass...
  Epoch 520, Batch 3/4: Calculating loss...
  Epoch 520, Batch 3/4: Backward pass...
  Epoch 520, Batch 3/4: Clipping gradients...
  Epoch 520, Batch 3/4: Optimizer step...
  Epoch 520, Batch 3/4: Completed in 0.20s
  Epoch 520, Batch 4/4: Loading data to device...
  Epoch 520, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 520, Batch 4/4: Zeroing gradients...
  Epoch 520, Batch 4/4: Forward pass...
  Epoch 520, Batch 4/4: Calculating loss...
  Epoch 520, Batch 4/4: Backward pass...
  Epoch 520, Batch 4/4: Clipping gradients...
  Epoch 520, Batch 4/4: Optimizer step...
  Epoch 520, Batch 4/4: Completed in 0.03s
Epoch 520: Training phase completed. Average Train Loss: 0.3290
Epoch 520: Starting validation phase...
  Epoch 520, Val Batch 1/1: Loading data...
  Epoch 520, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 520, Val Batch 1/1: Forward pass...
  Epoch 520, Val Batch 1/1: Calculating loss...
Epoch 520: Validation phase completed. Average Val Loss: 0.2241
Epoch 520 Summary ---> Train Loss: 0.3290 / Validation Loss: 0.2241
Epoch 520: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 44)
  Epoch 520: Validation loss did not improve. Epochs without improvement: 45
Epoch 520: Stepping scheduler...
--- Epoch 520 completed in 0.67 seconds ---

--- Starting Epoch 521/1000 ---
Epoch 521: Starting training phase (4 batches)
  Epoch 521, Batch 1/4: Loading data to device...
  Epoch 521, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 521, Batch 1/4: Zeroing gradients...
  Epoch 521, Batch 1/4: Forward pass...
  Epoch 521, Batch 1/4: Calculating loss...
  Epoch 521, Batch 1/4: Backward pass...
  Epoch 521, Batch 1/4: Clipping gradients...
  Epoch 521, Batch 1/4: Optimizer step...
  Epoch 521, Batch 1/4: Completed in 0.19s
  Epoch 521, Batch 2/4: Loading data to device...
  Epoch 521, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 521, Batch 2/4: Zeroing gradients...
  Epoch 521, Batch 2/4: Forward pass...
  Epoch 521, Batch 2/4: Calculating loss...
  Epoch 521, Batch 2/4: Backward pass...
  Epoch 521, Batch 2/4: Clipping gradients...
  Epoch 521, Batch 2/4: Optimizer step...
  Epoch 521, Batch 2/4: Completed in 0.19s
  Epoch 521, Batch 3/4: Loading data to device...
  Epoch 521, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 521, Batch 3/4: Zeroing gradients...
  Epoch 521, Batch 3/4: Forward pass...
  Epoch 521, Batch 3/4: Calculating loss...
  Epoch 521, Batch 3/4: Backward pass...
  Epoch 521, Batch 3/4: Clipping gradients...
  Epoch 521, Batch 3/4: Optimizer step...
  Epoch 521, Batch 3/4: Completed in 0.18s
  Epoch 521, Batch 4/4: Loading data to device...
  Epoch 521, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 521, Batch 4/4: Zeroing gradients...
  Epoch 521, Batch 4/4: Forward pass...
  Epoch 521, Batch 4/4: Calculating loss...
  Epoch 521, Batch 4/4: Backward pass...
  Epoch 521, Batch 4/4: Clipping gradients...
  Epoch 521, Batch 4/4: Optimizer step...
  Epoch 521, Batch 4/4: Completed in 0.03s
Epoch 521: Training phase completed. Average Train Loss: 0.2781
Epoch 521: Starting validation phase...
  Epoch 521, Val Batch 1/1: Loading data...
  Epoch 521, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 521, Val Batch 1/1: Forward pass...
  Epoch 521, Val Batch 1/1: Calculating loss...
Epoch 521: Validation phase completed. Average Val Loss: 0.2211
Epoch 521 Summary ---> Train Loss: 0.2781 / Validation Loss: 0.2211
Epoch 521: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 45)
  Epoch 521: Validation loss did not improve. Epochs without improvement: 46
Epoch 521: Stepping scheduler...
--- Epoch 521 completed in 0.65 seconds ---

--- Starting Epoch 522/1000 ---
Epoch 522: Starting training phase (4 batches)
  Epoch 522, Batch 1/4: Loading data to device...
  Epoch 522, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 522, Batch 1/4: Zeroing gradients...
  Epoch 522, Batch 1/4: Forward pass...
  Epoch 522, Batch 1/4: Calculating loss...
  Epoch 522, Batch 1/4: Backward pass...
  Epoch 522, Batch 1/4: Clipping gradients...
  Epoch 522, Batch 1/4: Optimizer step...
  Epoch 522, Batch 1/4: Completed in 0.18s
  Epoch 522, Batch 2/4: Loading data to device...
  Epoch 522, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 522, Batch 2/4: Zeroing gradients...
  Epoch 522, Batch 2/4: Forward pass...
  Epoch 522, Batch 2/4: Calculating loss...
  Epoch 522, Batch 2/4: Backward pass...
  Epoch 522, Batch 2/4: Clipping gradients...
  Epoch 522, Batch 2/4: Optimizer step...
  Epoch 522, Batch 2/4: Completed in 0.19s
  Epoch 522, Batch 3/4: Loading data to device...
  Epoch 522, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 522, Batch 3/4: Zeroing gradients...
  Epoch 522, Batch 3/4: Forward pass...
  Epoch 522, Batch 3/4: Calculating loss...
  Epoch 522, Batch 3/4: Backward pass...
  Epoch 522, Batch 3/4: Clipping gradients...
  Epoch 522, Batch 3/4: Optimizer step...
  Epoch 522, Batch 3/4: Completed in 0.19s
  Epoch 522, Batch 4/4: Loading data to device...
  Epoch 522, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 522, Batch 4/4: Zeroing gradients...
  Epoch 522, Batch 4/4: Forward pass...
  Epoch 522, Batch 4/4: Calculating loss...
  Epoch 522, Batch 4/4: Backward pass...
  Epoch 522, Batch 4/4: Clipping gradients...
  Epoch 522, Batch 4/4: Optimizer step...
  Epoch 522, Batch 4/4: Completed in 0.03s
Epoch 522: Training phase completed. Average Train Loss: 0.3070
Epoch 522: Starting validation phase...
  Epoch 522, Val Batch 1/1: Loading data...
  Epoch 522, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 522, Val Batch 1/1: Forward pass...
  Epoch 522, Val Batch 1/1: Calculating loss...
Epoch 522: Validation phase completed. Average Val Loss: 0.2209
Epoch 522 Summary ---> Train Loss: 0.3070 / Validation Loss: 0.2209
Epoch 522: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 46)
  Epoch 522: Validation loss did not improve. Epochs without improvement: 47
Epoch 522: Stepping scheduler...
--- Epoch 522 completed in 0.66 seconds ---

--- Starting Epoch 523/1000 ---
Epoch 523: Starting training phase (4 batches)
  Epoch 523, Batch 1/4: Loading data to device...
  Epoch 523, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 523, Batch 1/4: Zeroing gradients...
  Epoch 523, Batch 1/4: Forward pass...
  Epoch 523, Batch 1/4: Calculating loss...
  Epoch 523, Batch 1/4: Backward pass...
  Epoch 523, Batch 1/4: Clipping gradients...
  Epoch 523, Batch 1/4: Optimizer step...
  Epoch 523, Batch 1/4: Completed in 0.19s
  Epoch 523, Batch 2/4: Loading data to device...
  Epoch 523, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 523, Batch 2/4: Zeroing gradients...
  Epoch 523, Batch 2/4: Forward pass...
  Epoch 523, Batch 2/4: Calculating loss...
  Epoch 523, Batch 2/4: Backward pass...
  Epoch 523, Batch 2/4: Clipping gradients...
  Epoch 523, Batch 2/4: Optimizer step...
  Epoch 523, Batch 2/4: Completed in 0.19s
  Epoch 523, Batch 3/4: Loading data to device...
  Epoch 523, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 523, Batch 3/4: Zeroing gradients...
  Epoch 523, Batch 3/4: Forward pass...
  Epoch 523, Batch 3/4: Calculating loss...
  Epoch 523, Batch 3/4: Backward pass...
  Epoch 523, Batch 3/4: Clipping gradients...
  Epoch 523, Batch 3/4: Optimizer step...
  Epoch 523, Batch 3/4: Completed in 0.19s
  Epoch 523, Batch 4/4: Loading data to device...
  Epoch 523, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 523, Batch 4/4: Zeroing gradients...
  Epoch 523, Batch 4/4: Forward pass...
  Epoch 523, Batch 4/4: Calculating loss...
  Epoch 523, Batch 4/4: Backward pass...
  Epoch 523, Batch 4/4: Clipping gradients...
  Epoch 523, Batch 4/4: Optimizer step...
  Epoch 523, Batch 4/4: Completed in 0.03s
Epoch 523: Training phase completed. Average Train Loss: 0.3393
Epoch 523: Starting validation phase...
  Epoch 523, Val Batch 1/1: Loading data...
  Epoch 523, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 523, Val Batch 1/1: Forward pass...
  Epoch 523, Val Batch 1/1: Calculating loss...
Epoch 523: Validation phase completed. Average Val Loss: 0.2222
Epoch 523 Summary ---> Train Loss: 0.3393 / Validation Loss: 0.2222
Epoch 523: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 47)
  Epoch 523: Validation loss did not improve. Epochs without improvement: 48
Epoch 523: Stepping scheduler...
--- Epoch 523 completed in 0.66 seconds ---

--- Starting Epoch 524/1000 ---
Epoch 524: Starting training phase (4 batches)
  Epoch 524, Batch 1/4: Loading data to device...
  Epoch 524, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 524, Batch 1/4: Zeroing gradients...
  Epoch 524, Batch 1/4: Forward pass...
  Epoch 524, Batch 1/4: Calculating loss...
  Epoch 524, Batch 1/4: Backward pass...
  Epoch 524, Batch 1/4: Clipping gradients...
  Epoch 524, Batch 1/4: Optimizer step...
  Epoch 524, Batch 1/4: Completed in 0.19s
  Epoch 524, Batch 2/4: Loading data to device...
  Epoch 524, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 524, Batch 2/4: Zeroing gradients...
  Epoch 524, Batch 2/4: Forward pass...
  Epoch 524, Batch 2/4: Calculating loss...
  Epoch 524, Batch 2/4: Backward pass...
  Epoch 524, Batch 2/4: Clipping gradients...
  Epoch 524, Batch 2/4: Optimizer step...
  Epoch 524, Batch 2/4: Completed in 0.20s
  Epoch 524, Batch 3/4: Loading data to device...
  Epoch 524, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 524, Batch 3/4: Zeroing gradients...
  Epoch 524, Batch 3/4: Forward pass...
  Epoch 524, Batch 3/4: Calculating loss...
  Epoch 524, Batch 3/4: Backward pass...
  Epoch 524, Batch 3/4: Clipping gradients...
  Epoch 524, Batch 3/4: Optimizer step...
  Epoch 524, Batch 3/4: Completed in 0.19s
  Epoch 524, Batch 4/4: Loading data to device...
  Epoch 524, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 524, Batch 4/4: Zeroing gradients...
  Epoch 524, Batch 4/4: Forward pass...
  Epoch 524, Batch 4/4: Calculating loss...
  Epoch 524, Batch 4/4: Backward pass...
  Epoch 524, Batch 4/4: Clipping gradients...
  Epoch 524, Batch 4/4: Optimizer step...
  Epoch 524, Batch 4/4: Completed in 0.03s
Epoch 524: Training phase completed. Average Train Loss: 0.2722
Epoch 524: Starting validation phase...
  Epoch 524, Val Batch 1/1: Loading data...
  Epoch 524, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 524, Val Batch 1/1: Forward pass...
  Epoch 524, Val Batch 1/1: Calculating loss...
Epoch 524: Validation phase completed. Average Val Loss: 0.2238
Epoch 524 Summary ---> Train Loss: 0.2722 / Validation Loss: 0.2238
Epoch 524: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 48)
  Epoch 524: Validation loss did not improve. Epochs without improvement: 49
Epoch 524: Stepping scheduler...
--- Epoch 524 completed in 0.67 seconds ---

--- Starting Epoch 525/1000 ---
Epoch 525: Starting training phase (4 batches)
  Epoch 525, Batch 1/4: Loading data to device...
  Epoch 525, Batch 1/4: Relabeling nodes (skipped)... 
  Epoch 525, Batch 1/4: Zeroing gradients...
  Epoch 525, Batch 1/4: Forward pass...
  Epoch 525, Batch 1/4: Calculating loss...
  Epoch 525, Batch 1/4: Backward pass...
  Epoch 525, Batch 1/4: Clipping gradients...
  Epoch 525, Batch 1/4: Optimizer step...
  Epoch 525, Batch 1/4: Completed in 0.19s
  Epoch 525, Batch 2/4: Loading data to device...
  Epoch 525, Batch 2/4: Relabeling nodes (skipped)... 
  Epoch 525, Batch 2/4: Zeroing gradients...
  Epoch 525, Batch 2/4: Forward pass...
  Epoch 525, Batch 2/4: Calculating loss...
  Epoch 525, Batch 2/4: Backward pass...
  Epoch 525, Batch 2/4: Clipping gradients...
  Epoch 525, Batch 2/4: Optimizer step...
  Epoch 525, Batch 2/4: Completed in 0.19s
  Epoch 525, Batch 3/4: Loading data to device...
  Epoch 525, Batch 3/4: Relabeling nodes (skipped)... 
  Epoch 525, Batch 3/4: Zeroing gradients...
  Epoch 525, Batch 3/4: Forward pass...
  Epoch 525, Batch 3/4: Calculating loss...
  Epoch 525, Batch 3/4: Backward pass...
  Epoch 525, Batch 3/4: Clipping gradients...
  Epoch 525, Batch 3/4: Optimizer step...
  Epoch 525, Batch 3/4: Completed in 0.19s
  Epoch 525, Batch 4/4: Loading data to device...
  Epoch 525, Batch 4/4: Relabeling nodes (skipped)... 
  Epoch 525, Batch 4/4: Zeroing gradients...
  Epoch 525, Batch 4/4: Forward pass...
  Epoch 525, Batch 4/4: Calculating loss...
  Epoch 525, Batch 4/4: Backward pass...
  Epoch 525, Batch 4/4: Clipping gradients...
  Epoch 525, Batch 4/4: Optimizer step...
  Epoch 525, Batch 4/4: Completed in 0.03s
Epoch 525: Training phase completed. Average Train Loss: 0.2992
Epoch 525: Starting validation phase...
  Epoch 525, Val Batch 1/1: Loading data...
  Epoch 525, Val Batch 1/1: Relabeling nodes (skipped)...
  Epoch 525, Val Batch 1/1: Forward pass...
  Epoch 525, Val Batch 1/1: Calculating loss...
Epoch 525: Validation phase completed. Average Val Loss: 0.2241
Epoch 525 Summary ---> Train Loss: 0.2992 / Validation Loss: 0.2241
Epoch 525: Checking early stopping... (Current Best Loss: 0.2202, Epochs No Improve: 49)
  Epoch 525: Validation loss did not improve. Epochs without improvement: 50

Early stopping triggered after 525 epochs!
DEBUG: Training loop completed
DEBUG: Progress updated: Calculating metrics...
DEBUG: Starting metrics calculation
DEBUG: Collected 45 labels and 45 probabilities
DEBUG: Plotting learning curve
DEBUG: Saved learning curve to /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/GNN_learning_curve.png

Probabilities: [np.float32(0.8372526), np.float32(0.54625005), np.float32(0.8426803), np.float32(0.8363751), np.float32(0.07767699), np.float32(0.12611939), np.float32(0.0921709), np.float32(0.09247746), np.float32(0.886043), np.float32(0.876489), np.float32(0.13298565), np.float32(0.54020256), np.float32(0.098376386), np.float32(0.6988614), np.float32(0.9181854), np.float32(0.07778561), np.float32(0.09577611), np.float32(0.15256794), np.float32(0.14364246), np.float32(0.8956886), np.float32(0.71006304), np.float32(0.11954875), np.float32(0.115760155), np.float32(0.08333726), np.float32(0.19770633), np.float32(0.17525166), np.float32(0.14347327), np.float32(0.17966688), np.float32(0.8065736), np.float32(0.12706187), np.float32(0.08267102), np.float32(0.922513), np.float32(0.9196303), np.float32(0.88648796), np.float32(0.8771143), np.float32(0.16427347), np.float32(0.10726505), np.float32(0.15952276), np.float32(0.86555326), np.float32(0.8585982), np.float32(0.10778398), np.float32(0.29302472), np.float32(0.85989344), np.float32(0.81007063), np.float32(0.7364837)]

Labels: [np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0)]
DEBUG: Finding optimal threshold
Optimal Classification Threshold (Highest): 0.54

DEBUG: Generating probability plots
DEBUG: Saved probability plots to /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/probability_plots.png
DEBUG: Calculating metrics
Using >= Highest Optimal Threshold, the results are:

Total: 45
TP: 20, FP: 1, TN: 24, FN: 0

Metrics saved to /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/metrics.csv
           Metric    Value
        Precision 0.952381
           Recall 1.000000
              FPR 0.040000
         F1 Score 0.952381
          ROC AUC 0.992000
          PRC AUC 0.989710
              MCC 0.956183
Optimal Threshold 0.540000
DEBUG: Generating ROC curve
DEBUG: Saved ROC curve to /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/roc_curve.png
DEBUG: Generating PRC curve
DEBUG: Saved PRC curve to /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/prc_curve.png
DEBUG: Saving model parameters

Model parameters saved.
DEBUG: Extracting fingerprints
DEBUG: Extracted 45 fingerprints
DEBUG: Saved fingerprints to /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/test_fingerprints.csv
DEBUG: Results saved to /home/muhammadwaqas/stablyzegraph_installer_updated/src/Tutorial/Benchmarking/results.json
DEBUG: Benchmarking pipeline completed successfully
DEBUG: run_benchmarking_pipeline function finished.
DEBUG: Progress updated: Benchmarking completed successfully.
DEBUG: Main script execution finished.

