DEBUG: Script execution started
DEBUG: Imported gc
DEBUG: Imported os
DEBUG: Imported numpy
DEBUG: Imported pandas
DEBUG: Imported torch
DEBUG: Imported BatchNorm1d
DEBUG: Imported torch.nn.functional
Error importing huggingface_hub.hf_api: No module named 'yaml'
DEBUG: Imported torch_geometric.data
DEBUG: Imported torch_geometric.loader
DEBUG: Imported torch_geometric.nn
DEBUG: Imported Bio.SeqIO
DEBUG: Imported Bio.AlignIO
DEBUG: Imported Bio.Align.AlignInfo
DEBUG: Imported Bio.PDB.PDBParser
DEBUG: Imported sklearn.preprocessing
DEBUG: Imported sklearn.svm
DEBUG: Imported sklearn.ensemble
DEBUG: Imported sklearn.linear_model
DEBUG: Imported sklearn.model_selection
DEBUG: Imported sklearn.metrics
DEBUG: Imported imblearn.over_sampling
DEBUG: Imported random
DEBUG: Imported subprocess
DEBUG: Imported logging
DEBUG: Imported joblib
DEBUG: Imported warnings
DEBUG: Imported matplotlib
DEBUG: Imported matplotlib.pyplot
DEBUG: Imported seaborn
DEBUG: Imported argparse
DEBUG: Imported json
DEBUG: Imported time
DEBUG: Imported Bio.Seq
DEBUG: Imported optuna
DEBUG: Script started - imports completed
DEBUG: Setting matplotlib backend
DEBUG: Matplotlib backend set
DEBUG: Setting up logging
DEBUG: Logging setup complete, warnings ignored
DEBUG: Setting random seeds
DEBUG: CPU seeds set
DEBUG: Checking for CUDA device
DEBUG: Using device: cpu
DEBUG: Defining model class
DEBUG: Defining helper functions
DEBUG: Defining main pipeline function
DEBUG: Defining Optuna objective function
DEBUG: Starting main script execution (__name__ == '__main__')
DEBUG: Parsing arguments
DEBUG: Arguments parsed: active_file=GPCR_Active_labeled.csv, inactive_file=GPCR_Inactive_labeled.csv
DEBUG: Optuna tuning enabled: False, n_trials=10
DEBUG: Setting up environment based on args
DEBUG: Using device: cpu
DEBUG: Creating output directory: 14102025_test
DEBUG: Progress updated: Initializing...
DEBUG: Progress updated: Starting benchmarking pipeline...
DEBUG: Calling run_benchmarking_pipeline function...
DEBUG: Starting benchmarking pipeline with active_file=GPCR_Active_labeled.csv, inactive_file=GPCR_Inactive_labeled.csv
DEBUG: Parameters - hidden_dim=128, dropout_rate=0.2, learning_rate=1e-05, l2_regularization=0.0001
DEBUG: Output directory: 14102025_test
DEBUG: Progress updated: Preparing data...
DEBUG: SEED: 42, DEVICE: cpu
DEBUG: Reading active sequences
DEBUG: Reading sequence file GPCR_Active_labeled.csv, is_active=True
DEBUG: Read 66 sequences
DEBUG: Reading inactive sequences
DEBUG: Reading sequence file GPCR_Inactive_labeled.csv, is_active=False
DEBUG: Read 74 sequences
DEBUG: Reading wild type sequence
DEBUG: Reading FASTA file wild_type.fasta
DEBUG: Read 1 wild type sequences
DEBUG: Progress updated: Extracting coordinates...
DEBUG: Extracting coordinates for active sequences
DEBUG: Extracted coordinates for 66 active sequences
DEBUG: Extracting coordinates for inactive sequences
DEBUG: Extracted coordinates for 74 inactive sequences
DEBUG: Progress updated: Loading features...
DEBUG: Loading property dictionaries
DEBUG: Loading dictionaries from amino_acid_properties.csv
DEBUG: Loaded 4 dictionaries
DEBUG: Writing combined sequences to combined_sequences.fasta
DEBUG: Writing active sequences to active_sequences.fasta
DEBUG: Writing inactive sequences to inactive_sequences.fasta
DEBUG: Progress updated: Calculating conservation scores...
DEBUG: Calculating conservation scores for active sequences
DEBUG: Calculating conservation scores from active_sequences.fasta
DEBUG: Running Clustal Omega
DEBUG: Clustal Omega completed successfully
DEBUG: Reading alignment file aligned_sequences.aln
DEBUG: Alignment read successfully, length: 254
DEBUG: Consensus sequence calculated, length: 254
DEBUG: Calculated 254 conservation scores
DEBUG: Progress updated: Generating graphs...
DEBUG: Converting active sequences to graphs
DEBUG: Converting active sequence 10/66 to graph
DEBUG: Converting active sequence 20/66 to graph
DEBUG: Converting active sequence 30/66 to graph
DEBUG: Converting active sequence 40/66 to graph
DEBUG: Converting active sequence 50/66 to graph
DEBUG: Converting active sequence 60/66 to graph
DEBUG: Converting active sequence 66/66 to graph
DEBUG: Converted 66 active sequences to graphs
DEBUG: Calculating conservation scores for inactive sequences
DEBUG: Calculating conservation scores from inactive_sequences.fasta
DEBUG: Running Clustal Omega
DEBUG: Clustal Omega completed successfully
DEBUG: Reading alignment file aligned_sequences.aln
DEBUG: Alignment read successfully, length: 254
DEBUG: Consensus sequence calculated, length: 254
DEBUG: Calculated 254 conservation scores
DEBUG: Converting inactive sequences to graphs
DEBUG: Converting inactive sequence 10/74 to graph
DEBUG: Converting inactive sequence 20/74 to graph
DEBUG: Converting inactive sequence 30/74 to graph
DEBUG: Converting inactive sequence 40/74 to graph
DEBUG: Converting inactive sequence 50/74 to graph
DEBUG: Converting inactive sequence 60/74 to graph
DEBUG: Converting inactive sequence 70/74 to graph
DEBUG: Converting inactive sequence 74/74 to graph
DEBUG: Converted 74 inactive sequences to graphs
DEBUG: Combined 140 features with 140 labels
DEBUG: Progress updated: Splitting data...
DEBUG: Input dimension: 5
DEBUG: Calculating class weights
DEBUG: Class weights - positive: 66, negative: 74, pos_weight: 1.121212124824524
DEBUG: Setting up K-fold cross-validation with n_splits=5, n_repeats=1
DEBUG: ========== Starting Fold 1/5 ==========
DEBUG: Fold output directory: 14102025_test/fold_1
DEBUG: Splitting data for fold 1
DEBUG: Fold 1 - train size: 112, test size: 28
DEBUG: Initializing model for fold 1
DEBUG: Initializing model with in_features=5, hidden_features=128
DEBUG: Model layers initialized
DEBUG: Model, optimizer, scheduler, and criterion initialized for fold 1
DEBUG: Resampling minority class for fold 1
DEBUG: Minority class count: 52
DEBUG: Using SMOTE with k_neighbors=10
DEBUG: Resampled to 120 samples
DEBUG: Created datasets for fold 1: train=120, test=28
DEBUG: Creating DataLoaders for fold 1
DEBUG: DataLoaders created for fold 1
DEBUG: Starting training loop for fold 1
DEBUG: Saved best model for fold 1 at epoch 1
DEBUG: Saved best model for fold 1 at epoch 16
DEBUG: Saved best model for fold 1 at epoch 20
DEBUG: Saved best model for fold 1 at epoch 30
DEBUG: Saved best model for fold 1 at epoch 41
DEBUG: Fold 1, Epoch 50/1000, Train Loss: 0.7135, Test Loss: 0.7475, Test ROC AUC: 0.4082
DEBUG: Saved best model for fold 1 at epoch 56
DEBUG: Fold 1, Epoch 100/1000, Train Loss: 0.6267, Test Loss: 0.9521, Test ROC AUC: 0.6173
DEBUG: Early stopping triggered for fold 1 at epoch 106
DEBUG: Loading best model for fold 1
DEBUG: Calculating metrics for fold 1
DEBUG: Optimal threshold for fold 1: 0.48197293281555176
DEBUG: Fold 1 metrics - Precision: 0.7500, Recall: 0.6429, FPR: 0.2143, F1: 0.6923, ROC AUC: 0.7551, PRC AUC: 0.7793, MCC: 0.4330
DEBUG: Generating plots for fold 1
DEBUG: Saved learning curve for fold 1
DEBUG: Saved probability plots for fold 1
DEBUG: Saved ROC curve for fold 1
DEBUG: Saved PRC curve for fold 1
DEBUG: Saved metrics for fold 1
DEBUG: ========== Completed Fold 1/5 ==========
DEBUG: ========== Starting Fold 2/5 ==========
DEBUG: Fold output directory: 14102025_test/fold_2
DEBUG: Splitting data for fold 2
DEBUG: Fold 2 - train size: 112, test size: 28
DEBUG: Initializing model for fold 2
DEBUG: Initializing model with in_features=5, hidden_features=128
DEBUG: Model layers initialized
DEBUG: Model, optimizer, scheduler, and criterion initialized for fold 2
DEBUG: Resampling minority class for fold 2
DEBUG: Minority class count: 53
DEBUG: Using SMOTE with k_neighbors=10
DEBUG: Resampled to 118 samples
DEBUG: Created datasets for fold 2: train=118, test=28
DEBUG: Creating DataLoaders for fold 2
DEBUG: DataLoaders created for fold 2
DEBUG: Starting training loop for fold 2
DEBUG: Saved best model for fold 2 at epoch 1
DEBUG: Saved best model for fold 2 at epoch 2
DEBUG: Saved best model for fold 2 at epoch 11
DEBUG: Saved best model for fold 2 at epoch 12
DEBUG: Saved best model for fold 2 at epoch 26
DEBUG: Saved best model for fold 2 at epoch 39
DEBUG: Saved best model for fold 2 at epoch 40
DEBUG: Fold 2, Epoch 50/1000, Train Loss: 0.6627, Test Loss: 0.7340, Test ROC AUC: 0.5333
DEBUG: Early stopping triggered for fold 2 at epoch 90
DEBUG: Loading best model for fold 2
DEBUG: Calculating metrics for fold 2
DEBUG: Optimal threshold for fold 2: 0.49070385098457336
DEBUG: Fold 2 metrics - Precision: 0.8333, Recall: 0.7692, FPR: 0.1333, F1: 0.8000, ROC AUC: 0.8205, PRC AUC: 0.7595, MCC: 0.6408
DEBUG: Generating plots for fold 2
DEBUG: Saved learning curve for fold 2
DEBUG: Saved probability plots for fold 2
DEBUG: Saved ROC curve for fold 2
DEBUG: Saved PRC curve for fold 2
DEBUG: Saved metrics for fold 2
DEBUG: ========== Completed Fold 2/5 ==========
DEBUG: ========== Starting Fold 3/5 ==========
DEBUG: Fold output directory: 14102025_test/fold_3
DEBUG: Splitting data for fold 3
DEBUG: Fold 3 - train size: 112, test size: 28
DEBUG: Initializing model for fold 3
DEBUG: Initializing model with in_features=5, hidden_features=128
DEBUG: Model layers initialized
DEBUG: Model, optimizer, scheduler, and criterion initialized for fold 3
DEBUG: Resampling minority class for fold 3
DEBUG: Minority class count: 53
DEBUG: Using SMOTE with k_neighbors=10
DEBUG: Resampled to 118 samples
DEBUG: Created datasets for fold 3: train=118, test=28
DEBUG: Creating DataLoaders for fold 3
DEBUG: DataLoaders created for fold 3
DEBUG: Starting training loop for fold 3
DEBUG: Saved best model for fold 3 at epoch 1
DEBUG: Saved best model for fold 3 at epoch 2
DEBUG: Saved best model for fold 3 at epoch 3
DEBUG: Saved best model for fold 3 at epoch 4
DEBUG: Saved best model for fold 3 at epoch 5
DEBUG: Saved best model for fold 3 at epoch 28
DEBUG: Saved best model for fold 3 at epoch 29
DEBUG: Saved best model for fold 3 at epoch 30
DEBUG: Saved best model for fold 3 at epoch 39
DEBUG: Saved best model for fold 3 at epoch 40
DEBUG: Saved best model for fold 3 at epoch 49
DEBUG: Fold 3, Epoch 50/1000, Train Loss: 0.6629, Test Loss: 0.7395, Test ROC AUC: 0.5436
DEBUG: Saved best model for fold 3 at epoch 50
DEBUG: Saved best model for fold 3 at epoch 51
DEBUG: Saved best model for fold 3 at epoch 52
DEBUG: Saved best model for fold 3 at epoch 53
DEBUG: Fold 3, Epoch 100/1000, Train Loss: 0.5946, Test Loss: 0.8150, Test ROC AUC: 0.5436
DEBUG: Early stopping triggered for fold 3 at epoch 103
DEBUG: Loading best model for fold 3
DEBUG: Calculating metrics for fold 3
DEBUG: Optimal threshold for fold 3: 0.4557185471057892
DEBUG: Fold 3 metrics - Precision: 0.7778, Recall: 0.5385, FPR: 0.1333, F1: 0.6364, ROC AUC: 0.7231, PRC AUC: 0.7205, MCC: 0.4326
DEBUG: Generating plots for fold 3
DEBUG: Saved learning curve for fold 3
DEBUG: Saved probability plots for fold 3
DEBUG: Saved ROC curve for fold 3
DEBUG: Saved PRC curve for fold 3
DEBUG: Saved metrics for fold 3
DEBUG: ========== Completed Fold 3/5 ==========
DEBUG: ========== Starting Fold 4/5 ==========
DEBUG: Fold output directory: 14102025_test/fold_4
DEBUG: Splitting data for fold 4
DEBUG: Fold 4 - train size: 112, test size: 28
DEBUG: Initializing model for fold 4
DEBUG: Initializing model with in_features=5, hidden_features=128
DEBUG: Model layers initialized
DEBUG: Model, optimizer, scheduler, and criterion initialized for fold 4
DEBUG: Resampling minority class for fold 4
DEBUG: Minority class count: 53
DEBUG: Using SMOTE with k_neighbors=10
DEBUG: Resampled to 118 samples
DEBUG: Created datasets for fold 4: train=118, test=28
DEBUG: Creating DataLoaders for fold 4
DEBUG: DataLoaders created for fold 4
DEBUG: Starting training loop for fold 4
DEBUG: Saved best model for fold 4 at epoch 1
DEBUG: Saved best model for fold 4 at epoch 2
DEBUG: Saved best model for fold 4 at epoch 3
DEBUG: Saved best model for fold 4 at epoch 4
DEBUG: Saved best model for fold 4 at epoch 5
DEBUG: Saved best model for fold 4 at epoch 14
DEBUG: Saved best model for fold 4 at epoch 15
DEBUG: Fold 4, Epoch 50/1000, Train Loss: 0.6133, Test Loss: 0.8344, Test ROC AUC: 0.8000
DEBUG: Saved best model for fold 4 at epoch 63
DEBUG: Saved best model for fold 4 at epoch 64
DEBUG: Saved best model for fold 4 at epoch 65
DEBUG: Saved best model for fold 4 at epoch 66
DEBUG: Saved best model for fold 4 at epoch 67
DEBUG: Saved best model for fold 4 at epoch 88
DEBUG: Saved best model for fold 4 at epoch 89
DEBUG: Saved best model for fold 4 at epoch 90
DEBUG: Saved best model for fold 4 at epoch 91
DEBUG: Saved best model for fold 4 at epoch 92
DEBUG: Saved best model for fold 4 at epoch 93
DEBUG: Saved best model for fold 4 at epoch 94
DEBUG: Saved best model for fold 4 at epoch 95
DEBUG: Fold 4, Epoch 100/1000, Train Loss: 0.5708, Test Loss: 0.6391, Test ROC AUC: 0.9282
DEBUG: Saved best model for fold 4 at epoch 120
DEBUG: Saved best model for fold 4 at epoch 121
DEBUG: Saved best model for fold 4 at epoch 122
DEBUG: Saved best model for fold 4 at epoch 123
DEBUG: Saved best model for fold 4 at epoch 124
DEBUG: Saved best model for fold 4 at epoch 125
DEBUG: Saved best model for fold 4 at epoch 126
DEBUG: Saved best model for fold 4 at epoch 127
DEBUG: Saved best model for fold 4 at epoch 128
DEBUG: Saved best model for fold 4 at epoch 129
DEBUG: Saved best model for fold 4 at epoch 130
DEBUG: Saved best model for fold 4 at epoch 131
DEBUG: Saved best model for fold 4 at epoch 132
DEBUG: Fold 4, Epoch 150/1000, Train Loss: 0.4815, Test Loss: 0.5856, Test ROC AUC: 0.9333
DEBUG: Saved best model for fold 4 at epoch 181
DEBUG: Saved best model for fold 4 at epoch 182
DEBUG: Saved best model for fold 4 at epoch 183
DEBUG: Saved best model for fold 4 at epoch 184
DEBUG: Saved best model for fold 4 at epoch 185
DEBUG: Saved best model for fold 4 at epoch 186
DEBUG: Saved best model for fold 4 at epoch 187
DEBUG: Saved best model for fold 4 at epoch 188
DEBUG: Saved best model for fold 4 at epoch 189
DEBUG: Saved best model for fold 4 at epoch 190
DEBUG: Saved best model for fold 4 at epoch 191
DEBUG: Saved best model for fold 4 at epoch 192
DEBUG: Saved best model for fold 4 at epoch 193
DEBUG: Saved best model for fold 4 at epoch 194
DEBUG: Saved best model for fold 4 at epoch 195
DEBUG: Saved best model for fold 4 at epoch 196
DEBUG: Saved best model for fold 4 at epoch 198
DEBUG: Saved best model for fold 4 at epoch 199
DEBUG: Fold 4, Epoch 200/1000, Train Loss: 0.4111, Test Loss: 0.4645, Test ROC AUC: 0.9487
DEBUG: Saved best model for fold 4 at epoch 203
DEBUG: Saved best model for fold 4 at epoch 204
DEBUG: Saved best model for fold 4 at epoch 205
DEBUG: Saved best model for fold 4 at epoch 215
DEBUG: Saved best model for fold 4 at epoch 216
DEBUG: Saved best model for fold 4 at epoch 217
DEBUG: Saved best model for fold 4 at epoch 220
DEBUG: Saved best model for fold 4 at epoch 221
DEBUG: Fold 4, Epoch 250/1000, Train Loss: 0.3663, Test Loss: 0.4464, Test ROC AUC: 0.9538
DEBUG: Saved best model for fold 4 at epoch 252
DEBUG: Saved best model for fold 4 at epoch 253
DEBUG: Saved best model for fold 4 at epoch 254
DEBUG: Saved best model for fold 4 at epoch 255
DEBUG: Fold 4, Epoch 300/1000, Train Loss: 0.3147, Test Loss: 0.4337, Test ROC AUC: 1.0000
DEBUG: Early stopping triggered for fold 4 at epoch 305
DEBUG: Loading best model for fold 4
DEBUG: Calculating metrics for fold 4
DEBUG: Optimal threshold for fold 4: 0.438579797744751
DEBUG: Fold 4 metrics - Precision: 0.9231, Recall: 0.9231, FPR: 0.0667, F1: 0.9231, ROC AUC: 0.9538, PRC AUC: 0.9255, MCC: 0.8564
DEBUG: Generating plots for fold 4
DEBUG: Saved learning curve for fold 4
DEBUG: Saved probability plots for fold 4
DEBUG: Saved ROC curve for fold 4
DEBUG: Saved PRC curve for fold 4
DEBUG: Saved metrics for fold 4
DEBUG: ========== Completed Fold 4/5 ==========
DEBUG: ========== Starting Fold 5/5 ==========
DEBUG: Fold output directory: 14102025_test/fold_5
DEBUG: Splitting data for fold 5
DEBUG: Fold 5 - train size: 112, test size: 28
DEBUG: Initializing model for fold 5
DEBUG: Initializing model with in_features=5, hidden_features=128
DEBUG: Model layers initialized
DEBUG: Model, optimizer, scheduler, and criterion initialized for fold 5
DEBUG: Resampling minority class for fold 5
DEBUG: Minority class count: 53
DEBUG: Using SMOTE with k_neighbors=10
DEBUG: Resampled to 118 samples
DEBUG: Created datasets for fold 5: train=118, test=28
DEBUG: Creating DataLoaders for fold 5
DEBUG: DataLoaders created for fold 5
DEBUG: Starting training loop for fold 5
DEBUG: Saved best model for fold 5 at epoch 1
DEBUG: Saved best model for fold 5 at epoch 11
DEBUG: Saved best model for fold 5 at epoch 12
DEBUG: Saved best model for fold 5 at epoch 13
DEBUG: Fold 5, Epoch 50/1000, Train Loss: 0.7022, Test Loss: 0.7713, Test ROC AUC: 0.3385
DEBUG: Early stopping triggered for fold 5 at epoch 63
DEBUG: Loading best model for fold 5
DEBUG: Calculating metrics for fold 5
DEBUG: Optimal threshold for fold 5: 0.5012039542198181
DEBUG: Fold 5 metrics - Precision: 0.8571, Recall: 0.4615, FPR: 0.0667, F1: 0.6000, ROC AUC: 0.7231, PRC AUC: 0.7756, MCC: 0.4548
DEBUG: Generating plots for fold 5
DEBUG: Saved learning curve for fold 5
DEBUG: Saved probability plots for fold 5
DEBUG: Saved ROC curve for fold 5
DEBUG: Saved PRC curve for fold 5
DEBUG: Saved metrics for fold 5
DEBUG: ========== Completed Fold 5/5 ==========
DEBUG: Aggregating metrics across all folds
DEBUG: All fold metrics saved to 14102025_test/all_fold_metrics.csv
DEBUG: Average ROC AUC across all folds: 0.7951
DEBUG: Benchmarking pipeline completed successfully
DEBUG: Successfully created results.json at 14102025_test/results.json
DEBUG_METRIC: Confusion Matrix Values - TP: 6, FP: 1, FN: 7, TN: 14
DEBUG_METRIC: F1 Discrepancy Analysis:
  - Confusion Matrix (TN, FP, FN, TP): 14, 1, 7, 6
  - pos_label=1: P=0.8571, R=0.4615, F1_check=0.6000, Manual_F1=0.6000
  - pos_label=0: P=0.6667, R=0.9333, F1_check=0.7778, Manual_F1=0.7778
  - Correct F1 (Matching P/R manual calc): 0.6000
DEBUG: run_benchmarking_pipeline function finished.
DEBUG: Progress updated: Benchmarking completed successfully.
DEBUG: Main script execution finished.
